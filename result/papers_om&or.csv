index,title,author,journal,volume,number,pages,year,month,keyword,keyword-plus,abstract
1,"The Recoverable Robust Two-Level Network Design Problem","Alvarez-Miranda, Eduardo and Ljubic, Ivana and Raghavan, S. and Toth, Paolo","INFORMS JOURNAL ON COMPUTING","27","1","1-19","2015","WIN","Network Design;Robust Optimization;Mixed-Integer Programming;Branch And Cut","","We consider a network design application that is modeled as the two-level network design problem under uncertainty. In this problem, one of the two available technologies can be installed on each edge and all customers of the network need to be served by at least the lower level (secondary) technology. The decision maker is confronted with uncertainty regarding the set of primary customers, i.e., the set of nodes that need to be served by the higher level (primary) technology. A set of discrete scenarios associated with the possible realizations of primary customers is available. The network is built in two stages. In the first stage the network topology must be determined. One may decide to install the primary technology on some of the edges in the first stage, or one can wait to see which scenario will be realized, in which case, edges with the installed secondary technology may be upgraded, if necessary to primary technology, but at higher recovery cost. The overall goal then is to build a recoverable robust spanning tree in the first stage that serves all customers by at least the lower level technology, and that minimizes the first-stage installation cost plus the worst-case cost needed to upgrade the edges of the selected tree, so that the primary customers of each scenario can be served using the primary technology. We discuss the complexity of the problem, provide mixed-integer programming models, and develop a branch-and-cut algorithm to solve it. Our extensive computational experiments demonstrate the efficacy of our approach."
2,"Statistical Database Auditing Without Query Denial Threat","Lu, Haibing and Vaidya, Jaideep and Atluri, Vijayalakshmi and Li, Yingjiu","INFORMS JOURNAL ON COMPUTING","27","1","20-34","2015","WIN","Statistical Database;Privacy;Auditing;Query Denial;Optimization","","Statistical database auditing is the process of checking aggregate queries that are submitted in a continuous manner, to prevent inference disclosure. Compared to other data protection mechanisms, auditing has the features of flexibility and maximum information. Auditing is typically accomplished by examining responses to past queries to determine whether a new query can be answered. It has been recognized that query denials release information and can cause data disclosure. This paper proposes an auditing mechanism that is free of query denial threat and applicable to mixed types of aggregate queries, including sum, max, min, deviation, etc. The core ideas are (i) deriving the complete information leakage from each query denial and (ii) carrying the complete leaked information derived from past answered and denied queries to audit each new query. The information leakage deriving problem can be formulated as a set of parametric optimization programs, and the whole auditing process can be modeled as a series of convex optimization problems."
3,"Column-Generation Framework of Nonlinear Similarity Model for Reconstructing Sibling Groups","Chou, Chun-An and Liang, Zhe and Chaovalitwongse, Wanpracha Art and Berger-Wolf, Tanya Y. and DasGupta, Bhaskar and Sheikh, Saad and Ashley, Mary V. and Caballero, Isabel C.","INFORMS JOURNAL ON COMPUTING","27","1","35-47","2015","WIN","Column Generation;Branch And Price;Set-Covering Problem;Mixed-Integer Programming;Computational Biology;Sibling Reconstruction","","Establishing family relationships, such as parentage and sibling relationships, is fundamental in biological research, especially in wild species, as they are often important to understanding evolutionary, ecological, and behavioral processes. Because it is commonly impossible to determine familial relationships from field observations alone, the reconstruction of sibling relationships often depends on informative genetic markers coupled with accurate sibling reconstruction algorithms. Most studies in the literature reconstruct sibling relationships using methods that are based on either statistical analyses (i.e., likelihood estimation) or combinatorial concepts (i.e., Mendelian inheritance laws) of genetic data. We present a novel computational framework that integrates both combinatorial concepts and statistical analyses into one sibling reconstruction optimization model. To solve this integrated model, we propose a column-generation approach with a branch-and-price method. Under the assumption of parsimonious reconstruction, the master problem is to find the minimum set of sibling groups to cover the tested population. Pricing subproblems, which include both statistical similarity and combinatorial concepts of genetic data, are iteratively solved to generate high-quality sibling group candidates. Tested on real biological data sets, our approach efficiently provides reconstruction results that are more accurate than those provided by other state-of-the-art reconstruction algorithms."
4,"A Cutting-Plane Neighborhood Structure for Fixed-Charge Capacitated Multicommodity Network Design Problem","Yaghini, Masoud and Karimi, Mohammad and Rahbar, Mohadeseh and Sharifitabar, Mohammad Hassan","INFORMS JOURNAL ON COMPUTING","27","1","48-58","2015","WIN","Fixed-Charge Capacitated Multicommodity Network Design;Cutting-Plane Neighborhood;Tabu Search;Design Of Experiments","","In this paper, a cutting-plane neighborhood structure is proposed for the fixed-charge capacitated multicommodity network design (CMND) problem. In the proposed structure, different strategies are used to select an open arc in the incumbent solution to be closed. Then a linear programming (LP) model is generated on the basis of the modified incumbent solution by relaxing binary variables and adding new constraints. The generated LP solution is improved using different cutting-plane inequalities. Subsequently, a new sub-mixed integer programming (MIP) model is created by fixing a number of variables in the generated LP solution. Then the local branching algorithm is used to solve the sub-MIP model and its solution is considered as a neighboring solution. A tabu search algorithm is used to evaluate the proposed neighborhood structure. To tune the parameters of the tabu search algorithm, we have used the design of experiments method. Standard problems with different sizes are employed to evaluate the proposed tabu search algorithm. Results show the efficiency and effectiveness of the tabu search algorithm compared to the best methods found in the literature."
5,"Algorithmic Approach for Improved Mixed-Integer Reformulations of Convex Generalized Disjunctive Programs","Trespalacios, Francisco and Grossmann, Ignacio E.","INFORMS JOURNAL ON COMPUTING","27","1","59-74","2015","WIN","Generalized Disjunctive Programming;Mixed-Integer Nonlinear Programming","","In this work, we propose an algorithmic approach to improve mixed-integer models that are originally formulated as convex generalized disjunctive programs (GDPs). The algorithm seeks to obtain an improved continuous relaxation of the mixed-integer linear and mixed-integer nonlinear programming (MILP/MINLP) model reformulation of the GDP while limiting the growth in the problem size. There are three main stages that form the basis of the algorithm. The first one is a presolve, consequence of the logic nature of GDP, which allows us to reduce the problem size, find good relaxation bounds, and identify properties that help us determine where to apply a basic step. The second stage is the iterative application of basic steps, selecting where to apply them and monitoring the improvement of the formulation. Finally, we use a hybrid reformulation of GDP that seeks to exploit both of the advantages attributed to the two common GDP-to-MILP/MINLP transformations, the Big-M, and the Hull reformulation. We illustrate the application of this algorithm with several examples. The results show the improvement in the problem formulations by generating models with improved relaxed solutions and relatively small growth of continuous variables and constraints. The algorithm generally leads to reduction in the solution times."
6,"On Bounding the Bandwidth of Graphs with Symmetry","van Dam, E. R. and Sotirov, R.","INFORMS JOURNAL ON COMPUTING","27","1","75-88","2015","WIN","Bandwidth;Minimum Cut;Semidefinite Programming;Hamming Graphs;Johnson Graphs;Kneser Graphs","","We derive a new lower bound for the bandwidth of a graph that is based on a new lower bound for the min-cut problem. Our new semidefinite programming relaxation of the min-cut problem is obtained by strengthening the known semidefinite programming relaxation for the quadratic assignment problem (or for the graph partition problem) by fixing two vertices in the graph; one on each side of the cut. Fixing results in several smaller subproblems that need to be solved to obtain the new bound. To efficiently solve these subproblems we exploit symmetry in the data; that is, both symmetry in the min-cut problem and symmetry in the graphs. To obtain upper bounds for the bandwidth of graphs with symmetry, we develop a heuristic approach based on the well-known reverse Cuthill-McKee algorithm, and that improves significantly its performance on the tested graphs. Our approaches result in the best known lower and upper bounds for the bandwidth of all graphs under consideration, i.e., Hamming graphs, 3-dimensional generalized Hamming graphs, Johnson graphs, and Kneser graphs, with up to 216 vertices."
7,"Solving Hierarchical Stochastic Programs: Application to the Maritime Fleet Renewal Problem","Pantuso, Giovanni and Fagerholt, Kjetil and Wallace, Stein W.","INFORMS JOURNAL ON COMPUTING","27","1","89-102","2015","WIN","Multistage Mixed-Integer Stochastic Programming;Fleet Planning","","This paper presents a solution scheme for a class of multistage stochastic programs (possibly mixed-integer at all stages) in which a hierarchy of decisions emerges. A special structure, common to many strategic problems affected by uncertainty, allows decomposing the problem into a master problem and many independent linear programming subproblems, facilitating the isolation and reduction of the complicating mixed-integer component of the problem. Specialized (possibly heuristic) procedures can be used for solving the master problem while subproblems can be efficiently solved to optimality. We adapt and test the decomposition scheme for a case of the maritime fleet renewal problem, whose real life instances cannot be solved by means of commercial off-the-shelf solvers."
8,"Maintaining Secure and Reliable Distributed Control Systems","Sleptchenko, Andrei and Johnson, M. Eric","INFORMS JOURNAL ON COMPUTING","27","1","103-117","2015","WIN","Reliability;Maintenance-Repairs;Queues;Priority;Queues;Optimization;Probability;Stochastic Model Applications;Probability;Markov Processes","","We consider the role of security in the maintenance of an automated system, controlled by a network of sensors and simple computing devices. Such systems are widely used in transportation, utilities, healthcare, and manufacturing. Devices in the network are subject to traditional failures that can lead to a larger system failure if not repaired. However, the devices are also subject to security breaches that can also lead to catastrophic system failure. These security breaches could result from either cyber attacks (such as viruses, hackers, or terrorists) or physical tampering. We formulate a stochastic model of the system to examine the repair policies for both real and suspected failures. We develop a linear programming-based model for optimizing repair priorities. We show that, given the state of the system, the optimal repair policy follows a unique threshold indicator (either work on the real failures or the suspected ones). We examine the behavior of the optimal policy under different failure rates and threat levels. Finally, we examine the robustness of our model to violations in the underlying assumptions and find the model remains useful over a range of operating assumptions."
9,"A Computational Study of Exact Approaches for the Bi-Objective Prize-Collecting Steiner Tree Problem","Leitner, Markus and Ljubic, Ivana and Sinnl, Markus","INFORMS JOURNAL ON COMPUTING","27","1","118-134","2015","WIN","Bicriteria;Optimization;Mixed-Integer Programming;Is An Element Of-Constraint Method;Two-Phase Method;Chebyshev Norm Method","","We introduce the bi-objective prize-collecting Steiner tree problem, whose goal is to find a subtree considering the conflicting objectives of minimizing the edge costs for building that tree, and maximizing the collected node revenues. We consider five iterative mixed-integer programming (MIP) frameworks that identify the complete Pareto front, i.e., one efficient solution for every point on the Pareto front. More precisely, the following methods are studied: an is an element of-constraint method, a two-phase method, a binary search in the objective space, a weighted Chebyshev norm method, and a method of Sylva and Crema. We also investigate how to exploit and recycle information gained during these iterative MIP procedures to accelerate the solution process. We consider (i) additional strengthening valid inequalities, (ii) procedures for initializing feasible solutions (using a solution pool), (iii) procedures for recycling violated cuts (using a cut pool), and (iv) guiding the branching process by previously detected Pareto optimal solutions. This work is a first study on exact approaches for solving the bi-objective prize-collecting Steiner tree problem. Standard benchmark instances from the literature are used to assess the efficacy of the proposed methods."
10,"A Strong Preemptive Relaxation for Weighted Tardiness and Earliness/Tardiness Problems on Unrelated Parallel Machines","Sen, Halil and Bulbul, Kerem","INFORMS JOURNAL ON COMPUTING","27","1","135-150","2015","WIN","Unrelated Parallel Machines;Weighted Tardiness;Weighted Earliness And Tardiness;Preemptive Relaxation;Benders Decomposition;Transportation Problem;Lower Bound;Heuristic","","Research on due date-oriented objectives in the parallel machine environment is at best scarce compared to objectives such as minimizing the makespan or the completion time-related performance measures. Moreover, almost all existing work in this area is focused on the identical parallel machine environment. In this study, we leverage on our previous work on the single machine total weighted tardiness (TWT) and total weighted earliness/tardiness (TWET) problems and develop a new preemptive relaxation for both problems on a bank of unrelated parallel machines. The key contribution of this paper is devising a computationally effective Benders decomposition algorithm to solve the preemptive relaxation formulated as a mixed-integer linear program. The optimal solution of the preemptive relaxation provides a tight lower bound. Moreover, it offers a near-optimal partition of the jobs to the machines. We then exploit recent advances in solving the nonpreemptive single-machine TWT and TWET problems for constructing nonpreemptive solutions of high quality to the original problem. We demonstrate the effectiveness of our approach with instances of up to five machines and 200 jobs."
11,"New Heuristic Approaches for the Bounded-Diameter Minimum Spanning Tree Problem","Steitz, Wolfgang","INFORMS JOURNAL ON COMPUTING","27","1","151-163","2015","WIN","Backbone;Bounded-Diameter Minimum Spanning Tree Problem;Construction Heuristics;Diameter;Optimization;Spanning Trees","","Given a bound, the bounded-diameter minimum spanning tree (BDMST) problem seeks a spanning tree of minimum total weight with a diameter not exceeding the given diameter bound. Depending on the tightness of the bound, optimal solutions have different structures. For loose bounds, optimal solutions are similar to the much easier minimum spanning tree problem, and greedy heuristics perform best. In contrast, these approaches fail for tight diameter bounds. This paper investigates how the structure of good solutions, and in particular their backbones, change depending on the diameter bound. Two new heuristics are then designed to overcome the shortcomings of existing approaches; required parameters are investigated; and the paper presents performance results for Euclidean BDMST instances."
12,"Solving the Maximum Clique and Vertex Coloring Problems on Very Large Sparse Networks","Verma, Anurag and Buchanan, Austin and Butenko, Sergiy","INFORMS JOURNAL ON COMPUTING","27","1","164-177","2015","WIN","Maximum Clique;Vertex Coloring;Very-Large-Scale Networks;Exact Algorithm;K-Community;K-Core;Clique Relaxation;Scale Reduction","","This paper explores techniques for solving the maximum clique and vertex coloring problems on very largescale real-life networks. Because of the size of such networks and the intractability of the considered problems, previously developed exact algorithms may not be directly applicable. The proposed approaches aim to reduce the network instances to a size that is tractable for existing solvers, while preserving optimality. Two clique relaxation structures are exploited for this purpose. In addition to the known k -core structure, a newly introduced clique relaxation, k -community, is used to further reduce the instance size. Experimental results on real-life graphs (collaboration networks, P2P networks, social networks, etc.) show the proposed procedures to be effective by finding, for the first time, exact solutions for instances with over 18 million vertices."
13,"An Integer Programming Approach for Fault-Tolerant Connected Dominating Sets","Buchanan, Austin and Sung, Je Sang and Butenko, Sergiy","INFORMS JOURNAL ON COMPUTING","27","1","178-188","2015","WIN","Connected Dominating Set;K-Connected M-Dominating Set;Integer Programming;Fault-Tolerant","","This paper considers the minimum k -connected d -dominating set problem, which is a fault-tolerant generalization of the minimum connected dominating set ( MCDS) problem. Three integer programming formulations based on vertex cuts are proposed ( depending on whether d < k, d D k, or d > k) and their integer hulls are studied. The separation problem for the vertex-cut inequalities is a weighted vertex-connectivity problem and is polytime solvable, meaning that the LP relaxation can be solved in polytime despite having exponentially many constraints. A new class of valid inequalities-r-robust vertex-cut inequalities-is introduced and is shown to induce exponentially many facets. Finally, a lazy-constraint approach is shown to compare favorably with existing approaches for the MCDS problem ( the case k = d = 1), and is in fact the fastest in literature for standard test instances. A key subroutine is an algorithm for finding an inclusion-wise minimal vertex cut in linear time. Computational results for (k, d) =(2, 1), (2, 2), (3, 3), (4, 4) are provided as well."
14,"A Criterion Space Search Algorithm for Biobjective Mixed Integer Programming: The Triangle Splitting Method","Boland, Natashia and Charkhgard, Hadi and Savelsbergh, Martin","INFORMS JOURNAL ON COMPUTING","27","4","597-618","2015","FAL","Biobjective Mixed Integer Programming;Criterion Space Search Algorithm;The Triangle Splitting Method","","We present the first criterion space search algorithm, the triangle splitting method, for finding all nondominated points of a biobjective mixed integer program. The algorithm is relatively easy to implement and converges quickly to the complete set of nondominated points. The algorithm maintains, at any point in time, a diverse set of nondominated points, and is thus ideally suited for fast approximation of the nondominated frontier. An extensive computational study demonstrates the efficacy of the triangle splitting method."
15,"Growth Projections and Assortment Planning of Commodity Products Across Multiple Stores: A Data Mining and Optimization Approach","Bai, Xue and Bhattacharjee, Sudip and Boylu, Fidan and Gopal, Ram","INFORMS JOURNAL ON COMPUTING","27","4","619-635","2015","FAL","Data Mining;Assortment Planning;Association Rule Mining;Product Variety;Sales Efficiency","","Product assortment and availability are important determinants of sales success for firms of industrial commodity products. Well-known pricing and promotion strategies for differentiated products do not translate well to such products where price is closely tied to the cost of the products. Consequently, firms with multiple stores of commodity products are faced with the problem of product assortment that incorporates varying geographic and demographic conditions of locations they serve. The paper presents a model for assortment planning and optimization for multiple stores of a company. The novelty of our approach is twofold: first, it deploys data mining techniques to identify sales pattern information across multiple stores through existing sales data across segments and across stores; second, it identifies the optimal product assortment for each store and permits analyses of assortment efficiency evaluation among all existing stores. Our model first finds frequent itemsets based on association rule analysis and prunes them using a novel conflict resolution method. It then incorporates the identified product combinations into the development of the optimization formulation. Our methodology offers solutions that have important implications on product assortment, including complements versus substitutes and product bundling, and sheds lights on product planning and assortment strategies in general. A data set from an industry leading plastics manufacturer and retailer in the United States is used to demonstrate our model."
16,"A 3/2-Approximation Algorithm for the Multiple TSP with a Fixed Number of Depots","Xu, Zhou and Rodrigues, Brian","INFORMS JOURNAL ON COMPUTING","27","4","636-645","2015","FAL","Approximation Algorithm;Multiple Depots;Traveling Salesman;Matroid","","We study a natural extension of the classical traveling salesman problem (TSP) in the situation where multiple salesmen are dispatched from a number of different depots. As with the TSP, this problem is motivated by a large range of applications in vehicle routing. Although it is known to have a 2-approximation algorithm, whether the problem has a 3/2-approximation algorithm, as is the case with the well-known Christofides heuristic for the TSP, remains an open question. We answer this question positively by providing a 3/2-approximation algorithm for the problem with a fixed number of depots. The algorithm uses an edge exchange strategy, and its analysis hinges on a newly discovered exchange property of matroids. In addition, the algorithm is applied to multidepot extensions of other TSP variants, and we show for the first time, to our knowledge, that for these multidepot extensions the same best constant approximation ratios can be achieved as for their respective single-depot cases."
17,"Linear Programming and the Control of Diffusion Processes","Ahn, Andrew and Haugh, Martin","INFORMS JOURNAL ON COMPUTING","27","4","646-657","2015","FAL","Linear Programming;Portfolio Optimization;Duality","","Recent work by Han and Van Roy [Han J, Van Roy B (2011) Control of diffusions via linear programming. Infanger G, ed. Stochastic Programming: The State of the Art, in Honor of George B. Dantzig (Springer, New York), 329-354] introduced a linear programming technique to compute good suboptimal solutions to high-dimensional control problems in a diffusion-based setting. Their problem formulation worked with finite horizon problems where the horizon, T, is an exponentially distributed random variable. We extend their approach to finite horizon problems with a fixed horizon T. We also apply these techniques to dynamic portfolio optimization problems and then simulate the resulting policies to obtain lower bounds on the optimal value functions. We also use these policies in conjunction with convex duality methods designed for portfolio optimization problems to construct upper bounds on the optimal value functions. In our numerical experiments we find that the primal and dual bounds are very close, and so we conclude, for these problems at least, that the linear programming approach performs very well."
18,"Exact and Heuristic Algorithms for Capacitated Vehicle Routing Problems with Quadratic Costs Structure","Martinelli, Rafael and Contardo, Claudio","INFORMS JOURNAL ON COMPUTING","27","4","658-676","2015","FAL","Quadratic Capacitated Vehicle Routing Problem;Angle Capacitated Vehicle Routing Problem;Capacitated Vehicle Routing Problem With Reload Costs;Branch And Cut;Hybrid Metaheuristic","","In this article we introduce the quadratic capacitated vehicle routing problem (QCVRP) motivated by two applications in engineering and logistics: the capacitated vehicle routing problem with angle penalties (angle-CVRP) and the capacitated vehicle routing problem with reload costs (CVRP-RC). We introduce a three-index vehicle-flow formulation of the problem, which is strengthened with valid inequalities, and we derive a branch-and-cut algorithm capable of providing tight lower bounds and solving small-to medium-size instances in short to moderate computing times. Furthermore, we present a hybrid metaheuristic capable of providing high quality solutions in short computing times. The two algorithms are tested on several instances from the CVRP literature modified to mimic the two problems that motivate our study."
19,"Roundoff-Error-Free Algorithms for Solving Linear Systems via Cholesky and LU Factorizations","Escobedo, Adolfo R. and Moreno-Centeno, Erick","INFORMS JOURNAL ON COMPUTING","27","4","677-689","2015","FAL","Exact Mathematical Programming;Exact Algorithms;Matrix Factorizations;Roundoff Errors;Solving Linear Systems","","LU and Cholesky factorizations are computational tools for efficiently solving linear systems that play a central role in solving linear programs and several other classes of mathematical programs. In many documented cases, however, the roundoff errors accrued during the construction and implementation of these factorizations lead to the misclassification of feasible problems as infeasible and vice versa. Hence, reducing these roundoff errors or eliminating them altogether is imperative to guarantee the correctness of the solutions provided by optimization solvers. To achieve this goal without having to use rational arithmetic, we introduce two roundoff-error-free factorizations that require storing the same number of individual elements and performing a similar number of operations as the traditional LU and Cholesky factorizations. Additionally, we present supplementary roundoff-error-free forward and backward substitution algorithms, thereby providing a complete tool set for solving systems of linear equations exactly and efficiently. An important property shared by the featured factorizations and substitution algorithms is that their individual coefficients' maximum word length-i.e., the maximum number of digits required for expression-is bounded polynomially. Unlike the rational arithmetic methods used in practice to solve linear systems exactly, however, the algorithms herein presented do not require any gcd calculations to bound the entries' word length. We also derive various other related theoretical results, including the total computational complexity of all the roundoff-error-free processes herein presented."
20,"Achieving Domain Consistency and Counting Solutions for Dispersion Constraints","Pesant, Gilles","INFORMS JOURNAL ON COMPUTING","27","4","690-703","2015","FAL","Combinatorial Optimization;Constraint Programming;Balance;Spread Constraint;Deviation Constraint;Filtering Algorithms;Branching Heuristics;Counting-Based Search","","Many combinatorial problems require that their solutions achieve a certain balance of given features. For this important aspect of modeling, the spread and deviation constraints have been proposed in Constraint Programming to express balance among a set of variables by constraining their mean and overall deviation from the mean. To our knowledge, the only practical filtering algorithms known for these constraints achieve bounds consistency. In this paper we improve that filtering by presenting an efficient domain consistency algorithm that applies to both constraints. We also extend it to count solutions so that it can be used in counting-based search, a generic and effective family of branching heuristics that free the user from having to write problem-specific search heuristics. We provide a time complexity analysis of our contributions and empirically evaluate them on benchmark problems."
21,"Cloud Computing in Space","Huang, Jiangchuan and Kirsch, Christoph M. and Sengupta, Raja","INFORMS JOURNAL ON COMPUTING","27","4","704-717","2015","FAL","Cloud Computing;Virtual Vehicle;Performance Isolation;Migration Gain","","We apply virtual machine abstractions to networked vehicles, enabling what we call cloud computing in space to create performance isolation between customers. In analogy to conventional system virtualization and cloud computing, there are customer-operated virtual vehicles that essentially perform like real vehicles, although they are in reality hosted by fewer, shared, provider-operated real vehicles. The motion of the virtual vehicles and real vehicles creates migration gain. As a result, cloud computing in space can do better than conventional cloud computing in the sense of realizing high performance isolation (e.g., 98%) while requiring significantly fewer real vehicles (e.g., approximately one for five). There is a video associated with this paper. Click here to view the Video Overview. To save the file, right click and choose Save Link As from the menu."
22,"Machine Learning Approaches for Early DRG Classification and Resource Allocation","Gartner, Daniel and Kolisch, Rainer and Neill, Daniel B. and Padman, Rema","INFORMS JOURNAL ON COMPUTING","27","4","718-734","2015","FAL","Machine Learning;Diagnosis-Related Groups;Attribute Selection;Classification;Mathematical Programming","","Recent research has highlighted the need for upstream planning in healthcare service delivery systems, patient scheduling, and resource allocation in the hospital inpatient setting. This study examines the value of upstream planning within hospital-wide resource allocation decisions based on machine learning (ML) and mixed-integer programming (MIP), focusing on prediction of diagnosis-related groups (DRGs) and the use of these predictions for allocating scarce hospital resources. DRGs are a payment scheme employed at patients' discharge, where the DRG and length of stay determine the revenue that the hospital obtains. We show that early and accurate DRG classification using ML methods, incorporated into an MIP-based resource allocation model, can increase the hospital's contribution margin, the number of admitted patients, and the utilization of resources such as operating rooms and beds. We test these methods on hospital data containing more than 16,000 inpatient records and demonstrate improved DRG classification accuracy as compared to the hospital's current approach. The largest improvements were observed at and before admission, when information such as procedures and diagnoses is typically incomplete, but performance was improved even after a substantial portion of the patient's length of stay, and under multiple scenarios making different assumptions about the available information. Using the improved DRG predictions within our resource allocation model improves contribution margin by 2.9% and the utilization of scarce resources such as operating rooms and beds from 66.3% to 67.3% and from 70.7% to 71.7%, respectively. This enables 9.0% more nonurgent elective patients to be admitted as compared to the baseline."
23,"A Criterion Space Search Algorithm for Biobjective Integer Programming: The Balanced Box Method","Boland, Natashia and Charkhgard, Hadi and Savelsbergh, Martin","INFORMS JOURNAL ON COMPUTING","27","4","735-754","2015","FAL","Biobjective Integer Programming;Criterion Space Search Algorithm;Balanced Box Method","","We present a new criterion space search algorithm, the balanced box method, for finding all nondominated points of a biobjective integer program. The method extends the box algorithm, is easy to implement, and converges quickly to the complete set of nondominated points. Because the method maintains, at any point in time, a diverse set of nondominated points, it is ideally suited for fast approximation of the efficient frontier. In addition, we present several enhancements of the well-known. epsilon-constraint, augmented weighted Tchebycheff, and perpendicular search methods. An extensive computational study, using instances from different classes of combinatorial optimization problems, demonstrates the efficacy of the balanced box method."
24,"A Progressive Hedging Approach for Surgery Planning Under Uncertainty","Gul, Serhat and Denton, Brian T. and Fowler, John W.","INFORMS JOURNAL ON COMPUTING","27","4","755-772","2015","FAL","Surgery Planning;Scheduling;Stochastic Programming;Progressive Hedging;Heuristics","","We propose a multistage stochastic mixed-integer programming formulation for the assignment of surgeries to operating rooms over a finite planning horizon. We consider the demand for and the duration of surgery to be random variables. The objective is to minimize three competing criteria: expected cost of surgery cancellations, patient waiting time, and operating room overtime. We discuss properties of the model and an implementation of the progressive hedging algorithm to find near-optimal surgery schedules. We conduct numerical experiments using data from a large hospital to identify managerial insights related to surgery planning and the avoidance of surgery cancellations. We compare the progressive hedging algorithm to an easy-to-implement heuristic for practical problem instances to estimate the value of the stochastic solution. Finally, we discuss an implementation of the progressive hedging algorithm within a rolling horizon framework for extended planning periods."
25,"Improved Primal Simplex: A More General Theoretical Framework and an Extended Experimental Analysis","Omer, Jeremy and Rosat, Samuel and Raymond, Vincent and Soumis, Francois","INFORMS JOURNAL ON COMPUTING","27","4","773-787","2015","FAL","Linear Programming;Simplex;Degeneracy;Decomposition;Primal Algorithms","","In this article, we propose a general framework for an algorithm derived from the primal simplex that guarantees a strict improvement in the objective after each iteration. Our approach relies on the identification of compatible variables that ensure a nondegenerate iteration if pivoted into the basis. The problem of finding a strict improvement in the objective function is proved to be equivalent to two smaller problems, respectively, focusing on compatible and incompatible variables. We then show that the improved primal simplex (IPS) is a particular implementation of this generic theoretical framework. The resulting new description of IPS naturally emphasizes what should be considered as necessary adaptations of the framework versus specific implementation choices. This provides original insight into IPS that allows for the identification of weaknesses and potential alternative choices that would extend the efficiency of the method to a wider set of problems. We perform experimental tests on an extended collection of data sets including instances of Mittelmann's benchmark for linear programming. The results confirm the excellent potential of IPS and highlight some of its limits while showing a path toward an improved implementation of the generic algorithm."
26,"Optimization of Radiation Therapy Fractionation Schedules in the Presence of Tumor Repopulation","Bortfeld, Thomas and Ramakrishnan, Jagdish and Tsitsiklis, John N. and Unkelbach, Jan","INFORMS JOURNAL ON COMPUTING","27","4","788-803","2015","FAL","Dynamic Programming: Applications;Healthcare: Treatment","","We analyze the effect of tumor repopulation on optimal dose delivery in radiation therapy. We are primarily motivated by accelerated tumor repopulation toward the end of radiation treatment, which is believed to play a role in treatment failure for some tumor sites. A dynamic programming framework is developed to determine an optimal fractionation scheme based on a model of cell kill from radiation and tumor growth in between treatment days. We find that faster tumor growth suggests shorter overall treatment duration. In addition, the presence of accelerated repopulation suggests larger dose fractions later in the treatment to compensate for the increased tumor proliferation. We prove that the optimal dose fractions are increasing over time. Numerical simulations indicate a potential for improvement in treatment effectiveness."
27,"Period Decompositions for the Capacitated Lot Sizing Problem with Setup Times","de Araujo, Silvio Alexandre and De Reyck, Bert and Degraeve, Zeger and Fragkos, Ioannis and Jans, Raf","INFORMS JOURNAL ON COMPUTING","27","3","431-448","2015","SUM","Lot Sizing;Column Generation;Lagrange Relaxation;Branch And Price;Heuristics","","We study the multi-item capacitated lot sizing problem with setup times. Based on two strong reformulations of the problem, we present a transformed reformulation and valid inequalities that speed up column generation and Lagrange relaxation. We demonstrate computationally how both ideas enhance the performance of our algorithm and show theoretically how they are related to dual space reduction techniques. We compare several solution methods and propose a new efficient hybrid scheme that combines column generation and Lagrange relaxation in a novel way. Computational experiments show that the proposed solution method for finding lower bounds is competitive with textbook approaches and state-of-the-art approaches found in the literature. Finally, we design a branch-and-price-based heuristic and report computational results. The heuristic scheme compares favorably or outperforms other approaches."
28,"Automatic Minimal-Height Table Layout","Bilauca, Mihai and Gange, Graeme and Healy, Patrick and Marriott, Kim and Moulder, Peter and Stuckey, Peter J.","INFORMS JOURNAL ON COMPUTING","27","3","449-461","2015","SUM","Automatic Table Layout;Constrained Optimization;Typography","","Automatic layout of tables is useful in word processing applications and is required in online applications because of the need to tailor the layout to viewport width, choice of font, and dynamic content. However, if the table contains text, minimizing the height of the table for a given maximum width is a difficult combinatorial optimization problem because of the need to find the right choice of height/width configuration for each cell in the table. We investigate the modelling decisions involved in formulating this problem for use with standard combinatorial optimization techniques that are guaranteed to find the minimal-height table. To the best of our knowledge, we are the first to do so. We provide a detailed empirical evaluation of the resulting models using mixed integer programming and constraint programming with lazy clause generation."
29,"Optimal Policies for Security Patch Management","Dey, Debabrata and Lahiri, Atanu and Zhang, Guoying","INFORMS JOURNAL ON COMPUTING","27","3","462-477","2015","SUM","Security;Vulnerability;Patching;Patching Policy;Exploitation Cost;Setup Cost;Disruption Cost","","Effective patch management is critical to ensure the security of information systems that modern organizations count on today. Facing numerous patch releases from vendors, an information technology (IT) manager must weigh the costs of frequent patching against the security risks that can arise from delays in patch application. To this end, we develop a rigorous quantitative framework to analyze and compare several patching policies that are of practical interest. Our analyses of pure policies-policies that rely on a single metric such as elapsed time or patch severity level-show that certain policies are never optimal and no single policy may fit all information systems uniformly well. Depending on the context parameters, particularly the setup and business disruption costs for patching, either a time-based approach or an approach based on the cumulative severity level may be effective. To develop a more complete guideline for policy selection, we decipher hybrid policies that combine multiple metrics. Finally, we conduct extensive numerical experiments to verify the robustness of our analytical results. Overall, our paper establishes a comprehensive framework for analyzing various patching policies and furnishes useful insights for IT managers."
30,"Online Checkpointing with Improved Worst-Case Guarantees","Bringmann, Karl and Doerr, Benjamin and Neumann, Adrian and Sliacan, Jakub","INFORMS JOURNAL ON COMPUTING","27","3","478-490","2015","SUM","Bounded Memory;Breakpoints;Empirical Evaluation","","In the online checkpointing problem, the task is to continuously maintain a set of k checkpoints that allow rewinding an ongoing computation faster than by a full restart. The only operation allowed is to replace an old checkpoint by the current state. Our aim is checkpoint placement strategies that minimize rewinding cost, i.e., such that at all times T when requested to rewind to some time t <= T the number of computation steps that need to be redone to get to t from a checkpoint before t is as few as possible. In particular, we want the closest checkpoint earlier than t to be no farther away from t than q(k) times the ideal distance T/(k + 1), where q(k) is a small constant. Improving earlier work showing 1+1/k <= q(k) <= 2, we show that q(k) can be chosen asymptotically less than 2. We present algorithms with asymptotic discrepancy q(k) <= 1.59 + o(1) valid for all k and q(k) <= ln(4) + o(1) <= 1.39 + o(1) valid for k being a power of two. Experiments indicate the uniform bound p(k) <= 1.7 for all k. For small k, we show how to use a linear programming approach to compute good checkpointing algorithms. This gives discrepancies of less than 1.55 for all k < 60. We prove the first lower bound that is asymptotically more than 1, namely q(k) >= 1.30 - o(1). We also show that optimal algorithms (yielding the infimum discrepancy) exist for all k."
31,"Achieving Rapid Recovery in an Overload Control for Large-Scale Service Systems","Perry, Ohad and Whitt, Ward","INFORMS JOURNAL ON COMPUTING","27","3","491-506","2015","SUM","Service Systems;Overload Control;Congestion Collapse;Time-Varying Queues;Many-Server Queues;Recover After Overload Incident;Fluid Models","","We consider an automatic overload control for two large service systems modeled as multiserver queues such as call centers. We assume that the two systems are designed to operate independently, but want to help each other respond to unexpected overloads. The proposed overload control automatically activates sharing (sending some customers from one system to the other) once a ratio of the queue lengths in the two systems crosses an activation threshold (with ratio and activation threshold parameters for each direction). In this paper, we are primarily concerned with ensuring that the system recovers rapidly after the overload is over, either because (i) the two systems return to normal loading or (ii) the direction of the overload suddenly shifts in the opposite direction. To achieve rapid recovery, we introduce lower thresholds for the queue ratios, below which one-way sharing is released. As a basis for studying the complex dynamics, we develop a new six-dimensional fluid approximation for a system with time-varying arrival rates, extending a previous fluid approximation involving a stochastic averaging principle. We conduct simulations to confirm that the new algorithm is effective for predicting the system performance and choosing effective control parameters. The simulation and the algorithm show that the system can experience an inefficient nearly periodic behavior, corresponding to an oscillating equilibrium (congestion collapse) if the sharing is strongly inefficient and the control parameters are set inappropriately."
32,"Robust Network Design with Uncertain Outsourcing Cost","Pessoa, Artur Alves and Poss, Michael","INFORMS JOURNAL ON COMPUTING","27","3","507-524","2015","SUM","Robust Optimization;Network Design;Random Recourse;Linear Multiplicative Programming;Convex Optimization","","The expansion of a telecommunications network faces two sources of uncertainty, which are the demand for traffic that will transit through the expanded network and the outsourcing cost that the network operator will have to pay to handle the traffic that exceeds the capacity of her network. The latter is determined by the future cost of telecommunications services, whose negative correlation with the total demand is empirically measured in the literature through the price elasticity of demand. Unlike previous robust optimization works on the subject, we consider in this paper both sources of uncertainty and the correlation between them. The resulting mathematical model is a linear program that exhibits a constraint with quadratic dependency on the uncertainties. To solve the model, we propose a decomposition approach that avoids considering the constraint for all scenarios. Instead, we use a cutting-plane algorithm that generates required scenarios on the fly by solving linear multiplicative programs. Computational experiments realized on the networks from SNDlib show that our approach is orders of magnitude faster than the classical semidefinite programming reformulation for such problems."
33,"Optimal Hour-Ahead Bidding in the Real-Time Electricity Market with Battery Storage Using Approximate Dynamic Programming","Jiang, Daniel R. and Powell, Warren B.","INFORMS JOURNAL ON COMPUTING","27","3","525-543","2015","SUM","Approximate Dynamic Programming;Bidding;Hour-Ahead;Energy Storage;Real-Time Market","","There is growing interest in the use of grid-level storage to smooth variations in supply that are likely to arise with an increased use of wind and solar energy. Energy arbitrage, the process of buying, storing, and selling electricity to exploit variations in electricity spot prices, is becoming an important way of paying for expensive investments into grid-level storage. Independent system operators such as the New York Independent System Operator (NYISO) require that battery storage operators place bids into an hour-ahead market (although settlements may occur in increments as small as five minutes, which is considered near real-time). The operator has to place these bids without knowing the energy level in the battery at the beginning of the hour and simultaneously accounting for the value of leftover energy at the end of the hour. The problem is formulated as a dynamic program. We describe and employ a convergent approximate dynamic programming (ADP) algorithm that exploits monotonicity of the value function to find a revenue-generating bidding policy; using optimal benchmarks, we empirically show the computational benefits of the algorithm. Furthermore, we propose a distribution-free variant of the ADP algorithm that does not require any knowledge of the distribution of the price process (and makes no assumptions regarding a specific real-time price model). We demonstrate that a policy trained on historical real-time price data from the NYISO using this distribution-free approach is indeed effective."
34,"Optimization of Industrial-Scale Assemble-to-Order Systems","van Jaarsveld, Willem and Scheller-Wolf, Alan","INFORMS JOURNAL ON COMPUTING","27","3","544-560","2015","SUM","Continuous-Time Assemble-To-Order Systems;Industrial-Scale Problems;Base-Stock Policies;First-Come-First-Served Allocation;Optimal Allocation;Stochastic Programming","","Using a novel stochastic programming (SP) formulation, we develop an algorithm for inventory control in industrial-size assemble-to-order (ATO) systems that has unparalleled efficiency and scalability. Applying our algorithm to several numerical examples, we generate new insights regarding the control and optimization of these systems. We consider a continuous time model, seeking base-stock levels for components that minimize the sum of holding costs and product-specific backorder costs. Our initial focus is on first-come, first-served (FCFS) allocation of components to products; for this setting our algorithm quickly computes solutions for which the asymptotic optimality gap with the optimal FCFS base-stock policy is less than 1%. We then turn to two related questions: How do common heuristics used in practice compare to our performance, and how costly is the FCFS assumption? For the first question, we investigate the effectiveness of ignoring simultaneous stock-outs (ISS), a heuristic that has been used by companies such as IBM and Dell. Our experiments indicate that ISS performance, when compared to the optimal FCFS base-stock policy, improves as the average newsvendor (NV) fractiles increase but suffers under lead-time demand correlations. For the second question, we develop an efficiently computable upper bound on the benefit of optimal allocation over FCFS. We find that for many large ATO systems, FCFS performs surprisingly well and that its performance improves with decreasing NV fractile asymmetry among products and, again, with increasing average NV fractiles. We also investigate simple no-holdback allocation policies and find that they tend to outperform the best FCFS policies."
35,"Learning Context-Sensitive Domain Ontologies from Folksonomies: A Cognitively Motivated Method","Lau, Raymond Y. K. and Zhao, J. Leon and Zhang, Wenping and Cai, Yi and Ngai, Eric W. T.","INFORMS JOURNAL ON COMPUTING","27","3","561-578","2015","SUM","Folksonomies;Ontology Learning;Machine Learning;Artificial Intelligence;Knowledge Management","","Ontology is the backbone of the Semantic Web, helping users search for relevant resources from the Web of linked data. The existing context-free mapping approach between tags and concepts fails to address the problems of social synonymy and social polysemy when ontologies are induced from folksonomies. The novel contributions of this paper are threefold. First, grounded in the cognitively motivated category utility measure, a novel basic-level concept mining algorithm is developed to construct semantically rich concept vectors to alleviate the problem of social synonymy. Second, contextual aspects of ontology learning are exploited via probabilistic topic modeling to address the problem of social polysemy. Third, a novel context-sensitive domain ontology learning algorithm that combines link- and content-based semantic analysis is developed to identify both taxonomic and associative relations among concepts. To the best of our knowledge, this is the first successful research that exploits a cognitively motivated method to learn context-sensitive domain ontologies from folksonomies. By using the Open Directory Project ontology as a benchmark, we examined the effectiveness of the proposed algorithms based on social annotations crawled from three different folksonomy sites. Our experimental results show that the proposed ontology learning system significantly outperforms the best baseline system by 13.83% in terms of taxonomic F-measure. The practical implication of our research is that high-quality ontologies are constructed with minimal human intervention to facilitate concept-driven retrieval of linked data and the knowledge-based interoperability among enterprises."
36,"Multivariate Mixtures of Normal Distributions: Properties, Random Vector Generation, Fitting, and as Models of Market Daily Changes","Wang, Jin and Taaffe, Michael R.","INFORMS JOURNAL ON COMPUTING","27","2","193-203","2015","SPR","Monte Carlo Simulation;Mixture Of Normals;Kurtosis And Skewness;Em Algorithm","","Mixtures of normal distributions provide a useful modeling extension of the normal distribution-both univariate and multivariate. Unlike the normal distribution, mixtures of normals can capture the kurtosis (fat tails) and nonzero skewness often necessary for accurately modeling a variety of real-world variables. An efficient analytical Monte Carlo method is proposed for considering multivariate mixtures of normal distributions having arbitrary covariance matrices. The method consists of a linear transformation of a multivariate normal having a computed covariance matrix into the desired multivariate mixture of normal distributions. The computed covariance matrix is derived analytically. Among the properties of the multivariate mixture of normals that we demonstrate is that any linear combination of mixtures of normal distributions is also a mixture of normal distributions. Methods of fitting mixtures of normal distributions are briefly discussed. A motivating example carried throughout this paper is the use of multivariate mixtures of normals for modeling daily changes in market variables."
37,"The Generalized Regenerator Location Problem","Chen, Si and Ljubic, Ivana and Raghavan, S.","INFORMS JOURNAL ON COMPUTING","27","2","204-220","2015","SPR","Optical Network Design;Extended Formulations;Multicommodity Flow;Branch And Cut;Heuristics Regenerator Location","","In an optical network a signal can only travel a maximum distance dmax before its quality deteriorates to the point that it must be regenerated by installing regenerators at nodes of the network. As the cost of a regenerator is high, we wish to deploy as few regenerators as possible in the network, while ensuring all nodes can communicate with each other. In this paper we introduce the generalized regenerator location problem (GRLP) in which we are given a set S of nodes that corresponds to candidate locations for regenerators, and a set T of nodes that must communicate with each other. If S = T = N, we obtain the regenerator location problem (RLP), which we have studied previously and shown to be NP-complete. Our solution procedure to the RLP is based on its equivalence to the maximum leaf spanning tree problem (MLSTP). Unfortunately, this equivalence does not apply to the GRLP, nor do the procedures developed previously for the RLP. To solve the GRLP, we propose reduction procedures, two construction heuristics, and a local search procedure that we collectively refer to as a heuristic framework. We also establish a correspondence between the (node-weighted) directed Steiner forest problem and the GRLP. Using this fact, we provide several ways to derive natural and extended integer programming (IP) and mixed-integer programming (MIP) models for the GRLP and compare the strength of these models. Using the strongest model derived on the natural node selection variables we develop a branch- and-cut approach to solve the problem to optimality. The results indicate that the exact approach can easily solve instances with up to 200 nodes to optimality, whereas the heuristic framework is a high-quality approach for solving large-scale instances."
38,"Dynamic Programming Driven Memetic Search for the Steiner Tree Problem with Revenues, Budget, and Hop Constraints","Fu, Zhang-Hua and Hao, Jin-Kao","INFORMS JOURNAL ON COMPUTING","27","2","221-237","2015","SPR","Constrained Steiner Trees;Evolutionary Computation;Heuristics;Dynamic Programming;Content Distribution Networks","","We present a highly effective dynamic programming driven memetic algorithm for the Steiner tree problem with revenues, budget, and hop constraints (STPRBH), which aims at determining a subtree of an undirected graph, so as to maximize the collected revenue, subject to both budget and hop constraints. The main features of the proposed algorithm include a probabilistic constructive procedure to generate initial solutions, a neighborhood search procedure using dynamic programming to significantly speed up neighborhood exploration, a backbone-based crossover operator to generate offspring solutions, as well as a quality-and-distance updating strategy to manage the population. Computational results based on four groups of 384 well-known benchmarks demonstrate the value of the proposed algorithm, compared to the state of the art approaches. In particular, for the 56 most challenging instances with unknown optima, our algorithm succeeds in providing 45 improved best known solutions within a short computing time. We additionally provide results for a group of 30 challenging instances that are introduced in the paper. We provide a complexity analysis of the proposed algorithm and study the impact of some ingredients on the performance of the algorithm."
39,"Computing in Operations Research Using Julia","Lubin, Miles and Dunning, Iain","INFORMS JOURNAL ON COMPUTING","27","2","238-248","2015","SPR","Algebraic Modeling;Scientific Computing;Programming Languages;Metaprogramming","","The state of numerical computing is currently characterized by a divide between highly efficient yet typically cumbersome low-level languages such as C, C++, and Fortran and highly expressive yet typically slow high-level languages such as Python and MATLAB. This paper explores how Julia, a modern programming language for numerical computing that claims to bridge this divide by incorporating recent advances in language and compiler design (such as just-in-time compilation), can be used for implementing software and algorithms fundamental to the field of operations research, with a focus on mathematical optimization. In particular, we demonstrate algebraic modeling for linear and nonlinear optimization and a partial implementation of a practical simplex code. Extensive cross-language benchmarks suggest that Julia is capable of obtaining state-of-the-art performance."
40,"A Network Structural Approach to the Link Prediction Problem","Lee, Chungmok and Minh Pham and Jeong, Myong K. and Kim, Dohyun and Lin, Dennis K. J. and Chavalitwongse, Wanpracha Art","INFORMS JOURNAL ON COMPUTING","27","2","249-267","2015","SPR","Analysis Of Algorithms;Data Mining;Link Prediction;Optimization","","The link prediction problem is an emerging real-life social network problem in which data mining techniques have played a critical role. It arises in many practical applications such as recommender systems, information retrieval, and marketing analysis of social networks. We propose a new mathematical programming approach for predicting a future network using estimated node degree distribution identified from historical data. The link prediction problem is formulated as an integer programming problem that maximizes the sum of link scores (probabilities) with respect to the estimated node degree distribution. The performance of the proposed framework is tested on real-life social networks, and the computational results show that the proposed approach can improve the performance of previously published link prediction methods."
41,"Solving Variants of the Job Shop Scheduling Problem Through Conflict-Directed Search","Grimes, Diarmuid and Hebrard, Emmanuel","INFORMS JOURNAL ON COMPUTING","27","2","268-284","2015","SPR","Scheduling;Combinatorial Optimization;Disjunctive/Unary Resource;Constraint Programming;Adaptive Search Heuristics","","We introduce a simple technique for disjunctive machine scheduling problems and show that this method can match or even outperform state-of-the-art algorithms on a number of problem types. Our approach combines a number of generic search techniques such as restarts, adaptive heuristics, and solution-guided branching on a simple model based on a decomposition of disjunctive constraints and on the reification of these disjuncts. This paper describes the method and its application to variants of the job shop scheduling problem (JSP). We show that our method can easily be adapted to handle additional side constraints and different objective functions, often outperforming the state-of-the-art and closing a number of open problems. Moreover, we perform in-depth analysis of the various factors that make this approach efficient. We show that, while most of the factors give moderate benefits, the variable and value ordering components are key."
42,"Optimal Budget Allocation Across Search Advertising Markets","Yang, Yanwu and Zeng, Daniel and Yang, Yinghui and Zhang, Jie","INFORMS JOURNAL ON COMPUTING","27","2","285-300","2015","SPR","Sponsored Search;Budget Allocation;Budget Strategy;Search Markets","","One critical operational decision facing online advertisers when they engage in sponsored search advertising is concerned with the allocation of a limited advertising budget. In particular, dealing with multi-keyword search markets over multiple decision periods poses significant decision-making challenges. In this paper, we develop a novel budget allocation optimization model with multiple search advertising markets and a finite time horizon. One key element of our modeling work is developing a customized advertising response function when considering distinctive features of sponsored search, including the quality score and the dynamic advertising effort. We derive a feasible solution to our budget model and study its properties. Computational experiments are conducted on real-world data to evaluate our budget model and perform parameter sensitivity analysis. Experimental results indicate that our budget allocation strategy significantly outperforms several baseline strategies. In addition, the identified properties derived from the solution process illuminate critical managerial insights for advertisers in sponsored search."
43,"Chance-Constrained Programming Models and Approximations for General Stochastic Bottleneck Spanning Tree Problems","Shen, Siqian and Kurt, Murat and Wang, Jue","INFORMS JOURNAL ON COMPUTING","27","2","301-316","2015","SPR","Stochastic Bottleneck Spanning Tree;Chance-Constrained Programming;Special Ordered Sets;Bisection Algorithm;Np-Complete","","We consider a balance-constrained stochastic bottleneck spanning tree problem (BCSBSTP) where edge weights are independently distributed but may follow arbitrary continuous distributions. The goal is to minimize a threshold variable that may be exceeded by the maximum edge weight at certain risk, subject to the minimum edge weight being no less than a fixed threshold with a probability guarantee. We characterize these two requirements as chance constraints, which are typically used for bounding the risk of undesirable random outcomes. Given independently distributed edge weights, we reformulate BCSBSTP as a mixed-integer nonlinear program, approximated by two mixed-integer linear programs based on special ordered set of type one (SOS1) and special ordered set of type two (SOS2) variables. By relaxing the probabilistic guarantee on the minimum edge weight in BCSBSTP, we also consider a stochastic bottleneck spanning tree problem (SBSTP), of which optimal tree solutions are approximated via a bisection algorithm in pseudopolynomial time. We demonstrate computational results of our models and algorithms by testing randomly generated instances with edge weights following a diverse set of independent distributions."
44,"Chance Constrained Selection of the Best","Hong, L. Jeff and Luo, Jun and Nelson, Barry L.","INFORMS JOURNAL ON COMPUTING","27","2","317-334","2015","SPR","Simulation;Ranking And Selection;Chance Constraints;Hypothesis Test;Statistical Validity;Multiple Performance Measures","","Selecting the solution with the largest or smallest mean of a primary performance measure from a finite set of solutions while requiring secondary performance measures to satisfy certain constraints is called constrained selection of the best (CSB) in the simulation ranking and selection literature. In this paper, we consider CSB problems with secondary performance measures that must satisfy probabilistic constraints, and we call such problems chance constrained selection of the best (CCSB). We design procedures that first check the feasibility of all solutions and then select the best among all the sample feasible solutions. We prove the statistical validity of these procedures for variations of the CCSB problem under the indifference-zone formulation. Numerical results show that the proposed procedures can efficiently handle CCSB problems with up to 100 solutions, each with five chance constraints."
45,"Approximation Methods for Pricing Problems Under the Nested Logit Model with Price Bounds","Rayfield, W. Zachary and Rusmevichientong, Paat and Topaloglu, Huseyin","INFORMS JOURNAL ON COMPUTING","27","2","335-357","2015","SPR","Nested Logit;Choice Modeling;Pricing;Revenue Management","","We consider two variants of a pricing problem under the nested logit model. In the first variant, the set of products offered to customers is fixed, and we want to determine the prices of the products. In the second variant, we jointly determine the set of offered products and their corresponding prices. In both variants, the price of each product has to be chosen within given upper and lower bounds specific to the product, each customer chooses among the offered products according to the nested logit model, and the objective is to maximize the expected revenue from each customer. We give approximation methods for both variants. For any rho > 0, our approximation methods obtain a solution with an expected revenue deviating from the optimal expected revenue by no more than a factor of 1 + rho. To obtain such a solution, our approximation methods solve a linear program whose size grows at rate 1/rho. In addition to our approximation methods, we develop a linear program that we can use to obtain an upper bound on the optimal expected revenue. In our computational experiments, we compare the expected revenues from the solutions obtained by our approximation methods with the upper bounds on the optimal expected revenues and show that we can obtain high-quality solutions quite fast."
46,"Importance Sampling in Stochastic Programming: A Markov Chain Monte Carlo Approach","Parpas, Panos and Ustun, Berk and Webster, Mort and Quang Kha Tran","INFORMS JOURNAL ON COMPUTING","27","2","358-377","2015","SPR","Benders' Decomposition;Cutting Plane Algorithms;Stochastic Optimization;Stochastic Programming;Importance Sampling;Variance Reduction;Monte Carlo;Markov Chain Monte Carlo;Kernel Density Estimation;Nonparametric","","Stochastic programming models are large-scale optimization problems that are used to facilitate decision making under uncertainty. Optimization algorithms for such problems need to evaluate the expected future costs of current decisions, often referred to as the recourse function. In practice, this calculation is computationally difficult as it requires the evaluation of a multidimensional integral whose integrand is an optimization problem. In turn, the recourse function has to be estimated using techniques such as scenario trees or Monte Carlo methods, both of which require numerous functional evaluations to produce accurate results for large-scale problems with multiple periods and high-dimensional uncertainty. In this work, we introduce an importance sampling framework for stochastic programming that can produce accurate estimates of the recourse function using a small number of samples. Our framework combines Markov chain Monte Carlo methods with kernel density estimation algorithms to build a nonparametric importance sampling distribution, which can then be used to produce a lower-variance estimate of the recourse function. We demonstrate the increased accuracy and efficiency of our approach using variants of well-known multistage stochastic programming problems. Our numerical results show that our framework produces more accurate estimates of the optimal value of stochastic programming models, especially for problems with moderate variance, multimodal, or rare-event distributions."
47,"A New Semidefinite Programming Relaxation for the Quadratic Assignment Problem and Its Computational Perspectives","de Klerk, E. and Sotirov, R. and Truetsch, U.","INFORMS JOURNAL ON COMPUTING","27","2","378-391","2015","SPR","Quadratic Assignment Problem;Semidefinite Programming Bounds;Branch And Bound;Convex Relaxations","","Recent progress in solving quadratic assignment problems (QAPs) from the QAPLIB (Quadratic Assignment Problem Library) test set has come from mixed-integer linear or quadratic programming models that are solved in a branch-and-bound framework. Semidefinite programming (SDP) bounds for QAPs have also been studied in some detail, but their computational impact has been limited so far, mostly because of the restrictive size of the early relaxations. Some recent progress has been made by studying smaller SDP relaxations and by exploiting group symmetry in the QAP data. In this work, we introduce a new SDP relaxation, where the matrix variables are only of the order of the QAP dimension, and we show how one may exploit group symmetry in the problem data for this relaxation. We also provide a detailed numerical comparison with related bounds from the literature. In particular, we compute the best-known lower bounds for two QAPLIB instances."
48,"Heuristic and Exact Algorithms for the Interval Min-Max Regret Knapsack Problem","Furini, Fabio and Iori, Manuel and Martello, Silvano and Yagiura, Mutsunori","INFORMS JOURNAL ON COMPUTING","27","2","392-405","2015","SPR","Robust Optimization;Knapsack Problem;Interval Min-Max Regret;Local Search;Lagrangian Relaxation;Branch And Cut","","We consider a generalization of the 0-1 knapsack problem in which the profit of each item can take any value in a range characterized by a minimum and a maximum possible profit. A set of specific profits is called a scenario. Each feasible solution associated with a scenario has a regret, given by the difference between the optimal solution value for such scenario and the value of the considered solution. The interval min-max regret knapsack problem (MRKP) is then to find a feasible solution such that the maximum regret over all scenarios is minimized. The problem is extremely challenging both from a theoretical and a practical point of view. Its decision version is complete for the second level of the polynomial hierarchy hence it is most probably not in NP. In addition, even computing the regret of a solution with respect to a scenario requires the solution of an NP-hard problem. We examine the behavior of classical combinatorial optimization approaches when adapted to the solution of the MRKP. We introduce an iterated local search approach and a Lagrangian-based branch-and-cut algorithm and evaluate their performance through extensive computational experiments."
49,"Model Counting of Monotone Conjunctive Normal Form Formulas with Spectra","Vaisman, Radislav and Strichman, Ofer and Gertsbakh, Ilya","INFORMS JOURNAL ON COMPUTING","27","2","406-415","2015","SPR","Simulation;Counting;Monte Carlo;Monotone Cnf;Random Graphs","","Model counting is the #P problem of counting the number of satisfying solutions of a given propositional formula. Here we focus on a restricted variant of this problem, where the input formula is monotone (i.e., there are no negations). A monotone conjunctive normal form (CNF) formula is sufficient for modeling various graph problems, e.g., the vertex covers of a graph. Even for this restricted case, there is no known efficient approximation scheme. We show that the classical Spectra technique that is widely used in network reliability can be adapted for counting monotone CNF formulas. We prove that the proposed algorithm is logarithmically efficient for random monotone 2-CNF instances. Although we do not prove the efficiency of Spectra for k-CNF where k > 2, our experiments show that it is effective in practice for such formulas."
50,"A Scenario Decomposition Algorithm for Stochastic Programming Problems with a Class of Downside Risk Measures","Rysz, Maciej and Vinel, Alexander and Krokhmal, Pavlo and Pasiliao, Eduardo L.","INFORMS JOURNAL ON COMPUTING","27","2","416-430","2015","SPR","Stochastic Optimization;Risk Measures;Utility Theory;Certainty Equivalent;Scenario Decomposition;Higher-Moment Coherent Risk Measures;Log-Exponential Convex Risk Measures","","We present an efficient scenario decomposition algorithm for solving large-scale convex stochastic programming problems that involve a particular class of downside risk measures. The considered risk functionals encompass coherent and convex measures of risk that can be represented as an infimal convolution of a convex certainty equivalent, and include well-known measures, such as conditional value-at-risk, as special cases. The resulting structure of the feasible set is then exploited via iterative solving of relaxed problems, and it is shown that the number of iterations is bounded by a parameter that depends on the problem size. The computational performance of the developed scenario decomposition method is illustrated on portfolio optimization problems involving two families of nonlinear measures of risk, the higher-moment coherent risk measures, and log-exponential convex risk measures. It is demonstrated that for large-scale nonlinear problems the proposed approach can provide up to an order-of-magnitude improvement in computational time in comparison to state-of-the-art solvers, such as CPLEX, Gurobi, and MOSEK."
51,"Survivability in Hierarchical Telecommunications Networks Under Dual Homing","Karasan, Oya Ekin and Mahjoub, A. Ridha and Ozkok, Onur and Yaman, Hande","INFORMS JOURNAL ON COMPUTING","26","1","1-15","2014","WIN","Hierarchical Network Design;Two-Edge Connectedness;Dual-Homing Survivability;Facets;Branch And Cut;Variable Fixing","","The motivation behind this study is the essential need for survivability in the telecommunications networks. An optical signal should find its destination even if the network experiences an occasional fiber cut. We consider the design of a two-level survivable telecommunications network. Terminals compiling the access layer communicate through hubs forming the backbone layer. To hedge against single link failures in the network, we require the backbone subgraph to be two-edge connected and the terminal nodes to connect to the backbone layer in a dual-homed fashion, i.e., at two distinct hubs. The underlying design problem partitions a given set of nodes into hubs and terminals, chooses a set of connections between the hubs such that the resulting backbone network is two-edge connected, and for each terminal chooses two hubs to provide the dual-homing backbone access. All of these decisions are jointly made based on some cost considerations. We give alternative formulations using cut inequalities, compare these formulations, provide a polyhedral analysis of the small-sized formulation, describe valid inequalities, study the associated separation problems, and design variable fixing rules. All of these findings are then utilized in devising an efficient branch-and-cut algorithm to solve this network design problem."
52,"An Efficient Semidefinite Programming Relaxation for the Graph Partition Problem","Sotirov, Renata","INFORMS JOURNAL ON COMPUTING","26","1","16-30","2014","WIN","Graph Partition;Graph Equipartition;Matrix Lifting;Vector Lifting;Semidefinite Programming","","We derive a new semidefinite programming relaxation for the general graph partition problem (GPP). Our relaxation is based on matrix lifting with matrix variable having order equal to the number of vertices of the graph. We show that this relaxation is equivalent to the Frieze-Jerrum relaxation for the maximum k-cut problem with an additional constraint that involves the restrictions on the subset sizes. Because the new relaxation does not depend on the number of subsets k into which the graph should be partitioned we are able to compute bounds for large k. We compare theoretically and numerically the new relaxation with other semidefinite programming (SDP) relaxations for the GPP. The results show that our relaxation provides competitive bounds and is solved significantly faster than any other known SDP bound for the general GPP."
53,"An Outer-Inner Approximation for Separable Mixed-Integer Nonlinear Programs","Hijazi, Hassan and Bonami, Pierre and Ouorou, Adam","INFORMS JOURNAL ON COMPUTING","26","1","31-44","2014","WIN","Mixed-Integer Nonlinear Programming;Outer Approximation","","A common structure in convex mixed-integer nonlinear programs (MINLPs) is separable nonlinear functions. In the presence of such structures, we propose three improvements to the outer approximation algorithms. The first improvement is a simple extended formulation, the second is a refined outer approximation, and the third is a heuristic inner approximation of the feasible region. As a side result, we exhibit a simple example where a classical implementation of the outer approximation would take an exponential number of iterations, whereas it is easily solved with our modifications. These methods have been implemented in the open source solver BONMIN and are available for download from the Computational Infrastructure for Operations Research project website. We test the effectiveness of the approach on three real-world applications and on a larger set of models from an MINLP benchmark library. Finally, we show how the techniques can be extended to perspective formulations of several problems. The proposed tools lead to an important reduction in computing time on most tested instances."
54,"The Supervised Normalized Cut Method for Detecting, Classifying, and Identifying Special Nuclear Materials","Yang, Yan T. and Fishbain, Barak and Hochbaum, Dorit S. and Norman, Eric B. and Swanberg, Erik","INFORMS JOURNAL ON COMPUTING","26","1","45-58","2014","WIN","Nuclear Material Detection;Supervised Learning;Normalized Cut;Support Vector Machine;Multiclassification","","The detection of illicit nuclear materials is a major tool in preventing and deterring nuclear terrorism. The detection task is extremely difficult because of physical limitations of nuclear radiation detectors, shielding by intervening cargo materials, and the presence of background noise. We aim at enhancing the capabilities of detectors with algorithmic methods specifically tailored for nuclear data. This paper describes a novel graph-theory-based methodology for this task. This research considers for the first time the utilization of supervised normalized cut (SNC) for data mining and classification of measurements obtained from plastic scintillation detectors that are of particularly low resolution. Specifically, the situation considered here is for when both energy spectra and the time dependence of such data are acquired. We present here a computational study, comparing the supervised normalized cut method with alternative classification methods based on support vector machine (SVM), specialized feature-reducing SVMs (i.e., 1-norm SVM, recursive feature elimination SVM, and Newton linear program SVM), and linear discriminant analysis (LDA). The study evaluates the performance of the suggested method in binary and multiple classification problems of nuclear data. The results demonstrate that the new approach is on par or superior in terms of accuracy and much better in computational complexity to SVM (with or without dimension or feature reduction) and LDA with principal components analysis as preprocessing. For binary and multiple classifications, the SNC method is more accurate, more robust, and is computationally more efficient by a factor of 2-80 than the SVM-based and LDA methods."
55,"Algorithms for Time-Varying Networks of Many-Server Fluid Queues","Liu, Yunan and Whitt, Ward","INFORMS JOURNAL ON COMPUTING","26","1","59-73","2014","WIN","Queues With Time-Varying Arrival Rates;Nonstationary Queues;Queueing Networks;Many-Server Queues;Deterministic Fluid Models;Fluid Approximation;Nonstationary Networks Of Fluid Queues;Customer Abandonment;Non-Markovian Queues","","Motivated by large-scale service systems with network structure, we introduced in a previous paper a time-varying open network of many-server fluid queues with customer abandonment from each queue and time-varying proportional routing among the queues, and showed how performance functions can be determined. The deterministic fluid model serves as an approximation for the corresponding non-Markovian stochastic network of many-server queues with Markovian routing, experiencing periods of overloading at the queues. In this paper we develop a new algorithm for the previous model and generalize the model to include non-exponential service-time distributions. In this paper we report results of implementing the algorithms and studying their computational complexity. We also conduct simulation experiments to confirm that the algorithms are effective in computing the performance functions and that these performance functions provide useful approximations for the corresponding stochastic models."
56,"Quantifying Input Uncertainty via Simulation Confidence Intervals","Barton, Russell R. and Nelson, Barry L. and Xie, Wei","INFORMS JOURNAL ON COMPUTING","26","1","74-87","2014","WIN","Input Modeling;Bootstrapping;Confidence Intervals;Metamodeling;Stochastic Kriging","","We consider the problem of deriving confidence intervals for the mean response of a system that is represented by a stochastic simulation whose parametric input models have been estimated from real-world data. As opposed to standard simulation confidence intervals, we provide confidence intervals that account for uncertainty about the input model parameters; our method is appropriate when enough simulation effort can be expended to make simulation-estimation error relatively small. To achieve this we introduce metamodel-assisted bootstrapping that propagates input variability through to the simulation response via an equation-based model rather than by simulating. We develop a metamodel strategy and associated experiment design method that avoid the need for low-order approximation to the response and that minimizes the impact of intrinsic (simulation) error on confidence level accuracy. Asymptotic analysis and empirical tests over a wide range of simulation effort show that confidence intervals obtained via metamodel-assisted bootstrapping achieve the desired coverage."
57,"An Exact Algorithm Based on Cut-and-Column Generation for the Capacitated Location-Routing Problem","Contardo, Claudio and Cordeau, Jean-Francois and Gendron, Bernard","INFORMS JOURNAL ON COMPUTING","26","1","88-102","2014","WIN","Location Routing;Vehicle Routing;Branch-And-Cut-And-Price;Column Generation","","In this paper we present an exact algorithm for the capacitated location-routing problem (CLRP) based on cut-and-column generation. The CLRP is formulated as a set-partitioning problem that also inherits all of the known valid inequalities for the flow formulations of the CLRP. We introduce five new families of inequalities that are shown to dominate some of the cuts from the two-index formulation. The problem is solved by column generation, where the subproblem consists in finding a shortest path of minimum reduced cost under capacity constraints. We first use the two-index formulation for enumerating all of the possible subsets of depot locations that could lead to an optimal solution of cost less than or equal to a given upper bound. For each of these subsets, the corresponding multiple depot vehicle routing problem is then solved by means of column generation. The results show that we can improve the bounds found in the literature, solve to optimality some previously open instances, and improve the upper bounds on some other instances."
58,"Formulations and Branch-and-Cut Algorithms for Multivehicle Production and Inventory Routing Problems","Adulyasak, Yossiri and Cordeau, Jean-Francois and Jans, Raf","INFORMS JOURNAL ON COMPUTING","26","1","103-120","2014","WIN","Integrated Supply Chain Planning;Inventory Routing;Production Routing;Multivehicle;Symmetry Breaking;Branch-And-Cut","","The inventory routing problem (IRP) and the production routing problem (PRP) are two difficult problems arising in the planning of integrated supply chains. These problems are solved in an attempt to jointly optimize production, inventory, distribution, and routing decisions. Although several studies have proposed exact algorithms to solve the single-vehicle problems, the multivehicle aspect is often neglected because of its complexity. We introduce multivehicle PRP and IRP formulations, with and without a vehicle index, to solve the problems under both the maximum level (ML) and order-up-to level (OU) inventory replenishment policies. The vehicle index formulations are further improved using symmetry breaking constraints; the nonvehicle index formulations are strengthened by several cuts. A heuristic based on an adaptive large neighborhood search technique is also developed to determine initial solutions, and branch-and-cut algorithms are proposed to solve the different formulations. The results show that the vehicle index formulations are superior in finding optimal solutions, whereas the nonvehicle index formulations are generally better at providing good lower bounds on larger instances. IRP and PRP instances with up to 35 customers, three periods, and three vehicles can be solved to optimality within two hours for the ML policy. By using parallel computing, the algorithms could solve the instances for the same policy with up to 45 and 50 customers, three periods, and three vehicles for the IRP and PRP, respectively. For the more difficult IRP (PRP) under the OU policy, the algorithms could handle instances with up to 30 customers, three (six) periods, and three vehicles on a single core machine, and up to 45 (35) customers, three (six) periods, and three vehicles on a multicore machine."
59,"On the Approximate Linear Programming Approach for Network Revenue Management Problems","Tong, Chaoxu and Topaloglu, Huseyin","INFORMS JOURNAL ON COMPUTING","26","1","121-134","2014","WIN","Dynamic Programming Optimal Control;Applications;Transportation;Air;Revenue Management;Approximate Dynamic Programming","","One method to obtain high-quality bid prices for network revenue management problems involves using the approximate linear programming approach on the dynamic programming formulation of the problem. This approach ends up with a linear program whose number of constraints increases exponentially with the number of flight legs in the airline network. The linear program is solved using constraint generation, where each constraint can be generated by solving a separate integer program. The necessity to solve integer programs and the slow convergence behavior of constraint generation are generally recognized as drawbacks of this approach. In this paper, we show how to effectively eliminate these drawbacks. In particular, we establish that constraint generation can actually be carried out by solving minimum-cost network flow problems with natural integer solutions. Furthermore, using the structure of minimum-cost network flow problems, we a priori reduce the number of constraints in the linear program from exponential to linear in the number of flight legs. It turns out that the reduced linear program can be solved without using separate problems to generate constraints. The reduced linear program also provides a practically appealing interpretation. Computational experiments indicate that our results can speed up the computation time for the approximate linear programming approach by a factor ranging between 13 and 135."
60,"Dynamic Container Deployment: Two-Stage Robust Model, Complexity, and Computational Results","Shu, Jia and Song, Miao","INFORMS JOURNAL ON COMPUTING","26","1","135-149","2014","WIN","Empty Repositioning;Two-Stage Robust Optimization;Time-Expanded Network;Liner Shipping","","Containers are widely used in the shipping industry mainly because of their capability to facilitate multimodal transportation. How to effectively reposition the nonrevenue empty containers is the key to reduce the cost and improve the service in the liner shipping industry. In this paper, we propose a two-stage robust optimization model that takes into account the laden containers routing as well as the empty container repositioning, and define the robustness for this model with uncertainties in the supply and demand of the empty containers. Based on this definition, we present the robust formulations for the uncertainty sets corresponding to the l(p)-norm, where p = 1, 2, and infinity, and analyze the computational complexities for all of these formulations. The only polynomial-time solvable case corresponds to the l(1)-norm, which we use to conduct the numerical study. We compare our approach with both the deterministic model and the stochastic model for the same problem in the rolling horizon simulation environment. The computational results establish the potential practical usefulness of the proposed approach."
61,"Online Sequential Optimization with Biased Gradients: Theory and Applications to Censored Demand","Huh, Woonghee Tim and Rusmevichientong, Paat","INFORMS JOURNAL ON COMPUTING","26","1","150-159","2014","WIN","Online Optimization;Biased Gradients;Sequentially Convex Functions;Inventory Control With Censored Demand","","In this paper, we study a class of stochastic optimization problems, where although the objective functions may not be convex, they satisfy a generalization of convexity called the sequentially convex property. We focus on a setting where the distribution of the underlying uncertainty is unknown and the manager must make a decision in real time based on historical data. Because sequentially convex functions are not necessarily convex, they pose difficulties in applying standard adaptive methods for convex optimization. We propose a nonparametric algorithm based on a gradient descent method and show that the T-season average expected cost differs from the minimum cost by at most O(1/root T). Our analysis is based on a careful quantification of the bias that is inherent in gradient estimation because of the adaptive nature of the problem. We demonstrate the usefulness of the concept of sequential convexity by applying it to three canonical problems in inventory control, capacity allocation, and the lifetime buy decision, under the assumption that the manager does not know the demand distributions and has access only to historical sales (censored demand) data."
62,"Mathematical Programming Formulations and Algorithms for Discrete k-Median Clustering of Time-Series Data","Seref, Onur and Fan, Ya-Ju and Chaovalitwongse, Wanpracha Art","INFORMS JOURNAL ON COMPUTING","26","1","160-172","2014","WIN","Clustering;Optimization;Discrete K-Median;Mixed-Integer Programming;Uncoupled Bilinear Program Algorithm;Sequential Optimization;Time Series","","Discrete k-median (DKM) clustering problems arise in many real-life applications that involve time-series data sets, in which nondiscrete clustering methods may not represent the problem domain adequately. In this study, we propose mathematical programming formulations and solution methods to efficiently solve the DKM clustering problem. We develop approximation algorithms from a bilinear formulation of the discrete k-median problem using an uncoupled bilinear program algorithm. This approximation algorithm, which we refer to as DKM-L, is composed of two alternating linear programs, where one can be solved in linear time and the other is a minimum cost assignment problem. We then modify this algorithm by replacing the assignment problem with an efficient sequential algorithm for a faster approximation, which we call DKM-S. We also propose a compact exact integer formulation, DKM-I, and a more efficient network design-based exact mixed-integer formulation, DKM-M. All of our methods use arbitrary pairwise distance matrices as input. We apply our methods to simulated single-variate and multivariate random walk time-series data. We report comparative clustering performances using normalized mutual information (NMI) and solution speeds among the DKM methods we propose. We also compare our methods to other clustering algorithms that can operate with distance matrices, such as hierarchical cluster trees (HCT) and partition around medoids (PAM). We present NMI scores and classification accuracies of our DKM algorithms compared to HCT and PAM using five different distance measures on simluated data, as well as public benchmark and real-life neural time-series data sets. We show that DKM-S is much faster than HCT, PAM, and all other DKM methods and produces consistently good clustering results on all data sets."
63,"A Dynamic Programming Heuristic for the Quadratic Knapsack Problem","Fomeni, Franklin Djeumou and Letchford, Adam N.","INFORMS JOURNAL ON COMPUTING","26","1","173-182","2014","WIN","Knapsack Problems;Integer Programming;Dynamic Programming","","It is well known that the standard (linear) knapsack problem can be solved exactly by dynamic programming in O(nc) time, where n is the number of items and c is the capacity of the knapsack. The quadratic knapsack problem, on the other hand, is NP-hard in the strong sense, which makes it unlikely that it can be solved in pseudo-polynomial time. We show, however, that the dynamic programming approach to the linear knapsack problem can be modified to yield a highly effective constructive heuristic for the quadratic version. In our experiments, the lower bounds obtained by our heuristic were consistently within a fraction of a percent of optimal. Moreover, the addition of a simple local search step enabled us to obtain the optimal solution of all instances considered."
64,"The Weighted Set Covering Game: A Vaccine Pricing Model for Pediatric Immunization","Robbins, Matthew J. and Jacobson, Sheldon H. and Shanbhag, Uday V. and Behzad, Banafsheh","INFORMS JOURNAL ON COMPUTING","26","1","183-198","2014","WIN","Game Theory;Weighted Set Covering Game;Immunization;Pediatric Vaccines","","The United States pediatric vaccine manufacturing market is analyzed using a static Bertrand oligopoly pricing model that characterizes oligopolistic interactions between asymmetric firms in a homogeneous multiple product market. Firms satisfy demand by appropriately pricing and selling its given set of bundles, where each bundle contains one or more products. In analyzing the pediatric vaccine market, a bundle is a vaccine, where each vaccine contains one or more immunogenic antigens. Consumers seek to purchase at least one of each antigen at an overall minimum cost. Demand is captured by defining a weighted set covering optimization problem, with the weights (prices) controlled by firms engaged in Bertrand competition. A repeated game version of the model enables multiple interactions between firms, allowing examination of tacit collusion. An iterative improvement algorithm is defined that constructs a pure strategy Nash equilibrium (some in the limiting sense) for the static game. Sufficient conditions for the existence of pure strategy Nash equilibria are provided, indicating that this class of games always yields at least one pure strategy equilibrium. Practical results of the pediatric vaccine market analysis follow from the difference in the repeated game equilibrium prices between two combination vaccines, Pediarix (R) and Pentacel (R). Assuming the manufacturers of these vaccines agree to share the market equally with respect to volume, the equilibrium prices from the repeated game indicate a price difference of $0.86, whereas the difference in price between Pediarix (R) and Pentacel (R) for contract prices ending March 31, 2010 was $2.74. Interestingly, the subsequent public sector vaccine price list (contract prices ending March 31, 2011) shows a price difference of $0.95, with the price of Pentacel (R) actually reduced from the previous year-an unusual occurrence. The results presented in this paper suggest that a smaller price difference between these two important combination vaccines is appropriate, which is what occurred. In general, such results could serve to inform both manufacturers and purchasers on the appropriate pricing of combination vaccines, given the existence of a reasonable set of collusive agreements."
65,"Benders Decomposition, Branch-and-Cut, and Hybrid Algorithms for the Minimum Connected Dominating Set Problem","Gendron, Bernard and Lucena, Abilio and da Cunha, Alexandre Salles and Simonetti, Luidi","INFORMS JOURNAL ON COMPUTING","26","4","645-657","2014","FAL","Connected Dominating Sets;Valid Inequalities;Benders Decomposition;Branch And Cut","","We present exact algorithms for solving the minimum connected dominating set problem in an undirected graph. The algorithms are based on two approaches: a Benders decomposition algorithm and a branch-and-cut method. We also develop a hybrid algorithm that combines these two approaches. Two variants of each of the three resulting algorithms are considered: a stand-alone version and an iterative probing variant. The latter variant is based on a simple property of the problem, which states that if no connected dominating set of a given cardinality exists, then there are no connected dominating sets of lower cardinality. We present computational results on a large set of instances from the literature."
66,"A Decomposition-Based Heuristic for Collaborative Scheduling in a Network of Open-Pit Mines","Blom, Michelle L. and Burt, Christina N. and Pearce, Adrian R. and Stuckey, Peter J.","INFORMS JOURNAL ON COMPUTING","26","4","658-676","2014","FAL","Short-Term Open-Pit Mine Production Scheduling;Hybrid Optimisation;Nonlinear Programming","","We consider the short-term production scheduling problem for a network of multiple open-pit mines and ports. Ore produced at each mine is transported by rail to a set of ports and blended into signature products for shipping. Consistency in the grade and quality of production over time is critical for customer satisfaction, whereas the maximal production of blended products is required to maximise profit. In practice, short-term schedules are formed independently at each mine, tasked with achieving the grade and quality targets outlined in a medium-term plan. However, because of uncertainty in the data available to a medium-term planner and the dynamics of the mining environment, such targets may not be feasible in the short term. We present a decomposition-based heuristic for this short-term scheduling problem in which the grade and quality goals assigned to each mine are collaboratively adapted-ensuring the satisfaction of blending constraints at each port and exploiting opportunities to maximise production in the network that would otherwise be missed."
67,"A Zig-Zag Approach for Competitive Group Testing","Cheng, Yongxi and Du, Ding-Zhu and Xu, Yinfeng","INFORMS JOURNAL ON COMPUTING","26","4","677-689","2014","FAL","Fault Detection;Group Testing;Algorithms","","In many fault-detection problems, we want to identify defective items from a set of n items using the minimum number of tests. Group testing is a scenario in which each test is on a subset of items and determines whether the subset contains at least one defective item. In practice, the number d of defective items is often unknown in advance. In this paper, we present a new algorithm for the above group testing problem and prove that it has very good performance guarantee. More specifically, the number of tests used by the new algorithm is bounded from above by d log(n/d) + 3d + O(log(2) d). The new algorithm is designed based on a zig-zag approach that has not been studied before and is intuitive and easy to implement. When 0 < d < rho(0)n where rho(0) = 1 - 4/e(2) = 0.45..., which holds for most practical applications, our new algorithm has better performance guarantee than any previous best result. Computational results show that the new algorithm has very good practical performances."
68,"Improving the Performance of MIQP Solvers for Quadratic Programs with Cardinality and Minimum Threshold Constraints: A Semidefinite Program Approach","Zheng, Xiaojin and Sun, Xiaoling and Li, Duan","INFORMS JOURNAL ON COMPUTING","26","4","690-703","2014","FAL","Quadratic Programming With Semicontinuous Variables And Cardinality Constraint;Perspective Reformulation;Diagonal Decomposition;Semidefinite Program;Lagrangian Decomposition","","We consider in this paper quadratic programming problems with cardinality and minimum threshold constraints that arise naturally in various real-world applications such as portfolio selection and subset selection in regression. This class of problems can be formulated as mixed-integer 0-1 quadratic programs. We propose a new semidefinite program (SDP) approach for computing the best diagonal decomposition that gives the tightest continuous relaxation of the perspective reformulation of the problem. We also give an alternative way of deriving the perspective reformulation by applying a special Lagrangian decomposition scheme to the diagonal decomposition of the problem. This derivation can be viewed as a dual method to the convexification method employing the perspective function on semicontinuous variables. Computational results show that the proposed SDP approach can be advantageous for improving the performance of mixed-integer quadratic programming solvers when applied to the perspective reformulations of the problem."
69,"A Wide Branching Strategy for the Graph Coloring Problem","Morrison, David R. and Sauppe, Jason J. and Sewell, Edward C. and Jacobson, Sheldon H.","INFORMS JOURNAL ON COMPUTING","26","4","704-717","2014","FAL","Graph Coloring;Integer Programming;Branch-And-Price;Computational Experiments","","Branch-and-price algorithms for the graph coloring problem use an exponentially sized independent set-based integer programming formulation to produce usually tight lower bounds to enable more aggressive pruning in the branch-and-bound tree. One major problem inherent to any branch-and-price scheme for graph coloring is that to avoid destroying the pricing problem structure during column generation, difficult-to-implement branching rules that modify the underlying graph must be used. This paper proposes an alternative branching strategy that does not change the graph to solve the pricing problem but rather modifies the search tree to require fewer calls to difficult instances of the pricing problem. This approach, called wide branching, generates many subproblems at each node in the branch-and-price tree; this significantly reduces the length of any path through the search tree. In contrast, traditional deep branching only creates two subproblems per node, assigning a variable to either 0 or 1. A delayed branching procedure is introduced that prevents the branching factor at any particular node from growing too large in this scheme. Finally, computational results are presented that show the wide branching strategy to be competitive with state-of-the-art graph coloring solvers."
70,"A Linear-Programming Approximation of AC Power Flows","Coffrin, Carleton and Van Hentenryck, Pascal","INFORMS JOURNAL ON COMPUTING","26","4","718-734","2014","FAL","Dc Power Flow;Ac Power Flow;Lp Power Flow;Polyhedral Relaxation;Power System Analysis;Capacitor Placement;Power System Restoration","","Linear active-power-only power flow approximations are pervasive in the planning and control of power systems. However, AC power systems are governed by a system of nonlinear nonconvex power flow equations. Existing linear approximations fail to capture key power flow variables, including reactive power and voltage magnitudes, both of which are necessary in many applications that require voltage management and AC power flow feasibility. This paper proposes novel linear-programming models (the LPAC models) that incorporate reactive power and voltage magnitudes in a linear power flow approximation. The LPAC models are built on a polyhedral relaxation of the cosine terms in the AC equations as well as Taylor approximations of the remaining nonlinear terms. Experimental comparisons with AC solutions on a variety of standard IEEE and Matpower benchmarks show that the LPAC models produce accurate values for active and reactive power, phase angles, and voltage magnitudes. The potential benefits of the LPAC models are illustrated on two proof-of-concept studies in power restoration and capacitor placement."
71,"Chance-Constrained Binary Packing Problems","Song, Yongjia and Luedtke, James R. and Kuecuekyavuz, Simge","INFORMS JOURNAL ON COMPUTING","26","4","735-747","2014","FAL","Chance-Constrained Stochastic Programming;Integer Programming","","We consider a class of packing problems with uncertain data, which we refer to as the chance-constrained binary packing problem. In this problem, a subset of items is selected that maximizes the total profit so that a generic packing constraint is satisfied with high probability. Interesting special cases of our problem include chance-constrained knapsack and set packing problems with random coefficients. We propose a problem formulation in its original space based on the so-called probabilistic covers. We focus our solution approaches on the special case in which the uncertainty is represented by a finite number of scenarios. In this case, the problem can be formulated as an integer program by introducing a binary decision variable to represent feasibility of each scenario. We derive a computationally efficient coefficient strengthening procedure for this formulation, and demonstrate how the scenario variables can be efficiently projected out of the linear programming relaxation. We also study how methods for lifting deterministic cover inequalities can be leveraged to perform approximate lifting of probabilistic cover inequalities. We conduct an extensive computational study to illustrate the potential benefits of our proposed techniques on various problem classes."
72,"Efficient Use of Semidefinite Programming for Selection of Rotamers in Protein Conformations","Burkowski, Forbes and Cheung, Yuen-Lam and Wolkowicz, Henry","INFORMS JOURNAL ON COMPUTING","26","4","748-766","2014","FAL","Protein Structures;Side Chain Positioning;Semidefinite Programming","","Determination of a protein's structure can facilitate an understanding of how the structure changes when that protein combines with other proteins or smaller molecules. In this paper we study a semidefinite programming (SDP) relaxation of the (NP-hard) side chain positioning problem presented in Chazelle et al. [Chazelle B, Kingsford C, Singh M (2004) A semidefinite programming approach to side chain positioning with new rounding strategies. INFORMS J. Comput. 16:380-392]. We show that the Slater constraint qualification (strict feasibility) fails for the SDP relaxation. We then show the advantages of using facial reduction to regularize the SDP. In fact, after applying facial reduction, we have a smaller problem that is more stable both in theory and in practice. We include cutting planes to improve the rounded SDP approximate solutions."
73,"Lot Sizing with Piecewise Concave Production Costs","Koca, Esra and Yaman, Hande and Akturk, M. Selim","INFORMS JOURNAL ON COMPUTING","26","4","767-779","2014","FAL","Lot Sizing;Piecewise Concave Production Cost;Quantity Discounts;Subcontracting;Dynamic Programming","","We study the lot-sizing problem with piecewise concave production costs and concave holding costs. This problem is a generalization of the lot-sizing problem with quantity discounts, minimum order quantities, capacities, overloading, subcontracting or a combination of these. We develop a dynamic programming algorithm to solve this problem and answer an open question in the literature: we show that the problem is polynomially solvable when the breakpoints of the production cost function are time invariant and the number of breakpoints is fixed. For the special cases with capacities and subcontracting, the time complexity of our algorithm is as good as the complexity of algorithms available in the literature. We report the results of a computational experiment where the dynamic programming is able to solve instances that are hard for a mixed-integer programming solver. We enhance the mixed-integer programming formulation with valid inequalities based on mixing sets and use a cut-and-branch algorithm to compute better bounds. We propose a state space reduction-based heuristic algorithm for large instances and show that the solutions are of good quality by comparing them with the bounds obtained from the cut-and-branch."
74,"Computational Experiments with Cross and Crooked Cross Cuts","Dash, Sanjeeb and Guenluek, Oktay and Vielma, Juan Pablo","INFORMS JOURNAL ON COMPUTING","26","4","780-797","2014","FAL","Mixed Integer Programming;Cutting Planes;Elementary Closures","","In this paper, we study whether cuts obtained from two simplex tableau rows at a time can strengthen the bounds obtained by Gomory mixed-integer (GMI) cuts based on single tableau rows. We also study whether cross and crooked cross cuts, which generalize split cuts, can be separated in an effective manner for practical mixed-integer programs (MIPs) and can yield a nontrivial improvement over the bounds obtained by split cuts. We give positive answers to both these questions for MIPLIB 3.0 problems. Cross cuts are a special case of the t-branch split cuts studied by Li and Richard [Li Y, Richard J-PP (2008) Cook, Kannan and Schrijvers's example revisited. Discrete Optim. 5:724-734]. Split cuts are 1-branch split cuts, and cross cuts are 2-branch split cuts. Crooked cross cuts were introduced by Dash, Gunluk, and Lodi [Dash S, Gunluk O, Lodi A (2010) MIR closures of polyhedral sets. Math Programming 121:33-60] and were shown to dominate cross cuts by Dash, Gunluk, and Molinaro [Dash S, Gunluk O, Molinaro M (2012b) On the relative strength of different generalizations of split cuts. IBM Technical Report RC25326, IBM, Yorktown Heights, NY]."
75,"Integrated Facility Layout Design and Flow Assignment Problem Under Uncertainty","Zhao, Yifei and Wallace, Stein W.","INFORMS JOURNAL ON COMPUTING","26","4","798-808","2014","FAL","Facility Layout;Random Demand;Machine Capacities","","The facility layout problem is the problem of assigning facilities to locations. We study the case of limited machine capacity and hence multiple copies of each machine type. We take into account stochastic demand, described by several types of jobs (i.e., sequences of machine types), each with an uncertain demand level. We develop a heuristic framework allowing us to find good solutions to the stochastic case whenever it is possible to solve the corresponding deterministic quadratic assignment problem (QAP), exactly or heuristically. Athough the QAP is a very hard problem in its own right, our approach allows randomness (and hence relevance) to be added at only a marginal increase in computational costs."
76,"Districting for Arc Routing","Butsch, Alexander and Kalcsics, Joerg and Laporte, Gilbert","INFORMS JOURNAL ON COMPUTING","26","4","809-824","2014","FAL","Districting;Arc Routing;Multicriteria;Adaptive Large Neighborhood Search;Tabu Search","","This paper proposes a heuristic for districting problems arising in an arc routing context. The aim is to design districts by amalgamating edges of a graph as opposed to cells. Solutions must satisfy two hard criteria (complete and exclusive assignment as well as connectedness) and several soft criteria (balance, small deadheading, local compactness, and global compactness). The latter criteria are amalgamated into a weighted objective. The proposed heuristic applies a construction procedure followed by a tabu search improvement phase in which several subroutines are defined and selected according to a roulette wheel mechanism, as in adaptive large neighborhood search. Extensive tests conducted on instances derived from real-world street data confirm the efficiency of the proposed methodology."
77,"Two-Stage Decomposition Algorithms for Single Product Maritime Inventory Routing","Papageorgiou, Dimitri J. and Keha, Ahmet B. and Nemhauser, George L. and Sokol, Joel","INFORMS JOURNAL ON COMPUTING","26","4","825-847","2014","FAL","Aggregation;Decomposition;Deterministic Inventory Routing;Lot Sizing;Maritime Transportation;Mixed-Integer Linear Programming","","We present two decomposition algorithms for single product deep-sea maritime inventory routing problems (MIRPs) that possess a core substructure common in many real-world applications. The problem involves routing vessels, each belonging to a particular vessel class, between loading and discharging ports, each belonging to a particular region. Our algorithms iteratively solve a MIRP by zooming out and then zooming in on the problem. Specifically, in the zoomed out phase, we solve a first-stage master problem in which aggregate information about regions and vessel classes is used to route vessels between regions, while only implicitly considering inventory and capacity requirements, berth limits, and other side constraints. In the zoomed in phase, we solve a series of second-stage subproblems, one for each region, in which individual vessels are routed through each region and load and discharge quantities are determined. Computational experience shows that an integrated approach that combines these two algorithms is vastly superior to solving the problem directly with a commercial mixed-integer programming solver."
78,"Estimating Sensitivities of Portfolio Credit Risk Using Monte Carlo","Hong, L. Jeff and Juneja, Sandeep and Luo, Jun","INFORMS JOURNAL ON COMPUTING","26","4","848-865","2014","FAL","Sensitivity Estimation;Monte Carlo Simulation;Conditioning Techniques","","Estimating the sensitivities of portfolio credit risk with respect to the underlying model parameters is an important problem for credit risk management. In this paper, we consider performance measures that may be expressed as an expectation of a performance function of the portfolio credit loss and derive closed-form expressions of its sensitivities to the underlying parameters. Our results are applicable to both idiosyncratic and macroeconomic parameters and to performance functions that may or may not be continuous. Based on the closed-form expressions, we first develop an estimator for sensitivities, in a general framework, that relies on the kernel method for estimation. The unified estimator allows us to further derive two general forms of the estimators by using conditioning techniques on either idiosyncratic or macroeconomic factors. We then specialize our results to develop faster estimators for three popular classes of models used for portfolio credit risk: latent variable models, Bernoulli mixture models, and doubly stochastic models."
79,"Role Refinement in Access Control: Model and Analysis","Xia, Hao and Dawande, Milind and Mookerjee, Vijay","INFORMS JOURNAL ON COMPUTING","26","4","866-884","2014","FAL","Software Systems;Role-Based Access Control;Role Refinement;Approximation Algorithms","","Access control mechanisms in software systems administer user privileges by granting users permission to perform certain operations while denying unauthorized access to others. Such mechanisms are essential to ensure that important business functions in an organization are conducted securely and smoothly. Currently, the dominant access control approach in most major software systems is role-based access control. In this approach, permissions are first assigned to roles, and users acquire permissions by becoming members of certain roles. However, given the dynamic nature of organizations, a fixed set of roles usually cannot meet the demands that users (existing or new) have to conduct business. The typical response to this problem is to myopically create new roles to meet immediate demand that cannot be satisfied by an existing set of roles. This ad hoc creation of roles invariably leads to a proliferation in the number of roles with the accompanying administrative overhead. Based on discussions with practitioners, we propose a role refinement scheme that reconstructs a system of roles to reduce the cost of role management. We first show that the role-refinement problem is strongly NP-hard and then provide two polynomial-time approximation algorithms (a greedy algorithm and a randomized rounding algorithm) and establish their performance guarantees. Finally, numerical experiments-based on a real data set from a firm's enterprise resource planning system-are conducted to demonstrate the applicability and performance of our refinement scheme."
80,"Computing the Distribution for the Number of Renewals with Bulk Arrivals","Fisher, Brent and Chaudhry, Mohan","INFORMS JOURNAL ON COMPUTING","26","4","885-892","2014","FAL","Continuous Time Renewal Theory;Numerical Results;Asymptotic Results;Bulk Arrivals;Laplace Transform","","The distribution of the number of renewals for bulk arrivals in continuous time is calculated using an algorithm employed through MAPLE software. These numerical results are acquired by considering rational as well as nonrational Laplace transforms and Pade-approximated Laplace transforms for the distributions of interrenewal times. Further, through the use of Laplace transforms an elegant solution to determine the asymptotic results for the first and second moments of the number of bulk renewals is presented. These derivations help validate the numerical results and are an extension of previous work by the authors regarding single-arrival renewal theory in discrete time."
81,"Chance-Constrained Optimization of Reliable Fixed Broadband Wireless Networks","Classen, Grit and Koster, Arie M. C. A. and Coudert, David and Nepomuceno, Napoleao","INFORMS JOURNAL ON COMPUTING","26","4","893-909","2014","FAL","Fixed Wireless Networks;Capacitated Network Design;Network Reliability;Chance-Constrained Programming;Integer Programming","","In this paper, we extend our former investigation on conceiving reliable fixed point-to-point wireless networks under outage probability constraints. We consider the problem of determining the minimum cost bandwidth assignment of a network, while guaranteeing a reliability level of the solution. If the optimal bandwidth assignment and routing of traffic demands are accomplished, the reliability criterion requires that network flows remain feasible with high probability, regarding that the performance of microwave links is prone to variations due to external factors, e.g., weather. We introduce a chance-constrained programming approach to tackle this problem and we present reformulations to standard integer linear programming models, including a budget-constrained formulation. To improve the solving performance, we propose new valid inequalities and a primal heuristic. Computational results present a performance analysis of the valid inequalities and the heuristic. Further, the outperformance of the novel model compared to more traditional approaches is documented."
82,"An Integer-Programming-Based Approach to the Close-Enough Traveling Salesman Problem","Behdani, Behnam and Smith, J. Cole","INFORMS JOURNAL ON COMPUTING","26","3","415-432","2014","SUM","Close-Enough Traveling Salesman Problem;Geometric Routing Problems;Mixed-Integer Programming;Computational Geometry;Discretization","","W e address a variant of the Euclidean traveling salesman problem known as the close-enough traveling salesman problem (CETSP), where the traveler visits a node if it enters a compact neighborhood set of that node. We formulate a mixed-integer programming model based on a discretization scheme for the problem. Both lower and upper bounds on the optimal CETSP tour length can be derived from the solution of this model, and the quality of the bounds obtained depends on the granularity of the discretization scheme. Our approach first develops valid inequalities that enhance the bound and solvability of this formulation. We then provide two alternative formulations, one that yields an improved lower bound on the optimal CETSP tour length, and one that greatly improves the solvability of the original formulation by recasting it as a two-stage problem amenable to decomposition. Computational results demonstrate the effectiveness of the proposed methods."
83,"Association Rules for Recommendations with Multiple Items","Ghoshal, Abhijeet and Sarkar, Sumit","INFORMS JOURNAL ON COMPUTING","26","3","433-448","2014","SUM","Data Mining;Disjunctive Rules;Personalization;Bounce Rate;Collaborative Filtering;Matrix Factorization","","In Web-based environments, a site has the ability to recommend multiple items to a customer in each interaction. Traditionally, rules used to make recommendations either have single items in their consequents or have conjunctions of items in their consequents. Such rules may be of limited use when the site wishes to maximize the likelihood of the customer being interested in at least one of the items recommended in each interaction (with a session comprising multiple interactions). Rules with disjunctions of items in their consequents and conjunctions of items in their antecedents are more appropriate for such environments. We refer to such rules as disjunctive consequent rules. We have developed a novel mining algorithm to obtain such rules. We identify several properties of disjunctive consequent rules that can be used to prune the search space when mining such rules. We demonstrate that the pruning techniques drastically reduce the proportion of disjunctive rules explored, with the pruning effectiveness increasing rapidly with an increase in the number of items to be recommended. We conduct experiments to compare the use of disjunctive rules with that of traditional (conjunctive) association rules on several real-world data sets and show that the accuracies of recommendations made using disjunctive consequent rules are significantly higher than those made using traditional association rules. We also compare the disjunctive consequent rules approach with two other state-of-the-art recommendation approaches-collaborative filtering and matrix factorization. Its performance is generally superior to both these techniques on two transactional data sets. The relative performance on a very sparse click-stream data set is mixed. Its performance is inferior to that of collaborative filtering and superior to that of matrix factorization for that data set."
84,"On the Lattice Structure of a Special Class of Multiple Recursive Random Number Generators","L'Ecuyer, Pierre and Simard, Richard","INFORMS JOURNAL ON COMPUTING","26","3","449-460","2014","SUM","Random Number Generators;Multiple Recursive Generators;Lattice Structure;Simulation","","We examine some properties of the points produced by certain classes of long-period linear multiple recursive random number generators proposed by L.-Y. Deng and his co-authors in several papers. These generators have their parameters selected in special ways to make the implementation faster. We show that as a result, the points produced by these generators have a poor lattice structure, and a poor initialization of the state can have long-lasting impact, because of the limited diffusion capacity of the recurrence."
85,"Effective Active Learning Strategies for the Use of Large-Margin Classifiers in Semantic Annotation: An Optimal Parameter Discovery Perspective","Xu, Kaiquan and Liao, Stephen Shaoyi and Lau, Raymond Y. K. and Zhao, J. Leon","INFORMS JOURNAL ON COMPUTING","26","3","461-483","2014","SUM","Active Learning;Machine Learning;Data Mining;Optimization;Business Intelligence","","Classical supervised machine learning techniques have been explored for semantically annotating unstructured textual data such as consumers' comments archived at social media websites to extract business intelligence. However, these techniques often require a large number of manually labeled training examples to produce accurate annotations. Several active learning approaches that are designed based on probabilistic sequence models have been explored to minimize the number of labeled training examples for semantic annotation tasks. Recent research has shown that large-margin classifiers are viable alternatives to automated semantic annotation, given their strong generalization capabilities and the ability to process high-dimensional data. However, the existing active learning methods that are designed for probabilistic sequence models cannot be easily adapted and applied to large-margin classifiers. The main contribution of this paper is the development of novel active learning methods for large-margin classifiers to fill the aforementioned research gap. In particular, we propose an innovative perspective of taking active learning as a search of optimal parameters for large-margin classifiers. A rigorous evaluation involving two benchmark tests and an empirical test based on real-world data extracted from Amazon.com reveals that the proposed active learning methods can train effective classifiers with significantly fewer training examples while achieving similar annotation performance, compared to a typical state-of-the-art classifier that only uses several labeled training examples. More specifically, one of our proposed active learning methods can reduce the number of training examples by 19.74% at the 68% level of F 1 when compared to the best baseline method, as evaluated based on the Amazon data set. Our research opens the door to the application of intelligent semantic annotation techniques to support real-world applications such as automatically analyzing consumer comments for customer relationship management."
86,"Regression Models Augmented with Direct Stochastic Gradient Estimators","Fu, Michael C. and Qu, Huashuai","INFORMS JOURNAL ON COMPUTING","26","3","484-499","2014","SUM","Regression;Stochastic Gradient Estimation;Response Surface Methodology;Stochastic Simulation;Perturbation Analysis","","Traditional regression assumes that the only data available are measurements of the value of the dependent variable for each combination of values for the independent variable. However, in many settings in stochastic (Monte Carlo) simulation, directly estimated derivative information is also available via techniques such as perturbation analysis or the likelihood ratio method. In this paper, we investigate potential modeling improvements that can be achieved by exploiting this additional gradient information in the regression setting. Using least squares and maximum likelihood estimation, we propose various direct gradient augmented regression (DiGAR) models that incorporate direct gradient estimators, starting with a one-dimensional independent variable and then extending to multidimensional input. For some special settings, we are able to characterize the variance of the estimated parameters in DiGAR and compare them analytically with the standard regression model. For a more typical stochastic simulation setting, we investigate the potential effectiveness of the augmented model by comparing it with standard regression in fitting a functional relationship for a simple queueing model, including both one-dimensional and four-dimensional examples. The preliminary empirical results are quite encouraging, as they indicate how DiGAR can capture trends that the standard model would miss. Even in queueing examples where there is a high correlation between the output and the gradient estimators, the basic DiGAR model that does not explicitly account for these correlations performs significantly better than the standard regression model."
87,"Multiobjective Interacting Particle Algorithm for Global Optimization","Mete, Huseyin Onur and Zabinsky, Zelda B.","INFORMS JOURNAL ON COMPUTING","26","3","500-513","2014","SUM","Multiobjective Optimization;Random Search Algorithms;Global Optimization;Simulated Annealing;Markov Chain Monte Carlo Sampling;Pareto Optimality;Efficient Frontier;Population-Based Algorithms;Pattern Hit-And-Run","","We develop a population-based algorithm for the optimization of multiple, nonconvex, nondifferentiable, and possibly discontinuous objective functions. The algorithm employs Markov kernels, Hit-and-Run, and Pattern Hit-and-Run for exploration of the solution space and Pareto ordering rules for the selection of the population and to update the approximate Pareto optimal list. Our multiobjective interacting particle algorithm asymptotically converges to the stationary distribution associated with the Pareto ordering rules. We present numerical benchmark results on test problems."
88,"Enhanced Models for a Mixed Arrival-Departure Aircraft Sequencing Problem","Ghoniem, Ahmed and Sherali, Hanif D. and Baik, Hojong","INFORMS JOURNAL ON COMPUTING","26","3","514-530","2014","SUM","Sequencing;Runway Operations;Valid Inequalities;Reformulation-Linearization Technique (Rlt);Mixed-Integer Programming","","This paper addresses the static aircraft sequencing problem over a mixed-mode single runway (or closely interacting parallel runways), which commonly constitutes a critical bottleneck at airports. In contrast with disjunctive formulations, our modeling approach takes advantage of the underlying structure of an asymmetric traveling salesman problem with time-windows. This enables the development of efficient preprocessing and probing procedures, and motivates the derivation of several classes of valid inequalities along with partial convex hull representations to enhance problem solvability via tighter reformulations. The lifted model is further embedded within the framework of two proposed heuristics that are compared against the traditional first-come first-served (FCFS) heuristic with landing priority: an optimized FCFS policy (OFCFS) and a threshold-based suboptimized heuristic (TSH) with an a priori fixing of the relative order of aircraft that are sufficiently time-separated. Computational results using real data based on Doha International Airport (DOH) as well as simulated instances are reported to demonstrate the efficacy of the proposed exact and heuristic solution methods. In particular, for the DOH instances, heuristics OFCFS and TSH achieved an attractive runway utilization (4.3% and 5.0% makespan reduction, respectively, over the base FCFS policy with landing priority), while exhibiting limited aircraft position deviations (0.45 and 0.49 deviations on average, respectively, from the base FCFS positions with landing priority, with similar results being obtained for the simulated instances). The superiority of the proposed optimization models over previous disjunctive formulations is also demonstrated for challenging problem instances, resulting in over 50% CPU savings for the larger instances in our test-bed."
89,"Covering Linear Programming with Violations","Qiu, Feng and Ahmed, Shabbir and Dey, Santanu S. and Wolsey, Laurence A.","INFORMS JOURNAL ON COMPUTING","26","3","531-546","2014","SUM","Integer Programming;Linear Programming","","We consider a class of linear programs involving a set of covering constraints of which at most k are allowed to be violated. We show that this covering linear program with violation is strongly N P-hard. To improve the performance of mixed-integer programming-based schemes for these problems, we introduce and analyze a coefficient strengthening scheme, adapt and analyze an existing cutting plane technique, and present a branching technique. Through computational experiments, we empirically verify that these techniques are significantly effective in improving solution times over the CPLEX mixed-integer programming solver. In particular, we observe that the proposed schemes can cut down solution times from as much as six days to under four hours."
90,"Complexity and Approximation Results for the Balance Optimization Subset Selection Model for Causal Inference in Observational Studies","Sauppe, Jason J. and Jacobson, Sheldon H. and Sewell, Edward C.","INFORMS JOURNAL ON COMPUTING","26","3","547-566","2014","SUM","Observational Studies;Causal Inference;Comparative Effectiveness Research;Matching;Fine Balance;Balance Optimization;Mixed Integer Programming;Computational Complexity;Approximation Algorithms","","Matching is widely used in the estimation of treatment effects in observational studies. However, the matching paradigm may be too restrictive in many cases because exact matches often do not exist in the available data. One mechanism for overcoming this issue is to relax the requirement of exact matching on some or all of the covariates (attributes that may affect the response to treatment) to a requirement of balance on the covariate distributions for the treatment and control groups. The balance optimization subset selection (BOSS) model can be used to identify a control group featuring optimal covariate balance. This paper explores the relationship between the matching and BOSS models and shows how BOSS subsumes matching. Complexity and approximation results are presented for the resulting models. Computational results demonstrate some of the important trade-offs between matching and BOSS."
91,"Solving a Multigroup Mixed-Integer Programming-Based Constrained Discrimination Model","Brooks, J. Paul and Lee, Eva K.","INFORMS JOURNAL ON COMPUTING","26","3","567-585","2014","SUM","Constrained Discrimination;Integer Programming;Classification","","Solution methods are presented for a mixed-integer program (MIP) associated with a method for constrained discrimination. In constrained discrimination, one wishes to maximize the probability of correct classification subject to intergroup misclassification limits. The misclassification limits are satisfied by allowing the placement of observations in a reserved judgment group. The approach investigated here involves modifying a standard classification rule by solving an optimization problem. A polynomial-time algorithm for solving the problem is given for two-group discrimination. The decision problem upon which the optimization problem is based is shown to be NP complete for a general number of groups. For three or more groups, an MIP is used to solve the problem. Solution methods incorporating cutting planes from conflict graphs are presented for solving instances in a branch-and-bound framework. These methods are used to enhance industry-standard software, and are shown to provide as much as a 20-fold reduction in computational time over the software alone. Computational experiments illustrate the tradeoff between misclassification rates and reserved judgment rates. Some base classifiers are not well suited to be modified to a constrained discrimination rule. The method for constrained discrimination studied here performs particularly well in the presence of class imbalance. For certain other data sets, however, the method is outperformed by a simple centroid method."
92,"Domain Adaptation for Sentiment Classification in Light of Multiple Sources","Fang, Fang and Dutta, Kaushik and Datta, Anindya","INFORMS JOURNAL ON COMPUTING","26","3","586-598","2014","SUM","Sentiment Analysis;Business Intelligence;Domain Adaptation","","Sentiment classification is one of the most extensively studied problems in sentiment analysis, and supervised learning methods, which require labeled data for training, have been proven quite effective. However, supervised methods assume that the training domain and the testing domain share the same distribution; otherwise, accuracy drops dramatically. Although this does not pose problems when training data are readily available, in some circumstances, labeled data is quite expensive to acquire. For instance, if we want to detect sentiment from Tweets or Facebook comments, the only way to acquire is to manually label it, and this is prohibitively burdensome and time-consuming. In this paper, we propose a hybrid approach that integrates the sentiment information from source-domain labeled data and a set of preselected sentiment words to solve this problem. The experimental results suggest that our method statistically outperforms the state of the art and even, in some cases, surpasses the in-domain gold standard."
93,"Optimal Implantable Cardioverter Defibrillator (ICD) Generator Replacement","Khojandi, Anahita and Maillart, Lisa M. and Prokopyev, Oleg A. and Roberts, Mark S. and Brown, Timothy and Barrington, William W.","INFORMS JOURNAL ON COMPUTING","26","3","599-615","2014","SUM","Optimal Replacement;Markov Decision Processes;Threshold Policy","","Implantable cardioverter defibrillators ( ICDs) include small, battery-powered generators, the longevity of which depends on a patient's rate of consumption. Generator replacement, however, involves risks, including death. Hence, a trade-off exists between prematurely exposing the patient to these risks and allowing for the possibility that the device is unable to deliver therapy when needed. Currently, replacements are performed using a one-size-fits-all approach. Here, we develop a Markov decision process model to determine patient-specific optimal replacement policies as a function of patient age and the remaining battery capacity. We analytically establish that the optimal policy is of threshold-type in the remaining capacity, but not necessarily in patient age. Based on clinical data, we conduct a large computational study that suggests that under the optimal policy, patients undergoing initial implantation at age 30-40, 41-60, and 61-80 see an approximate decrease in the total expected number of replacements of 8%-14%, 8%-15% and 8%-19%, respectively, while achieving the same or greater expected lifetime."
94,"On Convergence Rates of Convex Regression in Multiple Dimensions","Lim, Eunji","INFORMS JOURNAL ON COMPUTING","26","3","616-628","2014","SUM","Nonparametric Regression;Multidimensional Convex Functions;Convergence Rates;Asymptotic Properties","","We consider a least squares estimator for estimating a convex function f({*}): [0,1](d) -> R with bounded su-gradients. A rate at which the sum of squared differences between the estimator and the true function f({*}) converges to zero is computed. This work sheds light on computing the convergence rate of the multidimenstional convex regression estimator."
95,"A Game-Theoretic Approach to Graph Clustering","Mandala, Supreet and Kumara, Soundar and Chatterjee, Kalyan","INFORMS JOURNAL ON COMPUTING","26","3","629-643","2014","SUM","Networks;Community Detection;Overlapping Clusters;Game Theory;Parallel Algorithms;Graph Mining","","The last decade has witnessed an explosion in the modeling of complex systems. Predominantly, graphs are used to represent these systems. The problem of detecting overlapping clusters in graphs is of utmost importance. We present a novel definition of overlapping clusters. A noncooperative game is proposed such that the equilibrium conditions of the game correspond to the clusters in the graph. Several properties of the game are analyzed and exploited to show the existence of a pure Nash equilibrium (NE) and compute it effectively. We present two algorithms to compute NE and prove their convergence. Empirically, the running times of both algorithms are nearly linear in the number of edges. Also, one of the algorithms can be readily parallelized, making it scalable. Finally, our approach is compared with existing overlapping cluster detection algorithms and validated on several artificial and real data sets."
96,"Optimizing the Layout of Proportional Symbol Maps: Polyhedra and Computation","Kunigami, Guilherme and de Rezende, Pedro J. and de Souza, Cid C. and Yunes, Tallys","INFORMS JOURNAL ON COMPUTING","26","2","199-207","2014","SPR","Computational Geometry;Integer Programming;Cartography;Symbol Maps","","Proportional symbol maps are a cartographic tool to assist in the visualization and analysis of quantitative data associated with specific locations, such as earthquake magnitudes, oil well production, and temperature at weather stations. As the name suggests, symbol sizes are proportional to the magnitude of the physical quantities that they represent. We present two novel integer linear programming (ILP) models to solve this computational geometry problem: how to draw opaque disks on a map so as to maximize the total visible border of all disks. We focus on drawings obtained by layering symbols on top of each other, also known as stacking drawings. We introduce decomposition techniques as well as several families of facet-defining inequalities, which are used to strengthen the ILP models that are supplied to a commercial solver. We demonstrate the effectiveness of our approach through a series of computational experiments using hundreds of instances generated from real demographic and geophysical data sets. To the best of our knowledge, we are the first to use ILP to tackle this problem, and the first to provide provably optimal symbol maps for those data sets."
97,"A Tree-Based Contrast Set-Mining Approach to Detecting Group Differences","Liu, Hongyan and Yang, Yinghui (Catherine) and Chen, Zhuohua and Zheng, Yong","INFORMS JOURNAL ON COMPUTING","26","2","208-221","2014","SPR","Data Mining;Group Difference Detection;Contrast Set Mining","","Understanding differences between groups in a data set is one of the fundamental tasks in data analysis. As relevant applications accumulate, data-mining methods have been developed to specifically address the problem of group difference detection. Contrast set mining discovers group differences in the form of conjunction of feature-value pairs or items. In this paper, we incorporate absolute difference, relative difference, and statistical significance in our definition of a group difference, and develop a novel method named DIFF that uses the prefix-tree structure to compress the search space, follows a tree traversal procedure to discover the complete set of significant group differences, and employs efficient pruning strategies to expedite the search process. We conducted comprehensive experiments to compare our method with existing methods on completeness of results, pruning efficiency, and computational efficiency. The experiments demonstrate that our method guarantees completeness of results and achieves higher pruning efficiency and computational efficiency compared to STUCCO. In addition, our definition of group difference is more general than STUCCO. Our method is more effective than traditional approaches, such as classification trees, in discovering the complete set of significant group differences."
98,"On the Practical Strength of Two-Row Tableau Cuts","Dey, Santanu S. and Lodi, Andrea and Tramontani, Andrea and Wolsey, Laurence A.","INFORMS JOURNAL ON COMPUTING","26","2","222-237","2014","SPR","Mixed Integer Programming;Cutting Planes;Lattice-Free Sets;Computational Investigation","","Following the flurry of recent theoretical work on cutting planes from two-row mixed integer group relaxations of a linear programming tableau, we report on computational tests to evaluate the strength of two-row cuts based on lattice-free triangles having more than one integer point on one side. A heuristic procedure to generate such triangles (referred to in the literature as type 2 triangles) is presented, and then the coefficients of the integer variables are tightened by lifting. To test the effectiveness of triangle cuts, we compare the gap closed using Gomory mixed integer cuts for one round, the gap closed in one round using all the triangle cuts generated by our heuristic, and the gap closed by a small number of two-row split cuts. Our tests are carried out on randomly generated instances designed to represent different problem features by varying the number of integer nonbasic variables, bounds, nonnegativity constraints, and density, as well as on the classical MIPLIB instances. The outcome of this computational analysis is some insight into key characteristics of MIP instances whose presence makes two-row triangle cuts computationally effective. In particular, it appears to be necessary that the tableau row pairs are dense, and more subjectively that the nonbasic continuous variables are important. Unfortunately these characteristics seem to be rarely present among real-life instances, and more specifically the tableau rows of the MIPLIB instances are far from dense."
99,"Cost-Sensitive Decision Tree Induction with Label-Dependent Late Constraints","Kao, Hung-Pin and Tang, Kwei","INFORMS JOURNAL ON COMPUTING","26","2","238-252","2014","SPR","Classification;Decision Tree;Cost- And Time-Sensitive Learning;Constrained Data Mining;Classification Time Constraint","","Completion time requirements are often imposed on a classification task. In practice, the desired completion time for classifying a subject may depend on its label (target) value. For example, a timely diagnosis is important for an illness that requires immediate medical attention. It is common in medical diagnoses, therefore, to set completion times based on the severity level of the illness. In this study, we use label-dependent completion time requirements to formulate a new classification problem for cost-sensitive decision tree induction by adding late constraints to control the rate of tardy classifications for each label value. Adding the late constraints generalizes and enriches the decision tree induction problem, but also poses a challenge to developing an efficient solution algorithm because the conventional approach based on the divide-and-conquer strategy cannot be used. We develop a novel algorithm that relaxes the late constraints and iteratively solves a series of cost-sensitive decision tree problems under systematically-generated late penalties. The results of an extensive numerical experiment show that the proposed algorithm is effective in finding the optimal or a near-optimal solution."
100,"Optimization Bounds from Binary Decision Diagrams","Bergman, David and Cire, Andre A. and van Hoeve, Willem-Jan and Hooker, J. N.","INFORMS JOURNAL ON COMPUTING","26","2","253-268","2014","SPR","Binary Decision Diagrams;Independent Set;Relaxations","","We explore the idea of obtaining bounds on the value of an optimization problem from a discrete relaxation based on binary decision diagrams (BDDs). We show how to construct a BDD that represents a relaxation of a 0-1 optimization problem, and how to obtain a bound for a separable objective function by solving a shortest (or longest) path problem in the BDD. As a test case we apply the method to the maximum independent set problem on a graph. We find that for most problem instances, it delivers tighter bounds in less computation time, than state-of-the-art integer programming software obtains by solving a continuous relaxation augmented with cutting planes."
101,"Constructing Discrete Unbounded Distributions with Gaussian-Copula Dependence and Given Rank Correlation","Avramidis, Athanassios N.","INFORMS JOURNAL ON COMPUTING","26","2","269-279","2014","SPR","Statistics;Multivariate Distribution;Unbounded Discrete Distribution;Correlation;Gaussian Copula","","A random vector X with given univariate marginals can be obtained by first applying the normal distribution function to each coordinate of a vector Z of correlated standard normals to produce a vector U of correlated uniforms over (0, 1) and then transforming each coordinate of U by the relevant inverse marginal. One approach to fitting requires, separately for each pair of coordinates of X, the rank correlation, r(rho), or the product-moment correlation, r(L)(rho), where rho is the correlation of the corresponding coordinates of Z, to equal some target r{*}. We prove the existence and uniqueness of a solution for any feasible target, without imposing restrictions on the marginals. For the case where r(rho) cannot be computed exactly because of an infinite discrete support, the relevant infinite sums are approximated by truncation, and lower and upper bounds on the truncation errors are developed. With a function (r) over tilde(rho) defined by the truncated sums, a bound on the error r(rho{*}) - r{*} is given, where rho{*} is a solution to (r) over tilde(rho{*}) = r{*}. Based on this bound, an algorithm is proposed that determines truncation points so that the solution has any specified accuracy. The new truncation method has potential for significant work reduction relative to truncating heuristically, largely because as required accuracy decreases, so does the number of terms in the truncated sums. This is quantified with examples. The gain appears to increase with the heaviness of tails."
102,"An Approximation Algorithm for the Continuous k-Medians Problem in a Convex Polygon","Carlsson, John Gunnar and Jia, Fan and Li, Ying","INFORMS JOURNAL ON COMPUTING","26","2","280-289","2014","SPR","Approximation Algorithms;Geometric Algorithms;Continuous Location Theory","","We give a fast and simple factor 2.74 approximation algorithm for the problem of choosing the k medians of the continuum of demand points defined by a convex polygon C. Our algorithm first surrounds the input region with a bounding box, then subdivides the bounding box into subregions with equal area. Simulation results on the convex hulls of the 50 states in the United States show that the practical performance of our algorithm is within 10% of the optimal solution in the vast majority of cases."
103,"Resource-Constrained Assignment Problems with Shared Resource Consumption and Flexible Demand","Rainwater, Chase and Geunes, Joseph and Romeijn, H. Edwin","INFORMS JOURNAL ON COMPUTING","26","2","290-302","2014","SPR","Branch-And-Price;Capacitated Assignment Problem;Nonlinear Knapsack Problem","","This paper considers a very general class of customer-to-resource assignment problems relevant to a variety of manufacturing contexts. This problem class addresses settings in which subsets of customer types share resource capacities as well as a fixed amount of capacity consumption, independent of production volume. More broadly, our model addresses cross-facility production limits and shared capacity consumption within each customer type. To solve these large-scale optimization problems, we apply a branch-and-price solution approach. This approach relies on an effective solution method for a novel class of nonlinear knapsack pricing problems. As our computational results demonstrate, despite the fact that the resulting master problem is not a simple set-partitioning problem, the problem's relaxation is sufficiently tight to produce an algorithm that significantly outperforms CPLEX for a wide range of problem parameter settings."
104,"Constrained Min-Cut Replication for K-Way Hypergraph Partitioning","Yazici, Volkan and Aykanat, Cevdet","INFORMS JOURNAL ON COMPUTING","26","2","303-320","2014","SPR","Combinatorial Optimization;Graphs;Heuristics;Optimization;Programming: Integer","","Replication is a widely-used technique in information retrieval and database systems for providing fault tolerance and reducing parallelization and processing costs. Combinatorial models based on hypergraph partitioning are proposed for various problems arising in information retrieval and database systems. We consider the possibility of using vertex replication to improve the quality of hypergraph partitioning. In this study, we focus on the constrained min-cut replication (CMCR) problem, where we are initially given a maximum replication capacity and a K-way hypergraph partition with an initial imbalance ratio. The objective in the CMCR problem is finding the optimal vertex replication sets for each part of the given partition such that the initial cut size of the partition is minimized, where the initial imbalance is either preserved or reduced under the given replication capacity constraint. In this study, we present a complexity analysis of the CMCR problem and propose a model based on a unique blend of coarsening and integer linear programming (ILP) schemes. This coarsening algorithm is derived from a novel utilization of the Dulmage-Mendelsohn decomposition. Experiments show that the ILP formulation coupled with the Dulmage-Mendelsohn decomposition-based coarsening provides high quality results in practical execution times for reducing the cut size of a given K-way hypergraph partition."
105,"The Robust (Minmax Regret) Quadratic Assignment Problem with Interval Flows","Feizollahi, Mohammad Javad and Averbakh, Igor","INFORMS JOURNAL ON COMPUTING","26","2","321-335","2014","SPR","Robust Optimization;Minmax Regret;Quadratic Assignment Problem;Benders Decomposition;Tabu Search","","We consider a generalization of the classical quadratic assignment problem, where material flows between facilities are uncertain, and only upper and lower bounds are known for each flow. The objective is to find a minmax regret solution. We present an exact Benders decomposition algorithm based on two developed mathematical programming formulations and on the developed linearizations of master problems, and a heuristic based on using tabu search in the context of a Benders decomposition framework. Then, we develop a hybrid Benders decomposition approach that allows us to combine the speed of heuristics with the rigor and precision of the exact Benders method. We discuss the results of extensive computational experiments."
106,"On Chubanov's Method for Linear Programming","Basu, Amitabh and De Loera, Jesus A. and Junod, Mark","INFORMS JOURNAL ON COMPUTING","26","2","336-350","2014","SPR","Linear Programming;Relaxation Methods;Strongly Polynomial Time Algorithms","","We discuss the method recently proposed by S. Chubanov [Chubanov S (2012a) A strongly polynomial algorithm for linear systems having a binary solution. Math. Programming 134(3):533-570] for the linear feasibility problem. We present new, concise proofs and geometric interpretations of some of his results. From our ideas we derive the first strongly polynomial time algorithm based on relaxation method techniques for special classes of linear feasibility problems. Under certain conditions, these results provide new proofs of classical results obtained by Tardos for combinatorial linear programs. The paper ends with some experimental investigations."
107,"Optimization-Based Approaches for Maximizing Aggregate Recommendation Diversity","Adomavicius, Gediminas and Kwon, YoungOk","INFORMS JOURNAL ON COMPUTING","26","2","351-369","2014","SPR","Recommender Systems;Recommendation Diversity;Recommendation Accuracy;Collaborative Filtering;Optimization Techniques","","Recommender systems are being used to help users find relevant items from a large set of alternatives in many online applications. Most existing recommendation techniques have focused on improving recommendation accuracy; however, diversity of recommendations has also been increasingly recognized in research literature as an important aspect of recommendation quality. This paper proposes several optimization-based approaches for improving aggregate diversity of top-N recommendations, including a greedy maximization heuristic, a graph-theoretic approach based on maximum flow or maximum bipartite matching computations, and an integer programming approach. The proposed approaches are evaluated using real-world movie rating data sets and demonstrate substantial improvements in both diversity and accuracy as compared to the recommendation reranking approaches, which have been introduced in prior literature for the purposes of diversity improvement and were used for baseline comparisons in our study. The paper also discusses the computational complexity and the scalability of the proposed approaches, as well as the potential directions for future work."
108,"Penalty-Based Algorithms for the Stochastic Obstacle Scene Problem","Aksakalli, Vural and Ari, Ibrahim","INFORMS JOURNAL ON COMPUTING","26","2","370-384","2014","SPR","Probabilistic Path Planning;Stochastic Dynamic Programming;Markov Decision Process;Canadian Traveler'S Problem","","We consider the stochastic obstacle scene problem wherein an agent needs to traverse a spatial arrangement of possible obstacles, and the status of the obstacles may be disambiguated en route at a cost. The goal is to find an algorithm that decides what and where to disambiguate en route so that the expected length of the traversal is minimized. We present a polynomial-time method for a graph-theoretical version of the problem when the associated graph is restricted to parallel avenues with fixed policies within the avenues. We show how previously proposed algorithms for the continuous space version can be adapted to a discrete setting. We propose a generalized framework encompassing these algorithms that uses penalty functions to guide the navigation in real time. Within this framework, we introduce a new algorithm that provides near-optimal results within very short execution times. Our algorithms are illustrated via computational experiments involving synthetic data as well as an actual naval minefield data set."
109,"Conditional Value-at-Risk Approximation to Value-at-Risk Constrained Programs: A Remedy via Monte Carlo","Hong, L. Jeff and Hu, Zhaolin and Zhang, Liwei","INFORMS JOURNAL ON COMPUTING","26","2","385-400","2014","SPR","Value-At-Risk;Conditional Value-At-Risk;Monte Carlo;Cvar-Like Approximation","","We study optimization problems with value-at-risk (VaR) constraints. Because it lacks subadditivity, VaR is not a coherent risk measure and does not necessarily preserve the convexity. Thus, the problems we consider are typically not provably convex. As such, the conditional value-at-risk (CVaR) approximation is often used to handle such problems. Even though the CVaR approximation is known as the best convex conservative approximation, it sometimes leads to solutions with poor performance. In this paper, we investigate the CVaR approximation from a different perspective and demonstrate what is lost in this approximation. We then show that the lost part of this approximation can be remedied using a sequential convex approximation approach, in which each iteration only requires solving a CVaR-like approximation via certain Monte Carlo techniques. We show that the solution found by this approach generally makes the VaR constraints binding and is guaranteed to be better than the solution found by the CVaR approximation and moreover is empirically often globally optimal for the target problem. The numerical experiments show the effectiveness of our approach."
110,"New Formulations for Choice Network Revenue Management","Talluri, Kalyan","INFORMS JOURNAL ON COMPUTING","26","2","401-413","2014","SPR","Assortment Optimization;Randomized Algorithms;Network Revenue Management","","Models incorporating more realistic models of customer behavior, as customers choosing from an offer set, have recently become popular in assortment optimization and revenue management. The dynamic program for these models is intractable and approximated by a deterministic linear program called the choice deterministic linear program (CDLP), which has an exponential number of columns. Column generation has been proposed but finding an entering column is NP-hard when segment consideration sets overlap. In this paper we propose a new approach called segment-based deterministic concave program (SDCP) based on segments and their consideration sets. SDCP is a relaxation of CDLP and hence forms a looser upper bound on the dynamic program, but coincides with CDLP for the case of nonoverlapping segments. If the number of elements in a consideration set for a segment is not very large, SDCP can be applied to any discrete-choice model of consumer behavior. We tighten the SDCP bound by (i) simulations, called the randomized concave programming method, and (ii) by adding cuts to a recent compact formulation (SBLP) of the problem for a latent multinomial-choice model (MNL) of demand. This latter approach turns out to be very effective, essentially obtaining CDLP value, even for overlapping segments. By formulating the problem as a separation problem, we give insight into why CDLP is easy for the MNL with nonoverlapping consideration sets and why generalizations of MNL pose difficulties. Numerical conclusions that we derive from the present paper are the following: (a) The randomized linear programming approach that obtains significant tightening of the linear program upper bound under an older independent-class model seems to have relatively little effect for the choice case; (b) for the MNL choice model, the SBLP+ formulation we give here for overlapping segments is very fast and is potentially scalable to industrial-size problems."
111,"A Network Simplex Algorithm for the Equal Flow Problem on a Generalized Network","Morrison, David R. and Sauppe, Jason J. and Jacobson, Sheldon H.","INFORMS JOURNAL ON COMPUTING","25","1","2-12","2013","WIN","Generalized Network Flows;Equal Flow Sets;Side Constraints;Optimization;Linear Programming","","A network simplex algorithm is described for the minimum-cost network flow problem on a generalized network, with the additional constraint that there exist sets of arcs that must carry equal amounts of flow. This problem can be modeled as a linear programming problem and solved using the standard simplex algorithm. However, because of the structure of the problem, more efficient algorithms are possible that solve the problem by operating directly on the network itself. One such algorithm is described that leads to improved asymptotic performance per iteration over the standard simplex algorithm, as long as the number of side constraints is small relative to the size of the network. Computational results are given comparing this algorithm to CPLEX's primal simplex solver on randomly generated graphs."
112,"Benders Decomposition for the Hop-Constrained Survivable Network Design Problem","Botton, Quentin and Fortz, Bernard and Gouveia, Luis and Poss, Michael","INFORMS JOURNAL ON COMPUTING","25","1","13-26","2013","WIN","Survivable Network;Edge-Disjoint Paths;Hop-Constrained Paths;Benders Decomposition;Branch-And-Cut Algorithm","","Given a graph with nonnegative edge weights and node pairs Q, we study the problem of constructing minimum weight set of edges so that the induced subgraph contains at least K edge-disjoint paths containing at most L edges between each pair in Q. Using the layered representation introduced by Gouveia [Gouveia, L. 1998. Using variable redefinition for computing lower bounds for minimum spanning and Steiner trees with hop constraints. INFORMS J. Comput. 10(2) 180-188], we present a formulation for the problem valid for any K, L >= 1. We use a Benders decomposition method to efficiently handle the large number of variables and constraints. We show that our Benders cuts contain constraints used in previous studies to formulate the problem for L = 2, 3, 4, as well as new inequalities when L >= 5. Whereas some recent works on Benders decomposition study the impact of the normalization constraint in the dual subproblem, we focus here on when to generate the Benders cuts. We present a thorough computational study of various branch-and-cut algorithms on a large set of instances including the real-based instances from SNDlib. Our best branch-and-cut algorithm combined with an efficient heuristic is able to solve the instances significantly faster than CPLEX 12 on the extended formulation."
113,"Max-k-Cut by the Discrete Dynamic Convexized Method","Zhu, Wenxing and Lin, Geng and Ali, M. M.","INFORMS JOURNAL ON COMPUTING","25","1","27-40","2013","WIN","Max-K-Cut;Local Search;Dynamic Convexized Method","","In this paper, we propose a multistart-type algorithm for solving the max-k-cut problem. Central to our algorithin is an auxiliary function we propose. We formulate the max-k-cut problem as an explicit mathematical form, which allows us to use an easy implementable local search. The construction of the auxiliary function requires a local maximizer of the max-k-cut problem. If the best local maximizer obtained is used in the construction of the auxiliary function, then the local maximization of the auxiliary function leads to a better maximizer of the max-k-cut problem. This proves to be a good strategy to escape from the current local optima and to search a broader solution space. Indeed, we have shown, both numerically and theoretically, that the maximization of the auxiliary function by the local search method can escape successfully from previously converged discrete local maximizers by taking increasing values of a parameter. Computational results on many test instances with different sizes and densities show that the proposed algorithm is efficient and stable to find approximate global solutions for the max-k-cut problems. Although we have presented results for k >= 2, the robustness of our algorithm is shown for k = 2 by comparisons with a number of recent methods. A number of theoretical results are also presented, which justify the design of our algorithm."
114,"A Branch-and-Cut Algorithm for the Double Traveling Salesman Problem with Multiple Stacks","Martinez, Manuel A. Alba and Cordeau, Jean-Francois and Dell'Amico, Mauro and Iori, Manuel","INFORMS JOURNAL ON COMPUTING","25","1","41-55","2013","WIN","Traveling Salesman Problem;Pickup And Delivery;Last-In-First-Out Loading;Branch And Cut","","The double traveling salesman problem with multiple stacks is a variant of the pickup and delivery traveling 1 salesman problem in which all pickups must be completed before any delivery. In addition, items can be loaded on multiple stacks in the vehicle, and each stack must obey the last-in-first-out policy. The problem consists of finding the shortest Hamiltonian cycles covering all pickup and delivery locations while ensuring the feasibility of the loading plan. We formulate the problem as two traveling salesman problems linked by infeasible path constraints. We also introduce several strengthenings of these constraints, which are used within a branch-and-cut algorithm. Computational results performed on instances from the literature show that the algorithm outperforms existing exact algorithms. Instances with up to 28 requests (58 nodes) have been solved to optimality."
115,"Static Network Reliability Estimation via Generalized Splitting","Botev, Zdravko I. and L'Ecuyer, Pierre and Rubino, Gerardo and Simard, Richard and Tuffin, Bruno","INFORMS JOURNAL ON COMPUTING","25","1","56-71","2013","WIN","Network Reliability;Generalized Splitting;Graph Connectivity;Gibbs Sampling;Permutation Monte Carlo;Rare-Event Simulation;Conditional Monte Carlo","","We propose a novel simulation-based method that exploits a generalized splitting (GS) algorithm to estimate the reliability of a graph (or network), defined here as the probability that a given set of nodes are connected, when each link of the graph fails with a given (small) probability. For large graphs, in general, computing the exact reliability is an intractable problem and estimating it by standard Monte Carlo methods poses serious difficulties, because the unreliability (one minus the reliability) is often a rare-event probability. We show that the proposed GS algorithm can accurately estimate extremely small unreliabilities and we exhibit large examples where it performs much better than existing approaches. It is also flexible enough to dispense with the frequently made assumption of independent edge failures."
116,"A New Graph-Theoretical Model for the Guillotine-Cutting Problem","Clautiaux, Francois and Jouglet, Antoine and Moukrim, Aziz","INFORMS JOURNAL ON COMPUTING","25","1","72-86","2013","WIN","Two-Dimensional Packing;Graph Model;Constraint Programming","","We consider the problem of determining whether a given set of rectangular items can be cut from a larger rectangle using so-called guillotine cuts only. We introduce a new class of arc-colored directed graphs called guillotine graphs and show that each guillotine graph can be associated with a specific class of pattern solutions that we call a guillotine-cutting class. The properties of guillotine graphs are examined, and some effective algorithms for dealing with guillotine graphs are proposed. As an application, we then describe a constraint programming method based on guillotine graphs, and we propose effective filtering techniques that use the graph model properties in order to reduce the search space efficiently. Computational experiments are reported on benchmarks from the literature: our algorithm outperforms previous methods when solving the most difficult instances exactly."
117,"Rational Automata Networks: A Non-Markovian Modeling Approach","Buchholz, Peter and Telek, Miklos","INFORMS JOURNAL ON COMPUTING","25","1","87-101","2013","WIN","Applied Probability;Matrix Exponential Distributions;Rational Arrival Processes;Numerical Analysis;Automata Networks;Structured Analysis","","A new class of non-Markovian models is introduced that results from the combination of stochastic automata networks and a very general class of stochastic processes, namely, rational arrival processes, which are derived from matrix exponential distributions. It is shown that the modeling formalism allows a compact representation of complex models with large state spaces. The resulting stochastic process is non-Markovian, but it can be analyzed with numerical techniques like a Markov chain, and the results at the level of the automata are stochastic distributions that can be used to compute standard performance and dependability results. The model class includes stochastic automata networks with phase-type distributed and correlated event times and also includes models that have a finite state space but cannot be represented by finite Markov chains. The paper introduces the model class, shows how the descriptor matrix can be represented in compact form, presents some example models, and outlines methods to analyze the new models."
118,"Assessing the Value of Dynamic Pricing in Network Revenue Management","Zhang, Dan and Lu, Zhaosong","INFORMS JOURNAL ON COMPUTING","25","1","102-115","2013","WIN","Revenue Management;Dynamic Pricing;Approximate Dynamic Programming;Choice Models","","Dynamic pricing for a network of resources over a finite selling horizon has received considerable attention in recent years, yet few papers provide effective computational approaches to solve the problem. We consider a resource decomposition approach to solve the problem and investigate the performance of the approach in a computational study. We compare the performance of the approach to static pricing and choice-based availability control. Our numerical results show that dynamic pricing policies from network resource decomposition can achieve significant revenue lift compared with choice-based availability control and static pricing, even when the latter is frequently resolved. As a by-product of our approach, network decomposition provides an upper bound in revenue, which is provably tighter than the well-known upper bound from a deterministic approximation."
119,"Dynamic Appointment Scheduling of a Stochastic Server with Uncertain Demand","Erdogan, S. Ayca and Denton, Brian","INFORMS JOURNAL ON COMPUTING","25","1","116-132","2013","WIN","Appointment Scheduling;Stochastic Programming;Health Care","","We formulate and solve two new stochastic linear programming formulations of appointment scheduling problems that are motivated by the management of health services. We assume that service durations and the number of customers to be served on a particular day are uncertain. In the first model, customers may fail to show up for their appointments (no-show). This model is formulated as a two-stage stochastic linear program. In the second model, customers are scheduled dynamically, one at a time, as they request appointments. This model is formulated as a multistage stochastic linear program with stages defined by customer appointment requests. We analyze the structure of the models and adapt decomposition-based algorithms to solve the problems efficiently. We present numerical results that illustrate the impact of uncertainty on dynamic appointment scheduling, and we identify useful insights that can be applied in practice. We also present a case study based on real data for an outpatient procedure center."
120,"An Adaptive Hyperbox Algorithm for High-Dimensional Discrete Optimization via Simulation Problems","Xu, Jie and Nelson, Barry L. and Hong, L. Jeff","INFORMS JOURNAL ON COMPUTING","25","1","133-146","2013","WIN","Optimization Via Simulation;Random Search;Ranking And Selection","","We propose an adaptive hyperbox algorithm (AHA), which is an instance of a locally convergent, random search algorithm for solving discrete optimization via simulation problems. Compared to the COMPASS algorithm, AHA is more efficient in high-dimensional problems. By analyzing models of the behavior of COMPASS and AHA, we show why COMPASS slows down significantly as dimension increases, whereas AHA is less affected. Both AHA and COMPASS can be used as the local search algorithm within the Industrial Strength COMPASS framework, which consists of a global search phase, a local search phase, and a final cleanup phase. We compare the performance of AHA to COMPASS within the framework of Industrial Strength COMPASS and as stand-alone algorithms. Numerical experiments demonstrate that AHA scales up well in high-dimensional problems and has similar performance to COMPASS in low-dimensional problems."
121,"Convex Approximations of a Probabilistic Bicriteria Model with Disruptions","Rengarajan, Tara and Dimitrov, Nedialko and Morton, David P.","INFORMS JOURNAL ON COMPUTING","25","1","147-160","2013","WIN","Programming, Stochastic: Probabilistic Constraints;Simulation;Programming: Multiple Criteria","","We consider a multiperiod system operation problem with two conflicting objectives, minimizing cost and risk. Risk stems from uncertain disruptions to the system during operation. Whereas a general model would hedge against disruptions in each time period, we study special cases in which only a modest number of disruptions occur. To optimize for risk, we employ a convex approximation based on constraint sampling. We develop a stratified sampling scheme based on distributional information on the time of disruption. We establish that our scheme yields significant savings in sampling costs-up to an order of magnitude in the number of time periods-over naive sampling. Moreover, in the absence of distributional information, we exhibit a sampling strategy that has comparable performance to optimal stratification. We numerically demonstrate that stratification improves cost over naive sampling, improving the solution's proximity to the efficient frontier of the bicriteria problem."
122,"Discovery of Online Shopping Patterns Across Websites","Yang, Yinghui (Catherine) and Liu, Hongyan and Cai, Yuanjue","INFORMS JOURNAL ON COMPUTING","25","1","161-176","2013","WIN","Data Mining;E-Commerce;Analysis Of Algorithms","","In the online world, customers can easily navigate to different online stores to make purchases. The products purchased on one site are often associated with product purchases on other sites (e.g., a hotel reservation on one site and a car rental on another site). Whereas market basket analysis is often used to discover associations among products for brick-and-mortar stores, it is rarely applied in the online setting where consumers navigate among different online stores to buy products. We define online shopping patterns and develop two novel methods to perform market basket analysis across websites. While this research is motivated by online shopping applications, our contribution is mainly methodological. The two methods we develop in this paper can not only be used to identify various online shopping patterns across sites and products but can also be applied to settings where patterns exist across different dimensions. Experiments on both synthetic data and real online shopping data demonstrate the effectiveness of our methods."
123,"Steady-State Simulation with Replication-Dependent Initial Transients: Analysis and Examples","Argon, Nilay Tani and Andradottir, Sigrtin and Alexopoulos, Christos and Goldsman, David","INFORMS JOURNAL ON COMPUTING","25","1","177-191","2013","WIN","Variance Estimation;Batch Means;Independent Replications;Replicated Batch Means;Initialization Bias","","The replicated batch means (RBM) method for steady-state simulation output analysis generalizes both the independent replications (IR) and batch means (BM) methods. We analyze the performance of RBM in situations where the underlying stochastic process possesses an additive initial transient. Our analysis differs from prior work in that the initial transient is stochastic, and hence the sample paths of the transient process may be replication dependent, and possibly also correlated across replications. We provide asymptotic expressions for the mean and variance of the RBM estimators of the steady-state mean and variance parameter of the stochastic process being simulated. We then use our results to study the performance of RBM as a function of the number of replications, initialization method for the replications, and decay rate of the associated initialization bias. Our results provide guidance on when IR, BM, or a combination thereof is the best choice, and also on effective choices of initial states for the replications."
124,"The Cunningham-Geelen Method in Practice: Branch-Decompositions and Integer Programming","Margulies, S. and Ma, J. and Hicks, I. V.","INFORMS JOURNAL ON COMPUTING","25","4","599-610","2013","FAL","Optimization;Integer Programming;Branch-Decompositions","","In 2007, W. H. Cunningham and J. Geelen describe an algorithm for solving max{c(T)x: Ax = b, x >= 0, x is an element of Z(n)}, where A is an element of Z(>= 0)(mxn), b is an element of Z(m), and c is an element of Z(n), which utilizes a branch-decomposition of the matrix A and techniques from dynamic programming. In this paper, we report on the first implementation of the CG algorithm and compare our results with the commercial integer programming software GUROBI. Using branch-decomposition trees produced by heuristics and optimal trees produced by algorithms developed in our previous studies, we test both a memory-intensive and low-memory version of the CG algorithm on problem instances such as graph 3-coloring, set partition, market split, and knapsack. We isolate a class of set partition instances where the CG algorithm runs twice as fast as GUROBI, and demonstrate that certain infeasible market split and knapsack instances with width <= 6 range from running twice as fast as GUROBI, to running in a matter of minutes versus a matter of hours."
125,"Exact Approaches to Multilevel Vertical Orderings","Chimani, Markus and Hungerlaender, Philipp","INFORMS JOURNAL ON COMPUTING","25","4","611-624","2013","FAL","Quadratic Ordering Problem;Ilp And Sdp Approaches;Multilayer Graph Drawings;Crossing Minimization","","We present a semidefinite programming (SDP) approach for the problem of ordering vertices of a layered graph such that the edges of the graph are drawn as vertical as possible. This multilevel vertical ordering (MLVO) problem is a quadratic ordering problem and conceptually related to the well-studied problem of multilevel crossing minimization (MLCM). In contrast to the latter, it can be formulated such that it does not merely consist of multiple sequentially linked bilevel quadratic ordering problems, but as a genuine multilevel problem with dense cost matrix. This allows us to describe the graphs' structures more compactly and therefore obtain solutions for graphs too large for MLCM in practice. In this paper we give motivation and mathematical models for MLVO. We formulate linear and quadratic programs, including some strengthening constraint classes, and an SDP relaxation for MLVO. We compare all approaches both theoretically and experimentally and show that MLVO's properties render linear and quadratic programming approaches inapplicable, even for small sparse graphs, while the SDP works surprisingly well in practice. This is in stark contrast to other ordering problems like MLCM, where such graphs are typically solved more efficiently with integer linear programs. Finally, we also compare our approach to related MLCM approaches."
126,"Efficient Risk Hedging by Dynamic Forward Pricing: A Study in Cloud Computing","Du, Anna Ye and Das, Sanjukta and Ramesh, R.","INFORMS JOURNAL ON COMPUTING","25","4","625-642","2013","FAL","Risk Management;Risk Hedging;Contract Design;Cloud Computing;Infrastructure Platforms","","Commodities such as cloud resources (storage, computing, bandwidth) are often sold to clients on a pay-as-you-go basis. Thus, resource providers absorb all risk arising from end users' demand volatilities. We focus on the revenue risk management of commodities with highly volatile demand profiles using cloud computing as the application domain and bandwidth as the exemplar commodity. We extend the state of the art in risk hedging by introducing a new concept of dynamic forward contracts where a provider and a client flexibly interact through offers and responses over a set of time periods in a horizon. We develop an optimal pricing mechanism that takes into account the risk propensities of the provider and the client. The overall mechanism is modeled as a pair of nested dynamic programs denoting the offer-response interactions. The mechanism also incorporates two learning components: short-term learning on the client's demand and long-term learning on the client's risk propensity. We characterize two approaches for predicting the client's demand-a recursive demand prediction model and an aggregate demand prediction model. Detailed experimental studies of the proposed mechanism using real Web traffic data on the clients of Amazon Web Services have been carried out. The empirical results dearly demonstrate the superiority of the proposed mechanism over benchmark mechanisms such as the current industry practice of spot markets and static forward pricing mechanisms proposed in the literature in ex ante and ex post settings. The results also highlight key interaction effects among parameters controllable by a provider and the risk propensities of the market players, leading to valuable managerial implications for the practical adoption of the proposed mechanism."
127,"A Logarithmic Method for Reducing Binary Variables and Inequality Constraints in Solving Task Assignment Problems","Li, Han-Lin and Huang, Yao-Huei and Fang, Shu-Cherng","INFORMS JOURNAL ON COMPUTING","25","4","643-653","2013","FAL","Task Assignment Problem;Binary Variables;Mixed-Integer Programming Problem","","This paper studies the classical task assignment problem (TAP) in which M unbreakable tasks are assigned to N agents with the objective to minimize the communication and process costs subject to each agent's capacity constraint. Because a large-size TAP involves many binary variables, most, if not all, traditional methods experience the difficulty in solving the problem within a reasonable time period. Recent works present a logarithmic approach to reduce the number of binary variables in problems with mixed-integer variables. This study proposes a new logarithmic method that significantly reduces the numbers of binary variables and inequality constraints in solving task assignment problems. Our numerical experiments demonstrate that the proposed method is superior to other known methods of this kind for solving large-size TAPs."
128,"Zigzag Search for Continuous Multiobjective Optimization","Wang, Honggang","INFORMS JOURNAL ON COMPUTING","25","4","654-665","2013","FAL","Multiple Criteria Decision;Multiobjective Optimization;Pareto Optimal;Gradient Search;Nonlinear Programming","","A new method is proposed using a gradient-based zigzag search approach for multiobjective optimization (MOO) or vector optimization problems. The key idea of this method is searching around the Pareto front by applying an efficient local search procedure using the gradients of the objective functions. This local search zigzags along the Pareto surface guided by the gradients and iteratively returns the visited Pareto optima. Many continuous MOO problems have smooth objective functions and the set of the nondominated objective function values forms a regular surface in the image space. This fact motivates developing the zigzag search method for such relatively well-posed MOO problems. A simple implementation of this method, z-algorithm, is presented particularly for continuous bi-objective optimization (BOO) problems with well-connected Pareto optimal solutions. The efficiency of the z-algorithm is studied with a set of BOO problems and the algorithm performances are compared to those of a recently developed MOO algorithm, Pareto front approximation with adaptive weighted sum method."
129,"Safe Approximations of Ambiguous Chance Constraints Using Historical Data","Yanikoglu, Ihsan and den Hertog, Dick","INFORMS JOURNAL ON COMPUTING","25","4","666-681","2013","FAL","Robust Optimization;Chance Constraint;Phi-Divergence;Goodness-Of-Fit Statistics","","This paper proposes a new way to construct uncertainty sets for robust optimization. Our approach uses the 1 available historical data for the uncertain parameters and is based on goodness-of-fit statistics. It guarantees that the probability the uncertain constraint holds is at least the prescribed value. Compared to existing safe approximation methods for chance constraints, our approach directly uses the historical data information and leads to tighter uncertainty sets and therefore to better objective values. This improvement is significant, especially when the number of uncertain parameters is low. Other advantages of our approach are that it can handle joint chance constraints easily, it can deal with uncertain parameters that are dependent, and it can be extended to nonlinear inequalities. Several numerical examples illustrate the validity of our approach."
130,"Stochastic Operating Room Scheduling for High-Volume Specialties Under Block Booking","Shylo, Oleg V. and Prokopyev, Oleg A. and Schaefer, Andrew J.","INFORMS JOURNAL ON COMPUTING","25","4","682-692","2013","FAL","Surgical Suite;Operating Room Scheduling;Block Booking;Chance-Constrained Programs","","Scheduling elective procedures in an operating suite is a formidable task because of competing performance metrics and uncertain surgery durations. In this paper, we present an optimization framework for batch scheduling within a block booking system that maximizes the expected utilization of operating room resources subject to a set of probabilistic capacity constraints. The algorithm iteratively solves a series of mixed-integer programs that are based on a normal approximation of cumulative surgery durations. This approximation is suitable for high-volume medical specialities but might not be acceptable for the specialties that perform few procedures per block. We test our approach using the data from the ophthalmology department of the Veterans Affairs Pittsburgh Healthcare System. The performance of the schedules obtained by our approach is significantly better than schedules produced by simple heuristic scheduling rules."
131,"Backdoor Branching","Fischetti, Matteo and Monaci, Michele","INFORMS JOURNAL ON COMPUTING","25","4","693-700","2013","FAL","Mixed-Integer Programming;Branch And Bound;Computational Analysis","","We present an exact mixed-integer programming (MIP) solution scheme where a set-covering model is used to find a small set of first-choice branching variables. In a preliminary sampling phase, our method quickly collects a number of relevant low-cost fractional solutions that qualify as obstacles for the linear programming (LP) relaxation bound improvement. Then a set covering model is solved to detect a small subset of variables (a backdoor, in the artificial intelligence jargon) that cover the fractionality of the collected fractional solutions. These backdoor variables are put in a priority branching list, and a black-box MIP solver is eventually run-in its default mode-by taking this list into account, thus avoiding any other interference with its highly optimized internal mechanisms. Computational results on a large set of instances from the literature are presented, showing that some speedup can be achieved even with respect to a state-of-the-art solver such as IBM ILOG CPLEX 12.2."
132,"Construction of Risk-Averse Enhanced Index Funds","Lejeune, Miguel A. and Samatli-Pac, Gulay","INFORMS JOURNAL ON COMPUTING","25","4","701-719","2013","FAL","Stochastic Programming;Enhanced Index Fund;Risk Aversion;Outer Approximation","","We propose a partial replication strategy to construct risk-averse enhanced index funds. Our model takes into account the parameter estimation risk by defining the asset returns and the return covariance terms as random variables. The variance of the index fund return is required to be below a low-risk threshold with a large probability, thereby limiting the market risk exposure of the investors. The resulting stochastic integer problem is reformulated through the derivation of a deterministic equivalent for the risk constraint and the use of a block decomposition technique. We develop an exact outer approximation method based on the relaxation of some binary restrictions and the reformulation of the cardinality constraint. The method provides a hierarchical organization of the computations with expanding sets of integer-restricted variables and outperforms the Bonmin and the CPLEX solvers. The method can solve large instances (up to 1,000 securities), converges fast, scales well, and is general enough to be applicable to problems with buy-in-threshold constraints."
133,"An Efficient Approach for Solving Reliable Facility Location Models","Aboolian, Robert and Cui, Tingting and Shen, Zuo-Jun Max","INFORMS JOURNAL ON COMPUTING","25","4","720-729","2013","FAL","Facility Location;Reliability;Mixed Integer Program;Cutting Planes;Heuristics;Supply Chain Disruption","","We consider reliable facility location models in which facilities are subject to unexpected failures, and customers may be reassigned to facilities other than their regular facilities. The objective is to minimize the total expected costs in normal and failure scenarios. We allow facilities to have different failure rates and do not limit the number of facilities that might be assigned to a customer. Lower bounds for reliable uncapacitated fixed-charge location problem (RUFLP) are derived and used to introduce a class of efficient algorithms for solving the RUFLP problem."
134,"Dividing a Territory Among Several Facilities","Carlsson, John Gunnar and Devulapalli, Raghuveer","INFORMS JOURNAL ON COMPUTING","25","4","730-742","2013","FAL","Geometric Algorithms;Voronoi Diagrams;Vector Space Optimization;Equitable Partitioning","","We consider the problem of dividing a geographic region into subregions so as to minimize the maximum workload of a collection of facilities over that region. We assume that the cost of servicing a demand point is a monomial function of the distance to its assigned facility and that demand points follow a continuous probability density. We show that, when our objective is to minimize the maximum workload of all facilities, the optimal partition consists of a collection of circular arcs that are induced by a multiplicatively weighted Voronoi diagram. When we require that all subregions have equal area, the optimal partition consists of a collection of hyperbolic or quartic curves. We show that, for both problems, the dual variables correspond to prices for a facility to serve a demand point, and our objective is to determine a set of prices such that the entire region is purchased by the facilities, i.e., that the market clears. This allows us to solve the partitioning problem quickly without discretizing the service region."
135,"Efficient Transient Analysis of Markovian Models Using a Block Reduction Approach","de Souza e Silva, Edmundo and Leao, Rosa M. M. and Marie, Raymond","INFORMS JOURNAL ON COMPUTING","25","4","743-757","2013","FAL","Transient Analysis;Performability;Reward Models;Performance Models;Uniformization","","One of the most widely used techniques to obtain transient measures is the uniformization method. However, although uniformization has many advantages, the computational cost required to calculate transient probabilities is very large for stiff models. We study efficient solutions that can be applied to an approximate method developed for calculating transient state probabilities of Markov models and cumulative expected reward measures over a finite interval. Our work is based on a method that approximates the state probabilities at time t by the state probabilities calculated at a random time with Erlangian distribution. The original method requires an inversion of a matrix obtained from the state transition rate matrix that destroys special structures such as sparseness and banded matrices. This precludes the use of the technique for large models. In our work we propose efficient solutions that can take advantage of special structures. Finally, we present examples that show that the proposed technique is computationally very efficient for stiff models when compared with uniformization."
136,"Fitting the Ph-t/M-t/s/c Time-Dependent Departure Process for Use in Tandem Queueing Networks","Nasr, Walid W. and Taaffe, Michael R.","INFORMS JOURNAL ON COMPUTING","25","4","758-773","2013","FAL","Queues;Queueing;Tandem Queues;Algorithms;Phase-Type Distribution;Nonstationary Processes;Queueing Networks;Time Dependent;Transient;Mixture Of Erlangs;Count Process;Moment Matching","","This paper considers time-dependent Ph-t/M-t/s/c queueing nodes and small tandem networks of such nodes. We examine characteristics of the departure processes from a multiserver queueing node; in particular, we focus on solving for the first two time-dependent moments of the departure-count process. A finite set of partial moment differential equations is developed to numerically solve for the departure-count moments over specified intervals of time [t(i), t(i) + tau(i)). We also present a distribution fitting algorithm to match these key characteristics with a (Ph-t) over tilde process serving as the approximate departure process. A distribution fitting algorithm is presented for time-dependent point processes where a two-level balanced mixture of Erlang distribution is used to serve as the approximating process. We then use the (Ph-t) over tilde approximating departure process as the approximate composite arrival process to downstream node(s) in a network of tandem queues."
137,"A New General-Purpose Method for the Computation of the Interval Availability Distribution","Carrasco, Juan A.","INFORMS JOURNAL ON COMPUTING","25","4","774-791","2013","FAL","Engineering;Probability;Markov Processes;Reliability;Availability","","We develop a new randomization-based general-purpose method for the computation of the interval availability distribution of systems modeled by continuous-time Markov chains (CTMCs). The basic idea of the new method is the use of a randomization construct with different randomization rates for up and down states. The new method is numerically stable and computes the measure with well-controlled truncation error. In addition, for large CTMC models, when the maximum output rates from up and down states are significantly different, and when the interval availability has to be guaranteed to have a level close to one, the new method is significantly or moderately less costly in terms of CPU time than a previous randomization-based state-of-the-art method, depending on whether the maximum output rate from down states is larger than the maximum output rate from up states, or vice versa. Otherwise, the new method can be more costly, but a relatively inexpensive for large models switch of reasonable quality can be easily developed to choose the fastest method. Along the way, we show the correctness of a generalized randomization construct, in which arbitrarily different randomization rates can be associated with different states, for both finite CTMCs with infinitesimal generator and uniformizable CTMCs with denumerable state space."
138,"Positive-versus-Negative Classification for Model Aggregation in Predictive Data Mining","Lutu, Patricia E. N. and Engelbrecht, Andries P.","INFORMS JOURNAL ON COMPUTING","25","4","792-807","2013","FAL","Data Mining;Large Data Sets;Model Aggregation;Ensemble Classification;Boosting;Pvn Classification;Data Set Selection;Data Set Partitioning;Data Set Sampling","","The process of constructing several base models that are then combined into a single classification model for prediction is called model aggregation or ensemble classification. Positive-versus-negative (pVn) classification is a new method for the implementation of base models for aggregation. pVn classification involves the decomposition of a k-class prediction task into m (m < k) subproblems. One base model is constructed for each subproblem to predict a subset of the k classes. The base models are then combined into one aggregate model for prediction. This paper reports studies that were conducted to demonstrate the performance of pVn classification when large volumes of data are available for modeling as is commonly the case in data mining. It is demonstrated in this paper that pVn modeling provides the capability to use a large amount of available data (in a large data set) for base model training. It is also demonstrated that pVn models created from large data sets provide a higher level of predictive performance compared to single k-class models."
139,"Approximating the Split Closure","Fischetti, Matteo and Salvagnin, Domenico","INFORMS JOURNAL ON COMPUTING","25","4","808-819","2013","FAL","Mixed-Integer Programming;Gomory Cuts;Split Cuts","","The split closure has been proved in practice to be a very tight approximation of the integer hull formulation of a generic mixed-integer linear program. However, exact separation procedures for optimizing over the split closure have unacceptable computing times in practice; hence, many different heuristic strategies have been proposed in the last few years. In this paper we present a new overall framework for approximating the split closure that merges different ideas from the previous approaches. Computational results prove the effectiveness of the proposed procedure compared to the state of the art, showing that a good approximation of the split closure bound can be obtained with very reasonable computing times."
140,"Robust Modified Policy Iteration","Kaufman, David L. and Schaefer, Andrew J.","INFORMS JOURNAL ON COMPUTING","25","3","396-410","2013","SUM","Control Processes;Markov Processes;Optimization;Dynamic Programming;Robust Optimization","","Robust dynamic programming (robust DP) mitigates the effects of ambiguity in transition probabilities on the solutions of Markov decision problems. We consider the computation of robust DP solutions for discrete-stage, infinite-horizon, discounted problems with finite state and action spaces. We present robust modified policy iteration (RMPI) and demonstrate its convergence. RMPI encompasses both of the previously known algorithms, robust value iteration and robust policy iteration. In addition to proposing exact RMPI, in which the inner problem is solved precisely, we propose inexact RMPI, in which the inner problem is solved to within a specified tolerance. We also introduce new stopping criteria based on the span seminorm. Finally, we demonstrate through some numerical studies that RMPI can significantly reduce computation time."
141,"A Time Predefined Variable Depth Search for Nurse Rostering","Burke, Edmund K. and Curtois, Timothy and Qu, Rong and Berghe, Greet Vanden","INFORMS JOURNAL ON COMPUTING","25","3","411-419","2013","SUM","Timetabling;Personnel;Local Search;Heuristics","","This paper presents a variable depth search for the nurse rostering problem. The algorithm works by chaining together single neighbourhood swaps into more effective compound moves. It achieves this by using heuristics to decide whether to continue extending a chain and which candidates to examine as the next potential link in the chain. Because end users vary in how long they are willing to wait for solutions, a particular goal of this research was to create an algorithm that accepts a user specified computational time limit and uses it effectively. When compared against previously published approaches the results show that the algorithm is very competitive."
142,"Separation and Extension of Cover Inequalities for Conic Quadratic Knapsack Constraints with Generalized Upper Bounds","Atamtuerk, Alper and Muller, Laurent Flindt and Pisinger, David","INFORMS JOURNAL ON COMPUTING","25","3","420-431","2013","SUM","Programming: Integer;Nonlinear;Convex;Constraints;Computational Analysis","","Motivated by addressing probabilistic 0-1 programs we study the conic quadratic knapsack polytope with generalized upper bound (GUB) constraints. In particular, we investigate separating and extending GUB cover inequalities. We show that, unlike in the linear case, determining whether a cover can be extended with a single variable NP-hard. We describe and compare a number of exact and heuristic separation and extension algorithms which make use of the structure of the constraints. Computational experiments are performed for comparing the proposed separation and extension algorithms. These experiments show that a judicious application of the extended GUB cover cuts can reduce the solution time of conic quadratic 0-1 programs with GUB constraints substantially."
143,"I-SMOOTH: Iteratively Smoothing Mean-Constrained and Nonnegative Piecewise-Constant Functions","Chen, Huifen and Schmeiser, Bruce","INFORMS JOURNAL ON COMPUTING","25","3","432-445","2013","SUM","Poisson Process;Rate Function;Quadratic Optimization;Spline Approximation;Monte Carlo;Next Event;Dynamic;Simulation","","Continuous nonnegative functions, such as Poisson rate functions, are sometimes approximated as piecewise-constant functions. We consider the problem of automatically smoothing such functions while maintaining the integral of each piece and maintaining nonnegativity everywhere, without specifying a parametric function. We develop logic for SMOOTH (Smoothing via Mean-constrained Optimized-Objective Time Halving), a quadratic-optimization algorithm that yields a smoother nonnegative piecewise-constant rate function having twice as many time intervals, each of half the length. I-SMOOTH (Iterated SMOOTH) iterates the SMOOTH formulation to create a sequence of piecewise-constant rate functions that, in the limit, yields a nonparametric continuous function. We consider two contexts: finite-horizon and cyclic. We develop a sequence of computational simplifications for SMOOTH, moving from numerically minimizing the quadratic objective function, to numerically computing a matrix inverse, to a closed-form matrix inverse obtained as finite sums, to optimal decision-variable values that are linear combinations of the given rates, and to simple approximations."
144,"Column Generation for the Minimum Hyperplanes Clustering Problem","Amaldi, Edoardo and Dhyani, Kanika and Ceselli, Alberto","INFORMS JOURNAL ON COMPUTING","25","3","446-460","2013","SUM","Hyperplane Clustering;Column Generation;Infeasible Linear Systems","","Given n points in R-d and a maximum allowed tolerance epsilon > 0, the minimum hyperplanes clustering problem consists in finding a minimum number of hyperplanes such that the Euclidean distance between each point and the nearest hyperplane is at most E. We present a column generation approach for this problem based on a mixed integer nonlinear formulation in which the master is a set covering problem and the pricing subproblem is a mixed integer program with a nonconvex normalization constraint. We propose different ways of generating the initial pool of columns and investigate their impact on the overall algorithm. Since the pricing subproblem is substantially complicated by the l(2)-norm constraint, we consider approximate pricing subproblems involving different norms. Some strategies for refining the solution and speeding-up the overall method are also discussed. The performance of our column generation algorithm is assessed on realistic randomly generated instances as well as on real-world instances."
145,"Grammar-Based Column Generation for Personalized Multi-Activity Shift Scheduling","Cote, Marie-Claude and Gendron, Bernard and Rousseau, Louis-Martin","INFORMS JOURNAL ON COMPUTING","25","3","461-474","2013","SUM","Shift Scheduling;Context-Free Grammars;Column Generation;Branch-And-Price","","We present a branch-and-price algorithm to solve personalized multi-activity shift scheduling problems. The subproblems in the column generation method are formulated using grammars and solved with dynamic programming. The expressiveness of context-free grammars is exploited to easily model restrictions over shifts, allowing the branch-and-price algorithm to solve large-scale problem instances. We present computational experiments on two types of multi-activity shift scheduling problems and compare our approach with existing methods in the literature. These experiments show that our approach can efficiently solve large-scale instances and is flexible enough to model different classes of problems."
146,"Combining Lift-and-Project and Reduce-and-Split","Balas, Egon and Cornuejols, Gerard and Kis, Tamas and Nannicini, Giacomo","INFORMS JOURNAL ON COMPUTING","25","3","475-487","2013","SUM","Programming;Integer;Computational Analysis;Branch-And-Cut;Lift-And-Project","","Split cuts constitute a class of cutting planes that has been successfully employed by the majority of branch-and-cut solvers for mixed-integer linear programs. Given a basis of the linear programming (LP) relaxation and a split disjunction, the corresponding split cut can be computed with a closed-form expression. In this paper, we use the lift-and-project framework introduced by Balas and Perregaard to provide the basis, and the reduce-and-split algorithm as described by Cornuejols and Nannicini to compute the split disjunction. We propose a cut generation algorithm that starts from a Gomory mixed-integer cut and alternates between lift-and-project and reduce-and-split in order to strengthen it. This paper has two main contributions. First, we extend the Balas and Perregaard procedure for strengthening cuts arising from split disjunctions involving one variable to split disjunctions on multiple variables. Second, we apply the reduce-and-split algorithm to nonoptimal bases of the LP relaxation. We provide detailed computational testing of the proposed methods."
147,"Scenario Trees and Policy Selection for Multistage Stochastic Programming Using Machine Learning","Defourny, Boris and Ernst, Damien and Wehenkel, Louis","INFORMS JOURNAL ON COMPUTING","25","3","488-501","2013","SUM","Stochastic Programming;Out-Of-Sample Validation;Artificial Intelligence","","In the context of multistage stochastic optimization problems, we propose a hybrid strategy for generalizing to nonlinear decision rules, using machine learning, a finite data set of constrained vector-valued recourse decisions optimized using scenario-tree techniques from multistage stochastic programming. The decision rules are based on a statistical model inferred from a given scenario-tree solution and are selected by out-of-sample simulation given the true problem. Because the learned rules depend on the given scenario tree, we repeat the procedure for a large number of randomly generated scenario trees and then select the best solution (policy) found for the true problem. The scheme leads to an ex post selection of the scenario tree itself. Numerical tests evaluate the dependence of the approach on the machine learning aspects and show cases where one can obtain near-optimal solutions, starting with a weak scenario-tree generator that randomizes the branching structure of the trees."
148,"Self-Organized Formation and Evolution of Peer-to-Peer Networks","Li, Yung-Ming and Tan, Yong and De, Prabuddha","INFORMS JOURNAL ON COMPUTING","25","3","502-516","2013","SUM","Peer-To-Peer Networks;Distributed Data Management;Distributed Computing;Self-Organization;Network Formation And Evolution;Stability;Efficiency;Incentive Mechanism","","Peer-to-peer (P2P) networks are social networks for pooling network and information resources and are considered superior conduits for distributed computing and data management. In this paper, we utilize the theories of social networks and economic incentives to investigate the formation of P2P networks with rational participating agents (active peers). The paper proposes a framework for multilevel formation dynamics, including an individual level (content-sharing decision and group selection) and a group level (membership admission, splitting, and interconnection). It is found that if the network size (the number of peer nodes) is sufficiently large, the stable (self-selected equilibrium) free-riding ratio could be nonzero, contrary to the common belief that everybody should free ride. The efficient (welfare-maximizing) free-riding ratio is not necessarily zero; that is, a certain degree of free riding is beneficial and should be tolerated. The sharing level in a network increases (decreases) with the download (upload) capacities of its peer nodes. In addition, the heterogeneity of content availability and upload capacity discourages sharing activities. Although the sharing level of a stable group is typically lower than that of an efficient group, the self-formed network may have a larger or smaller group size than what is efficient, depending on the structure of the group admission decision process. It is also observed that self-organized interconnections among groups lead to network inefficiency because the network may be over- or underlinked. To recover the efficiency loss during the formation process, we propose internal transfer mechanisms to force stable networks to become efficient."
149,"Base Model Combination Algorithm for Resolving Tied Predictions for K-Nearest Neighbor OVA Ensemble Models","Lutu, Patricia E. N. and Engelbrecht, Andries P.","INFORMS JOURNAL ON COMPUTING","25","3","517-526","2013","SUM","Ensemble Classification;Model Aggregation;Combination Algorithm;Ova Classification;K-Nearest Neighbor Classification;Predictive Data Mining;Data Mining","","Model aggregation is the process of constructing several base models that are then combined into a single model for prediction. Ensemble classification has been studied by many researchers and found to provide significant performance improvements over single models. This paper presents a new base model combination algorithm for K-nearest neighbor (KNN) ensemble models based on One-Versus-All (OVA) classification. The proposed algorithm uses two decision functions to determine the best prediction among the many predictions provided by the base models. It is demonstrated in this paper that tied or conflicting predictions can be effectively resolved when a probabilistic function and a distance function are used by a combination algorithm for OVA KNN base model predictions. The resolution of tied predictions leads to improvements in predictive performance."
150,"Optimal Sampling Laws for Stochastically Constrained Simulation Optimization on Finite Sets","Hunter, Susan R. and Pasupathy, Raghu","INFORMS JOURNAL ON COMPUTING","25","3","527-542","2013","SUM","Constrained Simulation Optimization;Optimal Allocation;Ranking And Selection","","Consider the context of selecting an optimal system from among a finite set of competing systems, based on a stochastic objective function and subject to multiple stochastic constraints. In this context, we characterize the asymptotically optimal sample allocation that maximizes the rate at which the probability of false selection tends to zero. Since the optimal allocation is the result of a concave maximization problem, its solution is particularly easy to obtain in contexts where the underlying distributions are known or can be assumed. We provide a consistent estimator for the optimal allocation and a corresponding sequential algorithm fit for implementation. Various numerical examples demonstrate how the proposed allocation differs from competing algorithms."
151,"Flexible Process Compliance with Semantic Constraints Using Mixed-Integer Programming","Kumar, Akhil and Yao, Wen and Chu, Chao-Hsien","INFORMS JOURNAL ON COMPUTING","25","3","543-559","2013","SUM","Adaptive Process Management Systems;Semantic Constraints;Compliance;Change Operations;Mixed Integer Programming","","An adaptive process management system (APMS) allows for flexible, dynamic, and even ad hoc adaptation of processes based on case data, context, and events. These processes may arise in various domains such as business, healthcare, etc. In knowledge-intensive environments, it is important that APMS technology ensures error-free process execution and compliance with semantic constraints. However, most process design tools handle only syntactic constraints. This restricts their value in real-world applications considerably. This paper proposes a novel approach to check the compliance of process models against semantic constraints and the validity of process change operations using mixed-integer programming (MIP). The MIP formulation allows us to describe existential, dependency, ordering, and various other relationships among tasks along with business policies in a standard way. In addition to incorporating the semantic constraint specifications into an MIP formulation, we introduce three novel ideas in this paper: (1) the notion of degree of compliance of processes to constraints based on a penalty function, (2) the concepts of full and partial validity of change operations, and (3) the idea of compliance by compensation. Thus, compensation operations derived from compliance degree can transform a noncompliant process into a compliant one both at design and execution time. We illustrate our approach in the context of a healthcare workflow as a way to reduce medical errors and argue that it is more elegant and superior to a pure logic-based approach. Complex scenarios with multiple concurrent processes (and constraints across them) for a single patient are also considered."
152,"Uncommon Dantzig-Wolfe Reformulation for the Temporal Knapsack Problem","Caprara, Alberto and Furini, Fabio and Malaguti, Enrico","INFORMS JOURNAL ON COMPUTING","25","3","560-571","2013","SUM","Temporal Knapsack Problem;Dantzig-Wolfe Reformulation;Column Generation","","We study a natural generalization of the knapsack problem, in which each item exists only for a given time interval. One has to select a subset of the items (as in the classical case), guaranteeing that for each time instant, the set of existing selected items has total weight no larger than the knapsack capacity. We focus on the exact solution of the problem, noting that prior to our work, the best method was the straightforward application of a general-purpose solver to the natural integer linear programming formulation. Our results indicate that much better results can be obtained by using the same general-purpose solver to tackle a nonstandard Dantzig-Wolfe reformulation in which subproblems are associated with groups of constraints. This is also interesting because the more natural Dantzig-Wolfe reformulation of single constraints performs extremely poorly in practice."
153,"Approximation Algorithms for Integrated Distribution Network Design Problems","Li, Yu and Shu, Jia and Wang, Xi and Xiu, Naihua and Xu, Dachuan and Zhang, Jiawei","INFORMS JOURNAL ON COMPUTING","25","3","572-584","2013","SUM","Approximation Algorithm;Supply Chain Network Design;Facility Location","","In this paper, we study approximation algorithms for two supply chain network design problems, namely, the warehouse-retailer network design problem (WRND) and the stochastic transportation-inventory network design problem (MIND). These two problems generalize the classical uncapacitated facility location problem by incorporating, respectively, the warehouse-retailer echelon inventory cost and the warehouse cycle inventory together with the safety stock costs. The WRND and the STIND were initially studied, respectively, by Teo and Shu (Teo CP, Shu J (2004) Warehouse-retailer network design problem. Oper. Res. 52(3):396-408) and Shu et al. (Shu J, Teo CP, Shen ZJM (2005) Stochastic transportation-inventory network design problem. Oper. Res. 53(1):48-60), where they are formulated as set-covering problems, and column-generation algorithms were used to solve their linear programming relaxations. Both problems can be regarded as special cases of the so-called facility location with submodular facility costs proposed by Svitkina and Tardos (Svitkina Z, Tardos E (2010) Facility location with hierarchical facility costs. ACM Trans. Algorithms 6(2), Article No. 37), for which only a logarithmic-factor approximation algorithm is known. Our main contribution is to obtain efficient constant-factor approximation algorithms for the WRND and the STIND, which are capable of solving large-scale instances of these problems efficiently."
154,"Exact Algorithms for a Bandwidth Packing Problem with Queueing Delay Guarantees","Han, Jinil and Lee, Kyungsik and Lee, Chungmok and Park, Sungsoo","INFORMS JOURNAL ON COMPUTING","25","3","585-596","2013","SUM","Bandwidth Packing;Queueing Delay;Telecommunications Networks;Branch-And-Price Procedure;Integer Programming","","The bandwidth packing problem (BWP) concerns the selection of calls from a given set and the assignment of one path to each selected call. The ultimate aim of the BWP is to maximize profit while the routings of the selected calls observe the capacity constraints of the links. Here, we additionally consider queueing delays in the network, which may cause a deterioration in the quality of service to users if they exceed the acceptable limits. The integer programming formulation for the BWP with the queueing delay restriction contains a nonlinear constraint that is intrinsic to the model. We apply the Dantzig-Wolfe decomposition to this nonlinear constraint, and since the Dantzig-Wolfe decomposition has exponentially many variables, we propose the branch-and-price procedure to find optimal solutions. We also propose a generalized Dantzig-Wolfe reformulation based on the aggregation of variables, which makes our branch-and-price algorithm more competitive. Computational results on cases of randomly generated networks and some real-life telecommunication networks demonstrate that our algorithm performs well for large networks."
155,"An Exact Algorithm for the Multitrip Vehicle Routing Problem","Mingozzi, Aristide and Roberti, Roberto and Toth, Paolo","INFORMS JOURNAL ON COMPUTING","25","2","193-207","2013","SPR","Vehicle Routing;Multiple Trips;Dual Ascent Heuristics;Column-And-Cut Generation","","The multitrip vehicle routing problem (MTVRP) is a variant of the capacitated vehicle routing problem where each vehicle can perform a subset of routes, called a vehicle schedule, subject to maximum driving time constraints. Despite its practical importance, the MTVRP has received little attention in the literature. Few heuristics have been proposed, and only an exact algorithm has been presented for a variant of the MTVRP with customer time window constraints and unlimited driving time for each vehicle. We describe two set-partitioning-like formulations of the MTVRP. The first formulation requires the generation of all feasible routes, whereas the second formulation is based on the generation of all feasible schedules. We study valid lower bounds, based on the linear relaxations of both formulations enforced with valid inequalities, that are embedded into an exact solution method. The computational results show that the proposed exact algorithm can solve MTVRP instances taken from the literature, with up to 120 customers."
156,"A New Local Search Algorithm for Binary Optimization","Bertsimas, Dimitris and Iancu, Dan A. and Katz, Dmitriy","INFORMS JOURNAL ON COMPUTING","25","2","208-221","2013","SPR","Programming;Integer;Algorithms;Heuristic","","We develop a new local search algorithm for binary optimization problems, whose complexity and performance are explicitly controlled by a parameter Q, measuring the depth of the local search neighborhood. We show that the algorithm is pseudo-polynomial for general cost vector c, and achieves a w(2)/(2w - 1) approximation guarantee for set packing problems with exactly w ones in each column of the constraint matrix A, when using Q = w(2). Most importantly, we find that the method has practical promise on large, randomly generated instances of both set covering and set packing problems, as it delivers performance that is competitive with leading general-purpose optimization software (CPLEX 11.2)."
157,"On Maximum Speedup Ratio of Restart Algorithm Portfolios","Mostovyi, Oleksii and Prokopyev, Oleg A. and Shylo, Oleg V.","INFORMS JOURNAL ON COMPUTING","25","2","222-229","2013","SPR","Parallel Optimization;Restart;Algorithm Portfolio;Las Vegas Algorithm","","We discuss two possible parallel strategies for randomized restart algorithms. Given a set of available algorithms, one can either choose the best performing algorithm and run its multiple copies in parallel (single algorithm portfolio) or choose some subset of algorithms to run in parallel (mixed algorithm portfolio). It has been previously shown that the latter approach may provide better results computationally. In this paper, we provide theoretical investigation of the extent of such improvement generalizing some of the known results from the literature. In particular, we estimate the computational value of mixing randomized restart algorithms with different properties. Under some mild assumptions, we prove that in the best case the mixed algorithm portfolio may perform approximately up to 1.58 times faster than the best single algorithm portfolio. We also show that the obtained upper bound is sharp. Furthermore, the constructive proof of the main result allows us to characterize algorithms that are likely to form an effective mixed algorithm portfolio."
158,"Stochastic Trust-Region Response-Surface Method (STRONG)-A New Response-Surface Framework for Simulation Optimization","Chang, Kuo-Hao and Hong, L. Jeff and Wan, Hong","INFORMS JOURNAL ON COMPUTING","25","2","230-243","2013","SPR","Response Surface Methodology;Trust Region Method;Simulation Optimization;Black-Box Method","","Response surface methodology (RSM) is a widely used method for simulation optimization. Its strategy is to explore small subregions of the decision space in succession instead of attempting to explore the entire decision space in a single attempt. This method is especially suitable for complex stochastic systems where little knowledge is available. Although RSM is popular in practice, its current applications in simulation optimization treat simulation experiments the same as real experiments. However, the unique properties of simulation experiments make traditional RSM inappropriate in two important aspects: (1) It is not automated; human involvement is required at each step of the search process; (2) RSM is a heuristic procedure without convergence guarantee; the quality of the final solution cannot be quantified. We propose the stochastic trust-region response-surface method (STRONG) for simulation optimization in attempts to solve these problems. STRONG combines RSM with the classic trust-region method developed for deterministic optimization to eliminate the need for human intervention and to achieve the desired convergence properties. The numerical study shows that STRONG can outperform the existing methodologies, especially for problems that have grossly noisy response surfaces, and its computational advantage becomes more obvious when the dimension of the problem increases."
159,"Bin Packing with Conflicts: A Generic Branch-and-Price Algorithm","Sadykov, Ruslan and Vanderbeck, Francois","INFORMS JOURNAL ON COMPUTING","25","2","244-255","2013","SPR","Branch And Price;Bin Packing;Knapsack;Conflict Graphs;Interval Graphs","","The bin packing problem with conflicts consists of packing items in a minimum number of bins of limited capacity while avoiding joint assignments of items that are in conflict. Our study demonstrates that a generic implementation of a branch-and-price algorithm using specific pricing oracle yields comparatively good performance for this problem. We use our black-box branch-and-price solver BaPCod, relying on its generic branching scheme and primal heuristics. We developed a dynamic programming algorithm for pricing when the conflict graph is an interval graph, and a depth-first-search branch-and-bound approach for pricing when the conflict graph has no special structure. The exact method is tested on instances from the literature where the conflict graph is an interval graph, as well as harder instances that we generated with an arbitrary conflict graph and larger number of items per bin. Our computational experiment report sets new benchmark results for this problem, closing all open instances of the literature in one hour of CPU time."
160,"Layered Graph Approaches to the Hop Constrained Connected Facility Location Problem","Ljubic, Ivana and Gollowitzer, Stefan","INFORMS JOURNAL ON COMPUTING","25","2","256-270","2013","SPR","Hop Constrained Minimum Spanning Trees;Hop Constrained Steiner Trees;Connected Facility Location;Mixed Integer Programming Models;Lp-Relaxations","","Given a set of customers, a set of potential facility locations, and some interconnection nodes, the goal of the connected facility location problem (ConFL) is to find the minimum-cost way of assigning each customer to exactly one open facility and connecting the open facilities via a Steiner tree. The sum of costs needed for building the Steiner tree, facility opening costs, and the assignment costs needs to be minimized. If the number of edges between a prespecified node (the so-called root) and each open facility is limited, we speak of the hop constrained facility location problem (HC ConFL). This problem is of importance in the design of data-management and telecommunication networks. In this article we provide the first theoretical and computational study for this new problem that has not been studied in the literature so far. We propose two disaggregation techniques that enable the modeling of HC ConFL: (i) as a directed (asymmetric) ConFL on layered graphs, or (ii) as the Steiner arborescence problem (SA) on layered graphs. This allows for usage of best-known mixed integer programming models for ConFL or SA to solve the corresponding hop constrained problem to optimality. In our polyhedral study, we compare the obtained models with respect to the quality of their linear programming lower bounds. These models are finally computationally compared in an extensive computational study on a set of publicly available benchmark instances. Optimal values are reported for instances with up to 1,300 nodes and 115,000 edges."
161,"Valid Linear Programming Bounds for Exact Mixed-Integer Programming","Steffy, Daniel E. and Wolter, Kati","INFORMS JOURNAL ON COMPUTING","25","2","271-284","2013","SPR","Mixed-Integer Programming;Exact Computation","","Fast computation of valid linear programming (LP) bounds serves as an important subroutine for solving mixed-integer programming problems exactly. We introduce a new method for computing valid LP bounds designed for this application. The algorithm corrects approximate LP dual solutions to be exactly feasible, giving a valid bound. Solutions are repaired by performing a projection and a shift to ensure all constraints are satisfied; bound computations are accelerated by reusing structural information through the branch-and-bound tree. We demonstrate this method to be widely applicable and faster than solving a sequence of exact LPs. Several variations of the algorithm are described and computationally evaluated in an exact branch-and-bound algorithm within the mixed-integer programming framework SCIP (Solving Constraint Integer Programming)."
162,"Critically Loaded Time-Varying Multiserver Queues: Computational Challenges and Approximations","Ko, Young Myoung and Gautam, Natarajan","INFORMS JOURNAL ON COMPUTING","25","2","285-301","2013","SPR","Transient Analysis;Multiserver Queues;Nearly Critically Loaded;Uniform Acceleration;Strong Approximations","","In this paper, we consider time-varying multiserver queues with abandonment and retrials. For their performance analysis, fluid and diffusion limits utilizing strong approximations have been widely used in the literature. Although those limits are asymptotically exact, they may not accurately approximate performance of multiserver queues even if the number of servers is large. To address that concern, this paper focuses on developing a methodology by taking fluid and diffusion limits in a nontraditional fashion. We show that our approximation is significantly more accurate and also asymptotically true. We illustrate the effectiveness of our methodology by performing several numerical experiments."
163,"Branch-and-Price Guided Search for Integer Programs with an Application to the Multicommodity Fixed-Charge Network Flow Problem","Hewitt, Mike and Nemhauser, George and Savelsbergh, Martin W. P.","INFORMS JOURNAL ON COMPUTING","25","2","302-316","2013","SPR","Integer Programming;Column Generation;Local Search;Multicommodity Fixed-Charge Network Flow","","We develop an exact algorithm for integer programs that uses restrictions of the problem to produce high-quality solutions quickly. Column generation is used both for generating these problem restrictions and for producing bounds on the value of the optimal solution. The performance of the algorithm is greatly enhanced by using structure, such as arises in network flow type applications, to help define the restrictions that are solved. In addition, local search around the current best solution is incorporated to enhance overall performance. The approach is parallelized and computational experiments on a classical problem in network design demonstrate its efficacy."
164,"Rapid Screening Procedures for Zero-One Optimization via Simulation","Tsai, Shing Chih","INFORMS JOURNAL ON COMPUTING","25","2","317-331","2013","SPR","Simulation;Output Analysis;Ranking And Selection;Optimization Via Simulation","","Some existing simulation optimization algorithms (e.g., adaptive random search) become pure random search methods and thus are ineffective for the zero-one optimization via simulation problem. In this paper, we present highly efficient rapid screening procedures for solving the zero-one optimization via simulation problem. Three approaches adopting different sampling rules and providing different statistical guarantees are described. We also propose efficient neighborhood search methods and a simple algorithm for generation of initial solutions, all of which can be incorporated into our rapid screening procedures. The proposed procedures are more adaptive than ordinary ranking and selection procedures because in each iteration they can eliminate inferior solutions and intelligently sample promising solutions from the neighborhood of the survivors. Empirical studies are performed to compare the efficiency of the proposed procedures with other existing ones."
165,"A Binary Search Heuristic Algorithm Based on Randomized Local Search for the Rectangular Strip-Packing Problem","Zhang, Defu and Wei, Lijun and Leung, Stephen C. H. and Chen, Qingshan","INFORMS JOURNAL ON COMPUTING","25","2","332-345","2013","SPR","Rectangular Strip Packing;Heuristic;Local Search;Binary Search","","This paper presents a binary search heuristic algorithm for the rectangular strip-packing problem. The problem is to pack a number of rectangles into a sheet of given width and infinite height so as to minimize the required height. We first transform this optimization problem into a decision problem. A least-waste-first strategy and a minimal-inflexion-first strategy are proposed to solve the related decision problem. Lastly, we develop a binary search heuristic algorithm based on randomized local search to solve the original optimization problem. The computational results on six classes of benchmark problems have shown that the presented algorithm can find better solutions within a reasonable time than the published best heuristic algorithms for most zero-waste instances. In particular, the presented algorithm is proved to be the dominant algorithm for large zero-waste instances."
166,"A Powerful Genetic Algorithm Using Edge Assembly Crossover for the Traveling Salesman Problem","Nagata, Yuichi and Kobayashi, Shigenobu","INFORMS JOURNAL ON COMPUTING","25","2","346-363","2013","SPR","Genetic Algorithm;Traveling Salesman;Crossover;Population Diversity","","This paper presents a genetic algorithm (GA) for solving the traveling salesman problem (TSP). To construct a powerful GA, we use edge assembly crossover (EAX) and make substantial enhancements to it: (i) localization of EAX together with its efficient implementation and (ii) the use of a local search procedure in EAX to determine good combinations of building blocks of parent solutions for generating even better offspring solutions from very high-quality parent solutions. In addition, we develop (iii) an innovative selection model for maintaining population diversity at a negligible computational cost. Experimental results on well-studied TSP benchmarks demonstrate that the proposed GA outperforms state-of-the-art heuristic algorithms in finding very high-quality solutions on instances with up to 200,000 cities. In contrast to the state-of-the-art TSP heuristics, which are all based on the Lin-Kernighan (LK) algorithm, our GA achieves top performance without using an LK-based algorithm."
167,"Expected Tardiness Computations in Multiclass Priority M/M/c Queues","Hafizoglu, A. Baykal and Gel, Esma S. and Keskinocak, Pinar","INFORMS JOURNAL ON COMPUTING","25","2","364-376","2013","SPR","Due Date Quotation;Scheduling;Priority Queues;Laplace Transforms","","We discuss the evaluation of expected tardiness of an order at the time of arrival in an M/M/c queuing system with N priority classes, considering both nonpreemptive and preemptive service disciplines. Upon arrival, a customer order is quoted a lead time of d, and placed in the queue according to the priority class of the customer. Orders within the same priority class are processed on a first-come, first-served basis. We derive the Laplace transforms of the expected tardiness of the order given the quoted lead time, priority class of the order, and system status. For the special case of single priority class, the Laplace transform can be inverted into a closed-form expression. For the case with multiple priority classes, a closed-form expression cannot be obtained, hence, we develop three customized numerical inverse Laplace transformation algorithms. Two of these algorithms provide upper and lower bounds for the expected tardiness under a simple condition on system parameters. Using this property, we obtain error bounds for our customized algorithms; such bounds are not available for general purpose numerical inversion algorithms in the literature. Next, we develop a novel methodology to compare the precision of general purpose numerical inversion algorithms and analyze the performances of three algorithms from the literature. Finally, we provide a recommendation scheme given computational time and error tolerances of the decision maker. The methods developed in this paper for the accurate estimation of expected tardiness establish an important step toward developing due date quotation policies in a multiclass queue, contributing to the due date quotation literature that has been largely focused on single-class queues."
168,"An Algorithm for Approximating Convex Pareto Surfaces Based on Dual Techniques","Bokrantz, Rasmus and Forsgren, Anders","INFORMS JOURNAL ON COMPUTING","25","2","377-393","2013","SPR","Multicriteria Optimization;Pareto Optimality;Sandwich Algorithms;Radiation Therapy;Hausdorff Distance","","We consider the problem of approximating Pareto surfaces of convex multicriteria optimization problems by a discrete set of points and their convex combinations. Finding the scalarization parameters that optimally limit the approximation error when generating a single Pareto optimal solution is a nonconvex optimization problem. This problem can be solved by enumerative techniques but at a cost that increases exponentially with the number of objectives. We present an algorithm for solving the Pareto surface approximation problem that is practical with 10 or less conflicting objectives, motivated by an application to radiation therapy optimization. Our enumerative scheme is, in a sense, dual to a family of previous algorithms. The proposed technique retains the quality of the best previous algorithm in this class while solving fewer subproblems. A further improvement is provided by a procedure for discarding subproblems based on reusing information from previous solves. The combined effect of the enhancements is empirically demonstrated to reduce the computational expense of solving the Pareto surface approximation problem by orders of magnitude. For problems where the objectives have positive curvature, an improved bound on the approximation error is demonstrated using transformations of the initial objectives with strictly increasing and concave functions."
169,"Automating Bivariate Transformations","Yang, Jeff X. and Drew, John H. and Leemis, Lawrence M.","INFORMS JOURNAL ON COMPUTING","24","1","1-9","2012","WIN","Computational Probability;Computer Algebra Systems;Continuous Random Variables;Transformation Of Random Variables","","We automate the bivariate change-of-variables technique for bivariate continuous random variables with arbitrary distributions. This extends the algorithm for univariate change-of-variables devised by Glen et al. [Glen, A. G., L. M. Leemis, J. H. Drew. 1997. A generalized univariate change-of-variable transformation technique. INFORMS J. Comput. 9(3) 288-295]. Our transformation procedure handles one-to-one, k-to-one, and piecewise k-to-one transformations for both independent and dependent random variables. We also present other procedures that operate on bivariate random variables (e.g., calculating correlation and marginal distributions)."
170,"Transient Queueing Analysis","Kaczynski, William H. and Leemis, Lawrence M. and Drew, John H.","INFORMS JOURNAL ON COMPUTING","24","1","10-28","2012","WIN","Exponential Distribution;Poisson Process;Queueing Theory","","The exact distribution of the nth customer's sojourn time in an M/M/s queue with k customers initially present is derived. Algorithms for computing the covariance between sojourn times for an M/M/1 queue with k customers present at time 0 are also developed. Maple computer code is developed for practical application of transient queue analysis for many system measures of performance without regard to traffic intensity (i.e., the system may be unstable with traffic intensity greater than 1)."
171,"Efficient and Reliable Computation of Birth-Death Process Performance Measures","Ingolfsson, Armann and Tang, Ling","INFORMS JOURNAL ON COMPUTING","24","1","29-41","2012","WIN","Queues;Algorithms;Birth-Death;Erlang B;Erlang C;Erlang A","","We present an efficient, reliable, and easy-to-implement algorithm to compute steady-state probabilities for birth-death processes whose upper-tail probabilities decay geometrically or faster. The algorithm can provide any required accuracy and avoids over- and underflow. In addition to steady-state probabilities, the algorithm can compute any performance measure that can be expressed as the expected value of a function of the population size, for nonnegative functions that are bounded by a constant, linear, or quadratic function of population size. The algorithm works with conditional steady-state probabilities, given that the population is in a range that is extended up and down as the algorithm progresses. These conditional probabilities facilitate the derivation of truncation error bounds. We illustrate the application of the algorithm to the Erlang B, C, and A queueing systems."
172,"An Algorithm for Fitting Heavy-Tailed Distributions via Generalized Hyperexponentials","Yu, Kaiqi and Huang, Mei-Ling and Brill, Percy H.","INFORMS JOURNAL ON COMPUTING","24","1","42-52","2012","WIN","Fitting Algorithm;Heavy-Tailed Distribution;Generalized Hyperexponential Distribution;Hyperexponential Distribution","","In this paper, we propose an algorithm to fit heavy-tailed (HT) distribution functions by generalized hyperexponential (GH) distribution functions. A discussion of the steps, usage, and accuracy of the GH algorithm is given. Several examples in this paper show that the proposed method can be applied to fit HT distributions with a completely monotone probability density function (pdf) very well, like the Pareto distribution and the Weibull distribution with the shape parameter less than one, as well as HT distributions whose pdf is not completely monotone, like the lognormal distribution. In addition, we provide an example that shows that the proposed method can be applied to density estimation of real data presenting a heavy tail."
173,"An Asymptotic Test of Optimality Conditions in Multiresponse Simulation Optimization","Angun, Ebru and Kleijnen, Jack","INFORMS JOURNAL ON COMPUTING","24","1","53-65","2012","WIN","Simulation, Design Of Experiments;Simulation, Statistical Analysis;Black-Box Simulation-Optimization;White-Box Simulation-Optimization","","This paper derives a novel, asymptotic statistical test of the Karush-Kuhn-Tucker first-order necessary optimality conditions in random simulation models with multiple responses. This test combines a simple form of the delta method and a generalized version of Wald's statistic. The test is applied to both a toy problem and an (s, S) inventory-optimization problem with a service-level constraint; its numerical results are encouraging."
174,"Constraint-Based Local Search for Inventory Control Under Stochastic Demand and Lead Time","Rossi, Roberto and Tarim, S. Armagan and Bollapragada, Ramesh","INFORMS JOURNAL ON COMPUTING","24","1","66-80","2012","WIN","Inventory Control;Demand Uncertainty;Supplier Lead Time Uncertainty;Constraint-Based Local Search;Heuristics","","In this paper, we address the general multiperiod production/inventory problem with nonstationary stochastic demand and supplier lead time under service-level constraints. A replenishment cycle policy is modeled. We propose two hybrid algorithms that blend constraint programming and local search for computing near-optimal policy parameters. Both algorithms rely on a coordinate descent local search strategy; what differs is the way this strategy interacts with the constraint programming solver. These two heuristics are first, compared for small instances against an existing optimal solution method. Second, they are tested and compared with each other in terms of solution quality and run time on a set of larger instances that are intractable for the exact approach. Our numerical experiments show the effectiveness of our methods."
175,"Exact Solution of Graph Coloring Problems via Constraint Programming and Column Generation","Gualandi, Stefano and Malucelli, Federico","INFORMS JOURNAL ON COMPUTING","24","1","81-100","2012","WIN","Column Generation;Integer Linear Programming;Constraint Programming;Graph Coloring","","We consider two approaches for solving the classical minimum vertex coloring problem-that is, the problem of coloring the vertices of a graph so that adjacent vertices have different colors and minimizing the number of used colors-namely, constraint programming and column generation. Constraint programming is able to solve very efficiently many of the benchmarks but suffers from a lack of effective bounding methods. On the contrary, column generation provides tight lower bounds by solving the fractional vertex coloring problem exploited in a branch-and-price algorithm, as already proposed in the literature. The column generation approach is here enhanced by using constraint programming to solve the pricing subproblem and to compute heuristic solutions. Moreover, new techniques are introduced to improve the performance of the column generation approach in solving both the linear relaxation and the integer problem. We report extensive computational results applied to the benchmark instances: we are able to prove optimality of 11 new instances and to improve the best-known lower bounds on 17 other instances. Moreover, we extend the solution approaches to a generalization of the problem known as the minimum vertex graph multicoloring problem, where a given number of colors has to be assigned to each vertex."
176,"A Hybrid Heuristic for an Inventory Routing Problem","Archetti, Claudia and Bertazzi, Luca and Hertz, Alain and Speranza, M. Grazia","INFORMS JOURNAL ON COMPUTING","24","1","101-116","2012","WIN","Inventory Routing Problem;Metaheuristic;Tabu Search;Optimization;Integer Programming","","We consider an inventory routing problem in discrete time where a supplier has to serve a set of customers over a multiperiod horizon. A capacity constraint for the inventory is given for each customer, and the service cannot cause any stockout situation. Two different replenishment policies are considered: the order-up-to-level and the maximum-level policies. A single vehicle with a given capacity is available. The transportation cost is proportional to the distance traveled, whereas the inventory holding cost is proportional to the level of the inventory at the customers and at the supplier. The objective is the minimization of the sum of the inventory and transportation costs. We present a heuristic that combines a tabu search scheme with ad hoc designed mixed-integer programming models. The effectiveness of the heuristic is proved over a set of benchmark instances for which the optimal solution is known."
177,"Shilling Attack Detection-A New Approach for a Trustworthy Recommender System","Lee, Jong-Seok and Zhu, Dan","INFORMS JOURNAL ON COMPUTING","24","1","117-131","2012","WIN","Recommender Systems;Shilling Attacks;Multidimensional Scaling;Clustering","","Recommender systems rely on the opinions of many users to predict the preferences of potential customers. These systems have been broadly used to make quality recommendations to increase sales. However, recommender systems are vulnerable to even small data inputs of malicious information. Inappropriate products can be offered to users by injecting a few unscrupulous shilling profiles into the recommender system. This research proposes to identify a cluster of profiles by focusing on filler ratings. We examine a number of properties of such profiles, followed by empirical evidence and detailed analysis of various characteristics of the shilling attacks. We then propose a hybrid two-phase procedure for shilling attack detection. First, a multidimensional scaling approach is adopted to identify distinct behaviors that help to detect and secure the recommendation activities. Clustering-based methods are subsequently proposed to discriminate attack users. Experimental studies are conducted to show the effectiveness of the proposed method."
178,"A Time Bucket Formulation for the Traveling Salesman Problem with Time Windows","Dash, Sanjeeb and Guenluek, Oktay and Lodi, Andrea and Tramontani, Andrea","INFORMS JOURNAL ON COMPUTING","24","1","132-147","2012","WIN","Traveling Salesman Problem;Time Windows;Cutting Planes;Integer Programming","","The traveling salesman problem with time windows (TSPTW) is the problem of finding a minimum-cost path visiting a set of cities exactly once, where each city must be visited within a given time window. We present an extended formulation for the problem based on partitioning the time windows into subwindows that we call buckets. We present cutting planes for this formulation that are computationally more effective than the ones known in the literature because they exploit the division of the time windows into buckets. To obtain a good partition of the time windows, we propose an iterative linear programming (LP)-based procedure that may produce buckets of different sizes. The LP relaxation of this formulation yields strong lower bounds for the TSPTW and provides a good starting point for our branch-and-cut algorithm. We also present encouraging computational results on hard test problems from the literature, namely, asymmetric instances arising from a practical scheduling application, as well as randomly generated symmetric instances. In particular, we solve a number of previously unsolved benchmark instances."
179,"Computing Near-Optimal Policies in Generalized Joint Replenishment","Adelman, Daniel and Klabjan, Diego","INFORMS JOURNAL ON COMPUTING","24","1","148-164","2012","WIN","Approximate Dynamic Programming;Piecewise-Linear Ridge Functions;Generalized Joint Replenishment","","We provide a practical methodology for solving the generalized joint replenishment (GJR) problem, based on a mathematical programming approach to approximate dynamic programming. We show how to automatically generate a value function approximation basis built upon piecewise-linear ridge functions by developing and exploiting a theoretical connection with the problem of finding optimal cyclic schedules. We provide a variant of the algorithm that is effective in practice, and we exploit the special structure of the GJR problem to provide a coherent, implementable framework."
180,"Computational Testing of a Separation Procedure for the Knapsack Set with a Single Continuous Variable","Avella, Pasquale and Boccia, Maurizio and Vasilyev, Igor","INFORMS JOURNAL ON COMPUTING","24","1","165-171","2012","WIN","Knapsack Set With A Single Continuous Variable;Exact Separation","","We study an exact separation procedure-SEP-MK-for the knapsack set with a single continuous variable X-MK. Then, we address the question of whether SEP-M K can be of practical use in tightening mixed-integer programming (MIP) formulations when using standard (floating-point) MIP solvers. To this purpose, we present a separation procedure for MIP problems-SEP-MIPMK-where we derive knapsack sets of the form X-MK by aggregating the continuous variables in the mixed knapsack inequalities of the formulation. Then, we use SEP-M K to generate cutting planes. Before the continuous variables are aggregated, the mixed knapsack inequalities are modified through the use of a bound substitution procedure to take into account fixed and variable bounds on the continuous variables. Bound substitution is made according to some heuristic rules, so even if its basic component SEP-M K is exact, the overall separation procedure for MIP problems, SEP-MIPMK, is heuristic. We perform a computational study on a wide set of mixed-integer programming instances from the MIPLIB 2003 [Achterberg, T., T. Koch, A. Martin. 2006. Mixed Integer Problem Library (MIPLIB) 2003. Konrad-Zuse-Zentrum fur Informationstechnik Berlin, Berlin. http://miplib.zib.de] and Mittelmann [Mittelmann, H. 2010. MILP testcases. http://plato.asu.edu/ftp/milp] benchmark sets. Computational experiments confirm that lifted cover and mixed-integer rounding (MIR) inequalities are effective from a computational viewpoint. Nevertheless, there are several instances where SEP-MIPMK is able to significantly raise the lower bounds given by lifted cover and MIR inequalities."
181,"Disjunctive Decomposition for Two-Stage Stochastic Mixed-Binary Programs with Generalized Upper Bound Constraints","Keller, Brian and Bayraksan, Guezin","INFORMS JOURNAL ON COMPUTING","24","1","172-186","2012","WIN","Stochastic Integer Programming;Disjunctive Decomposition;Generalized Upper Bound Constraints;Stochastic Scheduling","","The disjunctive decomposition (D-2) algorithm has emerged as a powerful tool to solve stochastic integer programs. In this paper, we consider two-stage stochastic integer programs with binary first-stage and mixedbinary second-stage decisions and present several computational enhancements to D-2. First, we explore the use of a cut generation problem restricted to a subspace of the variables, which yields significant computational savings. Then, we examine problems with generalized upper bound constraints in the second stage and exploit this structure to generate cuts. We establish convergence of D-2 variants. We present computational results on a new stochastic scheduling problem with an uncertain number of jobs motivated by companies in industries such as consulting and defense contracting, where these companies bid on future contracts but may or may not win the bid. The enhancements reduced computation time on average by 45% on a set of test problems."
182,"Quantifying the Trade-off Between IMRT Treatment Plan Quality and Delivery Efficiency Using Direct Aperture Optimization","Salari, Ehsan and Romeijn, H. Edwin","INFORMS JOURNAL ON COMPUTING","24","4","518-533","2012","FAL","Intensity-Modulated Radiation Therapy;Direct Aperture Optimization;Beam-On Time","","Beam-on time is an important measure of the delivery efficiency in intensity-modulated radiation therapy (IMRT). Traditionally, minimizing beam-on time has been postponed until the leaf sequencing stage, where the treatment plan quality is already determined and fixed. However, there is a trade-off between the beam-on time and the treatment plan quality. The aim of this study is to incorporate the beam-on time into the treatment plan optimization stage using a direct aperture optimization approach that allows for explicitly quantifying the trade-off. The proposed approach can provide clinicians with valuable information for each patient case so that they can design clinically attractive yet efficient treatment plans. Using the special structure of the problem, we propose an exact solution approach that sequentially characterizes segments of the Pareto-efficient frontier. In addition, an approximate solution technique that is applicable to more classes of evaluation criteria is developed. Our approximate technique is tested on clinical cancer cases, and its performance is compared with the general approximation techniques that are available for convex bicriteria optimization problems. The results of our experiments validate that our approach can achieve a more accurate representation of the Pareto-efficient frontier with less computational effort."
183,"The Generalized Covering Salesman Problem","Golden, Bruce and Naji-Azimi, Zahra and Raghavan, S. and Salari, Majid and Toth, Paolo","INFORMS JOURNAL ON COMPUTING","24","4","534-553","2012","FAL","Covering Salesman Problem;Generalized Covering Salesman Problem;Generalized Traveling Salesman Problem;Heuristic Algorithms;Local Search","","Given a graph G = (N, E), the covering salesman problem (CSP) is to identify the minimum length tour covering all the nodes. More specifically, it seeks the minimum-length tour visiting a subset of the nodes in N such that each node i not on the tour is within a predetermined distance d(i) of a node on the tour. In this paper, we define and develop a generalized version of the CSP, and we refer to it as the generalized covering salesman problem (GCSP). Here, each node i needs to be covered at least k(i) times, and there is a cost associated with visiting each node. We seek a minimum-cost tour such that each node i is covered at least k(i) times by the tour. We define three variants of the GCSP. In the first case, each node can be visited by the tour at most once. In the second case, visiting a node i more than once is possible, but an overnight stay is not allowed (i. e., to revisit a node i, the tour has to visit another node before it can return to i). Finally, in the third case, the tour can visit each node more than once consecutively. In this paper, we develop two local search heuristics to find high-quality solutions to the three GCSP variants. To test the proposed algorithms, we generated data sets based on traveling salesman problem library instances. Because the CSP and the generalized traveling salesman problem are special cases of the GCSP, we tested our heuristics on both of those problems as well. Overall, the results show that our proposed heuristics find high-quality solutions very rapidly."
184,"A Generic Branch-and-Cut Algorithm for Multiobjective Optimization Problems: Application to the Multilabel Traveling Salesman Problem","Jozefowiez, Nicolas and Laporte, Gilbert and Semet, Frederic","INFORMS JOURNAL ON COMPUTING","24","4","554-564","2012","FAL","Decision Analysis;Multiple Criteria;Programming;Multiple Criteria;Programming;Integer;Algorithm;Cutting Plane;Networks-Graphs;Traveling Salesman","","This paper describes a generic branch-and-cut algorithm applicable to the solution of multiobjective optimization problems for which a lower bound can be defined as a polynomially solvable multiobjective problem. The algorithm closely follows standard branch and cut except for the definition of the lower and upper bounds and some optional speed-up mechanisms. It is applied to a routing problem called the multilabel traveling salesman problem, a variant of the traveling salesman problem in which labels are attributed to the edges. The goal is to find a Hamiltonian cycle that minimizes the tour length and the number of labels in the tour. Implementations of the generic multiobjective branch-and-cut algorithm and speed-up mechanisms are described. Computational experiments are conducted, and the method is compared to the classical is an element of-constraint method."
185,"Dividing a Territory Among Several Vehicles","Carlsson, John Gunnar","INFORMS JOURNAL ON COMPUTING","24","4","565-577","2012","FAL","Geometric Optimization;Equitable Assignment;Vehicle Routing","","We consider an uncapacitated stochastic vehicle routing problem in which vehicle depot locations are fixed, and client locations in a service region are unknown but are assumed to be independent and identically distributed samples from a given probability density function. We present an algorithm for partitioning the service region into subregions so as to balance the workloads of all vehicles when the service region is simply connected and point-to-point distances follow some natural metric, such as any L p norm. This algorithm can also be applied to load balancing of other combinatorial structures, such as minimum spanning trees and minimum matchings."
186,"The Fixed-Charge Shortest-Path Problem","Engineer, Faramroze G. and Nemhauser, George L. and Savelsbergh, Martin W. P. and Song, Jin-Hwa","INFORMS JOURNAL ON COMPUTING","24","4","578-596","2012","FAL","Shortest Path;Fixed Charge;Dynamic Programming","","Consider a network N = (N, A) and associate with each arc e is an element of A a fixed cost c(e) for using arc e, an interval [l(e), u(e)] (l(e), u(e) is an element of Z) specifying the range of allowable resource consumption quantities along arc e, and a per-unit cost (c) over bar (e) for resource consumed along e. Furthermore, for each node n is an element of N, let U-n is an element of N be the maximum amount of resource consumption a path can accumulate before visiting node n. Given a source node n(s) is an element of N and sink node n(t) is an element of N, the fixed-charge shortest-path problem (FCSPP) seeks to find a minimum-cost-feasible path from n(s) to n(t). When resource consumption is simply additive, the resource-constrained shortest-path problem (RCSPP) is a special case of FCSPP. We develop a new dynamic programming algorithm for FCSPP. The algorithm uses solutions from labeling and dominance techniques for standard RCSPPs on slightly modified problems, and it combines these solutions by exploiting the structure provided by certain classes of knapsack problems to efficiently construct an optimal solution to FCSPP. Computational experiments demonstrate that our algorithm is often several orders of magnitude faster than naive dynamic programming procedures."
187,"A Simple but Usually Fast Branch-and-Bound Algorithm for the Capacitated Facility Location Problem","Goertz, Simon and Klose, Andreas","INFORMS JOURNAL ON COMPUTING","24","4","597-610","2012","FAL","Mixed-Integer Programming;Lagrangean Relaxation;Capacitated Facility Location;Subgradient Optimization;Volume Algorithm;Branch And Bound","","This paper presents a simple branch-and-bound method based on Lagrangean relaxation and subgradient optimization for solving large instances of the capacitated facility location problem (CFLP) to optimality. To guess a primal solution to the Lagrangean dual, we average solutions to the Lagrangean subproblem. Branching decisions are then based on this estimated (fractional) primal solution. Extensive numerical results reveal that the method is much faster and more robust than other state-of-the-art methods for solving the CFLP exactly."
188,"Structural Search and Optimization in Social Networks","Dawande, Milind and Mookerjee, Vijay and Sriskandarajah, Chelliah and Zhu, Yunxia","INFORMS JOURNAL ON COMPUTING","24","4","611-623","2012","FAL","Social Networks;Structural Search;Analysis Of Algorithms;Computational Complexity","","The explosive growth in the variety and size of social networks has focused attention on searching these networks for useful structures. Like the Internet or the telephone network, the ability to efficiently search large social networks will play an important role in the extent of their use by individuals and organizations alike. However, unlike these domains, search on social networks is likely to involve measures that require a set of individuals to collectively satisfy some skill requirement or be tightly related to each other via some underlying social property of interest. The aim of this paper is to highlight-and demonstrate via specific examples-the need for algorithmic results for some fundamental set-based notions on which search in social networks is expected to be prevalent. To this end, we argue that the concepts of an influential set and a central set that highlight, respectively, the specific role and the specific location of a set are likely to be useful in practice. We formulate two specific search problems: the elite group problem (EGP) and the portal problem (PP), that represent these two concepts and provide a variety of algorithmic results. We first demonstrate the relevance of EGP and PP across a variety of social networks reported in the literature. For simple networks (e. g., structured trees and bipartite graphs, cycles, paths), we show that an optimal solution to both EGP and PP is easy to obtain. Next, we show that EGP is polynomially solvable on a general graph, whereas PP is strongly NP-hard. Motivated by practical considerations, we also discuss (i) a size-constrained variant of EGP together with its penalty-based relaxation and (ii) the solution of PP on balanced and full d-trees and general trees."
189,"Finite-Sample Performance of Absolute Precision Stopping Rules","Singham, Dashi I. and Schruben, Lee W.","INFORMS JOURNAL ON COMPUTING","24","4","624-635","2012","FAL","Simulation;Statistical Analysis;Design Of Experiments","","Absolute precision stopping rules are often used to determine the length of sequential experiments to estimate confidence intervals for simulated performance measures. Much is known about the asymptotic behavior of such procedures. In this paper, we introduce coverage contours to quantify the trade-offs in interval coverage, stopping times, and precision for finite-sample experiments using absolute precision rules. We use these contours to evaluate the coverage of a basic absolute precision stopping rule, and we show that this rule will lead to a bias in coverage even if all of the assumptions supporting the procedure are true. We define optimal stopping rules that deliver nominal coverage with the smallest expected number of observations. Contrary to previous asymptotic results that suggest decreasing the precision of the rule to approach nominal coverage in the limit, we find that it is optimal to increase the confidence coefficient used in the stopping rule, thus obtaining nominal coverage in a finite-sample experiment. If the simulation data are independent and identically normally distributed, we can calculate coverage contours analytically and find a stopping rule that is insensitive to the variance of the data while delivering at least nominal coverage for any precision value."
190,"Large-Order Multiple Recursive Generators with Modulus 2(31)-1","Deng, Lih-Yuan and Shiau, Jyh-Jen Horng and Lu, Henry Horng-Shing","INFORMS JOURNAL ON COMPUTING","24","4","636-647","2012","FAL","Dx/Dl/Ds Generators;Equidistribution;Portable And Efficient Generators;Pollard'S (P-1) Method;Pollard Rho Method;Primality Testing","","The performance of a maximum-period multiple recursive generator (MRG) depends on the choices of the recurrence order k, the prime modulus p, and the multipliers used. For a maximum-period MRG, a large-order k not only means a large period length (i.e., p(k) - 1) but, more importantly, also guarantees the equidistribution property in high dimensions (i. e., up to k dimensions), a desirable feature for a good random-number generator. As to generating efficiency, in addition to the multipliers, some special choices of the prime modulus p can significantly speed up the generation of pseudo-random numbers by replacing the expensive modulo operation with efficient logical operations. To construct efficient maximum-period MRGs of a large order, we consider the prime modulus p = 2(31) - 1 and, via extensive computer search, find two large values of k, 7 1 499 and 20,897, for which p(k) - 1 can be completely factorized. The successful search is achieved with the help of some results in number theory as well as some modern factorization methods. A general class of MRGs is introduced, which includes several existing classes of efficient generators. With the factorization results, we are able to identify via computer search within this class many portable and efficient maximum-period MRGs of order 7,499 or 20,897 with prime modulus 2(31) - 1 and multipliers of powers-of-two decomposition. These MRGs all pass the stringent TestU01 test suite empirically."
191,"A Mathematical Framework for Data Quality Management in Enterprise Systems","Bai, Xue","INFORMS JOURNAL ON COMPUTING","24","4","648-664","2012","FAL","Data Quality;Control;Business Process;Mathematical Modeling;Multiple-Choice Knapsack Problem","","This paper addresses the issue of data quality management in information systems within an enterprise. Motivated by legislative mandates such as the Sarbanes-Oxley Act of 2002 on the reliability and integrity of the data and the enterprise systems from which the data are produced, we propose a process-based modeling framework to assess the impact of data errors in the business process information flow and the resulting data quality metrics. This framework is then integrated with a business control framework in which the placement and effectiveness of control procedures alter the propagation of errors and, ultimately, the quality of the data in the business process. This integrated framework enables mathematical formulations of managerial problems that lead to effective data quality control strategies. We develop a two-stage multiple-choice knapsack model as a special case, and we illustrate the model and analysis through a revenue realization process."
192,"SMART: A Stochastic Multiscale Model for the Analysis of Energy Resources, Technology, and Policy","Powell, Warren B. and George, Abraham and Simao, Hugo and Scott, Warren and Lamont, Alan and Stewart, Jeffrey","INFORMS JOURNAL ON COMPUTING","24","4","665-682","2012","FAL","Artificial Intelligence;Simulation;Statistical Analysis;Analysis Of Algorithms;Queues","","We address the problem of modeling energy resource allocation, including dispatch, storage, and the long-term investments in new technologies, capturing different sources of uncertainty such as energy from wind, demands, prices, and rainfall. We also wish to model long-term investment decisions in the presence of uncertainty. Accurately modeling the value of all investments, such as wind turbines and solar panels, requires handling fine-grained temporal variability and uncertainty in wind and solar in the presence of storage. We propose a modeling and algorithmic strategy based on the framework of approximate dynamic programming (ADP) that can model these problems at hourly time increments over an entire year or several decades. We demonstrate the methodology using both spatially aggregate and disaggregate representations of energy supply and demand. This paper describes the initial proof of concept experiments for an ADP-based model called SMART; we describe the modeling and algorithmic strategy and provide comparisons against a deterministic benchmark as well as initial experiments on stochastic data sets."
193,"A Hybrid Tabu Search and Constraint Programming Algorithm for the Dynamic Dial-a-Ride Problem","Berbeglia, Gerardo and Cordeau, Jean-Francois and Laporte, Gilbert","INFORMS JOURNAL ON COMPUTING","24","3","343-355","2012","SUM","Dial-A-Ride Problem;Dynamic;Constraint Programming;Tabu Search;Scheduling","","This paper introduces a hybrid algorithm for the dynamic dial-a-ride problem in which service requests arrive in real time. The hybrid algorithm combines an exact constraint programming algorithm and a tabu search heuristic. An important component of the tabu search heuristic consists of three scheduling procedures that are executed sequentially. Experiments show that the constraint programming algorithm is sometimes able to accept or reject incoming requests, and that the hybrid method outperforms each of the two algorithms when they are executed alone."
194,"New State-Space Relaxations for Solving the Traveling Salesman Problem with Time Windows","Baldacci, Roberto and Mingozzi, Aristide and Roberti, Roberto","INFORMS JOURNAL ON COMPUTING","24","3","356-371","2012","SUM","Traveling Salesman Problem;Time Windows;State-Space Relaxations","","The traveling salesman problem with time windows (TSPTW) is the problem of finding in a weighted digraph a least-cost tour starting from a selected vertex, visiting each vertex of the graph exactly once according to a given time window, and returning to the starting vertex. This NP-hard problem arises in routing and scheduling applications. This paper introduces a new tour relaxation, called ngL-tour, to compute a valid lower bound on the TSPTW obtained as the cost of a near-optimal dual solution of a problem that seeks a minimum-weight convex combination of nonnecessarily elementary tours. This problem is solved by column generation. The optimal integer TSPTW solution is computed with a dynamic programming algorithm that uses bounding functions based on different tour relaxations and the dual solution obtained. An extensive computational analysis on basically all TSPTW instances (involving up to 233 vertices) from the literature is reported. The results show that the proposed algorithm solves all but one instance and outperforms all exact methods published in the literature so far."
195,"Discovery of Periodic Patterns in Sequence Data: A Variance-Based Approach","Yang, Yinghui (Catherine) and Padmanabhan, Balaji and Liu, Hongyan and Wang, Xiaoyu","INFORMS JOURNAL ON COMPUTING","24","3","372-386","2012","SUM","Data Mining;Sequential Patterns;Variance Reduction;Analysis Of Algorithms","","We address the discovery of periodic patterns in sequence data. Building on prior work in this area, we present definitions and new methods for characterizing and identifying four types of periodic patterns. A unifying concept across the different types of periodic patterns we consider is the use of statistical variance to define periodicity. This lends itself to efficient variance-reduction algorithms for identifying periodic patterns. We motivate and test our approach using both extensive simulated sequences and real sequence data from online clickstream data."
196,"Using Logic-Based Benders Decomposition to Solve the Capacity- and Distance-Constrained Plant Location Problem","Fazel-Zarandi, Mohammad M. and Beck, J. Christopher","INFORMS JOURNAL ON COMPUTING","24","3","387-398","2012","SUM","Facility Location;Fleet Management;Logic-Based Benders Decomposition;Ip/Cp Hybrid","","We address an optimization problem that requires deciding the location of a set of facilities, the allocation of customers to those facilities under capacity constraints, and the allocation of customers to trucks at those facilities under truck travel-distance constraints. We present a hybrid approach that combines integer and constraint programming using logic-based Benders decomposition. Computational experiments demonstrate that the Benders model is able to find and prove optimal solutions up to three orders-of-magnitude faster than an existing integer programming approach; it also finds better feasible solutions in less time when compared with an existing tabu search algorithm."
197,"CORAL: An Exact Algorithm for the Multidimensional Knapsack Problem","Mansini, Renata and Speranza, M. Grazia","INFORMS JOURNAL ON COMPUTING","24","3","399-415","2012","SUM","Multidimensional Knapsack Problem;Exact Algorithm;Reduced Costs;Recursive Variable Fixing;Cardinality Constraint","","The multidimensional knapsack problem (MKP) is a well-known, strongly NP-hard problem and one of the most challenging problems in the class of the knapsack problems. In the last few years, it has been a favorite playground for metaheuristics, but very few contributions have appeared on exact methods. In this paper we introduce an exact approach based on the optimal solution of subproblems limited to a subset of variables. Each subproblem is faced through a recursive variable-fixing process that continues until the number of variables decreases below a given threshold (restricted core problem). The solution space of the restricted core problem is split into subspaces, each containing solutions of a given cardinality. Each subspace is then explored with a branch-and-bound algorithm. Pruning conditions are introduced to improve the efficiency of the branch-and-bound routine. In all the tested instances, the proposed method was shown to be, on average, more efficient than the recent branch-and-bound method proposed by Vimont et al. [Vimont, Y., S. Boussier, M. Vasquez. 2008. Reduced costs propagation in an efficient implicit enumeration for the 0-1 multidimensional knapsack problem. J. Combin. Optim. 15(2) 165-178] and CPLEX 10. We were able to improve the best-known solutions for some of the largest and most difficult instances of the OR-LIBRARY data set [Chu, P. C., J. E. Beasley. 1998. A genetic algorithm for the multidimensional knapsack problem. J. Heuristics 4(1) 63-86]."
198,"On the Prevention of Fraud and Privacy Exposure in Process Information Flow","Bai, Xue and Gopal, Ram and Nunez, Manuel and Zhdanov, Dmitry","INFORMS JOURNAL ON COMPUTING","24","3","416-432","2012","SUM","Information Security;Data Privacy;Workflow Optimization;Queueing Theory;Open Jackson Networks","","Our work addresses internal information breaches that emanate from organizational workflows. Information breaches are particularly piquant in organizational workflows, as the underlying tasks constitute natural points where private information on individuals is accessed to execute the workflows. Our work builds on and extends the widely used role-based access controls by considering processwide security considerations to both optimize the efficiency of workflow staffing and minimize data exposure in complex workflows. We employ a Jackson queueing network modeling framework, which allows both predictable and stochastic variability as well as varied employee skill sets. This framework enables the modeling of internal security threats that emanate from cross-task and cross-personnel assignments and the development of optimal staffing strategies that meet security requirements at minimum operational costs. Our detailed implementation analysis reveals that the model developed is not demanding in terms of required parameters and that the proposed approach is practical and adaptable to evolving business, regulatory, and workforce conditions. Our model is applicable to any digital transformation that involves confidential data sequences that carry security vulnerability, as is often the case in many settings such as health care, online banking, electronic payment systems, and interorganizational data interchange."
199,"A Branch, Bound, and Remember Algorithm for the Simple Assembly Line Balancing Problem","Sewell, E. C. and Jacobson, S. H.","INFORMS JOURNAL ON COMPUTING","24","3","433-442","2012","SUM","Combinatorial Optimization;Heuristics;Production;Programming;Branch And Bound","","We present a new exact algorithm for the assembly line balancing problem. The algorithm finds and verifies the optimal solution for every problem in the combined benchmarks of Hoffmann, Talbot, and Scholl in less than one-half second per problem, on average, including one problem that has remained open for over 10 years. The previous best-known algorithm is able to solve 257 of the 269 benchmarks. The new algorithm is based on a branch-and-bound method that uses memory to eliminate redundant subproblems."
200,"A Branch-and-Cut Approach for the Minimum-Energy Broadcasting Problem in Wireless Networks","Li, Xiangyong and Aneja, Y. P.","INFORMS JOURNAL ON COMPUTING","24","3","443-456","2012","SUM","Programming, Integer;Algorithm, Cutting Plane;Minimum-Energy Topology;Wireless Networks","","This paper studies the minimum-energy broadcasting problem (MEBP) in wireless sensor networks. The aim of the MEBP is to determine the power assignment of each node in a wireless sensor network such that a specified source node can broadcast messages to each of the other nodes and the total energy consumption is minimized. We first present a new formulation involving an exponential number of constraints for the broadcasting requirement. We then prove that under a mild condition, these constraints for the broadcasting requirement are facet defining. Directly using the proposed formulation, we further present a new branch-and-cut (B&C) solution approach to optimally solve the MEBP. We propose three ways to identify violated cuts at each node in the enumeration tree. Finally, we test the proposed B&C approach on 1,000 randomly generated instances with different properties and compare it with other alternative methods in the literature. Computational results demonstrate the effectiveness and efficiency of our approach using the proposed formulation for instances with up to 100 nodes."
201,"Data Structures for Higher-Dimensional Rectilinear Packing","Allen, Sam D. and Burke, Edmund K.","INFORMS JOURNAL ON COMPUTING","24","3","457-470","2012","SUM","Computers: Data Structure;Cutting Stock;Combinatorial Optimization","","This paper presents an abstract data type (ADT) for producing higher-dimensional rectilinear packings using constructive methods, the Skyline ADT. Furthermore, a novel method and several approaches from the literature are presented in the form of concrete implementations of the presented ADT. Formal definitions of two three-dimensional packing problems are given, the concept of gaps is explained, and the polynomial growth worst-case behaviour of gaps is shown. The complexity of both the best-fit algorithm and implementations of the ADT are presented, and comparative runtime speeds are analysed over a range of data sets from the literature."
202,"Robust Optimization in Simulation: Taguchi and Krige Combined","Dellino, Gabriella and Kleijnen, Jack P. C. and Meloni, Carlo","INFORMS JOURNAL ON COMPUTING","24","3","471-484","2012","SUM","Statistics, Design Of Experiments;Inventory Production, Simulation;Decision Analysis: Risk","","Optimization of simulated systems is the goal of many methods, but most methods assume known environments. We, however, develop a robust methodology that accounts for uncertain environments. Our methodology uses Taguchi's view of the uncertain world but replaces his statistical techniques by design and analysis of simulation experiments based on Kriging (Gaussian process model); moreover, we use bootstrapping to quantify the variability in the estimated Kriging metamodels. In addition, we combine Kriging with nonlinear programming, and we estimate the Pareto frontier. We illustrate the resulting methodology through economic order quantity (EOQ) inventory models. Our results suggest that robust optimization requires order quantities that differ from the classic EOQ. We also compare our results with results we previously obtained using response surface methodology instead of Kriging."
203,"Coloring Graphs Using Two Colors While Avoiding Monochromatic Cycles","Nobibon, Fabrice Talla and Hurkens, Cor A. J. and Leus, Roel and Spieksma, Frits C. R.","INFORMS JOURNAL ON COMPUTING","24","3","485-499","2012","SUM","Directed Graph;Undirected Graph;Bipartite Graph;Acyclic Graph;Phase Transition;Np-Complete","","We consider the problem of deciding whether a given directed graph can be vertex partitioned into two acyclic subgraphs. Applications of this problem include testing rationality of collective consumption behavior, a subject in microeconomics. We prove that the problem is NP-complete even for oriented graphs and argue that the existence of a constant-factor approximation algorithm is unlikely for an optimization version that maximizes the number of vertices that can be colored using two colors while avoiding monochromatic cycles. We present three exact algorithms-namely, an integer-programming algorithm based on cycle identification, a backtracking algorithm, and a branch-and-check algorithm. We compare these three algorithms both on real-life instances and on randomly generated graphs. We find that for the latter set of graphs, every algorithm solves instances of considerable size within a few seconds; however, the CPU time of the integer-programming algorithm increases with the number of vertices in the graph more clearly than the CPU time of the two other procedures. For real-life instances, the integer-programming algorithm solves the largest instance in about a half hour, whereas the branch-and-check algorithm takes approximately 10 minutes and the backtracking algorithm less than 5 minutes. Finally, for every algorithm, we also study empirically the transition from a high to a low probability of a YES answer as a function of the number of arcs divided by the number of vertices."
204,"Robust Software Partitioning with Multiple Instantiation","Spacey, Simon A. and Wiesemann, Wolfram and Kuhn, Daniel and Luk, Wayne","INFORMS JOURNAL ON COMPUTING","24","3","500-515","2012","SUM","Robust Optimization;Software Partitioning;Decision-Dependent Uncertainty;Multiple Instance Partitioning","","The purpose of software partitioning is to assign code segments of a given computer program to a range of I execution locations such as general-purpose processors or specialist hardware components. These execution locations differ in speed, communication characteristics, and size. In particular, hardware components offering high speed tend to accommodate only few code segments. The goal of software partitioning is to find an assignment of code segments to execution locations that minimizes the overall program run time and respects the size constraints. In this paper we demonstrate that an additional speedup is obtained if we allow code segments to be instantiated on more than one location. We further show that the program run time not only depends on the execution frequency of the code segments but also on their execution order if there are multiply instantiated code segments. Unlike frequency information, however, sequence information is not available at the time when the software partition is selected. This motivates us to formulate the software-partitioning problem as a robust optimization problem with decision-dependent uncertainty. We transform this problem to a mixed-integer linear program of moderate size and report on promising numerical results."
205,"Core Routing on Dynamic Time-Dependent Road Networks","Delling, Daniel and Nannicini, Giacomo","INFORMS JOURNAL ON COMPUTING","24","2","187-201","2012","SPR","Shortest Paths;Route Planning;Time-Dependent Networks;Dynamic Road Networks","","Route planning in large-scale time-dependent road networks is an important practical application of the shortest-path problem that greatly benefits from speedup techniques. In this paper, we extend a two-level hierarchical approach for point-to-point shortest-path computations to the time-dependent case. This method, also known as core routing in the literature for static graphs, consists of the selection of a small subnetwork where most of the computations can be carried out, thus reducing the search space. We combine this approach with bidirectional goal-directed search to obtain an algorithm capable of finding shortest paths in a matter of milliseconds on continental-sized networks. Moreover, we tackle the dynamic scenario where the piecewise linear functions that we use to model time-dependent arc costs are not fixed but can have their coefficients updated requiring only a small computational effort."
206,"A Level-3 Reformulation-Linearization Technique-Based Bound for the Quadratic Assignment Problem","Hahn, Peter M. and Zhu, Yi-Rong and Guignard, Monique and Hightower, William L. and Saltzman, Matthew J.","INFORMS JOURNAL ON COMPUTING","24","2","202-209","2012","SPR","Quadratic Assignment;Qap;Reformulation Linearization;Rlt;Dual Ascent;Exact Solution","","We apply the level-3 reformulation-linearization technique (RLT3) to the quadratic assignment problem (QAP). We then present our experience in calculating lower bounds using an essentially new algorithm based on this RLT3 formulation. Our method is not guaranteed to calculate the RLT3 lower bound exactly, but it approximates this lower bound very closely and reaches it in some instances. For Nugent problem instances up to size 24, our RLT3-based lower bound calculation solves these problem instances exactly or serves to verify the optimal value. Calculating lower bounds for problem sizes larger than size 27 still presents a challenge because of the large amount of memory needed to implement the RLT3 formulation. Our presentation emphasizes the steps taken to significantly conserve memory by using the numerous problem symmetries in the RLT3 formulation of the QAP. We implemented this RLT3-based bound calculation in a branch-and-bound algorithm. Experimental results project significant runtime improvement over all other published QAP branch-and-bound solvers."
207,"Data-Mining-Driven Neighborhood Search","Samorani, Michele and Laguna, Manuel","INFORMS JOURNAL ON COMPUTING","24","2","210-227","2012","SPR","Data Mining;Off-Line Learning;Neighborhood Search;Metaheuristic Optimization","","Metaheuristic approaches based on the neighborhood search escape local optimality by applying predefined rules and constraints, such as tabu restrictions (in tabu search), acceptance criteria (in simulated annealing), and shaking (in variable neighborhood search). We propose a general approach that attempts to learn (off-line) the guiding constraints that, when applied online, will result in effective escape directions from local optima. Given a class of problems, the learning process is performed off-line, and the results are applied to constrained neighborhood searches to guide the solution process out of local optimality. Computational results on the constrained task allocation problem show that adding these guiding constraints to a simple tabu search improves the quality of the solutions found, making the overall method competitive with state-of-the-art methods for this class of problems. We also present a second set of tests on the matrix bandwidth minimization problem."
208,"Optimal Constraint Programming Approach to the Open-Shop Problem","Malapert, Arnaud and Cambazard, Hadrien and Gueret, Christelle and Jussien, Narendra and Langevin, Andre and Rousseau, Louis-Martin","INFORMS JOURNAL ON COMPUTING","24","2","228-244","2012","SPR","Production Scheduling;Open Shop;Computers;Computer Science;Artificial Intelligence;Constraint Programming;Randomization And Restart","","This paper presents an optimal constraint programming approach for the open-shop scheduling problem, which integrates recent constraint propagation and branching techniques with new upper bound heuristics. Randomized restart policies combined with nogood recording allow us to search diversification and learning from restarts. This approach is compared with the best-known metaheuristics and exact algorithms, and it shows better results on a wide range of benchmark instances."
209,"Finding All Stable Pairs and Solutions to the Many-to-Many Stable Matching Problem","Eirinakis, Pavlos and Magos, Dimitrios and Mourtos, Ioannis and Miliotis, Panayiotis","INFORMS JOURNAL ON COMPUTING","24","2","245-259","2012","SPR","Constraint Programming;Analysis Of Algorithms;Economics","","The many-to-many stable matching problem (MM), defined in the context of a job market, asks for an assignment of workers to firms satisfying the quota of each agent and being stable, pairwise or setwise, with respect to given preference lists or relations. In this paper, we propose a time-optimal algorithm that identifies all stable worker-firm pairs and all stable assignments under pairwise stability, individual preferences, and the max-min criterion. We revisit the poset graph of rotations to obtain an optimal algorithm for enumerating all solutions to the MM and an improved algorithm finding the minimum-weight one. Furthermore, we establish the applicability of all aforementioned algorithms under more complex preference and stability criteria. In a constraint programming context, we introduce a constraint that models the MM and an encoding of the MM as a constraint satisfaction problem. Finally, we provide a series of computational results, including the case where side constraints are imposed."
210,"An Exact Method for Balancing Efficiency and Equity in the Liver Allocation Hierarchy","Demirci, Mehmet C. and Schaefer, Andrew J. and Romeijn, H. Edwin and Roberts, Mark S.","INFORMS JOURNAL ON COMPUTING","24","2","260-275","2012","SPR","Liver Transplantation;Multicriteria Optimization;Column Generation","","We study the problem of (re) designing the regional network by which cadaveric livers are allocated. Whereas prior research focused mainly on maximizing a measure of efficiency of the network that was based on aggregate patient survival, we explicitly account for the trade-off between efficiency and a measure of geographical equity in the allocation process. To this end, we extend earlier optimization models to incorporate both objectives and develop an exact branch-and-price approach to solve this problem, generalizing a solution approach studied for the case where only efficiency is taken into account. In addition, we propose an effective solution algorithm that approximates the (generally nonconcave) frontier of Pareto-efficient solutions with respect to the two objectives by simultaneously generating and successively improving upper and lower bounds on this frontier. We implement and test our approach on observed data and show that solutions significantly dominating the current configuration in both efficiency and equity can be found. Of course, other subjective criteria are needed to choose among the different Pareto-efficient candidate solutions."
211,"The Balanced Minimum Evolution Problem","Catanzaro, Daniele and Labbe, Martine and Pesenti, Raffaele and Salazar-Gonzalez, Juan-Jose","INFORMS JOURNAL ON COMPUTING","24","2","276-294","2012","SPR","Network Design;Combinatorial Optimization;Lagrangian Relaxation;Computational Biology;Balanced Minimum Evolution;Combinatorial Inequalities;Kraft Equality;Huffman Coding","","A phylogeny is an unrooted binary tree that represents the evolutionary relationships of a set of n species. Phylogenies find applications in several scientific areas ranging from medical research, to drug discovery, to epidemiology, to systematics, and to population dynamics. In such applications, the available information is usually restricted to the leaves of a phylogeny and is represented by molecular data extracted from the analyzed species, such as DNA, RNA, amino acid, or codon fragments. On the contrary, the information about the phylogeny itself is generally missing and is determined by solving an optimization problem, called the phylogeny estimation problem (PEP), whose versions depend on the criterion used to select a phylogeny from among plausible alternatives. In this paper, we investigate a recent version of the PEP, called the balanced minimum evolution problem (BMEP). We present a mixed-integer linear programming model to exactly solve instances of the BMEP and develop branching rules and families of valid inequalities to further strengthen the model. Our results give perspective on the mathematics of the BMEP and suggest new directions on the development of future efficient exact approaches to solutions of the problem."
212,"C-NORTA: A Rejection Procedure for Sampling from the Tail of Bivariate NORTA Distributions","Ghosh, Soumyadip and Pasupathy, Raghu","INFORMS JOURNAL ON COMPUTING","24","2","295-310","2012","SPR","Statistics;Simulation;Random Variable Generation;Multivariate Distribution;Correlation","","We propose C-NORTA, an exact algorithm to generate random variates from the tail of a bivariate NORTA random vector. (A NORTA random vector is specified by a pair of marginals and a rank or product-moment correlation, and it is sampled using the popular NORmal-To-Anything procedure.) We first demonstrate that a rejection-based adaptation of NORTA on such constrained random vector generation problems may often be fundamentally intractable. We then develop the C-NORTA algorithm, relying on strategic conditioning of the NORTA vector, followed by efficient approximation and acceptance/rejection steps. We show that, in a certain precise asymptotic sense, the sampling efficiency of C-NORTA is exponentially larger than what is achievable through a naive application of NORTA. Furthermore, for at least a certain class of problems, we show that the acceptance probability within C-NORTA decays only linearly with respect to a defined rarity parameter. The corresponding decay rate achievable through a naive adaptation of NORTA is exponential. We provide directives for efficient implementation."
213,"A Study of Quality and Accuracy Trade-offs in Process Mining","Huang, Zan and Kumar, Akhil","INFORMS JOURNAL ON COMPUTING","24","2","311-327","2012","SPR","Process Mining;Knowledge Discovery;Quality Metric;Quality-Accuracy Trade-Off;Quality-Based Algorithm","","In recent years, many algorithms have been proposed to extract process models from process execution logs. The process models describe the ordering relationships between tasks in a process in terms of standard constructs like sequence, parallel, choice, and loop. Most algorithms assume that each trace in a log represents a correct execution sequence based on a model. In practice, logs are often noisy, and algorithms designed for correct logs are not able to handle noisy logs. In this paper we share our key insights from a study of noise in process logs both real and synthetic. We found that all process logs can be explained by a block-structured model with two special self-loop and optional structures, making it trivial to build a fully accurate process model for any given log, even one with inaccurate data or noise present in it. However, such a model suffers from low quality. By controlling the use of self-loop and optional structures of tasks and blocks of tasks, we can balance the quality and accuracy trade-off to derive high-quality process models that explain a given percentage of traces in the log. Finally, new quality metrics and a novel quality-based algorithm for model extraction from noisy logs are described. The results of the experiments with the algorithm on real and synthetic data are reported and analyzed at length."
214,"An Improved Branch-and-Bound Method for Maximum Monomial Agreement","Eckstein, Jonathan and Goldberg, Noam","INFORMS JOURNAL ON COMPUTING","24","2","328-341","2012","SPR","Branch And Bound;Combinatorial Optimization;Machine Learning","","The NP-hard maximum monomial agreement problem consists of finding a single logical conjunction that is most consistent with or best fits a weighted data set of positive and negative binary vectors. Computing weighted voting classifiers using boosting methods involves a maximum agreement subproblem at each iteration, although such subproblems are typically solved in practice by heuristic methods. Here, we describe an exact branch-and-bound method for maximum agreement over Boolean monomials, improving on the earlier work of Goldberg and Shan [Goldberg, N., C. Shan. 2007. Boosting optimal logical patterns. Proc. 7th SIAM Internat. Conf. Data Mining, SIAM, Philadelphia, 228-236]. Specifically, we develop a tighter upper bounding function and an improved branching procedure that exploits knowledge of the bound and the particular data set, while having a lower branching factor. Experimental results show that the new method is able to solve larger problem instances and runs faster within a linear programming boosting procedure applied to medium-sized data sets from the UCI Machine Learning Repository. The new algorithm also runs much faster than applying a commercial mixed-integer programming solver, which uses linear programming relaxation-based bounds, to an integer linear programming formulation of the problem."
215,"Combining Constraint Programming and Local Search for Job-Shop Scheduling","Beck, J. Christopher and Feng, T. K. and Watson, Jean-Paul","INFORMS JOURNAL ON COMPUTING","23","1","1-14","2011","WIN","Scheduling;Tabu Search;Constraint Programming;Hybrid Algorithms","","Since their introduction, local search algorithms have consistently represented the state of the art in solution techniques for the classical job-shop scheduling problem. This dominance is despite the availability of powerful search and inference techniques for scheduling problems developed by the constraint programming community. In this paper, we introduce a simple hybrid algorithm for job-shop scheduling that leverages both the fast, broad search capabilities of modern tabu search algorithms and the scheduling-specific inference capabilities of constraint programming. The hybrid algorithm significantly improves the performance of a state-of-the-art tabu search algorithm for the job-shop problem and represents the first instance in which a constraint programming algorithm obtains performance competitive with the best local search algorithms. Furthermore, the variability in solution quality obtained by the hybrid is significantly lower than that of pure local search algorithms. Beyond performance demonstration, we perform a series of experiments that provide insights into the roles of the two component algorithms in the overall performance of the hybrid."
216,"A Parallel Branch-and-Bound Approach to the Rectangular Guillotine Strip Cutting Problem","Bak, Slawomir and Blazewicz, Jacek and Pawlak, Grzegorz and Plaza, Maciej and Burke, Edmund K. and Kendall, Graham","INFORMS JOURNAL ON COMPUTING","23","1","15-25","2011","WIN","Production Scheduling;Cutting Stock;Material Handling;Parallel Branch-And-Bound Method;Analysis Of Algorithms","","This paper presents a parallel branch-and-bound method to address the two-dimensional rectangular guillotine strip cutting problem. Our paper focuses on a parallel branching schema. We present a series of computational experiments to evaluate the strength of the approach. Optimal solutions have been found for some benchmark instances that had unknown solutions until now. For many other instances, we demonstrate that the proposed approach is time effective. The efficiency of the parallel version of the algorithm is compared and the speedup, when increasing the number of processors, is clearly demonstrated with an upper bound calculated by a specialised heuristic procedure."
217,"Decorous Lower Bounds for Minimum Linear Arrangement","Caprara, Alberto and Letchford, Adam N. and Salazar-Gonzalez, Juan-Jose","INFORMS JOURNAL ON COMPUTING","23","1","26-40","2011","WIN","Programming, Integer, Algorithm, Branch And Bound;Programming, Integer, Applications;Networks;Graphs, Applications;Analysis Of Algorithms","","Minimum linear arrangement is a classical basic combinatorial optimization problem from the 1960s that turns out to be extremely challenging in practice. In particular, for most of its benchmark instances, even the order of magnitude of the optimal solution value is unknown, as testified by the surveys on the problem that contain tables in which the best-known solution value often has one more digit than the best-known lower bound value. In this paper, we propose a linear programming-based approach to compute lower bounds on the optimum. This allows us, for the first time, to show that the best-known solutions are indeed not far from optimal for most of the benchmark instances."
218,"Branch and Price for Large-Scale Capacitated Hub Location Problems with Single Assignment","Contreras, Ivan and Diaz, Juan A. and Fernandez, Elena","INFORMS JOURNAL ON COMPUTING","23","1","41-55","2011","WIN","Hub Location;Lagrangean Relaxation;Column Generation","","This paper presents a branch-and-price algorithm for the capacitated hub location problem with single assignment, in which Lagrangean relaxation is used to obtain tight lower bounds of the restricted master problem. A lower bound that is valid at any stage of the column generation algorithm is proposed. The process to obtain this valid lower bound is combined with a constrained stabilization method that results in a considerable improvement on the overall efficiency of the solution algorithm. Numerical results on a battery of benchmark instances of up to 200 nodes are reported. These seem to be the largest instances that have been solved to optimality for this problem."
219,"Branch and Price for WDM Optical Networks with No Bifurcation of Flow","Raghavan, S. and Stanojevic, Daliborka","INFORMS JOURNAL ON COMPUTING","23","1","56-74","2011","WIN","Optical Networks;Multilayer Network Design;Network Flows;Mixed-Integer Programming Models;Branch-And-Price Procedure","","The second generation of optical networks with wavelength division multiplexing (WDM) is based on the notion of two layer networks, where the first layer represents a logical topology defined over the physical topology of optical fibers and the second layer represents multiple traffic requests combined (multiplexed) over the paths established in the logical topology. Because the design of both of these layers is challenging by itself, researchers have mainly focused on solving these problems either independently or in a sequential fashion. In this paper, we look at the WDM optical network design problem with nonbifurcated traffic flows and propose an exact branch-and-price procedure that simultaneously solves logical topology design and traffic routing over the established logical topology. The unique feature of the proposed algorithm is that it works with a row-incomplete mathematical formulation and two types of variables that exponentially grow in number with the problem size. We discuss computational issues related to the use of this procedure and propose two approximate branch-and-price procedures that can be used to obtain lower and upper bounds for this problem. Finally, we present the results of our computational experiments for two design objectives and alternative optical network settings."
220,"The Robust Network Loading Problem Under Hose Demand Uncertainty: Formulation, Polyhedral Analysis, and Computations","Altin, Aysegul and Yaman, Hande and Pinar, Mustafa C.","INFORMS JOURNAL ON COMPUTING","23","1","75-89","2011","WIN","Network Loading Problem;Polyhedral Demand Uncertainty;Hose Model;Robust Optimization;Polyhedral Analysis;Branch And Cut","","We consider the network loading problem (NLP) under a polyhedral uncertainty description of traffic demands. After giving a compact multicommodity flow formulation of the problem, we state a decomposition property obtained from projecting out the flow variables. This property considerably simplifies the resulting polyhedral analysis and computations by doing away with metric inequalities. Then we focus on a specific choice of the uncertainty description, called the hose model, which specifies aggregate traffic upper bounds for selected endpoints of the network. We study the polyhedral aspects of the NLP under hose demand uncertainty and use the results as the basis of an efficient branch-and-cut algorithm. The results of extensive computational experiments on well-known network design instances are reported."
221,"A Fully Distributed Lagrangean Solution for a Peer-to-Peer Overlay Network Design Problem","Boschetti, Marco A. and Maniezzo, Vittorio and Roffilli, Matteo","INFORMS JOURNAL ON COMPUTING","23","1","90-104","2011","WIN","Programming;Integer;Algorithms;Relaxation;Heuristic","","Peer-to-peer (P2P) computing already accounts for a large part of the traffic on the Internet, and it is likely to become as ubiquitous as current client/server architectures in next generation information systems. This paper addresses a central problem of P2P systems: the design of an optimal overlay communication network for a set of processes on the Internet. Such a network defines membership to the P2P group and allows for members to disseminate information within the group. The problem, named the membership overlay problem (MOP), can be formulated as a dynamic optimization problem where classical combinatorial optimization techniques must face the further challenge of time-varying input data. This paper proposes an innovative, fully distributed, and asynchronous subgradient optimization algorithm for the Lagrangean relaxation of the MOP, which can run online in fully decentralized P2P systems, and integrates it with a distributed heuristic that can achieve sound hot-start states for fast response to varying network structures."
222,"Dynamic Programming-Based Column Generation on Time-Expanded Networks: Application to the Dial-a-Flight Problem","Engineer, Faramroze G. and Nemhauser, George L. and Savelsbergh, Martin W. P.","INFORMS JOURNAL ON COMPUTING","23","1","105-119","2011","WIN","Dynamic Programming;Column Generation;Time-Expanded Networks;Dial-A-Flight","","We present a relaxation-based dynamic programming algorithm for solving resource-constrained shortest-path problems (RCSPPs) in the context of column generation for the dial-a-flight problem. The resulting network formulation and pricing problem require solving RCSPPs on extremely large time-expanded networks having a huge number of local resource constraints, i.e., constraints that apply to small subnetworks. The relaxation-based dynamic programming algorithm alternates between a forward and a backward search. Each search employs bounds derived in the previous search to prune the search space. Between consecutive searches, the relaxation is tightened using a set of critical resources and a set of critical arcs over which these resources are consumed. As a result, a relatively small state space is maintained, and many paths can be pruned while guaranteeing that an optimal path is ultimately found."
223,"Solving Talent Scheduling with Dynamic Programming","Garcia de la Banda, Maria and Stuckey, Peter J. and Chu, Geoffrey","INFORMS JOURNAL ON COMPUTING","23","1","120-137","2011","WIN","Dynamic Programming;Optimization;Scheduling","","We give a dynamic programming solution to the problem of scheduling scenes to minimize the cost of the talent. Starting from a basic dynamic program, we show a number of ways to improve the dynamic programming solution by preprocessing and restricting the search. We show how by considering a bounded version of the problem, and determining lower and upper bounds, we can improve the search. We then show how ordering the scenes from both ends can drastically reduce the search space. The final dynamic programming solution is orders of magnitude faster than competing approaches and finds optimal solutions to larger problems than were considered previously."
224,"Why Does Collaborative Filtering Work? Transaction-Based Recommendation Model Validation and Selection by Analyzing Bipartite Random Graphs","Huang, Zan and Zeng, Daniel Dajun","INFORMS JOURNAL ON COMPUTING","23","1","138-152","2011","WIN","Recommendation Algorithm;Random Graph Analysis;Collaborative Filtering;Bipartite Graph","","A large number of collaborative filtering algorithms have been proposed in the literature as the foundation of automated recommender systems. However, the underlying justification for these algorithms is lacking, and their relative performances are typically domain and data dependent. In this paper, we aim to develop initial understanding of the recommendation model/algorithm validation and selection issues based on the graph topological modeling methodology. By representing the input data in the form of consumer-product interactions as a bipartite graph, the consumer-product graph, we develop bipartite graph topological measures to capture patterns that exist in the input data relevant to the transaction-based recommendation task. We observe the deviations of these topological measures of real-world consumer-product graphs from the expected values for simulated random bipartite graphs. These deviations help explain why certain collaborative filtering algorithms work for particular recommendation data sets. They can also serve as the basis for a comprehensive model selection framework that recommends appropriate collaborative filtering algorithms given characteristics of the data set under study. We validate our approach using three real-world recommendation data sets and demonstrate the effectiveness of the proposed bipartite graph topological measures in selection and validation of commonly used heuristic-based recommendation algorithms, the user-based, item-based, and graph-based algorithms."
225,"Algorithms for Coxianization of Phase-Type Generators","He, Qi-Ming and Zhang, Hanqin and Xue, Jungong","INFORMS JOURNAL ON COMPUTING","23","1","153-164","2011","WIN","Matrix-Analytic Methods;Coxian Distribution;Phase-Type Distribution;Probability Distribution","","This paper develops algorithms for finding Coxian generators to phase-type (PH)-majorize a PH-generator T with only real eigenvalues. In the first part of this paper, we investigate matrices S and P satisfying TP = PS and Pe = e. Conditions on T are identified for S to be an ordered Coxian generator and for P to be nonnegative, which consequently implies that S PH-majorizes T. It is shown that every PH-generator with only real eigenvalues is PH-majorized by some Coxian generator. In the second part of this paper, the results on S and P and the conditions on T are used to develop efficient algorithms for Coxianization of PH-generators. Numerical examples are presented for a comparison between the developed algorithms."
226,"Triangular M/G/1-Type and Tree-Like Quasi-Birth-Death Markov Chains","Van Houdt, Benny and van Leeuwaarden, Johan S. H.","INFORMS JOURNAL ON COMPUTING","23","1","165-171","2011","WIN","Matrix-Analytic Methods;Quasi-Birth-Death Processes;Triangular M/G/1-Type Markov Chains;Tree-Like Qbd;Nonlinear Matrix Equation","","In applying matrix-analytic methods to M/G/1-type and tree-like quasi-birth-death (QBD) Markov chains, it is crucial to determine the solution to a (set of) nonlinear matrix equation(s). This is usually done via iterative methods. We consider the highly structured subclass of triangular M/G/1-type and tree-like QBD Markov chains that allows for an efficient direct solution of the matrix equation."
227,"Enhancement of Sandwich Algorithms for Approximating Higher-Dimensional Convex Pareto Sets","Rennen, Gijs and van Dam, Edwin R. and den Hertog, Dick","INFORMS JOURNAL ON COMPUTING","23","4","493-517","2011","FAL","Convexity;Epsilon-Efficiency;Epsilon-Pareto Optimality;Geometric Programming;Higher Dimensional;Inner And Outer Approximation;Imrt;Pareto Set;Multiobjective Optimization;Sandwich Algorithms;Transformations","","In many fields, we come across problems where we want to optimize several conflicting objectives simultaneously. To find a good solution for such multiobjective optimization problems, an approximation of the Pareto set is often generated. In this paper, we consider the approximation of higher-dimensional convex Pareto sets using sandwich algorithms. We extend higher-dimensional sandwich algorithms in three different ways. First, we introduce the new concept of adding dummy points to the inner approximation of a Pareto set. By using these dummy points, we can determine accurate inner and outer approximations more efficiently, i.e., using less time-consuming optimizations. Second, we introduce a new method for the calculation of an error measure that is easy to interpret. Third, we show how transforming certain objective functions can improve the results of sandwich algorithms and extend their applicability to certain nonconvex problems. To show the effect of these enhancements, we make a numerical comparison using four test cases, including a four-dimensional case from the field of intensity-modulated radiation therapy. The results of the different cases show that we can achieve an accurate approximation using significantly fewer optimizations by using the enhancements."
228,"Optimal Testing of Digital Microfluidic Biochips","Pasaniuc, Bogdan and Garfinkel, Robert and Mandoiu, Ion and Zelikovsky, Alex","INFORMS JOURNAL ON COMPUTING","23","4","518-529","2011","FAL","Digital Microfluidic Biochips;Lab-On-A-Chip;Defect Testing;Exact And Approximation Algorithms;Heuristics","","Digital microfluidic biochips (DMFBs) are rectangular arrays of electrodes, or cells, that enable precise manipulation of nanoliter-sized droplets of biological fluids and chemical reagents. Because of the safety-critical nature of their applications, biochips must be tested frequently, both off-line (e.g., postmanufacturing) and concurrent with assay execution. Under both scenarios, testing is accomplished by routing one or more test droplets across the chip and recording their arrival at the destination. In this paper, we formalize the DMFB-testing problem under the common objective of completion time minimization, including previously ignored constraints of droplet noninterference. Our contributions include a proof that the general version of the problem is NP-hard, tight lower bounds for both off-line and concurrent testing, optimal and approximation algorithms for off-line testing of commonly used rectangular shaped biochips, as well as a concurrent testing heuristic producing solutions within 23%-34% of the lower bound in experiments conducted on data sets simulating varying percentages of biochip cells occupied by concurrently running assays."
229,"New Stabilization Procedures for the Cutting Stock Problem","Clautiaux, Francois and Alves, Claudio and de Carvalho, Jose Valerio and Rietz, Juergen","INFORMS JOURNAL ON COMPUTING","23","4","530-545","2011","FAL","Combinatorial Optimization;Integer Programming;Cutting Stock","","In this paper, we deal with a column generation-based algorithm for the classical cutting stock problem. This algorithm is known to have convergence issues, which are addressed in this paper. Our methods are based on the fact that there are interesting characterizations of the structure of the dual problem, and that a large number of dual solutions are known. First, we describe methods based on the concept of dual cuts, proposed by Valerio de Carvalho [Valerio de Carvalho, J. M. 2005. Using extra dual cuts to accelerate column generation. INFORMS J. Comput. 17(2) 175-182]. We introduce a general framework for deriving cuts, and we describe a new type of dual cut that excludes solutions that are linear combinations of some other known solutions. We also explore new lower and upper bounds for the dual variables. Then we show how the prior knowledge of a good dual solution helps improve the results. It tightens the bounds around the dual values and makes the search converge faster if a solution is sought in its neighborhood first. A set of computational experiments on very hard instances is reported at the end of the paper; the results confirm the effectiveness of the methods proposed."
230,"Solving Large p-Median Problems with a Radius Formulation","Garcia, Sergio and Labbe, Martine and Marin, Alfredo","INFORMS JOURNAL ON COMPUTING","23","4","546-556","2011","FAL","Discrete Location;P-Median;Column-And-Row Generation","","By means of a model based on a set covering formulation, it is shown how the p-median problem can be solved with just a column generation approach that is embedded in a branch-and-bound framework based on dynamic reliability branching. This method is more than competitive in terms of computational times and size of the instances that have been optimally solved. In particular, problems of a size larger than the largest ones considered in the literature up to now are solved exactly in this paper."
231,"Optimization of Supply Chain Systems with Price Elasticity of Demand","Kaplan, Ugur and Turkay, Metin and Karasozen, Bulent and Biegler, Lorenz T.","INFORMS JOURNAL ON COMPUTING","23","4","557-568","2011","FAL","Mixed-Integer Nonlinear Programming;Supply Chain Management;Smoothing;Price Elasticity Of Demand","","A centralized multiechelon, multiproduct supply chain network is presented in a multiperiod setting with products that show varying demand against price. An important consideration in such complex supply chains is to maintain system performance at high levels for varying demands that may be sensitive to product price. To examine the price-centric behavior of the customers, the concept of price elasticity of demand is addressed. The proposed approach includes many realistic features of typical supply chain systems such as production planning and scheduling, inventory management, transportation delay, transportation cost, and transportation limits. In addition, the proposed system can be extended to meet unsatisfied demand in future periods by backordering. Effects of the elasticity in price demand in production and inventory decisions are also examined. The supply chain model is formulated as a convex mixed-integer nonlinear programming problem. Reformulations are presented to make the problem tractable. The differential equations are reformulated as difference equations, and unbounded derivatives in the nonlinear objective function are handled with an approximation, with guaranteed bounds on the loss of optimality. The approach is illustrated on a multiechelon, multiproduct supply chain network."
232,"An Improved Primal Simplex Algorithm for Degenerate Linear Programs","Elhallaoui, Issmail and Metrane, Abdelmoutalib and Desaulniers, Guy and Soumis, Francois","INFORMS JOURNAL ON COMPUTING","23","4","569-577","2011","FAL","Linear Programming;Primal Simplex Algorithm;Degeneracy","","Since its appearance in 1947, the primal simplex algorithm has been one of the most popular algorithms for solving linear programs. It is often very efficient when there is very little degeneracy, but it often struggles in the presence of high degeneracy, executing many pivots without improving the objective function value. In this paper, we propose an improved primal simplex algorithm that deals with this issue. This algorithm is based on new theoretical results that shed light on how to reduce the negative impact of degeneracy. In particular, we show that, from a nonoptimal basic solution with p positive-valued variables, there exists a sequence of at most m - p + 1 simplex pivots that guarantee the improvement of the objective value, where m is the number of constraints in the linear program. These pivots can be identified by solving an auxiliary linear program. Finally, we briefly summarize computational results that show the effectiveness of the proposed algorithm on degenerate linear programs."
233,"Experiments with Two-Row Cuts from Degenerate Tableaux","Basu, Amitabh and Bonami, Pierre and Cornuejols, Gerard and Margot, Francois","INFORMS JOURNAL ON COMPUTING","23","4","578-590","2011","FAL","Mixed-Integer Programming;Cutting Planes","","There has been a recent interest in cutting planes generated from two or more rows of the optimal simplex tableau. One can construct examples of integer programs for which a single cutting plane generated from two rows dominates the entire split closure. Motivated by these theoretical results, we study the effect of adding a family of cutting planes generated from two rows on a set of instances from the MIPLIB library. The conclusion of whether these cuts are competitive with Gomory mixed-integer cuts is very sensitive to the experimental setup. In particular, we consider the issue of reliability versus aggressiveness of the cut generators, an issue that is usually not addressed in the literature."
234,"A Method for Approximating Univariate Convex Functions Using Only Function Value Evaluations","Siem, A. Y. D. and den Hertog, D. and Hoffmann, A. L.","INFORMS JOURNAL ON COMPUTING","23","4","591-604","2011","FAL","Approximation;Convexity;Metamodel;Analysis Of Algorithms;Sandwich Algorithm","","In this paper, piecewise-linear upper and lower bounds for univariate convex functions are derived that are only based on function value information. These upper and lower bounds can be used to approximate univariate convex functions. Furthermore, new sandwich algorithms are proposed that iteratively add new input data points in a systematic way until a desired accuracy of the approximation is obtained. We show that our new algorithms that use only function value evaluations converge quadratically under certain conditions on the derivatives. Under other conditions, linear convergence can be shown. Some numerical examples that illustrate the usefulness of the algorithm, including a strategic investment model, are given."
235,"Combination of Nonlinear and Linear Optimization of Transient Gas Networks","Domschke, Pia and Geissler, Bjorn and Kolb, Oliver and Lang, Jens and Martin, Alexander and Morsi, Antonio","INFORMS JOURNAL ON COMPUTING","23","4","605-617","2011","FAL","Gas Networks;Optimal Control;Mixed-Integer Programming;Nonlinear Programming;Sequential Quadratic Programming","","In this paper, we study the problem of technical transient gas network optimization, which can be considered a minimum cost flow problem with a nonlinear objective function and additional nonlinear constraints on the network arcs. Applying an implicit box scheme to the isothermal Euler equation, we derive a mixed-integer nonlinear program. This is solved by means of a combination of (i) a novel mixed-integer linear programming approach based on piecewise linearization and (ii) a classical sequential quadratic program applied for given combinatorial constraints. Numerical experiments show that better approximations to the optimal control problem can be obtained by using solutions of the sequential quadratic programming algorithm to improve the mixed-integer linear program. Moreover, iteratively applying these two techniques improves the results even further."
236,"A New Evolutionary Algorithm for a Class of Nonlinear Bilevel Programming Problems and Its Global Convergence","Wang, Yuping and Li, Hong and Dang, Chuangyin","INFORMS JOURNAL ON COMPUTING","23","4","618-629","2011","FAL","Bilevel Programming;Evolutionary Algorithm;Global Optimization","","When the leader's objective function of a nonlinear bilevel programming problem is nondifferentiable and the follower's problem of it is nonconvex, the existing algorithms cannot solve the problem. In this paper, a new effective evolutionary algorithm is proposed for this class of nonlinear bilevel programming problems. First, based on the leader's objective function, a new fitness function is proposed that can be easily used to evaluate the quality of different types of potential solutions. Then, based on Latin squares, an efficient crossover operator is constructed that has the ability of local search. Furthermore, a new mutation operator is designed by using some good search directions so that the offspring can approach a global optimal solution quickly. To solve the follower's problem efficiently, we apply some efficient deterministic optimization algorithms in the MATLAB Toolbox to search for its solutions. The asymptotically global convergence of the algorithm is proved. Numerical experiments on 25 test problems show that the proposed algorithm has a better performance than the compared algorithms on most of the test problems and is effective and efficient."
237,"A Clock-and-Offer Auction Market for Grid Resources When Bidders Face Stochastic Computational Needs","Bapna, Ravi and Das, Sanjukta and Day, Robert and Garfinkel, Robert and Stallaert, Jan","INFORMS JOURNAL ON COMPUTING","23","4","630-647","2011","FAL","Grid Computing;Distributed Computing;Clock Auction;Market Design;Price Discovery","","Although significant technical advances have been made in the commercial deployment of grid computing, the pricing and allocation of distributed computing resources remains understudied. We develop a customized clock auction that is able to allocate grid resources and discover separate prices for the different computing resources under the condition that buyers do not know with certainty how much of these resources they will need. The proposed clock auction facilitates the discovery of unit prices for the resources in each time period in a finite-horizon market. Our mechanism exploits the lopsided nature of the grid market where a small number of large-scale jobs are expected to be completed by a large number of heterogeneous, distributed machines. The traditional stopping rule used for clock auctions is not effective in our setting, and therefore we design several adaptations that can be implemented in real time, geared toward ending the auction process quickly while producing a close-to-efficient allocation. Our extensive computations show that our clock-and-offer auction outperforms the traditional clock auction in terms of computational tractability, social welfare, and expected bidder's utility. For large problems of practical interest, we develop a transportation-based heuristic for the NP-complete bid feasibility problem and demonstrate theoretically and computationally that it quickly produces high-quality solutions to the overall problem."
238,"A Randomized Exhaustive Propositionalization Approach for Molecule Classification","Samorani, Michele and Laguna, Manuel and DeLisle, Robert Kirk and Weaver, Daniel C.","INFORMS JOURNAL ON COMPUTING","23","3","331-345","2011","SUM","Relational Learning;Propositionalization;Molecule Classification;Drug Discovery","","Drug discovery is the process of designing compounds that have desirable properties, such as activity and nontoxicity. Molecule classification techniques are used along with this process to predict the properties of the compounds to expedite their testing. Ideally, the classification rules found should be accurate and reveal novel chemical properties, but current molecule representation techniques lead to less-than-adequate accuracy and knowledge discovery. This work extends the propositionalization approach recently proposed for multirelational data mining in two ways: it generates expressive attributes exhaustively, and it uses randomization to sample a limited set of complex (deep) attributes. Our experimental tests show that the procedure is able to generate meaningful and interpretable attributes from molecular structural data, and that these features are effective for classification purposes."
239,"The Knowledge-Gradient Algorithm for Sequencing Experiments in Drug Discovery","Negoescu, Diana M. and Frazier, Peter I. and Powell, Warren B.","INFORMS JOURNAL ON COMPUTING","23","3","346-363","2011","SUM","Simulation: Design Of Experiments;Decision Analysis: Sequential;Statistics;Bayesian","","We present a new technique for adaptively choosing the sequence of molecular compounds to test in drug discovery. Beginning with a base compound, we consider the problem of searching for a chemical derivative of the molecule that best treats a given disease. The problem of choosing molecules to test to maximize the expected quality of the best compound discovered may be formulated mathematically as a ranking-and-selection problem in which each molecule is an alternative. We apply a recently developed algorithm, known as the knowledge-gradient algorithm, that uses correlations in our Bayesian prior distribution between the performance of different alternatives (molecules) to dramatically reduce the number of molecular tests required, but it has heavy computational requirements that limit the number of possible alternatives to a few thousand. We develop computational improvements that allow the knowledge-gradient method to consider much larger sets of alternatives, and we demonstrate the method on a problem with 87,120 alternatives."
240,"A Cluster-Based Context-Tree Model for Multivariate Data Streams with Applications to Anomaly Detection","Brice, Pierre and Jiang, Wei and Wan, Guohua","INFORMS JOURNAL ON COMPUTING","23","3","364-376","2011","SUM","Artificial Intelligence;Data Mining;Forecasting;Markov Chains;Trend Analysis;Variable-Length Markov Models (Vlmm)","","Many applications, such as telecommunication and commercial video broadcasting systems, computer and networks, and Web mining, require modeling data streams that exhibit context dependency. Context dependency refers to the fact that the statistical distribution of a new sample is heavily conditioned by a set of the most recent samples that precedes it. However, statistical models such as context trees (CTs) that capture context dependency tend to be poorly scalable. This paper proposes a solution to the scalability problem of these models by transforming a data stream into high-level aggregates of clusters instead of modeling the original data stream. Using an information-theoretical approach, we leverage existing clustering techniques for static categorical data sets to capture dynamic data streams based on the CT models. Because the proposed approach can be applied repeatedly on different levels of a clustering hierarchy, it is suitable for predicting trends and detecting anomalies at any aggregate (or detail) level required. Experimental results, including video stream modeling, network intrusion detection, and Monte Carlo simulations, show that the proposed method is efficient in capturing high-level aggregates of large-scale dynamic systems and very effective for trend prediction and anomaly detection."
241,"A Linearly Convergent Linear-Time First-Order Algorithm for Support Vector Classification with a Core Set Result","Kumar, Piyush and Yildirim, E. Alper","INFORMS JOURNAL ON COMPUTING","23","3","377-391","2011","SUM","Support Vector Machines;Support Vector Classification;Frank-Wolfe Algorithm;Approximation Algorithms;Core Sets;Linear Convergence","","We present a simple first-order approximation algorithm for the support vector classification problem. Given a pair of linearly separable data sets and epsilon is an element of(0, 1), the proposed algorithm computes a separating hyperplane whose margin is within a factor of (1-is an element of) of that of the maximum-margin separating hyperplane. We discuss how our algorithm can be extended to nonlinearly separable and inseparable data sets. The running time of our algorithm is linear in the number of data points and in 1/is an element of. In particular, the number of support vectors computed by the algorithm is bounded above by O(zeta/is an element of) for all sufficiently small is an element of > 0, where zeta is the square of the ratio of the distances between the farthest and closest pairs of points in the two data sets. Furthermore, we establish that our algorithm exhibits linear convergence. Our computational experiments, presented in the online supplement, reveal that the proposed algorithm performs quite well on standard data sets in comparison with other first-order algorithms. We adopt the real number model of computation in our analysis."
242,"Predicting the Solution Time of Branch-and-Bound Algorithms for Mixed-Integer Programs","Oezaltin, Osman Y. and Hunsaker, Brady and Schaefer, Andrew J.","INFORMS JOURNAL ON COMPUTING","23","3","392-403","2011","SUM","Solution Time Prediction;Mixed-Integer Programming;Branch-And-Bound Algorithm","","The most widely used progress measure for branch-and-bound (B&B) algorithms when solving mixed-integer programs (MIPs) is the MIP gap. We introduce a new progress measure that is often much smoother than the MIP gap. We propose a double exponential smoothing technique to predict the solution time of B&B algorithms and evaluate the prediction method using three MIP solvers. Our computational experiments show that accurate predictions of the solution time are possible, even in the early stages of B&B algorithms."
243,"A Branch-and-Price Algorithm for the Bin Packing Problem with Conflicts","Elhedhli, Samir and Li, Lingzi and Gzara, Mariem and Naoum-Sawaya, Joe","INFORMS JOURNAL ON COMPUTING","23","3","404-415","2011","SUM","Bin Packing Problem With Conflicts;Branch And Price;Lagrangean Relaxation;Maximal Clique Inequalities","","We provide a branch-and-price algorithm for the bin packing problem with conflicts, a variant of the classical bin packing problem that has major applications in scheduling and resource allocation. The proposed algorithm benefits from a number of special features that greatly contribute to its efficiency. First, we use a branching rule that matches the conflicting constraints, preserving the structure of the subproblems after branching. Second, maximal clique valid inequalities are generated based on the conflicting constraints and are added to the subproblems. The algorithm is tested on a standard set of problems and is compared to a recently proposed approach. Numerical results indicate its efficiency and stability."
244,"Lifted Tableaux Inequalities for 0-1 Mixed-Integer Programs: A Computational Study","Narisetty, Amar K. and Richard, Jean-Philippe P. and Nemhauser, George L.","INFORMS JOURNAL ON COMPUTING","23","3","416-424","2011","SUM","Mixed-Integer Programming;Cutting Planes;Lifting;Simplex Tableaux Cuts","","We describe families of inequalities for 0-1 mixed-integer programming problems that are obtained by lifting cover and packing inequalities. We show that these inequalities can be separated from single rows of the simplex tableaux of their linear programming relaxations. We present the results of a computational study comparing their performance with that of Gomory mixed-integer cuts on a collection of MIPLIB and randomly generated 0-1 mixed-integer programs. The computational study shows that these cuts yield better results than Gomory mixed-integer cuts."
245,"Minimal Equivalent Binary Knapsack Inequalities","Koehler, Gary J.","INFORMS JOURNAL ON COMPUTING","23","3","425-429","2011","SUM","Subset Sum;Hard Knapsack Problems;Computational Complexity","","It is known that a knapsack inequality can be reduced to one having the same solutions but with minimal integer coefficients. Although this procedure is not practical because an exponential amount of work may be required to find such minimal equivalent knapsacks, knowledge of minimal equivalent knapsacks can reduce hard knapsacks to trivial ones, as we show for both Todd and Avis knapsacks. In this paper, we show that even with an oracle able to supply minimal equivalent knapsacks at no computational cost, their practical value may not materialize because there are minimal knapsack inequalities with exponential values."
246,"Efficient Optimization of Reliable Two-Node Connected Networks: A Biobjective Approach","Konak, Abdullah and Smith, Alice E.","INFORMS JOURNAL ON COMPUTING","23","3","430-445","2011","SUM","Networks;Decision Theory;Multiple Criteria;Heuristics;Reliability;Genetic Algorithms;Simulation","","This paper presents a biobjective genetic algorithm (GA) to design reliable two-node connected telecommunication networks. Because the exact calculation of the reliability of a network is NP-hard, network designers have been reluctant to use network reliability as a design criterion; however, it is clearly an important aspect. Herein, three methods of reliability assessment are developed: an exact reliability calculation method using factoring, an efficient Monte Carlo estimation procedure using the sequential construction technique and network reductions, and an upper bound for the all-terminal reliability of networks with arbitrary arc reliabilities. These three methods of reliability assessment are used collectively in a biobjective GA with specialized mutation operators that perturb solutions without disturbing two-node connectivity. Computational experiments show that the proposed approach is tractable and significantly improves upon the results found by single-objective heuristics."
247,"Color-Coding Algorithms to the Balanced Path Problem: Computational Issues","Cappanera, Paola and Scutella, Maria Grazia","INFORMS JOURNAL ON COMPUTING","23","3","446-459","2011","SUM","Flow Algorithms;Heuristics;Analysis Of Algorithms;Flow Applications","","Given a weighted directed network G, we consider the problem of computing k balanced paths from given source nodes to given destination nodes of G, i.e., k paths such that the difference in cost between the longest path and the shortest path is minimized. Although not yet investigated by the OR scientific community, except for some preliminary theoretical results concerning the special case of acyclic networks, balanced path problems arise in several interesting applications, such as in transportation and in telecommunication settings. In this work, the focus is on the computation of node-disjoint balanced paths in the general case, where the input graph G could have any structure. Starting from some algorithmic ideas proposed for acyclic networks, a general framework based on the color-coding method for computing simple paths is first described. Then the general framework is specialized, and a pool of algorithms is designed that includes both an exact approach as well as alternative heuristics. The algorithms have been tested on a large suite of instances generated from some benchmark telecommunication instances. An additional set of instances, generated from some benchmark crew scheduling instances, has been used to get an idea of the behavior of the algorithms in the context of transportation applications. The obtained computational results are very interesting. For the telecommunication instances, in some cases the exact algorithm produced the optimal solution very rapidly; in the remaining cases, some of the proposed heuristics were able to generate high-quality solutions in a very quick time. As for the crew scheduling instances, which are larger and sometimes appear more difficult than the telecommunication ones, a suitable combination of the proposed color-coding issues allowed us to compute the optimal solutions in very short times."
248,"Preprocessing Stochastic Shortest-Path Problems with Application to PERT Activity Networks","Reich, Daniel and Lopes, Leo","INFORMS JOURNAL ON COMPUTING","23","3","460-469","2011","SUM","Preprocessing;Stochastic Optimization;Shortest Path;Pert;Integer Programming;Activity Network","","We present an algorithm for preprocessing a class of stochastic shortest-path problems on networks that have no negative cost cycles, almost surely. Our method adds utility to existing frameworks by significantly reducing input problem sizes and thereby increasing computational tractability. Given random costs with finite lower and upper bounds on each edge, our algorithm removes edges that cannot be in any optimal solution to the deterministic shortest-path problem, for any realization of the random costs. Although this problem is NP-complete, our algorithm efficiently preprocesses nearly all edges in a given network. We provide computational results both on sparse networks from PSPLIB-a well-known project evaluation and review technique library [Kolisch, R., A. Sprecher. 1996. PSPLIB-A project scheduling problem library. Eur. J. Oper. Res. 96(1) 205-216]-and dense synthetic ones: on average, less than 0.1% of the edges in the PSPLIB instances and 0.5% of the edges in the dense instances remain unclassified after preprocessing."
249,"The Reliable Facility Location Problem: Formulations, Heuristics, and Approximation Algorithms","Shen, Zuo-Jun Max and Zhan, Roger Lezhou and Zhang, Jiawei","INFORMS JOURNAL ON COMPUTING","23","3","470-482","2011","SUM","Reliable Facility Location Problem;Uncertainty;Heuristics;Approximation Algorithm","","We study a reliable facility location problem wherein some facilities are subject to failure from time to time. If a facility fails, customers originally assigned to it have to be reassigned to other (operational) facilities. We formulate this problem as a two-stage stochastic program and then as a nonlinear integer program. Several heuristics that can produce near-optimal solutions are proposed for this NP-hard problem. For the special case where the probability that a facility fails is a constant (independent of the facility), we provide an approximation algorithm with a worst-case bound of 4. The effectiveness of our heuristics is tested by extensive computational studies, which also lead to some managerial insights."
250,"An Efficient Global Approach for Posynomial Geometric Programming Problems","Tsai, Jung-Fa and Lin, Ming-Hua","INFORMS JOURNAL ON COMPUTING","23","3","483-492","2011","SUM","Posynomial Geometric Programming;Signomial Geometric Programming;Global Optimization;Convex Underestimation;Piecewise Linear Function","","A posynomial geometric programming problem is composed of a posynomial being minimized in the objective function subject to posynomial constraints. This study proposes an efficient method to solve a posynomial geometric program with separable functions. Power transformations and exponential transformations are utilized to convexify and underestimate posynomial terms. The inverse transformation functions of decision variables generated in the convexification process are approximated by superior piecewise linear functions. The original program therefore can be converted into a convex mixed-integer nonlinear program solvable to obtain a global optimum. Several numerical experiments are presented to investigate the impact of different convexification strategies on the obtained approximate solution and to demonstrate the advantages of the proposed method in terms of both computational efficiency and solution quality."
251,"Sequential Grid Computing: Models and Computational Experiments","Ransbotham, Sam and Murthy, Ishwar and Mitra, Sabyasachi and Narasimhan, Sridhar","INFORMS JOURNAL ON COMPUTING","23","2","174-188","2011","SPR","Grid Computing;Stochastic Shortest Path;Dynamic Programming","","Through recent technical advances, multiple resources can be connected to provide a computing grid for processing computationally intensive applications. We build on an approach, termed sequential grid computing, that takes advantage of idle processing power by routing jobs that require lengthy processing through a sequence of processors. We present two models that solve the static and dynamic versions of the sequential grid scheduling problem for a single job. In the static and dynamic versions, the model maximizes a reward function tied to the probability of completion within service-level agreement parameters. In the dynamic version, the static model is modified to accommodate real-time deviations from the plan. We then extend the static model to accommodate multiple jobs. Extensive computational experiments highlight situations (a) where the models provide improvements over scheduling the job on a single processor and (b) where certain factors affect the quality of solutions obtained."
252,"Decision Support and Optimization in Shutdown and Turnaround Scheduling","Megow, Nicole and Moehring, Rolf H. and Schulz, Jens","INFORMS JOURNAL ON COMPUTING","23","2","189-204","2011","SPR","Project Management;Planning;Scheduling;Resource Constraints;Risk Analysis;Applications;Large-Scale Systems;Chemical Industries","","Large-scale maintenance in industrial plants requires the entire shutdown of production units for disassembly, comprehensive inspection, and renewal. We derive models and algorithms for this so-called turnaround scheduling that include different features such as time-cost trade-off, precedence constraints, external resource units, resource leveling, different working shifts, and risk analysis. We propose a framework for decision support that consists of two phases. The first phase supports the manager in finding a good makespan for the turnaround. It computes an approximate project time-cost trade-off curve together with a stochastic evaluation. Our risk measures are the expected tardiness at time t and the probability of completing the turnaround within time t. In the second phase, we solve the actual scheduling optimization problem for the makespan chosen in the first phase heuristically and compute a detailed schedule that respects all side constraints. Again, we complement this by computing upper bounds for the same two risk measures. Our experimental results show that our methods solve large real-world instances from chemical manufacturing plants quickly and yield an excellent resource utilization. A comparison with solutions of a mixed-integer program on smaller instances proves the high quality of the schedules that our algorithms produce within a few minutes."
253,"Resource Allocation via Message Passing","Moallemi, Ciamac C. and Van Roy, Benjamin","INFORMS JOURNAL ON COMPUTING","23","2","205-219","2011","SPR","Message-Passing Algorithms;Min-Sum Algorithm;Resource Allocation;Convex Optimization;Decentralized Optimization","","We propose a message-passing paradigm for resource allocation problems. This serves to connect ideas from the message-passing literature, which has primarily grown out of the communications, statistical physics, and artificial intelligence communities, with a problem central to operations research. This also provides a new framework for decentralized management that generalizes price-based systems by allowing incentives to vary across activities and consumption levels. We demonstrate that message-based incentives, which are characterized by a new equilibrium concept, lead to system-optimal behavior for convex resource allocation problems yet yield allocations superior to those from price-based incentives for nonconvex problems. We describe a distributed and asynchronous message-passing algorithm for computing equilibrium messages and allocations, and we demonstrate its merits in the context of a network resource allocation problem."
254,"Operating Room Pooling and Parallel Surgery Processing Under Uncertainty","Batun, Sakine and Denton, Brian T. and Huschka, Todd R. and Schaefer, Andrew J.","INFORMS JOURNAL ON COMPUTING","23","2","220-237","2011","SPR","Operating Room Scheduling;Multiple Operating Rooms;Two-Stage Stochastic Mixed-Integer Programs;Operating Room Pooling;Parallel Surgery Processing","","Operating room (OR) scheduling is an important operational problem for most hospitals. In this study, we present a novel two-stage stochastic mixed-integer programming model to minimize total expected operating cost given that scheduling decisions are made before the resolution of uncertainty in surgery durations. We use this model to quantify the benefit of pooling ORs as a shared resource and to illustrate the impact of parallel surgery processing on surgery schedules. Decisions in our model include the number of ORs to open each day, the allocation of surgeries to ORs, the sequence of surgeries within each OR, and the start time for each surgeon. Realistic-sized instances of our model are difficult or impossible to solve with standard stochastic programming techniques. Therefore, we exploit several structural properties of the model to achieve computational advantages. Furthermore, we describe a novel set of widely applicable valid inequalities that make it possible to solve practical instances. Based on our results for different resource usage schemes, we conclude that the impact of parallel surgery processing and the benefit of OR pooling are significant. The latter may lead to total cost reductions between 21% and 59% on average."
255,"An Automated and Data-Driven Bidding Strategy for Online Auctions","Jank, Wolfgang and Zhang, Shu","INFORMS JOURNAL ON COMPUTING","23","2","238-253","2011","SPR","Functional Data;Dynamics;Model Selection;Online Auction;Bidding;Forecasting;Competition;Ebay;Electronic Commerce;Surplus","","The flexibility of time and location as well as the availability of an abundance of both old and new products makes online auctions an important part of people's daily shopping experience. Whereas many bidders rely on variants of the well-documented early or last-minute bidding strategies, neither strategy takes into account the aspect of auction competition: at any point in time, there are hundreds, even thousands, of the same or similar items up for sale, competing for the same bidder. In this paper, we propose a novel automated and data-driven bidding strategy. Our strategy consists of two main components. First, we develop a dynamic, forward-looking model for price in competing auctions. By incorporating dynamic features of the auction process and its competitive environment, our model is capable of accurately predicting an auction's price and outperforming model alternatives such as the generalized additive model, classification and regression trees, or Neural Networks. Then, using the idea of maximizing a bidder's surplus, we build a bidding framework around this model that selects the best auction to bid on and determines the best bid amount. The best auction is given by the one that yields the highest predicted surplus; the best bid amount is given by its predicted auction price. Our approach maximizes expected surplus and balances the probability of winning an auction with its average surplus. In simulations, we compare our automated strategy with early and last-minute bidding and find that our approach extracts 97% and 15% more expected surplus, respectively."
256,"Computing a Classic Index for Finite-Horizon Bandits","Nino-Mora, Jose","INFORMS JOURNAL ON COMPUTING","23","2","254-267","2011","SPR","Dynamic Programming, Markov;Bandits, Finite-Horizon;Index Policies;Analysis Of Algorithms;Computational Complexity","","This paper considers the efficient exact computation of the counterpart of the Gittins index for a finite-horizon discrete-state bandit, which measures for each initial state the average productivity, given by the maximum ratio of expected total discounted reward earned to expected total discounted time expended that can be achieved through a number of successive plays stopping by the given horizon. Besides characterizing optimal policies for the finite-horizon one-armed bandit problem, such an index provides a suboptimal heuristic index rule for the intractable finite-horizon multiarmed bandit problem, which represents the natural extension of the Gittins index rule (optimal in the infinite-horizon case). Although such a finite-horizon index was introduced in classic work in the 1950s, investigation of its efficient exact computation has received scant attention. This paper introduces a recursive adaptive-greedy algorithm using only arithmetic operations that computes the index in (pseudo-)polynomial time in the problem parameters (number of project states and time horizon length). In the special case of a project with limited transitions per state, the complexity is either reduced or depends only on the length of the time horizon. The proposed algorithm is benchmarked in a computational study against the conventional calibration method."
257,"An Efficient and Numerically Stable Method for Computing Bounds for the Interval Availability Distribution","Carrasco, Juan A.","INFORMS JOURNAL ON COMPUTING","23","2","268-283","2011","SPR","Engineering;Applications;Probability;Markov Processes;Reliability: Availability","","This paper is concerned with the computation of the interval availability (proportion of time in a time interval in which the system is up) distribution of a fault-tolerant system modeled by a finite (homogeneous) continuous-time Markov chain (CTMC). General-purpose methods for performing that computation tend to be very expensive when the CTMC and the time interval are large. Based on a previously available method (regenerative transformation) for computing the interval availability complementary distribution, we develop a method called bounding regenerative transformation for the computation of bounds for that measure. Similar to regenerative transformation, bounding regenerative transformation requires the selection of a regenerative state. The method is targeted at a certain class of models, including both exact and bounding failure/repair models of fault-tolerant systems with increasing structure function, with exponential failure and repair time distributions and repair in every state with failed components having failure rates much smaller than repair rates (F/R models), with a natural selection for the regenerative state. The method is numerically stable and computes the bounds with well-controlled error. For models in the targeted class and the natural selection for the regenerative state, computational cost should be traded off with bounds tightness through a control parameter. For large models in the class, the version of the method that should have the smallest computational cost should have small computational cost relative to the model size if the value above which the interval availability has to be guaranteed to be is close to 1. In addition, under additional conditions satisfied by F/R models, the bounds obtained with the natural selection for the regenerative state by the version that should have the smallest computational cost seem to be tight for all time intervals or not small time intervals, depending on whether the initial probability distribution of the CTMC is concentrated in the regenerative state or not."
258,"An Algorithm for Data Envelopment Analysis","Dula, J. H.","INFORMS JOURNAL ON COMPUTING","23","2","284-296","2011","SPR","Linear Programming;Convex Analysis;Computational Geometry;Data Envelopment Analysis (Dea)","","The standard approach to process a data envelopment analysis (DEA) data set, and the one in widespread use, consists of solving as many linear programs (LPs) as there are entities. The dimensions of these LPs are determined by the size of the data sets, and they keep their dimensions as each decision-making unit is scored. This approach can be computationally demanding, especially with large data sets. We present an algorithm for DEA based on a two-phase procedure. The first phase identifies the extreme efficient entities, the frame, of the production possibility set. The frame is then used in a second phase to score the rest of the entities. The new procedure applies to any of the four standard DEA returns to scale. It also imparts flexibility to a DEA study because it postpones the decision about orientation, benchmarking measurements, etc., until after the frame has been identified. Extensive computational testing on large data sets verifies and validates the procedure and demonstrates that it is computationally fast."
259,"Performance of Skart: A Skewness- and Autoregression-Adjusted Batch Means Procedure for Simulation Analysis","Tafazzoli, Ali and Wilson, James R. and Lada, Emily K. and Steiger, Natalie M.","INFORMS JOURNAL ON COMPUTING","23","2","297-314","2011","SPR","Simulation;Statistical Analysis;Steady-State Analysis;Method Of Batch Means;Cornish-Fisher Expansion;Autoregressive Representation","","An analysis is given for an extensive experimental performance evaluation of Skart, an automated sequential batch means procedure for constructing an asymptotically valid confidence interval (CI) on the steady-state mean of a simulation output process. Skart is designed to deliver a CI satisfying user-specified requirements on absolute or relative precision as well as coverage probability. Skart exploits separate adjustments to the half-length of the classical batch means CI so as to account for the effects on the distribution of the underlying Student's t-statistic that arise from skewness (nonnormality) and autocorrelation of the batch means. Skart also delivers a point estimator for the steady-state mean that is approximately free of initialization bias. In an experimental performance evaluation involving a wide range of test processes, Skart compared favorably with other steady-state simulation analysis methods-namely, its predecessors ASAP3, WASSP, and SBatch, as well as ABATCH, LBATCH, the Heidelberger-Welch procedure, and the Law-Carson procedure. Specifically, Skart exhibited competitive sampling efficiency and closer conformance to the given CI coverage probabilities than the other procedures, especially in the most difficult test processes."
260,"A Parallel Algorithm for the Vehicle Routing Problem","Groer, Chris and Golden, Bruce and Wasil, Edward","INFORMS JOURNAL ON COMPUTING","23","2","315-330","2011","SPR","Vehicle Routing;Optimization;Heuristics;Metaheuristics;Parallel Computing","","The vehicle routing problem (VRP) is a difficult and well-studied combinatorial optimization problem. We develop a parallel algorithm for the VRP that combines a heuristic local search improvement procedure with integer programming. We run our parallel algorithm with as many as 129 processors and are able to quickly find high-quality solutions to standard benchmark problems. We assess the impact of parallelism by analyzing our procedure's performance under a number of different scenarios."
261,"Sustainable evaluation and verification in supply chains: Aligning and leveraging accountability to stakeholders","Gualandris, Jury and Klassen, Robert D. and Vachon, Stephan and Kalchschmidt, Matteo","JOURNAL OF OPERATIONS MANAGEMENT","38","","1-13","2015","SEP","Social Responsibility;Monitoring;Inclusivity;Stakeholder Engagement","","Managers are being challenged by multiple (and diverse) stakeholders, which have variety of expectations and informational needs about their firm's supply chains. Collectively, these expectations and needs form a multi-faceted view of stakeholder accountability, namely the extent to which a firm justifies behaviors and actions across its extended supply chain to stakeholders. To date, sustainable supply chain management research has largely focused on monitoring as a self-managed set of narrowly defined evaluative activities employed by firms to provide stakeholder accountability. Nevertheless, evidence is emerging that firms have developed a wide variety of monitoring systems in order to align with stakeholders' expectations and leverage accountability to stakeholders. Drawing from the accounting literature, we synthesize a model that proposes how firms might address accountability for sustainability issues in their supply chain. At its core, the construct of sustainable evaluation and verification (SEV) captures three interrelated dimensions: inclusivity, scope, and disclosure. These dimensions characterize how supply chain processes might identify key measures, collect and process data, and finally, verify materiality, reliability and accuracy of any data and resulting information. As a result, the concept of monitoring is significantly extended, while also considering how different stakeholders can play diverse, active roles as metrics are established, audits are conducted, and information is validated. Also, several antecedents of SEV systems are explored. Finally, the means by which an SEV system can create a competitive advantage are investigated. (C) 2015 The Authors. Published by Elsevier B.V. This is an open access article under the CC BY-NC-ND license (http://creativecommons.org/licenses/by-nc-nd/4.0/)."
262,"Linking business strategy to service failures and financial performance: Empirical evidence from the US domestic airline industry","Mellat-Parast, Mahour and Golmohammadi, Davood and McFadden, Kathleen L. and Miller, Jason W.","JOURNAL OF OPERATIONS MANAGEMENT","38","","14-24","2015","SEP","Quality Management;Service Failures;Service Quality;Business Strategy;Firm Performance;Airline Operations","","Developing an understanding of the relationship between service quality and profitability is of central importance to operations management scholars. In this study we seek to reconcile inconsistencies between extant theory and empirical findings regarding the relationship between service quality and profitability in the airline industry. More specifically, we draw on theories from strategic management, operations strategy, and economics to explain why the relationship between measures of service quality and profitability will be moderated by an airline's competitive strategy. We test our hypotheses by fitting mixed-effects models to longitudinal data obtained from several governmental databases in the context of the U.S. domestic airline industry. We find that airline strategy moderates the relationship between some service failures and profitability. Specifically, we find that mishandled baggage and customer complaints more negatively affect the profitability of focused than non-focused airlines. We also find the relationship between arrival delays on profitability is universally negative for focused airlines, but displays an inverted U-shaped relationship for non-focused airlines. Our findings provide significant contributions to the existing body of knowledge in service quality and operations strategy. We further outline the implications of these findings for practice and future research. (C) 2015 Elsevier B.V. All rights reserved."
263,"Execution quality: An analysis of fulfillment errors at a retail distribution center","Craig, Nathan and DeHoratius, Nicole and Jiang, Yan and Klabjan, Diego","JOURNAL OF OPERATIONS MANAGEMENT","38","","25-40","2015","SEP","","","Purchase orders specify many aspects of a fulfillment process, including item quantity, delivery time, carton labeling, bar coding, electronic data interchange, retail ticketing, and others. These fulfillment terms are instrumental for highly optimized retail supply chains employing automation and techniques such as pack-by-store. When fulfilling a purchase order, a supplier may commit a fulfillment error, i.e., the supplier may fail to adhere to the terms specified by the retailer. The retailer may then penalize the supplier for the fulfillment error via a chargeback deduction, which reduces the supplier's revenue. We present a study of the fulfillment errors and chargebacks that occur in practice using data collected from a major retailer's distribution center. While fulfillment errors involving incorrect product quantities and delivery times have received the most attention in the literature, we find that the majority of fulfillment errors in the context we study involve documentation, bar coding, and retail ticketing. We refer to these as correctable fulfillment errors, since they are amended at the retailer's distribution center through rework. We develop a model of inventory management with correctable fulfillment errors and use the retailer's data to assess the cost of these correctable fulfillment errors to the retailer's inventory system. Our research provides guidance to managers in identifying products and suppliers that impose large fulfillment error costs as well as in setting appropriate chargebacks for fulfillment errors. (C) 2015 Elsevier B.V. All rights reserved."
264,"Managing contract manufacturer quality in the presence of performance ambiguity","Gray, John V. and Handley, Sean M.","JOURNAL OF OPERATIONS MANAGEMENT","38","","41-55","2015","SEP","Total Quality Management;Buyer-Supplier Relationships;Measurement Perspective;Relational View;Organizational Control;Theory Of The Firm;Supply Chain Management","","Brand-owing firms have been outsourcing the production of complete finished products to contract manufacturers (CMs) for some time. Increasingly, brand-owning firms have been employing CMs to produce products for which performance ambiguity is high. Doing so poses challenges for the management of CM performance. As expected, we find that quality performance ambiguity has a significant negative relationship with CM conformance quality performance, as reported by the buyers (the brand-owning firms). Drawing from and expanding the quality management (QM) literature, we assess the effectiveness of key constructs, derived primarily from the supplier QM meta-construct, at mitigating the detrimental effect of ambiguity. Two constructs consistently moderate the ambiguity-CM quality performance link. Heavily emphasizing quality at the time of CM selection moderates this relationship in the expected direction (i.e., it mitigates the challenges created by ambiguity). Surprisingly, we find that using one CM amplifies the negative relationship between ambiguity and conformance quality performance. One possible explanation is that employing only one CM aggravates existing opportunism concerns with regard to conformance quality performance under high levels of ambiguity. (C) 2015 Elsevier B.V. All rights reserved."
265,"Perceived versus actual value of product substitution flexibility: An experimental investigation","Bansal, Saurabh and Moritz, Brent","JOURNAL OF OPERATIONS MANAGEMENT","38","","56-70","2015","SEP","Behavioral Operations;Operational Flexibility","","Prior literature suggests that in the presence of operational uncertainties such as uncertain demand, firms should deploy operational flexibilities. However, these flexibilities are costly to develop and a correct valuation of these capabilities is necessary to ensure that they are only deployed when the expected benefits exceed the cost. Using a set of behavioral decision-making experiments for inventory of substitutable products, we investigate how decision-makers perform when estimating the value of operational flexibility of product substitution. We found that subjects consistently overestimated the monetary value of product substitution. Furthermore, the overestimation became more acute as demand correlation increased. This behavior is not explained by risk aversion or random errors. Instead, it appears to be driven by fundamental and systematic behavioral biases when estimating the conjunctive probability of substitution. We suggest and validate a decomposition-based approach to mitigate this overestimation. (C) 2015 Elsevier B.V. All rights reserved."
266,"How firm innovativeness and unexpected product reliability failures affect profitability","Mackelprang, Alan W. and Habermann, Marco and Swink, Morgan","JOURNAL OF OPERATIONS MANAGEMENT","38","","71-86","2015","SEP","Innovation Strategy;Product Quality;Firm Performance;Empirical;Warranty Claims;Longitudinal","","This study examines relationships among a firm's innovativeness, its unexpected product failure costs, and financial performance. When a firm chooses to develop more innovative products and processes, product reliability outcomes become more uncertain. These uncertainties in turn may lead to unexpected warranty claims costs, as well as other costs that can erode the advantages of an innovation leadership position. This study empirically tests these propositions using publically reported warranty and financial data from 2003 to 2013, representing 482 unique firms. Consistent with prior studies, our estimation of the direct effects of firm innovativeness on financial performance shows an inverted-u-shaped relationship. Importantly, we find that more innovative firms also experience more unexpected product failure costs, and, consistent with organizational information processing theory, the negative impacts of these costs on financial performance extend well beyond the direct costs associated with remediating warranty claims. Further, we find that this relationship is robust to differing levels of industry innovativeness. Hence, our study suggests that product failure risks associated with firm innovativeness are significant, and act to at least partially offset the financial benefits of innovation leadership. In addition, standard accounting for product warranty claims may substantially understate the true costs associated with product failures, which appear to generate significant SG&A, fixed asset, and inventory costs above and beyond direct warranty processing costs. Our study also demonstrates a novel usage of warranty claims data. We discuss the implications of these findings for both managers and researchers. (C) 2015 Elsevier B.V. All rights reserved."
267,"Firm performance in dynamic environments: The role of operational slack and operational scope","Kovach, Jeremy J. and Hora, Manpreet and Manikas, Andrew and Patel, Pankaj C.","JOURNAL OF OPERATIONS MANAGEMENT","37","","1-12","2015","JUL","Operations Strategy;Operational Slack;Operational Scope;Environmental Dynamism","","This study examines the effects of operational scope (breadth of product offering, extent of geographical diversification, and extent to which production processes can effectively meet varying demand) and operational slack (resources in excess of what is required to fulfill expected demand) on firm performance, contingent on two components of a firm's dynamic environment, unpredictability and instability. We collate quarterly data on 3857 publicly traded firms in 19 industries from the years 1991 to 2013 (representing 99,559 firm-quarter observations). Using panel data analysis, we find that narrow product offerings, low geographical diversification, low levels of excess capacity, and low inventory slack are each positively associated with firm performance. More importantly though, we find that operational scope is associated with improved performance in unpredictable environments, whereas operational slack is associated with improved performance in unstable environments. These findings contribute to the research on operations strategy by identifying the industry-specific environmental conditions under which operational slack and operational scope are associated with firm performance. (C) 2015 Elsevier B.V. All rights reserved."
268,"Team leader experience in improvement teams: A social networks perspective","Easton, George S. and Rosenzweig, Eve D.","JOURNAL OF OPERATIONS MANAGEMENT","37","","13-30","2015","JUL","Team Leader Experience;Team Leader Social Capital;Social Network Analysis;Learning;Quality Improvement Teams;Six Sigma","","In this research, we disentangle the relationship between several key aspects of a team leader's experience and the likelihood of improvement project success. Using the lens of socio-technical systems, we argue that the effect of team leader experience derives from the social system as well as the technical system. The aspects of team leader experience we examine include team leader social capital (a part of the social system) and team leader experience leading projects of the same type (a part of the technical system). We examine four different, yet related, dimensions of a team leader's social capital, which we motivate based on the social networks literature. One dimension, team leader familiarity, suggests that social capital is created when team leaders have experience working with current team members on prior improvement projects, and that such social capital increases the likelihood of improvement project success. We develop three additional dimensions, using social network analysis (SNA), to capture the idea that the improvement team leader's social capital extends beyond the current team to include everyone the leader has previously worked with on improvement projects. Contrasting our SNA-based dimensions with team leader familiarity enables us to better understand the impact of a team leader's social capital both inside and beyond the team. We also examine the effect of a team leader's experience leading prior projects of the same type, and consider the extent to which organizational experience may moderate the impact of both team leader social capital and same-type project experience. Based on analysis of archival data of six sigma projects spanning six years from a Fortune 500 consumer products manufacturer, we find that two of our SNA-based dimensions of team leader social capital, as well as experience leading projects of the same type, increase the likelihood of project success. In addition, we show that organizational experience moderates the relationship between team leader same-type project experience and project success. However, this is not the case for the relationship between the dimensions of team leader social capital and project success. These results provide insights regarding how dimensions of team leader experience and organizational experience collectively impact the operational performance of improvement teams. (C) 2015 Elsevier B.V. All rights reserved."
269,"A competitive advantage from the implementation timing of ISO management standards","Su, Hung-Chung and Dhanorkar, Suvrat and Linderman, Kevin","JOURNAL OF OPERATIONS MANAGEMENT","37","","31-44","2015","JUL","Iso 9001;Iso 14001;Management Standards;Competitive Strategy;Absorptive Capacity;Early Mover Advantage","","With the rise of globalization, firms increasingly implement management standards developed by the International Organization for Standardization (ISO) to assure they can meet their customers' expectations. ISO management standards reduce performance variability among suppliers and promote global trade. However, ISO standards also promote a certain degree of commonality or isomorphism between firms. If the very notion of 'standards' encourages a certain level of commonality between firms, then how can firms achieve a competitive advantage from implementing ISO standards? This research argues that the timing of when a firm implements an ISO standard relative to their rivals has strategic benefits. Drawing on the competitive dynamics literature we argue that firms can achieve an early mover advantage when implementing ISO 14001. However, an early mover advantage depends on the level of a firm's absorptive capacity (prior experience with ISO 9001) and the competitive intensity of their industry. This study uses longitudinal data from firms that implemented ISO 14001 at varying points in time to examine the benefits of an early mover advantage. More broadly, this research sheds light on when firms benefit the most from implementing new management standards. The results provide insights into implementing other emerging management standards. (C) 2015 Elsevier B.V. All rights reserved."
270,"Cultural embeddedness in supply networks","Wu, Zhaohui and Pullman, Madeleine E.","JOURNAL OF OPERATIONS MANAGEMENT","37","","45-58","2015","JUL","Cultural Embeddedness;Supply Networks;Agricultural Cooperatives;Decision Making;Sustainability;Grounded Research;Country Natural Beef","","Recent studies on structural and relational embeddedness suggest that favorable position and connections in supply networks benefit a firm. While fruitful, this focus misses the motivations that prompt firms to take economic action in the first place. Understanding cultural embeddedness provides insight into why individuals and firms behave as they do and how their behavior can influence network structure. Contrary to the belief that firms act solely for profit and growth, we note that cultural contents such as values, social issues and political ideologies explain firms' motives and guide their economic activities. We explore the role of cultural embeddedness through a grounded study of Country Natural Beef, a sustainability-oriented agricultural cooperative in the western United States. This supply network demonstrates strongly competing cultural claims among its members as well as a unique institutionalized culture. Cultural interactions at the node and network levels explain the functioning of and changes to the network. Through interviews, analysis of archival information and direct observation of pivotal events over a period of 5 years, we unpack cultural embeddedness and take an incremental step toward a theory of cultural embeddedness in cooperative supply networks. Published by Elsevier B.V."
271,"Are safety and operational effectiveness contradictory requirements: The roles of routines and relational coordination","Pagell, Mark and Klassen, Robert and Johnston, David and Shevchenko, Anton and Sharma, Sharvani","JOURNAL OF OPERATIONS MANAGEMENT","36","","1-14","2015","MAY","Safety;Routines;Contradictory Requirements;Relational Coordination","","The relationship between managing a production system to be safe and managing it to be operationally effective is often described in conflicting terms, creating confusion for research and practice. Some view improving safety as separate and distinct from increasing operational effectiveness; they are contradictory requirements. Others emphasize that safety and effectiveness are complementary, and combine to enhance competitiveness. Recent research proposes that this confusion can be explained by examining the operational and safety routines used in production. Specifically, when an organization chooses to manage safety and operations in a coordinated fashion using a joint management system, safety and operational effectiveness are complementary. Yet, the contradiction between safety and operations can occur when the functions are managed as separate and unequal silos. This research tests this supposition using the theory of relational coordination. The results, based on a combination of survey and archival safety data from 198 manufacturing firms, show that safety and operational outcomes are indirectly related via routines and that plants that manage safety and operations using a joint management system make these priorities complementary and do not create trade-offs between safety and operational performance. (C) 2015 Elsevier B.V. All rights reserved."
272,"The impact of bullwhip on supply chains: Performance pathways, control mechanisms, and managerial levers","Mackelprang, Alan W. and Malhotra, Manoj K.","JOURNAL OF OPERATIONS MANAGEMENT","36","","15-32","2015","MAY","Bullwhip Effect;Supplier Performance;Empirical;Supply Chain","","Even though few empirical studies have tried to actually explicate the relationship between the bullwhip effect and performance of the supplier firm, there exists a common perception for over 30 years among both practitioners and academics that the bullwhip effect naturally results in decreased firm profitability. Anecdotal evidence further suggests that this decline in profitability arises from a decline in operational performance. However, the results of our study, which empirically examines the bullwhip effect across supply chain partners through an analysis of 383 actual customer base-supplier dyads, challenge this commonly held position by suggesting that while traditional bullwhip often yields reduced ROA, it ultimately has no relationship with the firm's operating margin. Additionally, our results also call into question whether or not production coordination between customers and suppliers can minimize the need for inventory and capacity buffers, which are the two commonly utilized methods for battling the bullwhip effect. Thus the relationship between bullwhip and firm performance is far more nuanced and complicated than previously believed. We also show how the managerial bullwhip levers of coordinating production across supply chain partners, or deploying inventory and capacity buffer control mechanisms, can help maximize a firm's performance along different dimensions. (C) 2015 Elsevier B.V. All rights reserved."
273,"Effective judgmental forecasting in the context of fashion products","Seifert, Matthias and Siemsen, Enno and Hadida, Allegre L. and Eisingerich, Andreas B.","JOURNAL OF OPERATIONS MANAGEMENT","36","","33-45","2015","MAY","Judgmental Forecasting;Fashion Products;Lens Model Design;Demand Uncertainty;Music Industry;New Product Forecasting","","We study the conditions that influence judgmental forecasting effectiveness when predicting demand in the context of fashion products. Human judgment is of practical importance in this setting. Our goal is to investigate what type of decision support, in particular historical and/or contextual predictors, should be provided to human forecasters to improve their ability to detect and exploit linear and nonlinear cue-criterion relationships in the task environment. Using a field experiment on new product forecasts in the music industry, our analysis reveals that when forecasters are concerned with predictive accuracy and only managerial judgments are employed, providing both types of decision support data is beneficial. However, if judgmental forecasts are combined with a statistical forecast, restricting the decision support provided to human judges to contextual anchors is beneficial. We identify two novel interactions demonstrating that the exploitation of nonlinearities is easiest for human judgment if contextual data are present but historical data are absent. Thus, if the role of human judgment is to detect these nonlinearities (and the linearities are taken care of by some statistical model with which judgments are combined), then a restriction of the decision support provided makes sense. Implications for the theory and practice of building decision support models are discussed. (C) 2015 Elsevier B.V. All rights reserved."
274,"Effects of control on the performance of information systems projects: The moderating role of complexity risk","Liu, Shan","JOURNAL OF OPERATIONS MANAGEMENT","36","","46-62","2015","MAY","Project Management;Performance;Complexity Risk;Managerial Control;System Development","","Control of projects is a core issue for organizations. Successful projects, such as information systems projects, enable organizations to develop a superior supply network and enhance the capability of operations management. A few studies have investigated the effects of control on project performance; however, complexity risk has not been integrated into the relationship between control and performance. Limited evidence has been provided concerning whether modes of control differ in their effectiveness in the presence of a single risk factor. Based on quantitative data obtained from 128 information systems projects, behavior, outcome, clan, and self-control are empirically determined to be positively associated with the system performance of projects. However, complexity risk generates a mixed moderating effect on the relationship between control and performance. In the presence of a high complexity risk, the effects of behavior and self-control on performance are low, whereas the effectiveness of outcome and clan control increases. This finding implies that complexity risk is a double-edged sword with regard to control. Each control mode exhibits different characteristics and effectiveness under high complexity risk. Therefore, appropriate control modes should be carefully selected, and highly effective control modes, such as outcome and clan control, should be prioritized in managing complex system projects. (C) 2015 Elsevier B.V. All rights reserved."
275,"The role of executive problem solving in knowledge accumulation and manufacturing improvements","Choo, Adrian S. and Nag, Rajiv and Xia, Yusen","JOURNAL OF OPERATIONS MANAGEMENT","36","","63-74","2015","MAY","Manufacturing Improvements;Problem-Solving Orientation;Knowledge Stocks","","This study investigates how strategic leaders influence knowledge stocks and manufacturing improvements in firms. In doing so, we identify two related but distinct problem-solving orientations among senior executives. The first orientation uses short-term remedies to control and contain the impact of a problem, which we label as symptomatic problem solving (SPS). The other orientation addresses a problem situation with the objective of developing new understanding and skills, and we label it as generative problem solving (GPS). We test our theoretical framework using two waves of survey data from a sample of metal casting manufacturers (metal foundries) in the United States. Our analysis shows that GPS positively affects both internal and external knowledge stocks, while SPS negatively influences internal knowledge stock. Knowledge stocks, in turn, facilitate incremental and radical manufacturing improvements. Our results suggest that the two executive problem-solving orientations can potentially counteract each other in enhancing and depreciating knowledge stocks, and subsequently affect a manufacturer's ability to attain improvements both in the short and long terms Published by Elsevier B.V."
276,"Bullwhip effect under substitute products","Duan, Yongrui and Yao, Yuliang and Huo, Jiazhen","JOURNAL OF OPERATIONS MANAGEMENT","36","","75-89","2015","MAY","Bullwhip Effect;Substitute Products;Supply Chain Management;Empirical Analysis","","Using a large-scale, product-level dataset collected from a supply chain dyad, we examine the effect of own and substitute products on a focal product's bullwhip effect and estimate the existence and magnitude of the bullwhip effect at the product level. We find that, under substitute products, the bullwhip effect is not only affected by a product's own factors but also by those of its substitute products. An increase in the number of own price changes is associated with a decrease in the bullwhip effect in terms of the direct effect but with an increase in the bullwhip effect in terms of the total effect, and increases in the number of price changes of substitute products and own stockouts are associated with increases in the bullwhip effect. The potential effects for own price changes, price changes of substitute products and own stockouts are as much as 59.51%, 95.06% and 66.11%. We also find that the bullwhip effect is prevalent and very intensive at the product level. We discuss the theoretical and managerial implications of the findings. (C) 2015 Elsevier B.V. All rights reserved."
277,"Implementing corporate lean programs: The effect of management control practices","Netland, Torbjorn H. and Schloetzer, Jason D. and Ferdows, Kasra","JOURNAL OF OPERATIONS MANAGEMENT","36","","90-102","2015","MAY","Management Control;Lean Manufacturing;Lean Implementation;Factory Performance","","We examine how management control practices relate to the implementation of a corporate lean program at the factory level. Our empirical analysis uses data from a large manufacturing firm that is implementing a corporate lean program in its global plant network. We find that using dedicated teams to lead the lean program, developing and frequently reviewing lean-focused performance reports, and using nonfinancial rewards linked to lean implementation are favorably associated with more extensive implementation of lean practices in the factories. We do not find evidence that the use of management-initiated internal audits and financial rewards tied to lean implementation are strongly associated with more extensive lean implementation. We also present evidence of a positive relation between lean implementation and improvements in operational performance in the factories. Overall, these findings suggest that when implementing a corporate lean program, the firm must pay careful attention to the type of management control practices it uses for controlling the input, process, and output aspects of the lean program. (C) 2015 Elsevier B.V. All rights reserved."
278,"The impact of service design and process management on clinical quality: An exploration of synergetic effects","Ding, Xin (David)","JOURNAL OF OPERATIONS MANAGEMENT","36","","103-114","2015","MAY","Clinical Quality;Quality Improvement Initiatives;Focus;Service Design;Process Management","","While service design and process management have received research attention in the past, there is limited empirical work examining both factors in the hospital setting. Through operationalizing focus as a service design approach and quality improvement (QI) initiatives as process management efforts, we hypothesize that focus and QI initiatives affect clinical quality both individually and collectively. Utilizing heart attack procedures as the study context, we examine a set of hypotheses based on a panel dataset consisted of 201 hospitals from 2005 to 2011 in the state of Florida. After accounting for potential lag effects and endogeneity biases, we find empirical support to the proposed hypotheses. (C) 2015 Elsevier B.V. All rights reserved."
279,"Financial benefits and risks of dependency in triadic supply chain relationships","Kim, Yoon Hee and Henderson, Darren","JOURNAL OF OPERATIONS MANAGEMENT","36","","115-129","2015","MAY","Relationship Embeddedness;Resource Dependency;Financial Performance;Triadic Supply Chain Relationships;Econometric Analysis","","The economic consequences of interdependent relationships with suppliers and customers have long been of interest to supply chain managers and academics alike. Whereas previous studies have focused on the benefits or risks of embedded relationships that accrue to buying firms, this study simultaneously investigates the effects of a supplier's and a customer's embeddedness, arising from resource dependency, on a focal firm's financial performance in triadic supply chain relationships. Using 1,144 unique focal firm-years for U.S. firms from Compustat, we find that a supplier's and a customer's dependency both increase the focal firm's performance in terms of return on assets (ROA) and return on sales (ROS) by increasing asset turnover (ATO). As levels of supplier and customer dependency on the focal firm increase, however, the economic benefits of customer dependency diminish beyond a certain point, while those of supplier dependency continue to increase above that threshold. Thus, our findings show the paradoxically differing risks of the supplier's versus the customer's dependency, while establishing the unequivocal economic benefits of supplier and customer relations for focal firms in the middle of concentrated triadic relationships. (C) 2015 Elsevier B.V. All rights reserved."
280,"Optimal pricing for new and remanufactured products","Abbey, James D. and Blackburn, Joseph D. and Guide, Jr., V. Daniel R.","JOURNAL OF OPERATIONS MANAGEMENT","36","","130-146","2015","MAY","Closed-Loop Supply Chains;Remanufacturing;Consumer Products;Product Pricing","","This work investigates the optimal pricing of new and remanufactured products using a model of consumer preferences based on extensive experimentation. The experimental investigation reveals two distinct segments of consumers. One segment is relatively indifferent between new and remanufactured products and displays high sensitivity to price discounts. The second segment shows strong preferences for new products-with an accompanying aversion to remanufactured products-and realtively low sensitivity to price discounts. The pricing analysis examines several scenarios involving a new product manufacturer, ranging from a simple monopolist scenario to a more complex scenario involving competition with third-party remanufacturers. In contrast to the usual finding that new product prices should decrease when competitive remanufactured products enter the market, the introduction of market segments reveals a robust finding across all scenarios: when remanufactured products enter the market, the optimal price of the new product should increase. Through appropriate pricing of new products, the OEM can mitigate the effects of cannibalization and increase profitability. (C) 2015 Elsevier B.V. All rights reserved."
281,"Performance effects of using an ERP system for manufacturing planning and control under dynamic market requirements","Tenhiaelae, Antti and Helkio, Pekka","JOURNAL OF OPERATIONS MANAGEMENT","36","","147-164","2015","MAY","Decision Support Systems;Production Scheduling;Shop-Floor Control;Materials Management;Strong Inference;Dynamic Capabilities","","Enterprise resource planning (ERP) systems have a controversial reputation. Critics say that even if ERP systems may be beneficial for organizations operating in stable conditions, they are surely detrimental to organizations that face dynamic market requirements. This is because ERP systems are said to impose such procedures and constraints on organizations that make business processes inflexible to change. In contrast, proponents argue that the information-processing capabilities of ERP systems are crucial for organizations that face dynamic market requirements and also that the criticized procedures and constraints actually support process reengineering. These two contradictory arguments are often found in practitioner literature, but both of them can also be supported by management theory. The central tenets of the Organic Theory of organization design imply that ERP systems should be detrimental when market requirements change frequently, whereas the principles of Rigid Flexibility Theory suggest that they should be advantageous. In this study, we use cross-sectional data from 151 manufacturing plants to determine which argument is more applicable in the context of manufacturing planning and control. The results strongly favor the use of ERP systems under dynamic market requirements. To facilitate the reconciliation of the two contradictory arguments, we discuss how the results may have been influenced by two contextual factors: the predominantly technical nature of the studied organizational system and the tight interdependence of the studied activities. (C) 2014 Elsevier B.V. All rights reserved."
282,"How does technological diversity in supplier network drive buyer innovation? Relational process and contingencies","Gao, Gerald Yong and Xie, En and Zhou, Kevin Zheng","JOURNAL OF OPERATIONS MANAGEMENT","36","","165-177","2015","MAY","Supplier Network;Technological Diversity;Novel Information Sharing;Buyer-Supplier Relational Strength;Supplier Network Density;New Product Creativity","","External networks provide important knowledge sources of innovation for firms. Drawing on social network theory, this study examines how technological diversity in supplier network influences a focal buyer firm's innovation. The results from a survey of 202 Chinese manufacturing firms and their supplier networks reveal that novel information sharing partially mediates the effect of technological diversity in supplier network on buyer firms' new product creativity. The positive effect of technological diversity is enhanced by buyer-supplier relational strength but inhibited by supplier network density; competitive intensity positively moderates this effect, and technological turbulence negatively moderates it. These findings provide novel insights into how buyer firms can use their supplier networks to enhance product innovation. (C) 2014 Elsevier B.V. All rights reserved."
283,"Supply chain management research: Key elements of study design and statistical testing","Helmuth, Catherine A. and Craighead, Christopher W. and Connelly, Brian L. and Collier, Donovan Y. and Hanna, Joe B.","JOURNAL OF OPERATIONS MANAGEMENT","36","","178-186","2015","MAY","Supply Chain;Effect Size;Statistical Power;Reliability;Empirical Research","","Over the past three decades, supply chain management (SCM) has evolved from its origin's as a nascent field of study to encompass construct definition, identification of the field's central issues, and establishment of its conceptual boundaries. At this point, a sufficient body of empirical SCM research has been put forward to allow for quantitative assessment of the field. Therefore, we examine three key elements of study design to assess what has happened, what is currently happening, and where we should be heading as a field. To do so, following a pattern of reviews in similar disciplines, we begin with an examination of effect sizes of the relationships under investigation. Results show that effect sizes in SCM research have marginally increased over time and that sub-domains within SCM that receive the most scholarly attention also have higher effect sizes. We also conduct a post hoc analysis of statistical power and empirically examine a range of factors and study contexts that could influence power. Findings suggest that average statistical power in SCM research exceeds the statistical power of most related disciplines and is particularly high in several unique contexts. Lastly, we find that measurement reliability and the use of control variables have increased over time, possibly suggesting the field has matured, instilling a degree of confidence in its research. Overall, our results show that SCM research is becoming more empirically rigorous, but we also uncover key areas that warrant improvement. We describe implications of our review for the design of future SCM empirical studies. (C) 2014 Elsevier B.V. All rights reserved."
284,"Problem-solving effort and success in innovation contests: The role of national wealth and national culture","Bockstedt, Jesse and Druehl, Cheryl and Mishra, Anant","JOURNAL OF OPERATIONS MANAGEMENT","36","","187-200","2015","MAY","Innovation Contests;Problem Solving;National Culture;Crowdsourcing;Econometric Analysis","","Innovation contests allow firms to harness specialized skills and services from globally dispersed participants for solutions to business problems. Such contests provide a rich setting for operations management (OM) scholars to explore problem solving in global labor markets as firms continue to unbundle their innovation value chains. In this study, we examine the implications of specific types of diversity in innovation contests on problem-solving effort and success. First, we conceptualize diversity among contestants in terms of national wealth (measured as gross domestic product per capita (GDPP) adjusted for purchasing power parity) and national culture (measured using the culture dimensions of performance orientation and uncertainty avoidance) and examine how such factors influence problem-solving effort. Next, we examine how differences between contestants and contest holders in terms of the above factors influence contest outcomes. Using data from a popular online innovation contest platform and country-level archival data, we find that contestants from countries with lower levels of GDPP are more likely to exert greater problem-solving effort compared to other contestants. With regard to national culture, we find that performance orientation and uncertainty avoidance have positive and negative effects, respectively, each of which weakens with increasing levels of GDPP. Finally, our analysis provides evidence of homophily effects indicating that contestants who share greater similarities with the contest holder in terms of national wealth and national culture are more likely to be successful in a contest. We discuss the implications of the study's findings for contest holders and platform owners who organize innovation contests, and for emerging research on innovation contests. (C) 2014 Elsevier B.V. All rights reserved."
285,"Understanding information exchange in healthcare operations: Evidence from hospitals and patients","Dobrzykowski, David D. and Tarafdar, Monideepa","JOURNAL OF OPERATIONS MANAGEMENT","36","","201-214","2015","MAY","Hospital Operations;Health It;Electronic Health Records;Pacs;Physician Employment;Coordination;Vertical Integration;It Use;Social Ties","","Coordination - or the information exchange among physicians and hospital staff - is necessary for desirable patient outcomes in healthcare delivery. However, coordination is difficult because healthcare delivery processes are information intensive, complex and require interactions of hospitals with autonomous physicians working in multiple operational systems (i.e. multiple hospitals). We examine how three important variables distinctive of the healthcare operations context - use of IT for dissemination of test results (ITDR) (i.e. electronic health records systems) by physicians and hospital staff, social interaction ties among them, and physician employment - influence information exchange and patient perceptions of their care. Drawing from the literature on process inter-dependencies and coordination, vertical integration and social exchange, we develop and test research hypotheses linking ITDR, social interaction ties and physician employment to information exchange relationship, and information exchange relationship to provider-patient communication. Using a paired sample of primary survey data and secondary archival data from CMS HCAHPS for 173 hospitals in the USA, we find that increased information exchange relationship drives provider-patient communication, and increased social interaction ties drives information exchange relationship. Social interaction ties fully mediates the relationship between ITDR and information exchange relationship. Physician employment amplifies the link between ITDR and social interaction ties, but does not have an effect on the link between ITDR and information exchange. We do not find a direct relationship between ITDR, and information exchange relationship or provider-patient communication. Published by Elsevier B.V."
286,"Structural drivers of upstream supply chain complexity and the frequency of supply chain disruptions","Bode, Christoph and Wagner, Stephan M.","JOURNAL OF OPERATIONS MANAGEMENT","36","","215-228","2015","MAY","Supply Chain Disruption;Supply Chain Risk;Supply Chain Complexity;Count Regression","","A great deal of research has focused on supply chain risk management, but the question Which supply. chain characteristics increase the frequency of supply chain disruptions? has not received much attention from empirical research. This is a relevant question, because firms seek stability in their operations, and therefore managers need to know how the structure of their supply chains affects the occurrence of disruptions. The present study addresses this issue with a specific focus on upstream supply chain (supply-side) disruptions. Drawing on the literature on supply chain complexity, we devise and test a model that predicts the frequency of supply chain disruptions based on a multi-dimensional conceptualization of upstream supply chain complexity. Not only do the empirical findings suggest that all of the three investigated complexity drivers - horizontal, vertical, and spatial complexity - increase the frequency of disruptions, but also that they interact and amplify each other's effects in a synergistic fashion. (C) 2015 Elsevier B.V. All rights reserved."
287,"The effect of controversial global sourcing practices on the ethical judgments and intentions of US consumers","Bregman, Robert and Peng, David Xiaosong and Chin, Wynne","JOURNAL OF OPERATIONS MANAGEMENT","36","","229-243","2015","MAY","Global Sourcing;Consumer Intentions;Ethical Judgment;Hunt-Vitell;Structural Equation Modeling","","Global sourcing has led to lower cost and more effective supply chains for many companies. However, when the cost-driven practices of many suppliers in these chains come to light there is often considerable debate over the ethics of these practices. This research uses the well-known Hunt-Vitell framework as the theoretical foundation for a structural equation model of the deontological and teleological evaluations used by consumers when making ethical judgments of a firm's controversial cost-driven global sourcing practices. Data from a large-scale U.S. consumer survey show the importance of deontological and teleological evaluations in forming consumers' ethical judgments of global sourcing practices, and establish a strong relationship between ethical judgment and the intention of consumers to alter consumption of a firm's products. Extensions to the framework and demographic analyses for age, gender, and income provide insights as to how perceptions of these practices affect consumer evaluations of a company involved in global sourcing and how consumers actualize their resultant intentions. (C) 2015 Elsevier B.V. All rights reserved."
288,"Performance effects of early and late Six Sigma adoptions","Jacobs, Brian W. and Swink, Morgan and Linderman, Kevin","JOURNAL OF OPERATIONS MANAGEMENT","36","","244-257","2015","MAY","Six Sigma;Quality Management;Administrative Innovation;Adoption Timing;Organizational Learning;Empirical Research","","Operations managers confront the challenge of deciding when to implement various administrative innovations such as Six Sigma, ISO 9000, and Lean. This research examines the operating performance effects of early versus late adoption of Six Sigma process improvement. Using theories of organizational learning and knowledge transfer, we develop hypotheses describing the advantages of late adoption, and factors that affect a firm's ability to benefit from Six Sigma either as an early or late adopter. We test our hypotheses using an event study methodology. The empirical results show that, on average, late adopters in our sample enjoy significantly greater performance gains than early adopters. However, the analysis also shows that the advantages of late adopters tend to be moderated by certain environmental and structural characteristics of a firm. Specifically, late adoption has been favorable when firms operate in low-velocity industries, when they primarily sell in business-to-business markets, when they have good financial performance prior to adoption, and when they are large. Conversely, when adopters operate in conditions that have the opposite characteristics, then early adoption appears to have produced better results. Understanding the effects of these factors can enhance managers' abilities to determine appropriate adoption timing to increase performance. (C) 2015 Elsevier B.V. All rights reserved."
289,"Service triads: A research agenda for buyer-supplier-customer triads in business services","Wynstra, Finn and Spring, Martin and Schoenherr, Tobias","JOURNAL OF OPERATIONS MANAGEMENT","35","SI","1-20","2015","MAY","Service Triads;Buyer-Supplier-Customer Triads;Services;Networks;Empirical Research;Research Agenda","","Service triads, in which a buyer contracts with a supplier to deliver services directly to the buyer's customer, represent an emerging business model. This special issue is dedicated to this theme. To set the context, in this lead article, we first define service triads, both as a phenomenon and a research topic. We then provide a review of different strands of existing research and various theoretical frameworks that can inform our study of service triads. This culminates in an outline of a research agenda that can guide future study. As such, this paper not only introduces the articles in the special issue, but is also intended as a point of reference and motivation for further work on service triads, and on triads in general. (C) 2014 Elsevier B.V. All rights reserved."
290,"Shareholder value implications of service failures in triads: The case of customer information security breaches","Modi, Sachin B. and Wiles, Michael A. and Mishra, Saurabh","JOURNAL OF OPERATIONS MANAGEMENT","35","SI","21-39","2015","MAY","Service Triads;Service Recovery;Information Security Breach;Shareholder Value;Event Study","","The rise in front-end service outsourcing in recent years, despite its advantages, has also exposed buyer firms to unique challenges. One of the most salient risks for buyer firms in service triads is service failure due to the service provider. Indeed such service failures may be more costly for firms due to the greater relational and operational costs that may arise from the presence of the third-party provider. Yet, neither the services literature nor extant operations literature on service triads has paid much attention to the financial consequences to the buyer firm - i.e., service risks - of such service failures in triads. To fill this gap, we investigate the financial penalty of service failures due to the service provider using the event study methodology and a sample of 146 customer information security breaches as our empirical context. Analysis of the abnormal returns reveals that service failures due to the front-end service provider lead to greater shareholder losses than such failures due to the buyer firm. This provides important new insight into the financial risks arising from outsourcing front-end services. Further, we investigate the ability of the buyer firm's employee and financial resources to temper these shareholder losses. We find that buyer firm employee productivity can moderate the greater financial penalty associated with such triadic service failures but that buyer firm leverage tends to not have such a mitigating effect. This provides new guidance for theory and practice regarding how buyer firms can position themselves to buffer the financial risks arising from service failures due to front-end service providers. (C) 2014 Elsevier B.V. All rights reserved."
291,"Outsourcing customer support: The role of provider customer focus","Wuyts, Stefan and Rindfleisch, Aric and Citrin, Alka","JOURNAL OF OPERATIONS MANAGEMENT","35","SI","40-55","2015","MAY","Outsourcing;Service Triads;Customer Support;Customer Focus","","An increasing number of firms are outsourcing customer support to external service providers. This creates a triadic setting in which an outsourcing provider serves end customers on behalf of its clients. While outsourcing presents an opportunity to serve customers, service providers differ in their motivation and ability to fulfill customer needs. Prior research suggests that firms with a strong customer focus have an intrinsic motivation to address customer needs. We suggest that in an outsourcing context, this intrinsic motivation does not suffice. Using a Motivation-Opportunity-Ability framework, we posit that the effect of a provider's customer focus will be moderated by a set of relational, firm, and customer characteristics that affect its ability to serve end customers. We test our conceptualization among 171 outsourcing clients from the Netherlands and then validate these results among 135 Indian outsourcing providers. The findings reveal that customer-focused providers achieve higher levels of customer need fulfillment but this effect is contingent on their ability to serve end customers. In particular, customer-focused providers more effectively fulfill customer needs when clients and providers share close relational ties, when clients also have a high level of customer focus, and when end customer needs exhibit a low degree of turbulence. In addition, we find that, in turbulent markets, equipment-related services offer greater opportunity for effective customer need fulfillment than other outsourced services. (C) 2014 Elsevier B.V. All rights reserved."
292,"An agency perspective on service triads: Linking operational and financial performance","Zhang, Jie J. and Lawrence, Benjamin and Anderson, Chris K.","JOURNAL OF OPERATIONS MANAGEMENT","35","SI","56-66","2015","MAY","Service Triads;Customer Satisfaction;Service Outsourcing;Agency Theory;Franchising","","We explore one prolific type of service triad, the franchise triad, involving three primary stakeholders: the franchisor, the franchisee and the customer. In this triad, franchisees use their affiliation with the franchisor's brand to attract customers to their local outlets. In exchange for the right of assuming the identity of the brand, the franchisee pays the franchisor royalties and retains residual profits. Applying Agency Theory, this paper examines the inherent conflict of interests between a principal (i.e., franchisor) that controls and manages brand equity as a shared resource and an agent (i.e., franchisee) that retains pricing right and profits from the identity of the brand by interacting directly with customers. We empirically isolate the effect of triad structure on outlet performance by matching two unique datasets. One set of data captures operational performance in the form of aggregated online review scores and the other financial performance including average daily hotel rate and revenue per available room. We find that franchisees charge higher prices than their corporate counterparts even when controlling for operational performance. Even though franchisees charge higher prices they maintain similar financial performance in terms of revenue per available room. These results suggest that the triad structure plays a significant role in franchisees' ability to free-ride on shared brand equity and have important managerial implications for effective outsourcing, contract design and performance evaluation for a wide range of service industries. (C) 2014 Elsevier B.V. All rights reserved."
293,"Collaboration in Multi-Partner R&D Projects: The Impact of Partnering Scale and Scope","Mishra, Anant and Chandrasekaran, Aravind and MacCormack, Alan","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","1-14","2015","JAN","Multi-Partner R&D Projects;Empirical Research;New Product Development;Collaboration Structures;Partnering Scale And Scope","","How can firms design collaboration structures for effective performance in R&D projects that involve multiple partners? To address this question, we examine the theoretical underpinnings of collaboration structures in multi-partner R&D projects-i.e., the scale and the scope of partnering efforts. Partnering scale captures the extent of resource interdependencies between a firm and its partners; partnering scope captures both the breadth and depth of the interdependencies between a firm and its partners. Using primary data from 147 multi-partner R&D projects, we develop and test hypotheses that examine the impact of partnering scale and scope decisions on partnering performance. Results indicate that partnering scale has a curvilinear relationship with partnering performance. That is, intermediate levels of partnering scale are associated with higher partnering performance, compared to low or high levels of partnering scale. However, we also find that the nature of this relationship is moderated by the sub-dimensions of partnering scope. Specifically, increase in partnering breadth appears to magnify the negative effect of partnering scale on performance. In contrast, increase in partnering depth appears to overcome this negative effect, allowing firms to operate at higher levels of partnering scale. Taken together, these results highlight the importance of adopting a comprehensive approach to designing collaboration structures for multi-partner R&D projects. Published by Elsevier B.V."
294,"Revisiting the interplay between contractual and relational governance: A qualitative and meta-analytic investigation","Cao, Zhi and Lumineau, Fabrice","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","15-42","2015","JAN","Interorganizational Relationships;Contractual Governance;Relational Governance;Complementarity;Substitution;Meta-Analysis","","Although extant literature has shown that formal contracts and relational governance play a key role in interorganizational relationships, the nature of their interplay still remains equivocal. To better understand the relationships between contractual and relational governance, we conducted a qualitative review and meta-analysis of the existing literature. Meta-analytic results from 33,051 interorganizational relationships across 149 empirical studies have indicated that contractual governance is positively related to both sides of relational governance trust and relational norms. Our results have also indicated that contracts, trust, and relational norms jointly improve satisfaction and relationship performance and jointly reduce opportunism. These findings provide strong evidence for the complementarity arguments of the contractual-relational governance relationships and their joint impacts on performance. We also found that the mutual relationships between contractual and relational governance are moderated by the institutional environments, the interorganizational relationship type and length, and the construct measurement of contracts. Overall, this study provides new insights on when contractual and relational governance complement or substitute each other. We discuss the implications of our study for theory and practice and propose a research agenda for future research on governance in interorganizational relationships. (C) 2014 Elsevier B.V. All rights reserved."
295,"Supply network disruption and resilience: A network structural perspective","Kim, Yusoon and Chen, Yi-Su and Linderman, Kevin","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","43-59","2015","JAN","Supply Network Disruption;Resilience;Graph Theory;Complex Networks;Network Analysis","","Increasingly, scholars recognize the importance of understanding supply network disruptions. However, the literature still lacks a clear conceptualization of a network-level understanding of supply disruptions. Not having a network level understanding of supply disruptions prevents firms from fully mitigating the negative effects of a supply disruption. Graph theory helps to conceptualize a supply network and differentiate between disruptions at the node/arc level vs. network level. The structure of a supply network consists of a collection of nodes (facilities) and the connecting arcs (transportation). From this perspective, small events that disrupt a node or arc in the network can have major consequences for the network. A failure in a node or arc can potentially stop the flow of material across network. This study conceptualizes supply network disruption and resilience by examining the structural relationships among entities in the network. We compare four fundamental supply network structures to help understand supply network disruption and resilience. The analysis shows that node/arc-level disruptions do not necessarily lead to network-level disruptions, and demonstrates the importance of differentiating a node/arc disruption vs. a network disruption. The results also indicate that network structure significantly determines the likelihood of disruption. In general, different structural relationships among network entities have different levels of resilience. More specifically, resilience improves when the structural relationships in a network follow the power-law. This paper not only offers a new perspective of supply network disruption, but also suggests a useful analytical approach to assessing supply network structures for resilience. (C) 2014 Elsevier B.V. All rights reserved."
296,"Sourcing for the base of the pyramid: Constructing supply chains to address voids in subsistence markets","Parmigiani, Anne and Rivera-Santos, Miguel","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","60-70","2015","JAN","Subsistence Markets;Base Of The Pyramid;Sourcing;Supply Chains;Institutional Voids","","Substantial work has described downstream distribution systems for subsistence markets, but little is known about how upstream supply chains support these efforts. We suggest that a multinational corporation (MNC) entering these markets must resolve the institutional voids in product, labor, and capital markets, as well as address issues of regulatory ambiguities and the lack of contracting mechanisms that exist at the raw material, manufacturing, distribution, and marketing stages of the supply chain. We analyze the nature of these voids and their challenges, map them onto the value chain, discuss their interconnections, and suggest that they do not impact all firms equally. We provide examples from the food, beverage, and textile industries of how four firms have addressed institutional voids in constructing their supply chains. We conclude by providing implications, both across the value chain and regarding the trade-offs of partnering with non-profit agencies. Our analysis highlights the importance of going beyond the broad impact of the institutional environment to understanding its more nuanced and multi-faceted effect on supply chains. (C) 2014 Elsevier B.V. All rights reserved."
297,"Performance outcomes of supply chain agility: When should you be agile?","Gligor, David M. and Esmark, Carol L. and Holcomb, Mary C.","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","71-82","2015","JAN","Supply Chain Agility;Agility;Customer Effectiveness;Cost Efficiency;Performance;Environmental Uncertainty","","Traditionally, researchers have claimed agility as an attribute closely tied to the effectiveness of strategic supply chain management. Because of its association with customer effectiveness, some researchers have considered agility to be fundamentally different from lean, which has been linked to cost efficiency (Goldsby et al., 2006). Therefore, the relationship between agility and cost efficiency is not clear due to limited empirical scrutiny from researchers. Since elimination of waste is the cornerstone of lean, unraveling the relationship between agility and efficiency can also offer a better perspective on relationship between the fundamental paradigms of agility and lean. The manuscript makes a key contribution to the agility literature by examining the association between supply chain agility (FSCA), cost efficiency and customer effectiveness across various environmental situations. We use archival data to examine the moderating effects of environmental munificence, dynamism, and complexity. It has been argued that firms should embrace agile strategies when operating in highly uncertain environments, and embrace lean strategies when operating in more stable environments (Lee, 2002; Sebastiao and Golicic, 2008). We empirically question this premise to determine whether supply chain agility can also lead to superior performance for firms operating in stable environments. The study results also provide a better understanding of how FSCA contributes to firm financial performance. We evaluate the impact of FSCA on the firm's Return on Assets using archival data from the Compustat database. Thus, we provide evidence to managers that deploying resource to enhance FSCA can positively impact the firm's bottom line. (C) 2014 Elsevier B.V. All rights reserved."
298,"The relationship between team autonomy and new product development performance under different levels of technological turbulence","Chen, Jiyao and Neubaum, Donald O. and Reilly, Richard R. and Lynn, Gary S.","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","83-96","2015","JAN","Team Autonomy;Behavioral Effect;Mechanistic Effect;Technological Turbulence;New Product Development","","Operations management researchers have frequently suggested that autonomy can motivate teams to actively and flexibly adapt to fast-changing environments, fostering innovation and creative problem solving. However, empirical studies have not consistently supported the benefits of team autonomy. We articulate the behavioral and mechanistic effects of team autonomy by integrating operations management and behavioral literatures. Further, we view team autonomy as a bipolar factor and argue that both the behavioral and mechanistic effects of team autonomy on operational outcomes are non-linear. Drawing on information processing theory, we propose that the benefits of team autonomy depend on the degree of technological turbulence. A study of 212 new product development projects supports these propositions. Specifically, the relationship between team autonomy and operational outcomes is boolean AND-shaped in technologically turbulent environments and U-shaped in technologically stable environments. Further, operational outcomes mediate the relationships between team autonomy and product success. We discuss the theoretical implications regarding new product development, operations management, the bipolarity of autonomy, and information-processing theory. Published by Elsevier B.V."
299,"The importance of client heterogeneity in predicting make-or-buy decisions","Kistruck, Geoffrey M. and Morris, Shad S. and Webb, Justin W. and Stevens, Charles E.","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","97-110","2015","JAN","Intermediation;Outsourcing;Client Heterogeneity;Professional Services;Transaction Costs;Capabilities","","Scholars have begun to merge the transaction cost economics and capabilities perspectives to examine outsourcing decisions. Further integrating these perspectives with intermediation theory, we assert that a firm's decision to use an intermediary when entering a foreign market is largely a function of the intermediary's relative capabilities and relative transaction costs (i.e., relative advantage). We hypothesize that the intermediary's relative advantage is influenced by three significantly intertwined exchange conditions: client heterogeneity, intermediary risk, and firm learning. Using a sample of 929 new foreign market initiatives by a global consulting firm, our results support our theory. (C) 2014 Elsevier B.V. All rights reserved."
300,"Firm's resilience to supply chain disruptions: Scale development and empirical examination","Ambulkar, Saurabh and Blackhurst, Jennifer and Grawe, Scott","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","111-122","2015","JAN","Supply Chain;Resilience;Scale Development;Risk Management","","This paper expands our understanding of factors that contribute to development of firm resilience to supply chain disruptions. In doing so, we operationalize firm resilience to understand how supply chain disruption orientated firms can develop resilience to supply chain disruptions. We find that supply chain disruption orientation alone is not enough for a firm to develop resilience. Supply chain disruption oriented firms require the ability to reconfigure resources or have a risk management resource infrastructure to develop resilience. The way in which supply chain disruption oriented firms develop resilience through resource reconfiguration or risk management infrastructure depends on the context of the disruption as high impact or low impact. In a high impact disruption context, resource reconfiguration fully mediates the relationship between supply chain disruption orientation and firm resilience. In a low impact disruption context, supply chain disruption orientation and risk management infrastructure have a synergistic effect on developing firm resilience. Published by Elsevier B.V."
301,"Operational and strategic information processing: Complementing healthcare IT infrastructure","Gardner, John W. and Boyer, Kenneth K. and Gray, John V.","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","123-139","2015","JAN","Information Processing;Healthcare;Information Technology;Quality Management;Data Analysis","","Healthcare information technologies (HIT) have been promoted as key enablers of improved patient safety, reduced medical errors, and increased patient satisfaction but have yielded mixed results. Drawing upon information processing theory and quality management concepts, we examine HIT infrastructure simultaneously with two distinct means of processing information: (1) operational use of error data for detecting and reducing hospital errors, and (2) strategic use of objective data for organizational planning. We use time-sequenced data to examine HIT infrastructure (secondary data in 2008), information processing mechanisms (primary survey data from 258 hospitals in 2009), and two measures of hospital performance: (1) care quality, and (2) patient satisfaction (secondary data in 2010). Using hierarchical regression analysis we find that whether and how investments in HIT infrastructure are complemented by information processing mechanisms depends upon the performance measure under consideration and the form of information processing employed. Specifically, operational error processing complements HIT infrastructure in its association with higher care quality but not with patient satisfaction. In comparison, higher levels of strategic information processing complement HIT infrastructure in its association with higher patient satisfaction. (C) 2014 Elsevier B.V. All rights reserved."
302,"Assessing the contingent effects of collaboration on agility performance in buyer-supplier relationships","Narayanan, Sriram and Narasimhan, Ram and Schoenherr, Tobias","JOURNAL OF OPERATIONS MANAGEMENT","33-34","","140-154","2015","JAN","Collaboration;Transaction Cost Economics;Trust;Buyer-Supplier Relationships;Supply Chain Management;Agility Performance","","Several studies in the buyer-supplier relationship literature have addressed the impact of collaboration on agility performance. While some studies have concluded that collaboration leads to beneficial effects, others have questioned the positive effects of collaboration on relationship performance. Drawing on contingency theory and transaction cost economics (TCE), we seek to better understand the linkage among collaboration, trust and agility performance in a buyer-supplier relationship. Further, we study the contingent influence of requirements certainty and supplier asset specificity, two key TCE constructs in buyer-supplier relationships, on the collaboration-agility performance relationship. We show that while trust mediates the impact of collaboration on agility performance, the indirect effect of collaboration on agility performance via trust is significant only beyond a threshold level of collaboration. The theoretical implication of this result is that the performance relationship is non-linear, a result that has not been recognized in current literature. The practical implication is that organizations need to establish a certain level of collaboration before its positive impact can be realized. In addition, we show that the impact of collaboration on agility performance in buyer-supplier sourcing relationships can be positive, negative or neutral depending on the levels of trust, supplier asset specificity and requirements certainty, emphasizing the need to develop contingency theories. (C) 2014 Elsevier B.V. All rights reserved."
303,"The role of operations executives in strategy making","Demeester, Lieven and De Meyer, Arnoud and Grahovac, Jovan","JOURNAL OF OPERATIONS MANAGEMENT","32","7-8, SI","403-413","2014","NOV","Operations Strategy;Strategy Process;Information Processing;Contingency Theory","","Creating competitive advantage based on operations capabilities is likely to require much analysis and communication within the operations function. At the same time, much communication and joint strategizing with the top and other functional executives is likely to be needed as well. Hence, given that operations executives have limited time and also have to perform many other routine tasks, they need to manage two tradeoffs. The first one is between the time spent on strategy making and the time spent on everything else. The other is within strategy making, between the time spent on functional deliberation within the operations function and top-level communication with other executives. Using a survey of 134 operations executives, we find that an increase in the time the operations executive spends on strategy making is positively associated with performance in complex and hostile environments and when the relative strength of the operations function within the firm is low. Within the operations executive's strategy making, an increased emphasis on top-level communication is positively associated with performance in environments that are complex, stable (less uncertain), or hostile. (C) 2014 Elsevier B.V. All rights reserved."
304,"Lean manufacturing and firm performance: The incremental contribution of lean management accounting practices","Fullerton, Rosemary R. and Kennedy, Frances A. and Widener, Sally K.","JOURNAL OF OPERATIONS MANAGEMENT","32","7-8, SI","414-428","2014","NOV","Lean Manufacturing;Lean Accounting;Operations And Financial Performance;Survey Analysis;Structural Equation Modeling","","Manufacturing firms operating in rapidly changing and highly competitive markets have embraced the continuous process improvement mindset. They have worked to improve quality, flexibility, and customer response time using the principles of Lean thinking. To reach its potential, lean must be adopted as a holistic business strategy, rather than an activity isolated in operations. The lean enterprise calls for the integration of lean practices across operations and other business functions. As a critical component for achieving financial control, management accounting practices (MAP) need to be adjusted to meet the demands and objectives of lean organizations. Our aim is to help both researchers and practitioners better understand how lean MAP can support operations personnel with their internal decision making, and operations executives and business leaders in their objective of increasing lean operations performance as part of a holistic lean enterprise strategy. We use survey data from 244 U.S. manufacturing firms to construct a structural equation model. We document that the extent of lean manufacturing implementation is associated with the use of lean MAP, and further that the lean MAP are related in a systematic way: simplified and strategically aligned MAP positively influences the use of value stream costing, which in turn positively influences the use of visual performance measures. We also find that the extent of lean manufacturing practices is directly related to operations performance. More importantly, lean manufacturing practices also indirectly affect operations performance through lean MAP. These findings are consistent with the notion that lean thinking is a holistic business strategy. In order to derive the greatest impact on performance, our results indicate that operations management cannot operate in a vacuum. Instead, operations and accounting personnel must partner with each other to ensure that lean MAP are strategically integrated into the lean culture. In sum, lean MAP provide essential financial control that integrates with and supports operations to achieve desired benefits. (C) 2014 Elsevier B.V. All rights reserved."
305,"A comparative case study of sustaining quality as a competitive advantage","Su, Hung-Chung and Linderman, Kevin and Schroeder, Roger G. and Van de Ven, Andrew H.","JOURNAL OF OPERATIONS MANAGEMENT","32","7-8, SI","429-445","2014","NOV","Operations Strategy;Quality Management;Red Queen Effect","","Many organizations have achieved high levels of quality performance only to lose it later on. These firms that were once quality leaders can no longer compete on the quality of their products or services. This research develops a theoretical understanding of how organizations can sustain a quality advantage. It offers a conceptual definition of sustaining a quality advantage which involves not only sustaining a high level of quality performance, but also sustaining a high consistency of quality performance. A comparative case study provides evidence of three capabilities that distinguish firms with different levels of sustaining quality. These capabilities include: (1) meta-learning, (2) sensing weak signals, and (3) resilience to quality disruptions. The case analysis argues that meta-learning helps sustain a high level of quality performance, while sensing weak signals and resilience improves the consistency of quality performance. This study offers a dynamic capability-based strategy that explains how to sustain a competitive advantage in quality, which may also have implications for sustaining other operational competitive advantages. (C) 2014 Elsevier B.V. All rights reserved."
306,"Developing supplier integration capabilities for sustainable competitive advantage: A dynamic capabilities approach","Vanpoucke, Evelyne and Vereecke, Ann and Wetzels, Martin","JOURNAL OF OPERATIONS MANAGEMENT","32","7-8, SI","446-461","2014","NOV","Dynamic Capability;Buyer-Supplier Integration;Operational Performance;Dynamics;Supply Base Complexity","","Previous research describes supplier integration as a competitive resource that manufacturers use to create economic rents. Considering the mixed results obtained from linking supplier integration with performance outcomes, a 'dynamic' component - or the ability to reconfigure the supply chain to adapt to changing environments - appears critical to creating a sustainable competitive advantage. This study identifies integration sensing, seizing and transforming as sub-capabilities that together form a dynamic capability, referred to herein as supplier integrative capability (SIC). That is, SIC enables buyers to sense changes in the supply environment by sharing information with suppliers, seize opportunities presented by establishing procedures to analyse this information and make long-term changes to existing processes. A global sample from the industrial sector reveals that the three capabilities exhibit complementarity and must exist simultaneously for the capability to be effective, which then enhances both process flexibility and cost efficiency and helps firms avoid the traditional trade-off of cost and flexibility. In addition, market and technological dynamics strengthen the effect of SIC on operational performance; supply base complexity attenuates this link. (C) 2014 Elsevier B.V. All rights reserved."
307,"Top-down, bottom-up, or both? Toward an integrative perspective on operations strategy formation","Kim, Yoon Hee and Sting, Fabian J. and Loch, Christoph H.","JOURNAL OF OPERATIONS MANAGEMENT","32","7-8, SI","462-474","2014","NOV","Operations Strategy;Strategy Formation Process;Top Down;Bottom-Up;Integrative Perspective;Case Study","","Operations strategy is formed via complex processes that transpire in multiple directions at multiple organizational levels. While most previous studies focus on the macro-level process of strategy formation from the dominant top-down perspective, this study investigates the micro-level process of strategy formation that governs interactions among competitive priorities, objectives, and action plans within operations. Using 111 (59 top-down and 52 bottom-up) action plans collected from six German manufacturing plants, we build on Kim and Arnold's (1996) framework and propose an integrated process model of operations strategy formation that encompasses both top-down planning and bottom-up learning. We also identify a contingency factor that affects their balance: centralized versus decentralized organizational structure. Finally, based on the analysis of their respective strategic content, we provide evidence concerning the complementary roles of top-down and bottom-up action plans in operations strategy. Published by Elsevier B.V."
308,"Linking strategic flexibility and operational efficiency: The mediating role of ambidextrous operational capabilities","Kortmann, Sebastian and Gelhard, Carsten and Zimmermann, Carsten and Piller, Frank T.","JOURNAL OF OPERATIONS MANAGEMENT","32","7-8, SI","475-490","2014","NOV","Ambidextrous Operational Capabilities;Strategic Flexibility;Operational Efficiency;Mass Customization Capability;Innovative Ambidexterity","","We elucidate the important, though complex, relationship between strategic flexibility and operational efficiency. We incorporate insights from the dynamic resource-based view, ambidexterity literature and managerial practice to explain how two ambidextrous operational capabilities, i.e., mass customization capability and innovative ambidexterity, fully mediate the relationship between strategic flexibility and operational efficiency. Using top-level executive data in India and the United States of America, our structural equation models show that ambidextrous operational capabilities link strategic flexibility and operational efficiency. While informing the debate on developing sustainable competitive advantage, we derive important theoretical and managerial implications for both operations management and strategic management. (C) 2014 Elsevier B.V. All rights reserved."
309,"The role of physical distribution services as determinants of product returns in Internet retailing","Rao, Shashank and Rabinovich, Elliot and Raju, Dheeraj","JOURNAL OF OPERATIONS MANAGEMENT","32","6","295-312","2014","SEP","Online Retailing;Electronic Commerce;Order Fulfillment;Returns;Physical Distribution","","Pressure continues to build on Internet retailers to squeeze out inefficiencies from their day-to-day operations. One major source of such inefficiencies is product returns. Indeed, product returns in Internet retailing have been shown to be, on average, as high as 22% of sales. Yet, most retailers accept them as a necessary cost of doing business. This is not surprising since many retailers do not have a clear understanding of the causes of product returns. While it is known that return policies of retailers, along with product attributes, are two important factors related to product return incidents, little is known about which aspects of the online retail transaction make such a purchase more return-prone. In the current study, we seek to address this issue. We use a large data set of customer purchases and returns to identify haw process attributes in physical distribution service (PDS) influence product returns. The first attribute involves perceptions of scarcity conditions in inventory availability among consumers When retailers reveal to consumers information on inventory levels for the products that they intend to buy. Our results show that orders in which items are sold when these conditions are revealed to shoppers have a higher likelihood of being returned than orders in which these conditions are not revealed. While prior research has argued that inventory scarcity perceptions have an effect on purchases, our findings suggest that they are also related to the likelihood of these purchases being returned. The second attribute involves the reliability in the delivery of orders to consumers. We find that the likelihood of orders being returned depends on the consistency between retailer promises of timeliness in the delivery of orders and the actual delivery performance of the orders. Moreover, we find that the effect that consistency in the delivery has in the likelihood of returns, is stronger for orders that involve promises for expedited delivery than for orders with less expeditious promises. That is, although the occurrence of returns depends on the delays in the delivery of orders to consumers relative to the initial promises made by the retailers, this effect is more notable for orders that involve promises of fast delivery. (C) 2014 Elsevier B.V. All rights reserved."
310,"The effect of performance measurement systems on firm performance: A cross-sectional and a longitudinal study","Koufteros, Xenophon and Verghese, Anto (John) and Lucianetti, Lorenzo","JOURNAL OF OPERATIONS MANAGEMENT","32","6","313-336","2014","SEP","Performance Measurement Systems;Operations Management;Accounting;Financial Performance;Empirical;Panel Data","","Performance measurement (PM) systems have been popularized over the last 20 years and the operations management literature is replete with discussion of metrics and measurement systems. Yet, a comprehensive nomological network relating types of PM system uses to organizational capabilities and performance is lacking. Furthermore, there is scant empirical evidence attesting to the explanatory efficacy of PM systems as it relates to organizational performance. We view PM system uses through the lenses of the Resource Orchestration Theory (ROT) and explore specific relationships of underlying variables by relying on the Organizational Information Processing Theory (OIPT). Resting on the extant literature, we identify two types of uses which include Diagnostic Use (the review of critical performance variables in order to maintain, alter, or justify patterns in an organizational activity) and interactive use (a forward-looking activity exemplified by active and frequent involvement of top management envisioning new ways to orchestrate organizational resources for competitive advantage) and relate them along with their interaction (i.e., dynamic tension) to organizational capabilities. We further link capabilities to target performance, which subsequently impacts organizational performance (operationalized through both perceptual and objective financial performance measures). The nomological network is tested via a cross sectional study (386 Italian firms) while the efficacy of PM systems to explain organizational performance is examined by using longitudinal panel data approaches over a 10 year period. There is sufficient evidence to suggest that the use of PM systems leads to improved capabilities, which then impact performance. Contrary to the extant literature, however, we discovered that Diagnostic Use appears to be the most constructive explanatory variable for capabilities. On the other hand, in light of a longitudinal study, we also uncovered that Diagnostic Use experienced depreciating returns as far as objective financial measures are concerned. Also, when high levels of Diagnostic Use were coupled with low levels of Interactive Use, they produced the lowest levels of organizational capabilities. Conversely, high levels of both types of PM system use generated extraordinary high levels of capabilities. There is sufficient evidence to suggest that organizations cannot rely merely on Diagnostic Use of PM systems. We also learned that the effects of PM systems (measured via adaptation) fade unless high learning rates are applied. We offer detailed recommendations for future research which have theoretical as well as empirical implications. (C) 2014 Elsevier B.V. All rights reserved."
311,"Valuing lead time","de Treville, Suzanne and Bicer, Isik and Chavez-Demoulin, Valerie and Hagspiel, Verena and Schuerhoff, Norman and Tasserit, Christophe and Wager, Stefan","JOURNAL OF OPERATIONS MANAGEMENT","32","6","337-346","2014","SEP","Option Theory;Manufacturing Lead Time;Supply-Chain Mismatch Cost;Functional Products","","When do short lead times warrant a cost premium? Decision makers generally agree that short lead times enhance competitiveness, but have struggled to quantify their benefits. Blackburn (2012) argued that the marginal value of time is low when demand is predictable and salvage values are high. de Treville et al. (2014) used real-options theory to quantify the relationship between mismatch cost and demand volatility, demonstrating that the marginal value of time increases with demand volatility, and with the volatility of demand volatility. We use the de Treville et al. model to explore the marginal value of time in three industrial supply chains facing relatively low demand volatility, extending the model to incorporate factors such as tender-loss risk, demand clustering in an order-up-to model, and use of a target fill rate that exceeded the newsvendor profit-maximizing order quantity. Each of these factors substantially increases the marginal value of time. In all of the companies under study, managers had underestimated the mismatch costs arising from lead time, so had underinvested in cutting lead times. (C) 2014 Elsevier B.V. All rights reserved."
312,"The effect of environmental dynamism on returns to inventory leanness","Eroglu, Cuneyt and Hofer, Christian","JOURNAL OF OPERATIONS MANAGEMENT","32","6","347-356","2014","SEP","Environmental Dynamism;Innovation;Uncertainty;Competition;Firm Performance","","This paper adds to the empirical inventory management literature by examining the moderating effects of environmental dynamism on the relationship between inventory leanness and financial performance. While the financial implications of inventory management practices have been extensively studied in the literature, it is clear that lean inventory strategies may not have the same payoff for all firms in all industries. Grounded in inventory theory, this study explores how firm characteristics and environmental dynamism measured in terms of innovative intensity, demand uncertainty and competitive intensity moderate the inventory leanness-performance link. We use hierarchical linear modeling to analyze a data set of 5749 firm-year observations from 123 U.S. manufacturing industries. In line with the hypotheses set forth, the results indicate that innovative intensity in an industry increases the effect of inventory leanness on firm performance while competitive intensity has the opposite effect. The hypothesis with respect to the moderating role of demand uncertainty is not supported. Another interesting and important finding is that inventory leanness accounts for nearly one third of the variation in firm performance after controlling for firm size and growth, thus underlining the importance of efficient and effective inventory management for overall firm success. (C) 2014 Elsevier B.V. All rights reserved."
313,"The influence of supply network structure on firm innovation","Bellamy, Marcus A. and Ghosh, Soumen and Hora, Manpreet","JOURNAL OF OPERATIONS MANAGEMENT","32","6","357-373","2014","SEP","Innovation;Supply Networks;Structural Analysis;Negative Binomial Regression","","In this study, we examine the structural characteristics of supply networks and investigate the relationship between a firm's supply network accessibility and interconnectedness and its innovation output. We also examine potential moderating effects of absorptive capacity and supply network partner innovativeness on innovation output. We hypothesize that firms will experience greater innovation output from (I) higher levels of supply network accessibility and supply network interconnectedness, (2) the interaction between the levels of these two structural characteristics, (3) the moderating role of absorptive capacity on supply network accessibility and the moderating role of supply network partner innovativeness on supply network interconnectedness. Supply network partner relationships are drawn in the context of the electronics industry using data from multiple sources. We use social network analysis to create measures for each supply network structural characteristic. Using regression techniques to test the relationship between these structural characteristics and firm innovation for a sample of 390 firms, our findings suggest that supply network accessibility has a significant association with a firm's innovation output. The results also indicate that interconnected supply networks strengthen the association between supply network accessibility and innovation output. Moreover, the influence of the two structural characteristics on innovation output can be enhanced by a firm's absorptive capacity and level of supply network partner innovativeness. By addressing the need for deeper structural analysis, this study contributes to supply chain research by accounting for the embedded nature of ties in supply networks, and showing how these structural characteristics influence the knowledge and information flows residing within a firm's supply network. (C) 2014 Elsevier B.V. All rights reserved."
314,"Justice served: Mitigating damaged trust stemming from supply chain disruptions","Wang, Qiong and Craighead, Christopher W. and Li, Julie Juan","JOURNAL OF OPERATIONS MANAGEMENT","32","6","374-386","2014","SEP","Trust Damage;Relationship Repair;Supply Chain Disruptions;Justice Theory;Service Recovery;Buyer-Supplier Relationships","","This research examines the mitigation of damaged trust stemming from supplier-induced disruptions. We used the critical incident technique on 302 buying firms in China to capture two (one successful, one unsuccessful) supplier-induced disruptions (yielding a total of 604 incidents) to test our theorizing grounded in justice theory. We find evidence that different aspects of trust damage (ability, benevolence, and integrity) can be mitigated through the supplier's selective use of appropriate justice approaches (procedural, interactional, or distributive justice), which, in turn, foster relationship continuity intentions. Within this realm, we make a number of contributions. First, we find that procedural justice is the most effective mechanism (followed by distributive justice and interactional justice) to recoup the damage to buyers' trust in the suppliers' ability, benevolence, and integrity. Second, we find that mitigating damaged ability is the most powerful precursor (followed by recuperating damaged integrity) for locking in future business. Conversely, the mitigation of damaged benevolence is not found to affect future business intentions. Third, our post hoc results suggest that disruptions and consequent mitigation efforts pose relational threats as well as opportunities yet the double-edged nature is affected by the base level of trust (i.e., the trust level prior to the disruption). Broadly, our study suggests that suppliers can overcome the negative relational repercussions of disruptions (that they caused) by employing well-developed, but nuanced, mitigation efforts and, in doing so, repair, solidify or even enhance the relationships. (C) 2014 Elsevier B.V. All rights reserved."
315,"Economies of extremes: Lessons from venture-capital decision making","de Treville, Suzanne and Petty, Jeffrey S. and Wager, Stefan","JOURNAL OF OPERATIONS MANAGEMENT","32","6","387-398","2014","SEP","Capacity Strategy;Extreme-Value Theory;Venture-Capital Decision Making","","An organization's ability to exploit extreme events such as exceptional opportunities depends on its capacity strategy. The venture capital industry illustrates the interplay of expensive capacity and negative externalities from high utilization. The cost of adding a venture capitalist provides a strong incentive to run lean, but such leanness may make it impossible to evaluate all interesting investment opportunities. Using concepts from extreme-value theory, we analyze the trade-off between the costs and benefits arising from an increase in the number of evaluated deals. We ground our analysis in 11 years of archival data from a venture capital firm, representing 3631 deals, the decisions made, the reasons for those decisions, and the decision lead times. The firm identified 20% of arriving deals as worth evaluating during the screening process, but was not able to evaluate approximately 9% of those interesting deals due to a lack of capacity. We show that the value of increasing the number of deals evaluated increases with the tail weight of the distribution of deal values. When the right tail is light, increasing the number of deals evaluated may provide too modest a benefit to justify the cost. When, however, the right tail is heavy, the value of increasing the number of deals is likely to more than compensate for the cost of capacity. Our results provide new insight into the relative value of a chase capacity strategy that emphasizes responsiveness versus a high-utilization heuristic that emphasizes productivity. Our approach can be applied to other search operations such as personnel selection, quality circles seeking to identify root causes, and making employee capacity available for innovation. (C) 2014 Elsevier B.V. All rights reserved."
316,"Understanding supplier structural embeddedness: A social network perspective","Kim, Dong-Young","JOURNAL OF OPERATIONS MANAGEMENT","32","5","219-231","2014","JUL","Social Network Theory;Structural Embeddedness;Relational Embeddedness","","Despite a significant amount of attention, the potential of supplier structural embeddedness (i.e., the value of the structural position in an extended network) to improve the performance of a buying firm remains poorly understood. This study drew on the social network theory to empirically examine a conceptual framework specifying a relationship between the efforts of a buying firm to understand supplier structural configuration and operational and financial performance. This study also examines how the comprehension of structural embeddedness is transformed into performance for a buying firm through relational embeddedness (i.e., the strength of a dyadic relationship). Survey data collected from companies in the U.S. were analyzed using hierarchical regression analysis. The results indicate that the understanding of the structural dimension does help to enhance operational performance of a buying firm, but it does not lead to better financial performance. Empirical evidence shows that a buying firm does improve the quality of a dyadic relationship between the buying firm and a supplier by understanding how the supplier is connected to other firms and what positional values are produced. Further, relational embeddedness is found to mediate the influence of the enhanced understanding of the structural configuration on operational performance. (C) 2014 Elsevier B.V. All rights reserved."
317,"Renaissance of case research as a scientific method","Ketokivi, Mikko and Choi, Thomas","JOURNAL OF OPERATIONS MANAGEMENT","32","5","232-240","2014","JUL","Case Research;Methodology;Theory Building;Theory Testing;Theory Elaboration;Reasoning","","Since the seminal article by Eisenhardt (1989), scholarly interest in case research has mushroomed in operations management and organization sciences. Volumes of methodological texts are matched with a massive amount of empirical research that seeks to apply and further develop case research as a scientific method. What is missing from this literature is a treatment of the methodological diversity of case research. In this paper, we seek to unveil this heterogeneity by describing three distinct methodological accounts of case study: theory generation, theory testing, and theory elaboration. Each approach has its own idiosyncrasies, in particular when it comes to the interplay between theory and empirics. A typical case research incorporates both existing theories and empirical data to varying degrees. In light of this heterogeneity, we re-interpret key aspects of extant contributions and discuss guidelines for future case research. We propose that ultimately, case research rigor is determined by attention to idiosyncrasy and transparency of reasoning. We conclude by arguing that we have witnessed in the past 25 years in organization research what amounts to the Renaissance of case research. (C) 2014 Elsevier B.V. All rights reserved."
318,"Global sourcing and quality recalls: An empirical study of outsourcing-supplier concentration-product recalls linkages","Steven, Adams B. and Dong, Yan and Corsi, Thomas","JOURNAL OF OPERATIONS MANAGEMENT","32","5","241-253","2014","JUL","Product Recalls;Global Sourcing;Empirical Research;Outsourcing;Offshoring","","This study investigates how supply chain sourcing strategies are associated with product quality recalls. In particular, the research examines how make-or-buy decisions (i.e., outsourcing), the use of foreign suppliers (i.e., offshore outsourcing), the relocation of production to offshore markets (i.e., offshoring), and decisions to consolidate supply bases (i.e., the use of few vs. myriad suppliers) are related to product recalls. Product recalls are serious quality failures in supply chains with significant, negative impacts on firm performance. Product recalls are frequently connected to the globalization of supply chains. Globalization has, at times, promoted inconsistency in quality control and standards, leading to quality problems and failures. Data across multiple industries, with widely reported recalls, have been collected and analyzed using regression techniques. Our findings indicate that offshore outsourcing has a greater impact on recalls than offshoring without outsourcing; outsourcing domestically has the least influence. Outsourcing to a smaller supplier base may lead to fewer recalls at low levels of outsourcing. However, it may exacerbate the impact of outsourcing on recalls at high levels of outsourcing. (C) 2014 Elsevier B.V. All rights reserved."
319,"Toward a structural view of co-opetition in supply networks","Pathak, Surya D. and Wu, Zhaohui and Johnston, David","JOURNAL OF OPERATIONS MANAGEMENT","32","5","254-267","2014","JUL","Co-Opetition;Tertius Iungens;Tertius Gaudens;Supply Networks;Structural Holes;Archetypes","","Co-opetition, or simultaneous competition and cooperation, in the supply chain management literature has been treated as a dyadic relational phenomenon where the buyer's strategy is considered to be the primary driver. In this paper, we move beyond the dyadic view and propose a theory of co-opetition in supply networks. We argue that as firms within a supply network interact over time to access, share, and transform resources, new ties between firms are formed and existing ties dissolve, giving rise to co-opetition dynamics at the network level. Taking a configurational approach, we employ the inter-related dimensions of ties between firm, firm-level task, network-level objective, and governance to specify four practical supply network archetypes that cover a wide range of economic activities. We then explain how coopetitive relationships may evolve in these supply network archetypes. Specifically, we discuss how relationships form or dissolve in these archetypes and how local structural changes lead to co-opetition dynamics at the network level. We also discuss the implications of such dynamics from a managerial perspective. (C) 2014 Elsevier B.V. All rights reserved."
320,"OHSAS 18001 certification and operating performance: The role of complexity and coupling","Lo, Chris K. Y. and Pagell, Mark and Fan, Di and Wiengarten, Frank and Yeung, Andy C. L.","JOURNAL OF OPERATIONS MANAGEMENT","32","5","268-280","2014","JUL","Ohsas 18001;Event Study;Occupational Health And Safety;Contextual Factors","","Today, manufacturing firms encounter pressure from multiple stakeholders to manage occupational health and safety issues properly, systematically and transparently. While manufacturing firms commonly use internally developed Occupational Health and Safety Management Systems, there is growing pressure to adopt externally certified system such as OHSAS 18001. However, there are conflicting views and little empirical evidence that examines the linkage between OHSAS 18001 certification and operating performance. Hence, this paper examines the impact of OHSAS 18001 on operational performance through three theoretical lenses: Institutional Theory, Normal Accident Theory, and High Reliability Theory. We also investigate how complexity and coupling moderate the relationship between OHSAS 18001 and operational performance. Based on a sample of 211 U.S. listed manufacturing firms with OHSAS 18001 certification, we find that certification leads to significant increases in abnormal performance on safety, sales growth, labor productivity, and profitability and that these benefits increase as complexity and coupling increase. (C) 2014 Elsevier B.V. All rights reserved."
321,"Chain liability in multitier supply chains? Responsibility attributions for unsustainable supplier behavior","Hartmann, Julia and Moeller, Sabine","JOURNAL OF OPERATIONS MANAGEMENT","32","5","281-294","2014","JUL","Supply Chain Management;Environmental Issues;Attribution Theory;Vignette-Based Experiments;Structural Equation Modeling","","When it becomes publicly known that products are associated with suppliers that engage in unsustainable behaviors, consumers protest, as Nestle, Zara, and Kimberly Clark, among others, have learned. The phenomenon by which consumers hold firms responsible for the unsustainable behavior of their upstream partners suggests the notion of chain liability. This study aims to generate insights into the antecedents and consequences of such consumer responsibility attributions. Using data from four vignette-based survey experiments, the authors find that the chain liability effect increases if an environmental degradation incident (1) results from supplier behavior rather than force majeure, (2) results from a company decision rather than the decision of an individual employee, and (3) is more severe. Responsibility attributions do not differ with varying organizational distance from the supplier, firm size, strategic importance of the supplied product, or the existence of environmental management systems. The chain liability effect also creates strong risks for the focal firm; higher responsibility attributions increase consumers' anger and propensity to boycott. Therefore, firms should work to ensure sustainable behavior throughout the supply chain, to protect them from chain liability. (C) 2014 Elsevier B.V. All rights reserved."
322,"A critical evaluation of alternative methods and paradigms for conducting mediation analysis in operations management research","Malhotra, Manoj K. and Singhal, Cherry and Shang, Guangzhi and Ployhart, Robert E.","JOURNAL OF OPERATIONS MANAGEMENT","32","4","127-137","2014","MAY","Mediation Models;Methodological Review And Recommendation;Empirical","","Mediation as a theory testing approach has witnessed considerable adoption among Operations Management (OM) researchers. Although mediation-testing methods have evolved tremendously in the past decade, their dissemination in the OM field has not seen parallel growth. These advanced techniques facilitate the testing of existing and complex hypotheses in a more precise manner. With the intent of critically evaluating existing and alternative methods for conducting mediation analysis needed to support sophisticated empirical research, this paper first reviews OM studies that tested for mediation in the past eleven years (2002-2012) from top-tier OM journals. Four commonly used mediation approaches were identified. Based on principles of good theory building, type of mediation model, and properties of empirical data, we evaluate the existing methodologies and make recommendations on how to improve the rigor of OM mediation testing. Using published OM studies in top journals as examples, we then illustrate the relevance and advantages of these recommendations, as well as their ease of use. Furthermore, we empirically show that more robust and insightful results can be achieved by adopting these techniques, which in turn have the promise of leading to better theory building and testing in the field of operations management. (C) 2014 Elsevier B.V. All rights reserved."
323,"Product configuration, ambidexterity and firm performance in the context of industrial equipment manufacturing","Salvador, Fabrizio and Chandrasekaran, Aravind and Sohail, Tashfeen","JOURNAL OF OPERATIONS MANAGEMENT","32","4","138-153","2014","MAY","Product Configuration;Ambidexterity;Customization;Complexity;Organizational Capabilities;Firm Performance","","The practice of configuring products to individual customer orders has found application in a variety of industry contexts, but little is known about the specific capabilities that firms develop to successfully compete when offering configurable products. Our research begins to fill this gap in the context of industrial equipment manufacturing. Drawing from the ambidexterity literature, we argue that firms have to balance dual goals of reducing variation and promoting variation in their product configuration activities by fostering two distinct firm-level capabilities: product configuration effectiveness (PCE) and product configuration intelligence (PCI). Specifically, we hypothesize that the simultaneous presence of PCE and PCI that is, product configuration ambidexterity (PCA) drives superior firm responsiveness and, indirectly firm sales and operating margin. However, we also contend that responsiveness gains through PCA can diminish with product complexity and can increase operating cost. We test these hypotheses by collecting both primary and secondary data from a sample of 108 European industrial equipment manufacturing firms. Results from our analyses indicate that PCA has an indirect effect through responsiveness on sales and operating cost but not on operating margin, with this effect diminishing with product complexity. Taken together, our results suggest that investment in developing PCA may represent a conundrum for industrial equipment manufacturing firms, because it translates into market but not financial advantages, and it is intertwined with product design decisions. We conclude this study with a discussion of the findings for theory and practice. (C) 2014 Elsevier B.V. All rights reserved."
324,"Agent-system co-development in supply chain research: Propositions and demonstrative findings","Tangpong, Chanchai and Hung, Kuo-Ting and Li, Jin","JOURNAL OF OPERATIONS MANAGEMENT","32","4","154-174","2014","MAY","Behavioral Operations Management;Agent-System Co-Development;Supply Chains;Adaptive Complex Systems;Vignette-Based Experiment;Survey Research","","In this study, we develop an agent-system co-development (ASC) theoretical framework for behavioral research in supply chains. The ASC framework aims at explaining the dynamic agent-system relationships in supply chains whereby both action-influencing properties of human agents (e.g., beliefs, personalities, attitudes) and governance-influencing properties of supply chain systems (e.g., social norms, power-dependence, partnerial/adversarial relationship forms) mutually influence each other over time. Two empirical studies are conducted to illustrate how ASC can be a useful theoretical framework in supply chain research and to partially validate the central thesis of ASC in the contexts of partnerial/adversarial supply chain relationships and cooperative/competitive attitudes of human agents in supply chains. The results of both studies support the central thesis of ASC regarding the dynamic agent-system relationships. From two replicated experiments in Study 1, the results suggest that agents' cooperative and competitive attitudes in business relationships are altered as they are exposed to different supply chain conditions of partnerial and adversarial relationships. In addition, from the multi-method research efforts in Study 2, the results from two survey studies and an experiment are largely consistent with one another, suggesting that personnel turnovers in existing supply chain systems can eventually lead to changes in supply-chain-system properties including the degrees of long-term commitment, information sharing, and joint problem-solving between supply chain partners, as well as the frequency of opportunism occurrences in the supply chains. Finally, we propound that the dynamic agent-system relationships proposed in the ASC framework can be a useful analytical lens in viewing various supply chain issues, such as supply chain evolutions and changes, supply chain designs and personnel decisions, and self-reinforcing feedback loops and decision tendencies in supply chains. (C) 2014 Elsevier B.V. All rights reserved."
325,"Interfaces in service modularity: A typology developed in modular health care provision","de Blok, Carolien and Meijboom, Bert and Luijkx, Katrien and Schols, Jos and Schroeder, Roger","JOURNAL OF OPERATIONS MANAGEMENT","32","4","175-189","2014","MAY","Service Modularity;Interfaces;Elderly Care;Case Study;Typology","","We conduct case research in a particular service context, i.e. the sector for elderly care, in order to explore characteristics of interfaces and the role they play in service customization. Even though the study of modularity in areas other than goods production is increasing, little is known about interfaces outside the context of modular goods. From our case research, it follows that interfaces can be distinguished at the component level (linkages between components' contents) and at the service package level (linkages between service providers involved). The contribution of the paper is a first typology on interfaces in modular services. Four interface categories are distinguished, which offer a specification of the interfaces' function in creating variety and coherence, when linking content components as well as service providers. In addition, we provide a new definition of interfaces for services that differs from the accepted manufacturing definition. (C) 2014 Elsevier B.V. All rights reserved."
326,"A conceptual framework for tackling knowable unknown unknowns in project management","Ramasesh, Ranga V. and Browning, Tyson R.","JOURNAL OF OPERATIONS MANAGEMENT","32","4","190-204","2014","MAY","Unknown Unknowns;Project Management;Project Uncertainty;Complexity;Risk Management","","Understanding and dealing with the unknown is a major challenge in project management. An extensive body of knowledge-theory and technique-exists on the known unknowns, i.e., uncertainties which can be described probabilistically and addressed through the conventional techniques of risk management. Although some recent studies have addressed projects where the existence of unknown unknowns (unk unks) is readily apparent or may be assumed given the type of project-e.g., new product development or new process implementation-very little work has been reported with respect to projects in general on how a project manager might assess its vulnerability to unk unks. In this paper, we present a conceptual framework to deal with (i.e., recognize and reduce) knowable unk unks in project management. The framework is supported by insights from a variety of theories, case analyses, and experiences. In this framework, we first present a model of the key factors-relating to both project design and behavioral issues-that increase the likelihood of unk unks and a set of propositions linking these factors to unk unks. We then present a set of design and behavioral approaches that project managers could adopt to reduce knowable unk unks. Our framework fills a gap in the project management literature and makes a significant practical contribution: it helps project managers diagnose a project to recognize and reduce the likelihood of unk unks and thus deal more effectively with the otherwise unrecognized risks and opportunities. (C) 2014 Elsevier B.V. All rights reserved."
327,"Bracing for demand shocks: An experimental investigation","Tokar, Travis and Aloysius, John and Williams, Brent and Waller, Matthew","JOURNAL OF OPERATIONS MANAGEMENT","32","4","205-216","2014","MAY","Demand Shock;Anticipated Feedback;Bracing;Judgment Bias;Behavioral Experiment;Inventory Control","","We investigate inventory ordering decisions when decision makers anticipated a demand shock. Decision makers anticipating an event have been shown to brace for an uncertain negative outcome by overestimating the likelihood of that event. Decision makers faced with a spike in demand may incur increased holding costs because they may brace, exhibiting a judgment bias, and consequently a decision bias by over-ordering inventory. Three studies span conditions of uncertainty regarding the timing and magnitude of a demand shock: Employing three between-subjects experiments, Study 1 investigates behavior when decision makers were faced with uncertainty in timing and in magnitude of demand at the most elemental level, manipulating holding and stock out costs. The three experimental tasks feature uncertainty about the magnitude of demand (Experiment 1.1), uncertainty about the timing of demand (Experiment 1.2), and uncertainty about both the magnitude and timing of demand (Experiment 1.3). Study 2 uses a dynamic, multi-period replenishment task and a between-subjects manipulation regarding the uncertainty of timing and magnitude of a demand shock. Study 3 also employs a multi-period decision environment, but compares behavior under a demand shock condition with that in a condition featuring only random variability. The collective results from the three studies identify a bias toward over-ordering in response to a demand shock, relative to the optimal orders. The between-subjects manipulations in Study 2 points toward a possible remedy as we found that providing information concerning the timing and magnitude of a shock ameliorated the bias. The primary revelation was that decision makers had more difficulty dealing with uncertain timing than with uncertain magnitude of demand. One implication is that it is particularly critical for retailers to carefully plan and manage how they share information with upstream supply chain partners regarding when they plan to introduce store-level promotions. (C) 2013 Elsevier B.V. All rights reserved."
328,"Supplier relationship-specific investments and the role of safeguards for supplier innovation sharing","Wagner, Stephan M. and Bode, Christoph","JOURNAL OF OPERATIONS MANAGEMENT","32","3","65-78","2014","MAR","Supply Chain Management;Supplier Innovation;Process Innovation;Product Innovation;Transaction Cost Theory;Survey","","The vast majority of the supplier innovation literature has focused on how buying firms can effectively pull innovations from their suppliers. Yet, we know remarkably little about the factors that contribute to a supplier voluntarily pushing innovations to its customers. The present study addresses this research gap in the context of industrial buyer-supplier relationships and with a specific focus on relationship-specific investments. Drawing on theory from the relationship-marketing literature and on transaction cost theory, we devise and test a proposed theoretical model that links the level of a supplier's relationship-specific investments to its sharing of innovative ideas regarding products and processes with customers. The model also considers the role of contract length, relationship age, and buyer-supplier cooperation as possible safeguards. The empirical results suggest that a supplier's relationship-specific investments encourage a supplier to suggest ideas of process innovations but to refrain from suggestions about product innovations. The latter effect, however, can be attenuated by appropriate formal and informal safeguards. (C) 2013 Elsevier B.V. All rights reserved."
329,"The moderating effects of knowledge characteristics of firms on the financial value of innovative technology products","Liu, Xiaojin and Yeung, Andy C. L. and Lo, Chris K. Y. and Cheng, T. C. E.","JOURNAL OF OPERATIONS MANAGEMENT","32","3","79-87","2014","MAR","Innovative Technology Products;Knowledge-Based View;Knowledge Characteristics;Patent Citation;Return On Assets","","The development of innovative technology products is both costly and risky, and their economic value is highly uncertain. Based on a sample of 312 innovative technology products introduced between 1987 and 2006 in the U.S. and a long-horizon event study with control firms, we study the impact of innovative technology products on the long-term financial performance of a firm. In particular, we examine how the knowledge characteristics of the firm, which embrace its knowledge absorptive capacity, knowledge impact, and knowledge diversity, moderate such an impact. We find that on average an innovative technology product increases the firm's return on assets (ROA) (relative to control firms) by 2.18% in the second year after product introduction. However, the value of an innovative technology product varies with the knowledge characteristics of the firm that invented it. We find that the financial impact of technology products is stronger when firms have higher knowledge absorptive capacity, and more impactful and less diversified knowledge (as measured by patents). We classify firms into three categories based on their knowledge characteristics. We find that firms with a high knowledge fit increase their ROA by 4.55% after product introduction, while those with a low knowledge fit receive no benefit from the innovative technology products at all. (C) 2013 Elsevier B.V. All rights reserved."
330,"Are relational ties always good for knowledge acquisition? Buyer-supplier exchanges in China","Zhou, Kevin Zheng and Zhang, Qiyuan and Sheng, Shibin and Xie, En and Bao, Yeqing","JOURNAL OF OPERATIONS MANAGEMENT","32","3","88-98","2014","MAR","Relational View;Transaction Cost Economics;Relational Ties;Contract Specificity;Competitive Intensity;Knowledge Acquisition","","Relational ties between manufacturers and their suppliers serve as an important strategic resource for value creation and realization. However, conflicting evidence exists regarding their role in the acquisition of specific knowledge. This study proposes that relational ties have a nonlinear effect on specific knowledge acquisition and that this nonlinear relationship is conditional on contract specificity and competitive intensity. Results from a sample of 385 manufacturer-supplier exchanges in China demonstrate that a buyer's relational ties with its major supplier have an inverted U-shaped effect on specific knowledge acquisition from this supplier; this inverted U-shaped relationship is stronger (steeper) when contract specificity is high and competition is more intense. These findings suggest that managers should understand the benefits and downsides of relational ties in acquiring specific knowledge and avoid building highly embedded ties when they draft detailed contracts or competition is highly intensive. (C) 2014 Elsevier B.V. All rights reserved."
331,"Theorizing, testing, and concluding for mediation in SCM research: Tutorial and procedural recommendations","Rungtusanatham, M. and Miller, J. W. and Boyer, K. K.","JOURNAL OF OPERATIONS MANAGEMENT","32","3","99-113","2014","MAR","Mediation;Indirect Effect;Scm Empirical Research","","Empirical research in Supply Chain Management is increasingly interested in complex models involving mediation effects. We support these endeavors by directing attention to the practices for the theorizing of, the testing for, and the drawing of conclusions about mediation effects. Our paper synthesizes diverse literature in other disciplines to provide an accessible tutorial as to the mathematical foundation of mediation effects and the various methods available to test for these effects. We also provide guidance to SCM scholars in the form of eight recommendations aimed at improving the theorizing of, the testing for, and the drawing of conclusions about mediation effects. Recommendations pertaining to how mediation effects are hypothesized and stated and how to select among methods to test for mediation effects are novel contributions for and beyond the Supply Chain Management discipline. (C) 2014 Elsevier B.V. All rights reserved."
332,"The impact of cultural differences on buyer-supplier negotiations: An experimental study","Ribbink, Dina and Grimm, Curtis M.","JOURNAL OF OPERATIONS MANAGEMENT","32","3","114-126","2014","MAR","Buyer-Supplier Relationship;Negotiation;Cultural Differences;Behavioral Experiment;Bargaining Strategy","","In today's global economy, an ever-increasing number of companies are dealing with international partners, instigating a need to understand the impact of cultural differences on business interactions. Using Hall's distinction of high- and low-context culture, this study investigates the direct and moderating effects of cultural differences in dyadic buyer-supplier negotiations. Theory is developed regarding the impact of culture on joint profits, juxtaposing Transaction Cost Economics and the Relational View. The theory is tested with a negotiation experiment. Participants, classified by their country of origin, negotiate prices and quality levels for three products. This study finds that cultural differences within the negotiation dyad reduce joint profits when compared to dyads of participants with similar cultural backgrounds. Cultural differences also moderate the impact of trust and bargaining strategy on joint profits. Overall, this study concludes that cultural differences, as encountered in day-to-day business interactions in global supply chains, significantly impact negotiation outcomes. (C) 2014 Elsevier B.V. All rights reserved."
333,"The effect of experience, ownership and focus on productive efficiency: A longitudinal study of US hospitals","Ding, David Xin","JOURNAL OF OPERATIONS MANAGEMENT","32","1-2","1-14","2014","JAN","Organizational Learning;Hospital Ownership;Focus;Productive Efficiency;Experience","","Focusing on organizational learning research in healthcare settings, this paper studies how experience, ownership and focus affect productive efficiency in U.S. hospitals. Building on organizational learning theory, health economics and the focused factory concept, we propose that hospitals learn to improve productive efficiency and the relationship between productive efficiency and cumulative experience is curvilinear. We also hypothesize that clinical focus has a positive effect on productive efficiency and that nonprofit hospitals and proprietary hospitals trade off costs and quality differently. The proposed hypotheses are tested with yearly performance data for over 3700 major U.S. hospitals spanning from 1996 to 2010. We find strong support for the proposed hypotheses. (C) 2013 Elsevier B.V. All rights reserved."
334,"Triggers and patterns of integration initiatives in successful buyer-supplier relationships","Vanpoucke, Evelyne and Vereecke, Ann and Boyer, Kenneth K.","JOURNAL OF OPERATIONS MANAGEMENT","32","1-2","15-33","2014","JAN","Inter-Organizational Relationships;Integration Practices;Buy-Sell Relationships;Relationship Life-Cycle Theory","","While previous studies have focused on the benefits, risks and outcomes of buy-sell relationships, little is known about the dynamics of these relationships. Our study takes an initial step in this direction by examining how firms develop successful relationships. We review the literature and analyze multiple buyer-supplier relationships to explore developments overtime, identify triggers for change, and identify effective management practices for long-term inter-organizational relationships. We employ retrospective data to compare six long-standing buyer-supplier relationships. Our data suggest a recurring pattern of integration initiatives in the evolution towards a successful buy-sell relationship. Specifically, our field data indicate that this pattern starts with initiatives for logistics responsiveness, followed by knowledge exchange initiatives and finally initiatives to increase the use of common resources. Each of these initiatives are triggered by specific opportunities and are emergent in nature. By examining the triggers in the development and maintenance of buy-sell relationships, our study adds to the integration of existing life-cycle frameworks, which increases our understanding of a life-cycle theory for inter-organizational relationships. (C) 2013 Elsevier B.V. All rights reserved."
335,"The antecedents and consequences of product variety in new ventures: An empirical study","Patel, Pankaj C. and Jayaram, Jayanth","JOURNAL OF OPERATIONS MANAGEMENT","32","1-2","34-50","2014","JAN","Product Variety;Product Modularity;Process Modularity;Manufacturing Flexibility;Performance;New Ventures;Entrepreneurship","","Despite the known benefits of greater product variety for large firms, less is known about how new ventures pursue product variety. Liabilities of newness and smallness could possibly impede the ability of new ventures to develop the product design capabilities needed to increase product variety. Drawing on the design principles of product modularity, we posit that new ventures with modular product designs tend to have higher product variety. The benefits of product variety, however, are not monotonic, and at higher levels of product variety, increasing internal operational costs lead to an inverted-U type relationship between product variety and operational performance. We posit that process modularity, a systems-level capability, and manufacturing flexibility, an operations capability, enhance the benefits from product variety and mitigate the costs that arise from increasing product variety further. Based on a sample of 141 new ventures and using latent moderated structural model (LMS), we find support for the proposed model. The findings are robust against alternate model specifications. Academic and managerial implications from the findings are discussed. (C) 2013 Elsevier B.V. All rights reserved."
336,"Do a country's logistical capabilities moderate the external integration performance relationship?","Wiengarten, Frank and Pagell, Mark and Ahmed, Muhammad Usman and Gimenez, Cristina","JOURNAL OF OPERATIONS MANAGEMENT","32","1-2","51-63","2014","JAN","Supply Chain Management;Supply Chain Integration;Logistics;Performance","","Companies have reacted to the opportunities and threats of globalization through numerous production practices that have increased supply chain complexity. One of the ways companies have been able to manage this increased level of complexity is by integrating their supply chains. Logistical capabilities at the company level play a key role in integrating global supply chains, but logistical capabilities need not be company specific. In this study we explore the role of a country's logistical capabilities in external supply chain integration. Our results indicate that plants situated in countries with superior levels of logistical capabilities adopt significantly lower levels of external supply chain integration: Additionally, plants situated in countries with superior logistical capabilities do not gain the same performance benefits from external integration as plants situated in countries with relatively low levels of logistical capabilities. (C) 2013 Elsevier B.V. All rights reserved."
337,"Examining the impact of clinical quality and clinical flexibility on cardiology unit performance-Does experiential quality act as a specialized complementary asset?","Nair, Anand and Nicolae, Mariana and Narasimhan, Ram","JOURNAL OF OPERATIONS MANAGEMENT","31","7-8","505-522","2013","NOV","Healthcare;Quality;Flexibility;Length Of Stay;Cost;Multi-Level Analyses","","In this study we examine the association of clinical quality and clinical flexibility capabilities on cardiology unit length of stay and cost performance. These relate to the operational performance of cardiology units and capture the timeliness and cost efficiency of cardiac care. We also investigate the complementary role played by the experiential quality in enhancing the impact of clinical quality and clinical flexibility on operational performance measure. Experiential quality relates to patient-centered delivery of care by a hospital. We collect and combine data for 876 U.S. hospitals from four distinct sources and undertake multi-level analyses that consider a hierarchical structure in which the hospital is nested within county and state. To disentangle the effects at the levels of states, counties, and hospitals, we use the mixed-effects modeling approach. The results obtained from econometric analyses indicate that clinical quality and clinical flexibility reduce cardiology unit average length of stay. Clinical flexibility also helps in reducing the average cost of cardiology units. Experiential quality moderates the impact of clinical quality on length of stay and plays a complementary role in the relationship between clinical flexibility and cost. The paper discusses the implications of the findings and presents directions for future research. (C) 2013 Elsevier B.V. All rights reserved."
338,"Communication intensity, goal congruence, and uncertainty in buyer-supplier new product development","Yan, Tingting and Dooley, Kevin J.","JOURNAL OF OPERATIONS MANAGEMENT","31","7-8","523-542","2013","NOV","Communication;Goal Congruence;Uncertainty;New Product Development;Supplier Involvement;Contingency Theory","","Manufacturers involve suppliers in new product development in order to access knowledge and resources, but these benefits only occur with effective project-level integration. Adopting a contingency theory view, we develop hypotheses concerning how two integrative devices, intensive communication and congruent goals, influence project performance under various conditions of uncertainty. We test our theoretical model with a sample of 214 buyer-supplier joint new product development projects. Results suggest that communication intensity is positively associated with project performance when either task or relational uncertainty is high, but is also negatively associated with performance when task uncertainty is low. Goal congruence is positively associated with project performance, especially when either task uncertainty is low or relational uncertainty is high. We discuss the implications of these findings for theory and practice. (C) 2013 Elsevier B.V. All rights reserved."
339,"Leveraging supply chain visibility for responsiveness: The moderating role of internal integration","Williams, Brent D. and Roh, Joseph and Tokar, Travis and Swink, Morgan","JOURNAL OF OPERATIONS MANAGEMENT","31","7-8","543-554","2013","NOV","Supply Chain Visibility;Internal Integration;Responsiveness;Flexibility","","As global supply chains compete in an increasingly complex and rapidly changing business environment, supply chain responsiveness has become a highly prized capability. To increase responsiveness, supply chain managers often seek information that provides greater visibility into factors affecting both demand and supply. Managers often claim, however, that they are awash in data yet lacking in valuable information. Taken together, these conditions suggest that supply chain visibility is a necessary, but insufficient capability for enabling supply chain responsiveness. Based on organizational information processing theory, we posit that a supply chain organization's internal integration competence provides complementary information processing capabilities required to yield expected responsiveness from greater supply chain visibility. An analysis of data from 206 firms strongly supports this hypothesis. For supply chain managers, these findings indicate that a strategy for achieving supply chain responsiveness requires a dual-pronged approach that aligns increased visibility with extensive information processing capabilities from internal integration. For researchers, this study provides an initial examination of visibility as a construct, and extends a growing literature addressing integration as an information processing capability. (C) 2013 Elsevier B.V. All rights reserved."
340,"Modeling the operational capabilities for customized and commoditized services","Coltman, Tim and Devinney, Timothy M.","JOURNAL OF OPERATIONS MANAGEMENT","31","7-8","555-566","2013","NOV","Service Operations;Strategic Alignment;Discrete Choice Analysis;Capabilities","","According to the extant service operations management literature, substantial gains can be achieved for providers that are adept at aligning internal operational capabilities with customer needs. However, the most influential models in the field attempt to explain this alignment without regard to the core resource allocation choices relating operational capabilities to different service offerings. To further our understanding of service operations alignment, we apply a unique combination of experimental scenarios and discrete choice modeling to measure the role of managers in orchestrating operational capabilities. Using the third-party logistics tender review and bid preparation process as an empirical setting, we reveal the resource allocation choices that managers make between six distinctive operational capabilities (customer engagement, cross-functional coordination, creative solutions, operations improvement, IT infrastructure and professional delivery) and show the subtle ways in which these capabilities interact as the service context moves from one based on commoditization to one based on customization. (C) 2013 Elsevier B.V. All rights reserved."
341,"The relative impact of attribute, severity, and timing of psychological contract breach on behavioral and attitudinal outcomes","Eckerd, Stephanie and Hill, James and Boyer, Kenneth K. and Donohue, Karen and Ward, Peter T.","JOURNAL OF OPERATIONS MANAGEMENT","31","7-8","567-578","2013","NOV","Buyer-Supplier Relationships;Behavioral Supply Chain Management;Psychological Contracts;Fairness;Psychological Experiment","","A psychological contract defines the perceived reciprocal obligations that characterize a relationship between an individual and organizational entity. Breach of a psychological contract can negatively affect work behaviors and attitudinal perceptions, and may also elicit an emotional response (violation) which can help to explain these negative consequences. This research focuses on the role of psychological contracts in a supply chain setting. We explore when and how three conditions of psychological contract breach - attribute, severity, and timing - negatively impact outcomes, and assess the mediating role of psychological contract violation in this relationship. To evaluate our hypotheses, we employ a laboratory experiment in which participants assume the role of a purchasing manager. We impose various breach factors and observe their relative impact on the decision-making behavior and fairness perceptions of the participant. We show that while the breach factors significantly impact task behavior, these relationships are not explained by psychological contract violation. However, violation is useful in explaining, in part, the results pertaining to fairness perceptions. (C) 2013 Elsevier B.V. All rights reserved."
342,"Theorizing through metaphorical transfer in OM/SCM research: Divorce as a metaphor for strategic buyer-supplier relationship dissolution","Chen, Yi-Su and Rungtusanatham, M. Johnny and Goldstein, Susan Meyer and Koerner, Ascan F.","JOURNAL OF OPERATIONS MANAGEMENT","31","7-8","579-586","2013","NOV","Metaphor;Metaphorical Transfer;Theorizing;Strategic Buyer-Supplier Relationship;Dissolution;Divorce","","Operations Management and Supply Chain Management (OM/SCM), as a discipline, can benefit from proper theorizing to address persistent urgings for better and new theories. This paper hopes to inspire more theorizing engagements through the formal process of metaphorical transfer. Metaphorical transfer transforms casually-invoked metaphors in everyday language into theory-constitutive metaphors. This transformation process first mandates theorizing to ensure equivalence between the domain of the metaphor and that of a target phenomenon or research problem of interest. Second, theorizing during metaphorical transfer occurs when abstracted insights intended to govern both the metaphor and target phenomenon materialize. Finally, metaphorical transfer supports borrowing of theories from outside of OM/SCM for testing within OM/SCM by safeguarding against common mistakes. This paper demonstrates metaphorical transfer via the example of divorce and strategic buyer-supplier relationship dissolution and concludes by highlighting other metaphors that may be invoked for a number of exemplary supply chain relationship phenomena. Published by Elsevier B.V."
343,"Learning curves in collaborative planning, forecasting, and replenishment (CPFR) information systems: An empirical analysis from a mobile phone manufacturer","Yao, Yuliang and Kohli, Rajiv and Sherer, Susan A. and Cederlund, Jerold","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","285-297","2013","SEP","Cpfr;Organizational Learning;Empirical Analysis;Information Systems Value","","While Collaborative Planning, Forecasting, and Replenishment (CPFR) information systems have been increasingly deployed to improve supply chain operations in a cross section of industries, the extant literature has largely overlooked the learning effects within organizations, thereby resulting in incomplete assessment of their business value. Wing an operational-level panel data for nine product lines over 2.5 years, we empirically examine the learning curves in CPFR between Motorola, a mobile phone manufacturer, and one of its U.S.-based national retail partners. We found that the two key components of CPFR, collaborative forecasting (CF) and collaborative replenishment (CR), exhibit distinct learning curves. Forecast accuracy improves immediately following CPFR implementation but the rate of improvement slows over time, whereas inventory levels increase at first and begin decreasing after a period. Further, we found different learning effects in terms of inventory levels when products are later replaced with new form factors. Product replacements have lower inventory levels than their antecedents, at least for low-end products. We discuss important implications for theory and practice at the interface of information systems and operations management. (C) 2013 Elsevier B.V. All rights reserved."
344,"The relationship between information technology capability, inventory efficiency, and shareholder wealth: A firm-level empirical analysis","Mishra, Saurabh and Modi, Sachin B. and Animesh, Animesh","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","298-312","2013","SEP","Inventory Efficiency;It Capability;Stock Market Returns;Stock Market Risk;Operations/It Interface","","Inventories represent an important strategic resource for firms, with implications for shareholder wealth. As such, firms expend considerable effort in managing their inventories efficiently. Among other factors, information technology (IT) capability can play an important role in enabling inventory efficiency and financial performance. However, insight into the chain-of-effects linking IT capability, inventory efficiency, and stock market returns and risk remains limited. In this paper, we provide a conceptual model outlining the relationships between these constructs. Next, we evaluate the model using secondary information on firms from multiple industries across the 10-year time period of 2000-2009. Our analysis confirms that firms' IT capability plays a significant role in enhancing their inventory efficiency, which, in turn, is observed to increase stock market returns. Our results also reveal that firms' IT capability directly reduces their stock market risk and enhances their stock market returns. Taken together, these findings, along with the conceptual model that we advance, have important research and managerial implications. (C) 2013 Elsevier B.V. All rights reserved."
345,"Information systems for collaborating versus transacting: Impact on manufacturing plant performance in the presence of demand volatility","Saldanha, Terence J. V. and Melville, Nigel P. and Ramirez, Ronald and Richardson, Vernon J.","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","313-329","2013","SEP","Demand Volatility;E-Collaboration;It Business Value;Inventory Performance;Labor Productivity;Manufacturing Performance","","Research at the nexus of operations management and information systems suggests that manufacturing plants may benefit from the utilization of information systems for collaborating and transacting with suppliers and customers. The objective of this study is to examine the extent to which value generated by information systems for collaborating versus transacting is contingent upon demand volatility. We analyze a unique dataset assembled from non-public U.S. Census Bureau data of manufacturing plants. Our findings suggest that when faced with volatile demand, plants employing information systems for collaborating with suppliers and customers experience positive and significant benefits to performance, in terms of both labor productivity and inventory turnover. In contrast, results suggest that plants employing information systems for transacting in volatile environments do not experience such benefits. Further exploratory analysis suggests that in the context of demand volatility, these two distinct dimensions of IT-based integration have differing performance implications at different stages of the production process in terms of raw-materials inventory and finished-goods inventory, but not in terms of work-in-process inventory. Taken together, our study contributes to theoretical and managerial understanding of the contingent value of information systems in volatile demand conditions in the supply chain context. (C) 2013 Elsevier B.V. All rights reserved."
346,"Drivers and outcomes of open-standard interorganizational information systems assimilation in high-technology supply chains","Sodero, Annibal C. and Rabinovich, Elliot and Sinha, Rajiv K.","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","330-344","2013","SEP","Supply Chain Management Practices;Open Standards;Interorganizational Information Systems","","In recent years, firms in high-technology supply chains have established internet-based electronic linkages with their trading partners. As a result, they have improved their ability to coordinate and synchronize shared business processes by using more complete, accurate, and timely information. These electronic linkages are based on open-standard interorganizational information systems (OSIOS), which are fundamentally different from traditional electronic data interchanges. OSIOS capture not only the technical specifications for data interchange but also the sequential steps for the execution of shared business processes. Because OSIOS are still at an early diffusion stage, it remains unclear why firms would assimilate such an innovation and whether assimilation provides firms any benefits. In this research, we develop a framework grounded on the economics of standards, institutional theory, and strategic interorganizational information systems literatures to investigate the drivers and outcomes of OSIOS assimilation in a focused context. In order to test our hypotheses based on this framework, we used data from a high-technology supply chain and employed econometrics techniques. We found that both competition asymmetry across supply chain echelons and OSIOS assimilation within supply chain echelons predict individual firms' OSIOS assimilation. The results also suggest that firms' supply chain dominance is both a driver and an outcome of OSIOS assimilation, highlighting a mutually reinforcing process. In addition, our study reveals boundary conditions of the hypothesized relationships. The use of multiple theoretical perspectives, a unique dataset, and innovative statistical techniques to investigate OSIOS assimilation in high-technology supply chains contributes to the body of knowledge in both the supply chain management and management of information systems disciplines. Published by Elsevier B.V."
347,"Information systems and technology sourcing strategies of e-Retailers for value chain enablement","Tsai, Juliana Y. and Raghu, T. S. and Shao, Benjamin B. M.","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","345-362","2013","SEP","Contingency Theory;Complementary Sourcing;E-Retail Value Chain;Information Systems And Technology;Sourcing Strategy;Make Versus Buy","","In the e-Retail industry, a well-designed IT infrastructure is essential in creating a tightly integrated value chain and delivering high quality service. With intense competition for market share and profits, information systems and technology (IST) sourcing decisions are becoming increasingly important to eRetail firms to support continued growth and market responsiveness. Drawing on the contingency theory, we examine organizational and environmental factors that influence an e-Retailer's IST sourcing strategy of make versus buy in enabling its value chain activities, and we also look at firm-level performance impacts of 1ST sourcing decisions that involve bundling across value chain activities. We test the proposed model and hypotheses using a panel data set of 307 firms over the period of 2006-2010. The results show that firms that make transformative IT investments tend to source a smaller portion of IST for their eRetail value chain activities than firms that pursue automate or informate as their strategic role for IT investment. Capabilities are positively associated with IST sourcing. Firms experienced in e-Retail are more likely to build rather than buy their 1ST. In addition, we find mimicking behavior for IST sourcing among firms in the same merchandizer category. We find that IT strategic role is strongly associated with growth metric, whereas sourcing decisions predominantly impact operational performance measures. There is partial evidence that alignment between IT strategic role and IST sourcing decisions results in better performance effects. Moreover, complementary IST sourcing of synergistic marketing and sales activities positively impacts Web sales and conversion rate, but the sourcing combination of logistics, operations, and sales activities is associated with lower Web sales and conversion rate. 2013 Elsevier B.V. All rights reserved."
348,"The impact of supply-side electronic integration on customer service performance","Xue, Ling and Ray, Gautam and Sambamurthy, Vallabh","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","363-375","2013","SEP","Electronic Integration;Customer Service;Supply Chain Management;Vertical Integration;Diversification;Decentralization","","Although information technologies have been expected to directly enhance firm performance in specific value chain activities (e.g., supplier performance or customer service performance), their advanced capabilities offer the promise of organizational integration and spill-over benefits. Enterprise systems provide firms with platforms for electronically integrating their supplier and demand chain activities. Spill-over benefits refer to the impacts that occur when IT investments in one organizational domain benefit performance in a different value chain side of the firm. Supply-side electronic integration (SEI) refers to the use of electronic means to integrate the exchange of information and transactions with suppliers through enterprise systems. In our research, we examine whether SEI generates spill-over effects on customer service performance, over and beyond firms' direct investments in customer-side digitization. We also examine whether structural attributes of the firm (e.g., vertical integration, diversification, and centralization) moderate the effects of supply-side electronic integration on customer service performance. Our analysis of a secondary dataset of InformationWeek 500 firms shows that SEI helps firms realize cost-savings in their customer service performance, especially if they are less vertically integrated. In addition, SEI investments help diversified and centralized firms achieve cross-selling with their customers. We also find that SEI is more likely to help decentralized and diversified firms achieve customization in their customer service activities. These results suggest that SEI helps firms achieve twin goals in customer service: cost reduction and revenue expansion. Overall, our research reveals how supply-side electronic integration could generate benefits in customer service performance in firms. (C) 2013 Elsevier B.V. All rights reserved."
349,"Capability hierarchy in electronic procurement and procurement process performance: An empirical analysis","Mishra, Abhay Nath and Devaraj, Sarv and Vaidyanathan, Gahesh","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","376-390","2013","SEP","Capability Hierarchy;Digital Procurement Competence;Electronic Procurement;Procurement Capabilities;Procurement Integration Competence;Second-Order Construct","","This paper examines the interrelationship between two hierarchically structured functional capabilities pertinent in the organizational procurement process, and the impact of these capabilities on procurement process performance. These functional capabilities operate at different levels in an organization's procurement process. We draw upon resource-and knowledge-based views of the firm to theorize that in this hierarchy of information technology-enabled procurement capabilities, the higher-level capability procurement integration competence-enables firms to develop and deploy a lower-level capability-digital procurement competence. Further, we theorize that the lower-level capability impacts procurement process performance directly and completely mediates the relationship between higher-level capability and performance. Thus, although performance is impacted directly only by the lower-level capability, the higher-level capability facilitates the development and use of the lower-level capability. Our research model is tested using survey data from a large sample of 412 manufacturing firms. The results provide' strong support for the proposed research model. In particular, we find that as hypothesized, the impact of procurement integration competence on performance is completely mediated by digital procurement competence. Our results suggest that when examined at the procurement process level, the impact of higher-level capabilities may be manifested completely through the lower-level capabilities. Theoretical and practical implications of the research are discussed. (C) 2013 Elsevier B.V. All rights reserved."
350,"Enhancing hospital supply chain performance: A relational view and empirical test","Chen, Daniel Q. and Preston, David S. and Xia, Weidong","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","391-408","2013","SEP","Supply Chain Integration;Health Care Supply Chain;It Integration;Knowledge Exchange;Trust;Relational View","","Improving hospital supply chain performance has become increasingly important as healthcare organizations strive to improve operational efficiency and to reduce cost. In this study, we propose a research model based on a relational view, delineating the factors that influence hospital supply chain performance: trust, knowledge exchange, IT integration between the hospital and its suppliers, and hospital-supplier integration. Testing results of the research model based on data from a sample of 117 supply chain executives from U.S. hospitals show positive direct effects: (1) from trust and from IT integration to knowledge exchange respectively; (2) from knowledge exchange and from IT integration to hospital-supplier integration respectively; and (3) from hospital-supplier integration to hospital supply chain performance. The results also show the following indirect effects: (1) the influences of knowledge exchange and IT integration on hospital supply chain performance are partially and fully mediated by hospital-supplier integration, respectively and (2) the influences of trust and IT integration on hospital-supplier integration are fully and partially mediated by knowledge exchange, respectively. In addition, the results show the following moderating effects: (1) hospital system membership moderates the relationships between IT integration and knowledge exchange and between trust and knowledge exchange; (2) hospital environmental uncertainty moderates the relationship between trust and knowledge exchange; and (3) trust moderates the relationship between knowledge exchange and hospital-supplier integration. Implications of the study findings and directions for future research are discussed. (C) 2013 Published by Elsevier B.V."
351,"How information systems help create OM capabilities: Consequents and antecedents of operational absorptive capacity","Setia, Pankaj and Patel, Pankaj C.","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","409-431","2013","SEP","Operational Absorptive Capacity;Information Systems Capabilities;Strategic It Alignment;Tobin'S Q;Environmental Complexity","","In contemporary business environments, the ability to manage operational knowledge is an important predictor of organizational competitiveness. Organizations invest large sums in various types of information technologies (ITs) to manage operational knowledge. Because of their superior storage, processing and communication capabilities, ITs offer technical platforms to build knowledge management (KM) capabilities. However, merely acquiring ITs are not sufficient, and organizations must structure information system (IS) designs to leverage ITs for building KM capabilities. We study how technical and strategic IS designs enhance operational absorptive capacity (OAC) - the KM capability of an operations management (OM) department. Specifically, we use a capabilities perspective of absorptive capacity to examine potential absorptive capacity (POAC) and realized absorptive capacity (ROAC) capabilities - the two OAC capabilities that create and utilize knowledge, respectively. Our theory proposes that integrated IS capability, - an aspect of technical IS design - is an antecedent of POAC and ROAC capabilities, and business-IT alignment - an aspect of strategic IS design - moderates the relationship between integrated IS capability and ROAC capability. Combining data gleaned from a multi-respondent survey with archival data from COMPUSTAT, we test our hypotheses using a dataset from 153 manufacturing organizations. By proposing that IS design enables an OM department's KM processes, i.e., the POAC and ROAC capabilities, our interdisciplinary theoretical framework opens the black box of OAC and contributes to improved understanding of IS and OM synergies. We offer a detailed discussion of our contributions to the literature at the IS-OM interface and implications for practitioners. (C) 2013 Elsevier B.V. All rights reserved."
352,"The iron cage exposed: Institutional pressures and heterogeneity across the healthcare supply chain","Bhakoo, Vikram and Choi, Thomas","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","432-449","2013","SEP","Inter-Organizational Systems;Case Studies;Institutional Theory;Supply Chain;Healthcare","","The healthcare industry has been known to operate in a strong institutional environment (i.e. government regulations), and the implementation of inter-organizational systems (IOS) has followed an institutional process. Extending this perspective across different tiers in the healthcare supply chain, we investigate how organizations in different tiers in the supply chain (i.e. hospitals, distributors and manufacturers) respond to institutional pressures when implementing IOS. How institutional dynamics unfold across multiple tiers of a supply chain is an uncharted area of research, and we take the theory-building case study approach using data collected from ten organizations. Because organizations are embedded in their respective tiers, our within-tier analyses are equivalent to cross-organization analyses. In this regard, the cross-case analyses occur at two different levels: at each tier level (i.e. across multiple hospitals, multiple distributors and multiple manufacturers) and across the supply chain (i.e. across all three tiers). The study shows how different institutional pressures such as coercive, mimetic, and normative manifest across the tiers. It also demonstrates how a differential mix of endogenous and institutional pressures lead to mixed organizational responses across the tiers. The propositions developed from the study enrich institutional theory arguments within the information systems and supply chain management disciplines. They highlight how the IOS implementation dynamics within and across different tiers in a supply chain result in heterogeneous rather than isomorphic consequences, thereby exposing the iron cage of institutionalization. Published by Elsevier B.V."
353,"The effects of IT-enabled supply chain process change on job and process outcomes: A longitudinal investigation","Bala, Hillol","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","450-473","2013","SEP","Job Outcomes;Process Characteristics;Process Performance;Supply Chain Process;Supply Chain Management Systems;Relationship Quality","","Prior research on information technology (IT)-enabled supply chain management (SCM) has primarily focused on macro-level issues (e.g., IT capabilities related to SCM, and SCM design and optimization) and outcomes (e.g., firm performance). There has been limited research that. focuses on micro-level outcomes related to employees who actually execute SCM processes in organizations. These employee-level outcomes are important because successful implementation of SCM systems and processes hinges on SCM employees' support and commitment. I develop and test a model positing that SCM employees' perceptions of changes in their work process characteristics, i.e., process complexity and process rigidity, following a new SCM system implementation will influence their job outcomes, i.e., job performance, job satisfaction, job anxiety, and job security, and their perceptions of process outcomes, i.e., process performance and relationship quality. The model incorporates a holistic appraisal of the extent of change change radicalness as a mechanism between work process characteristics and outcomes. The model is supported in three studies conducted in the context of three different SCM system implementations (N=278, 282, and 304, respectively). In particular, I found that individuals perceived a significant change in their work process characteristics following an SCM system implementation, and changes in work process characteristics had a significant impact on job and process outcomes. These findings contribute to the information systems and operations management literatures and their intersections by offering insights on challenges related to IT-enabled SCM innovation implementation in organizations. (C) 2013 Elsevier B.V. All rights reserved."
354,"The impact of sourcing enterprise system use and work process interdependence on sourcing professionals' job outcomes","Rai, Arun and Hornyak, Rob","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","474-488","2013","SEP","Sourcing Enterprise System Use;Supplier Selection;Supplier Governance;Job Outcomes;Work Process Interdependence;It Capabilities","","We examine sourcing professionals' work context to conceptualize how they use sourcing enterprise systems (SESs) and to understand when SES use results in positive/negative job outcomes. We differentiate between SES use for supplier selection and supplier governance, identify sourcing professionals' work process interdependence as a moderator for the impacts of SES use on job satisfaction, and suggest job satisfaction mediates the impacts of SES use on job performance. We conducted a field study of sourcing professionals' SES use at one of the largest consumer product companies in the United States, which has implemented an SES to innovate its sourcing professionals' work processes. Based on our analysis of the survey and qualitative data we collected, we found the impacts of both types of SES use (1) to be negative on job satisfaction when work process interdependence was high, (2) to be positive on job satisfaction when work process interdependence was low, and (3) to be mediated by job satisfaction for job performance. We discuss the implications of our findings for the literature at the intersection of information systems and operations management as well as for the information technology enabled innovation of sourcing processes and, more generally, complex business processes. (C) 2013 Elsevier B.V. All rights reserved."
355,"User acceptance of complex electronic market mechanisms: Role of information feedback","Adomavicius, Gediminas and Curley, Shawn P. and Gupta, Alok and Sanyal, Pallab","JOURNAL OF OPERATIONS MANAGEMENT","31","6, SI","489-503","2013","SEP","Technology Acceptance;User Perceptions;Mechanism Design;Combinatorial Auctions;Information Feedback","","This paper broadens the scope of evaluating the design of economic mechanisms that is traditionally done solely from an economic perspective. We introduce and demonstrate the application of acceptability to evaluate complex economic mechanisms. In particular, we apply our approach to the evaluation of continuous combinatorial auctions, which represent a complex, sophisticated market mechanism that has not been generally available in the online marketplace but has the potential to enhance the economic efficiency of trade for assets with interdependent values. Such auctions are being increasingly used in industry, e.g., to procure logistical services. Intuitively, acceptance and usage of a complex mechanism can be fostered by a design that provides information and tools that meet the users' task demands. Based on prior research and an analysis of the auction tasks, we discuss practical and innovative information feedback schemes for reducing the cognitive burden of formulating bids in combinatorial auctions. Then, we use constructs from the technology acceptance model (TAM) - which have been consistently shown to be key determinants of technology acceptance in the extant literature - to compare the acceptability of the mechanism under three different information regimes. In addition, we borrow constructs from marketing theory to assess the potential growth in adoption of the mechanism. We compare user perceptions of the three alternative designs in a laboratory experiment with over 130 subjects. Our study constitutes a complementary and novel approach in evaluating the design of complex economic mechanisms. Results indicate a higher adoption and usage potential of the mechanism with advanced information feedback, supporting the potential of combinatorial auctions as a user-acceptable market mechanism with appropriate feedback. (C) 2013 Elsevier B.V. All rights reserved."
356,"The impact of contextual factors on the efficacy of ISO 9000 adoption","Lo, Chris K. Y. and Wiengarten, Frank and Humphreys, Paul and Yeung, Andy C. L. and Cheng, T. C. E.","JOURNAL OF OPERATIONS MANAGEMENT","31","5","229-235","2013","JUL","Iso 9000;Financial Performance;Contextual Factors;Hierarchical Linear Modeling","","This study investigates the importance of contextual factors on the efficacy of ISO 9000 adoption. We explore the role of various contextual factors at the firm-level (i.e., technology intensity, labor productivity, and labor intensity) and industry-level (i.e., industry efficiency level, industry competitiveness, industry sales growth, and industry ISO 9000 adoption level) that potentially impact the efficacy of ISO 9000 adoption. We carry out a hierarchical linear modeling (HLM) analysis based on objective financial data from 438 U.S. manufacturing firms. The results show that firms with low technology intensity, low labor productivity and high labor intensity reap more benefit from ISO 9000 adoption. Firms in industries with low efficiency levels, high competition, high sales growth and low ISO 9000 adoption levels also obtain more benefit from the adoption, Our research provides supporting evidence for the context-dependent proposition of ISO 9000 adoption. Given the significant costs and resources involved, it is crucial for operations managers to assess to what extent ISO 9000 might benefit their performance before embarking on the implementation process. (C) 2013 Elsevier B.V. All rights reserved."
357,"An Investigation of Justice in supply chain relationships and their performance impact","Narasimhan, Ram and Narayanan, Sriram and Srinivasan, Ravi","JOURNAL OF OPERATIONS MANAGEMENT","31","5","236-247","2013","JUL","Buyer-Supplier Relationships;Inter-Organizational Justice;Survey Research","","Justice is important in improving performance of supply chain relationships. However, the role of justice in improving performance in supply chain relationships is an under-investigated subject in the literature. In studying the joint impact of justice dimensions, the traditional assumption is that the three forms of justice interact with each other in a multiplicative manner. However, this assumption creates a managerial problem as discussed in this paper. We outline a different view of how the justice dimensions interact with one another utilizing the constraining factor model (CFM). We show that the CFM resolves some of the problems arising from the choice of multiplicative interaction of justice measures on performance. Specifically, we demonstrate that an increase in procedural, distributive or interactional justice results in a significant and positive improvement in performance only if the specific justice dimension is the constraining factor in the relationship. Overall, our analysis suggests that all three dimensions are important and a high level of one of the justice elements will not compensate for a low level of another, a view that is put forward by a number of past research studies injustice. We discuss the theoretical and managerial implications of our findings. (C) 2013 Published by Elsevier B.V."
358,"The impact of inventory dynamics on long-term stock returns - An empirical investigation of US manufacturing companies","Steinker, Sebastian and Hoberg, Kai","JOURNAL OF OPERATIONS MANAGEMENT","31","5","250-261","2013","JUL","Inventory Management;Inventory Dynamics;Financial Analysis;Long-Term Stock Returns;Empirical Research","","This paper investigates the relationship between the inventory dynamics and long-term stock returns of a large panel of U.S. manufacturing firms over the time period from 1991 to 2010. We propose two measures of inventory dynamics: one metric to assess the fluctuations of quarterly inventories within the year and a second metric to quantify relative year-over-year inventory growth. Our results indicate that within-year inventory volatility (IV) and abnormal year-over-year inventory growth (ABI) are associated with abnormal stock returns. Both metrics cannot be entirely explained by common risk factors. We find that firms with high IV and low ABI have the best long-term stock returns, and that stock performance decreases monotonically with higher ABI values. Our results are robust to various control variables including size, book-to-market value, industry and prior performance. We therefore conclude that changes in inventory levels provide valuable insights into the risks and opportunities faced by a company. (C) 2013 Elsevier B.V. All rights reserved."
359,"On the appropriate objective function for post-disaster humanitarian logistics models","Holguin-Veras, Jose and Perez, Noel and Jaller, Miguel and Van Wassenhove, Luk N. and Aros-Vera, Felipe","JOURNAL OF OPERATIONS MANAGEMENT","31","5","262-280","2013","JUL","Humanitarian Logistics;Deprivation Cost;Human Suffering;Optimization","","The paper argues that welfare economic principles must be incorporated in post-disaster humanitarian logistic models to ensure delivery strategies that lead to the greatest good for the greatest number of people. The paper's analyses suggest the use of social costs the summation of logistic and deprivation costs as the preferred objective function for post-disaster humanitarian logistic models. The paper defines deprivation cost as the economic valuation of the human suffering associated with a lack of access to a good or service. The use of deprivation costs is evaluated with a review of the philosophy and the economic literature to identify proper foundations for their estimation; a comparison of different proxy approaches to consider human suffering (e.g., minimization of penalties or weight factors, penalties for late deliveries, equity constraints, unmet demands) and their implications; and an analysis of the impacts of errors in estimation. In its final sections, the paper conducts numerical experiments to illustrate the comparative impacts of using the proxy approaches suggested in the literature, and concludes with a discussion of key findings. (C) 2013 Elsevier B.V. All rights reserved."
360,"Servitization: Disentangling the impact of service business model innovation on manufacturing firm performance","Visnjic Kastalli, Ivanka and Van Looy, Bart","JOURNAL OF OPERATIONS MANAGEMENT","31","4","169-180","2013","MAY","Servitization;Open Service Innovation;Business Model;Performance","","As manufacturing businesses operate in an ever more competitive, global economy where products are easily commoditized, innovating by adding services to the core product offering has become a popular strategy. Contrary to the economic benefits expected, recent findings pinpoint implementation hurdles that lead to a potential performance decline, the so-called 'servitization paradox'. In this paper, we analyze this paradox by disentangling the value creation and value appropriation processes of 44 national subsidiaries of a global manufacturing firm turned product-service provider, in the 2001-2007 period. Our findings show that the firm under study is able to successfully transcend the inherent substitution of products by services and to enact complementary sales dynamics between the two activities. Moreover, labor-intensive services such as maintenance, which imply higher levels of customer proximity, further enhance product sales. Empirical results also reveal a positive yet non-linear relationship between the scale of service activities and profitability: while initial levels of servicing result in a steep increase in profitability, a period of relative decline is observed before the positive relationship between the scale of services and profitability re-emerges. These findings suggest the presence of initial short-term gains but also indicate the existence of a 'profitability' hurdle; profitable growth seems feasible only to the extent that investments in service capability are translated into economies of scale. In helping to clarify the performance implications of service innovation, our findings suggest pathways to sustainable growth through servitization for manufacturing firms. (C) 2013 Elsevier B.V. All rights reserved."
361,"Examining the impact of information technology and patient flow on healthcare performance: A Theory of Swift and Even Flow (TSEF) perspective","Devaraj, Sarv and Ow, Terence T. and Kohli, Rajiv","JOURNAL OF OPERATIONS MANAGEMENT","31","4","181-192","2013","MAY","Theory Of Swift Even Flow (Tsef);Service Operations;Value Of Information Technology;Healthcare;Hospital Quality;Hospital Performance","","The impact of information technologies on manufacturing operations and performance is well established. However, scant research has been devoted to examining information technology (IT) investment among hospitals and how it influences patient care and financial performance. Using the lens of the Theory of Swift Even Flow (TSEF), we present an operations management-based perspective on the effect of IT in streamlining hospital operations. Specifically, we examined the role of IT on patient flow and its consequences for improved hospital efficiency and performance. Analysis of data from 567 U.S. hospitals shows that IT is associated with swift and even patient flow, which in turn is associated with improved revenues. Interestingly, we find that the improvement in financial performance is not at the expense of quality because we find similar effects of IT and patient flow in improvements in the quality of patient care. Further, we observed differential effects of swift flow and even flow on various measures of hospital performance. Although swift flow affects financial performance, even flow primarily affects quality performance. Taken together, they have a mutually reinforcing overall impact on hospital performance. The implications of these findings for hospital decision makers are that patient flow is an important mediating variable that is affected by IT and can significantly affect the quality of patient care and financial performance. (C) 2013 Elsevier B.V. All rights reserved."
362,"The effect of environmental complexity and environmental dynamism on lean practices","Azadegan, Arash and Patel, Pankaj C. and Zangoueinezhad, Abouzar and Linderman, Kevin","JOURNAL OF OPERATIONS MANAGEMENT","31","4","193-212","2013","MAY","Lean Operations;Lean Purchasing;Environmental Uncertainty;Complexity;Dynamism","","Increasingly manufacturers implement lean practices to improve operational performance. In addition, manufacturers operate in ever more complex and volatile environments. This research investigates the effects of environmental complexity and dynamism on lean operations and lean purchasing practices. It empirically examines these relationships using archival and survey data from 126 manufacturers. The results show that environmental complexity positively moderates the effects of lean operations and lean purchasing on performance. However, environmental dynamism reduces the benefits of lean operations on performance, but enhances the benefits of lean purchasing on performance. Robustness tests further confirm the contingent effects of complexity and dynamism on lean operations and lean purchasing. This research offers a more nuanced understanding of the effect of external environmental context on lean practices, and suggests that practitioners should carefully consider the external environment when implementing different types of lean practices. (C) 2013 Elsevier B.V. All rights reserved."
363,"International diversification of manufacturing operations: Performance implications and moderating forces","Lampel, Joseph and Giachetti, Claudio","JOURNAL OF OPERATIONS MANAGEMENT","31","4","213-227","2013","MAY","International Manufacturing;Diversification;Performance;Automotive Industry","","The strategic importance of diversifying international manufacturing for firms with global operations has been extensively documented in a series of studies. There is a lack of studies, however, of the performance implications of strategically spreading manufacturing operations across the globe. In fact, most research on international manufacturing to date has generalized from findings by researchers that examine international diversification at the level of the whole value chain, rather than specifically looking at the performance impact of dispersing production operations. Building on the concept of international manufacturing diversification, we show that its relationship with financial performance is inverted U-shaped, and that this relationship is positively moderated by product diversification and co-location of manufacturing and sales activities in the same geographic market. We place the development of international manufacturing diversification processes in the context of the resource based view and transaction costs economics. Hypotheses are tested using data on 38 firms with home base in 15 countries and car and light truck production activities in 45 countries from 2002 to 2008. (C) 2013 Published by Elsevier B.V."
364,"The influence of task- and location-specific complexity on the control and coordination costs in global outsourcing relationships","Handley, Sean M. and Benton, Jr., W. C.","JOURNAL OF OPERATIONS MANAGEMENT","31","3","109-128","2013","MAR","Outsourcing;Inter-Organizational Control;Inter-Organizational Coordination","","Several reputable industry sources have recognized that many organizations fail to realize the financial benefits sought with outsourcing. Further, prior research has found that outsourcing organizations struggle to estimate accurately the so called hidden costs associated with managing these inter-organizational relationships. This is especially true of complex, globally distributed outsourced services. In this study, we use dyadic data on 102 outsourcing relationships to investigate how dimensions of task- and location-specific complexity influence the degree of control and coordination costs incurred by the customer organization. Results from our hierarchical regression analysis demonstrate that the scale of the service and the geographic distance between the customer and provider locations are associated with higher levels of both control and coordination costs. Task breadth and geographic dispersion are significantly associated with increased control costs, but not coordination costs. Counter to our expectations, control costs decrease with the degree of service customization, whereas both control and coordination costs are negatively related to the average cultural distance between provider and customer organizations. These findings contribute unique empirical evidence to the outsourcing, offshoring, and international service operations literature. (c) 2012 Elsevier B.V. All rights reserved."
365,"Fairness in supply chain contracts: A laboratory study","Katok, Elena and Pavlov, Valery","JOURNAL OF OPERATIONS MANAGEMENT","31","3","129-137","2013","MAR","Supply Chain Contracts;Fairness;Bounded Rationality;Behavioral Operations Management","","Various contracts can be designed to coordinate a simple supplier-retailer channel, yet the contracts proposed in prior research and tested in a laboratory setting do not perform as standard theory predicts. The supplier, endowed with all bargaining power, can neither fully coordinate the channel nor extract all of the channel profit. We report on a sequence of laboratory experiments designed to separate possible causes of channel inefficiency. The three causes we consider are inequality aversion, bounded rationality, and incomplete information. It turns out that all three affect human behavior. Inequality aversion has by far the most explanatory power regarding retailers' behavior. Incomplete information about the retailer's degree of inequality aversion has the most explanatory power in regards to the suppliers' behavior. Bounded rationality affects both players, but is of secondary importance. (c) 2013 Elsevier B.V. All rights reserved."
366,"Sequence effects in service bundles: Implications for service design and scheduling","Dixon, Michael and Verma, Rohit","JOURNAL OF OPERATIONS MANAGEMENT","31","3","138-152","2013","MAR","Service Operations;Empirical Research;Archival Data Analysis;Econometric Modeling","","Researchers in several academic disciplines have investigated the effect of the sequence of pleasure and pain on the customer in service, experience, or healthcare-related interactions. Specifically, past research from psychology, behavioral economics, and other related fields suggests that the sequence effect can significantly impact a customer's overall impression of a service interaction. In this article, we test the influence that the sequence of discrete events separated by several days or weeks plays on customers' assessment of service bundles. If the relative importance of the sequence effect for discrete bundles is known, then a service designer and event scheduler can optimize and develop a better sequence of interactions for the customers, leading to higher satisfaction, loyalty, and repurchase. Using an extensive multi-year ticket purchase database from a world-renowned performing arts venue, we develop and test econometric models to predict season ticket subscription repurchase. The estimated models show that sequence effects do indeed play a significant role in determining customer repurchase of subscriptions. These results have important implications for effective service design and capacity planning for a wide range of service industries. This article suggests both managerial implications and future research opportunities related to sequence effects in service operations. (c) 2012 Elsevier B.V. All rights reserved."
367,"On the relationship between supplier integration and time-to-market","Perols, Johan and Zimmermann, Carsten and Kortmann, Sebastian","JOURNAL OF OPERATIONS MANAGEMENT","31","3","153-167","2013","MAR","Time-To-Market;Supplier Integration;Information Technology Adoption And Assimilation;Internal Exploration Activities;Structural Equation Model","","Recent operations management and innovation management research emphasizes the importance of supplier integration. However, the empirical results as to the relationship between supplier integration and time-to-market are ambivalent. To understand this important relationship, we incorporate two major recent developments. First, the literature has started to redefine supplier integration into two dimensions, supplier product integration and supplier process integration. Second, recent research has begun to examine spillover effects that extend beyond the direct costs and benefits of the supplier contract. Using survey data of 116 firms in the industrials, health care, and information technology industries, the results confirm our hypotheses and show that supplier product integration decelerates time-to-market while supplier process integration accelerates time-to-market. The results also show a positive relationship between supplier integration and the adoption of external technologies, which either decelerates or accelerates time-to-market depending on the level of internal exploration activities. Our research, thus, helps to open the 'black-box' of the relationship between supplier integration and time-to-market, and provides a theoretically grounded explanation to the apparent contradictory results in prior research about the influence of supplier integration on time-to-market. In addition, we contribute to research on spillover effects by emphasizing that information technology adoption and assimilation is an important spillover effect of supplier integration. (c) 2012 Elsevier B.V. All rights reserved."
368,"Social preferences and emotions as regulators of behavior in processes","Urda, Julie and Loch, Christoph H.","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","6-23","2013","JAN","Social Preferences;Status;Reciprocity;Group Identity;Emotions;Behavior In Processes;Experiments","","Behavior is driven not only by individual (economically) rational deliberation, but also by shortcuts (decision biases) and by social preferences (the achievement of status, reciprocal relationships, and group identity). An important aspect of these behavioral drivers is that they may operate (at least in part) through emotions. Emotions influence behavior in ways that are relevant to performance in processes; for example, anger prompts employees to refuse cooperation, fear inhibits workers' willingness to take initiatives (for example, in continuous improvement), and shame motivates them to change behavior. This study provides experimental evidence that the social preferences systematically trigger emotions. This happens not linearly (more achievement of a social preference might be expected to cause more positive emotions), but rather in more complex patterns that regulate social relationships. Arbitrary (but earned) status signals trigger pride, while status achievement from being lucky does not. An externally (not by an own fault) caused status loss triggers anger and disgust. Not receiving cooperation by another person triggers anger, but more so if the cooperation failure violates a reciprocity expectation; the happiness form receiving cooperation by another person is attenuated by guilt and sadness is the subject itself has previously refused cooperation to the other person. Events happening to salient in-group members trigger emotions as if they happened to subjects directly, including if the in-group member behaves in an embarrassing way. These results are relevant for front-line managers because they help predicting and interpreting emotional reactions of employees: awarding or withholding status, offering or demanding reciprocity, and the creation of in-groups have emotional effects that depend on the context in predictable ways. Our results also contribute to theory by connecting literatures on emotions, decision making, and behavioral operations. (C) 2013 Published by Elsevier B.V."
369,"Reducing uncertainty in supplier selection decisions: Antecedents and outcomes of procedural rationality","Riedl, Dominik F. and Kaufmann, Lutz and Zimmermann, Carsten and Perols, Johan L.","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","24-36","2013","JAN","Behavioral Operations Management;Uncertainty;Information Processing;Procedural Rationality;Supplier Selection;Structural Equation Modeling","","Supplier selection decisions are characterized by a high degree of uncertainty. We draw upon the behavioral operations management and decision-making literatures to examine factors that lead to the adoption of procedural rationality as a decision strategy. In addition, we emphasize the effect of procedural rationality on decision-makers' perceived uncertainty and subsequent supplier decision performance. Our structural equation model with cross-country survey data from 461 respondents in the United States and China reveals that (i) organizational, situational, and personal antecedents significantly influence the use of procedural rationality, (ii) procedural rationality is effective in reducing uncertainty in supplier selection decisions, and (iii) the reduction in decision uncertainty improves supplier decision performance. We also emphasize contextual idiosyncrasies between China and the United States. (C) 2012 Elsevier B.V. All rights reserved."
370,"Operational risk assessments by supply chain professionals: Process and performance","Tazelaar, Frits and Snijders, Chris","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","37-51","2013","JAN","Risk Assessment;Process;Performance;Behavioral Experiment;Expertise;Supply Chain Management","","We consider the process-performance paradox in the assessment of operational risks by professionals in the field of operations and supply chain management (OSCM). The paradox states that although professionals with more expertise tend to decide in different ways, they often do not make better assessments than those with less expertise. We first replicate that this paradox exists in a context of the assessment of operational supply risks, and then show how the paradox can be understood as the consequence of process characteristics mediating the relation between expertise and assessment performance. Using an experimental setup, we had 234 OSCM-professionals assess the operational risk in two series of different business cases, and measured several characteristics of their decision-making process. The strength of our approach lies in the fact that the business cases were real-life cases from our database of purchasing transactions in the area of IT-purchasing. This allows a comparison of the risk assessments of the professionals with the actual supply risk as was known from the survey database. Our findings show that, contrary to what is often assumed, the OSCM-professionals with more expertise do not use less information while assessing, nor are they faster. Instead, our results show that specialized expertise goes with increased certainty about the assessments, and general expertise goes with an increased use of intuitive judgment. However, the net effects of these expertise characteristics on assessment performance are zero. In the case of specialized expertise this is because specialized expertise is itself negatively related to performance. In the case of general expertise this is because the net effects of the use of intuition on performance are zero. (C) 2012 Elsevier B.V. All rights reserved."
371,"Learning from others' misfortune: Factors influencing knowledge acquisition to reduce operational risk","Hora, Manpreet and Klassen, Robert D.","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","52-61","2013","JAN","Operational Risk;Learning;Knowledge Acquisition;Behavioral Operations;Vignette-Based Field Experiment","","Risks arising from operations are increasingly being highlighted by managers, customers, and the popular press, particularly related to large-scale (and usually low-frequency) losses. If poorly managed, the resulting disruptions in customer service and environmental problems incur enormous recovery costs, prompt large legal liabilities, and damage customer goodwill and brand equity. Yet, despite conventional wisdom that firms should improve their own operations by observing problems that occur in others' processes, significant operational risks appear to be ignored and similar losses recur. Using a randomized vignette-based field experiment, we tested the influence of organization-level factors on knowledge acquisition. Two organization-level factors, namely perceived operational similarity, and to a lesser extent, market leadership, significantly influenced the risk manager's likelihood of acquiring knowledge about possible causes that triggered another firm's operational loss. These findings suggest that senior managers need to develop organizational systems and training to expand the screening by risk managers to enhance knowledge acquisition. Moreover, industry and trade organizations may have a role in fostering the transfer of knowledge and potential learning from operational losses of firms. 2012 Elsevier B.V. All rights reserved."
372,"Real-time feedback and booking behavior in the hospitality industry: Moderating the balance between imperfect judgment and imperfect prescription","Bendoly, Elliot","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","62-71","2013","JAN","Behavioral Operations;Biometrics;Revenue Management;Stress;Arousal","","Revenue management (RM) systems now have an established role in the hospitality industry. Nevertheless, use of the systems varies. The price points that these systems generate through the analysis of demand forecasts are, by their very nature, imperfect prescriptions. Given the risk of forecast error in certain reservation contexts, hotel agents are often given the latitude to accept rate bids below the pricing prescriptions of these systems. The frequency and extent of such deviation is dependent in large part on the judgment of reservation agents, who in turn are influenced by their perceptions of how their actions will be viewed by higher levels of management. In this study, we use a laboratory experiment to investigate how different forms of continuous performance feedback influence agent decisions. More specifically, we consider both a revenue-focused metric as well as a metric framed around pricing-curve adherence as the basis of two feedback mechanisms of interest. In an attempt to provide additional insight, we also monitored physiological markers of stress and arousal to determine the emotional state of subjects. The purpose is to use such observations in support of theory regarding the impact of performance measure orientation on decision making. The results suggest implications for the practical use of continuous feedback in these settings. (C) 2012 Elsevier B.V. All rights reserved."
373,"Individual differences in the newsvendor problem: Behavior and cognitive reflection","Moritz, Brent B. and Hill, Arthur V. and Donohue, Karen L.","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","72-85","2013","JAN","Newsvendor Problem;Behavioral Operations;Cognitive Reflection","","Previous research has shown that when solving a newsvendor problem, individuals systematically and persistently deviate from the profit maximizing quantity. This paper investigates the relationship between cognitive reflection and newsvendor decision making, testing experienced supply chain professionals and subjects affiliated with a university business school in a newsvendor experiment. We find that in high and medium critical ratio environments, individuals with higher cognitive reflection exhibit a lower tendency to chase demand. We also find that cognitive reflection is related to task outcome measures including average expected profit, average order quantity and order quantity variance, and that cognitive reflection is a better predictor of performance than college major, years of experience, and managerial position. These results suggest that cognitive reflection contributes to an understanding of newsvendor decision-making behavior. (C) 2012 Elsevier B.V. All rights reserved."
374,"Sex, risk and the newsvendor","de Vericourt, Francis and Jain, Kriti and Bearden, J. Neil and Filipowicz, Allan","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","86-92","2013","JAN","Newsvendor;Risk Aversion;Gender Difference;Behavioral Operations","","We present results from two experiments that reveal significant gender differences in ordering behavior in the newsvendor problem. In high margin settings, males tend to order more than females, and they also tend to achieve higher profits. There are no gender differences in low margin settings. We show that the observed gender differences are partially driven by (or mediated by) gender differences in risk appetite. Males tend to prefer taking greater risk than women, and this leads them to order more in the newsvendor problem (in high margin settings). We show that the risk-ordering relationship is related to financial risk attitudes but not to social risk attitudes, and also that the effect is not driven by gender differences in affect, a likely alternative explanation for the results. (C) 2012 Elsevier B.V. All rights reserved."
375,"Chinese perspective on newsvendor bias: An exploratory note","Cui, Yin and Chen, Lucy Gongtao and Chen, Jian and Gavirneni, Srinagesh and Wang, Qi","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","93-97","2013","JAN","Behavioral Operations;Inventory Management;Newsvendor Model;Cultural Differences;Verbal Protocol Analysis","","Chinese and American decision makers demonstrated significantly different biases while making newsvendor decisions in a laboratory experiment that utilizes the open-ended verbal protocol analysis approach. Chinese subjects (i) asked more questions before reaching their decision, which suggests that they are more cautious when making a decision; (ii) were more frequently able to come up with a new number as their decision whereas the American decision makers tended to use one of the given numbers as their decision; (iii) were more cognizant of salvage values and as a result ordered more than the American decision makers. Due to the open-ended, time-consuming nature of our experiment, our subject pool was small and thus we present these results as exploratory in nature and discuss directions that are worth further study in future experiments. (C) 2012 Elsevier B.V. All rights reserved."
376,"Implementing labor flexibility: A missing link between acquired labor flexibility and plant performance","Sawhney, Rajeev","JOURNAL OF OPERATIONS MANAGEMENT","31","1-2, SI","98-108","2013","JAN","Labor Flexibility;Partial Least-Squares (Pls);Plant Performance;Hrm-Practices;Overtime","","The existing studies conceptualize a direct relationship between acquired labor flexibility and plant performance, producing inconsistent empirical results, which makes the topic ripe for further inquiry. We believe acquiring labor flexibility is not sufficient; its implementation is an important intervening step when companies have to tackle accompanying technical and behavioral side effects of labor flexibility. In this paper, we develop and test a theoretical model in which we introduce an intervening variable to capture the implementation of labor flexibility. In addition, evolving human resource management practices that promote acquisition of labor flexibility are also examined in our model. Case studies in ten printed circuit board plants validated our model. Subsequently, survey data collected from 74 PCB plants was analyzed using Partial Least Squares method. Supporting the proposed model, the results show that the impact of acquired labor flexibility on plant performance is not direct but experienced through the sophistication of labor flexibility implementation exercised by the plant. Our findings also suggested that plants that emphasized process-focused training, provided greater job-rotation training, and designed positive reward structures, acquired higher labor flexibility. (C) 2012 Elsevier B.V. All rights reserved."
377,"The role of experience in six sigma project success: An empirical analysis of improvement projects","Easton, George S. and Rosenzweig, Eve D.","JOURNAL OF OPERATIONS MANAGEMENT","30","7-8","481-493","2012","NOV","Experience;Learning;Quality Improvement Teams;Structured Problem-Solving Process;Six Sigma;Dmaic","","Recent learning-by-doing research highlights the importance of examining multiple measures of experience and their relationship to the performance of work teams. Our paper studies the role of individual experience, organizational experience, team leader experience, and experience working together on a team (team familiarity) in the context of improvement teams. To do so, we analyze successful and failed six sigma improvement team projects at a Fortune 500 consumer products manufacturer with multiple business groups. Such improvement project teams focus on deliberate learning, which differs from the primary focus of work teams. Our analysis uses archival data generated by these improvement project teams over a six year time span. Of the four experience variables we study, we find that team leader experience exhibits the strongest relationship with project success, followed by organizational experience. Further, in contrast to prior-related research on work teams, we find no relationship between individual experience or team familiarity and project success beyond that explained by team leader and organizational experience. These results suggest that a well-developed and deployed structured problem-solving process-characteristic of effective six sigma deployments-may reduce the importance of team familiarity in the context of improvement teams. (c) 2012 Elsevier B.V. All rights reserved."
378,"On the unique features of post-disaster humanitarian logistics","Holguin-Veras, Jose and Jaller, Miguel and Van Wassenhove, Luk N. and Perez, Noel and Wachtendorf, Tricia","JOURNAL OF OPERATIONS MANAGEMENT","30","7-8","494-506","2012","NOV","Humanitarian Logistics;Commercial Logistics;Natural Disaster;Catastrophes;Material Convergence;Deprivation Costs","","Logistic activity can be thought of as a socio-technical process whereby a social network of individuals orchestrates a series of technical activities using supporting systems such as transportation and communications. To understand the functioning of the entire system requires proper consideration of all its components. We identify seven key components: the objectives being pursued, the origin of the commodity flows to be transported, knowledge of demand, the decision-making structure, periodicity and volume of logistic activities, and the state of the social networks and supporting systems. Based on our analysis of the differences between commercial and humanitarian logistics, we pinpoint research gaps that need to be filled to enhance both the efficiency of humanitarian logistics and the realism of the mathematical models designed to support it. We argue that humanitarian logistics is too broad a field to fit neatly into a single definition of operational conditions. At one end of the spectrum we find humanitarian logistic efforts of the kind conducted in long-term disaster recovery and humanitarian assistance, where operational efficiency - akin to commercial logistics - is a prime consideration. At the other, post-disaster humanitarian logistic operations involved in disaster response and short-term recovery activities represent a vastly different operational environment, often in chaotic settings where urgent needs, life-or-death decisions and scarce resources are the norm. The huge contrast between these operational environments requires that they be treated separately. (c) 2012 Elsevier B.V. All rights reserved."
379,"Effect of purchase volume flexibility and purchase mix flexibility on e-procurement performance: An analysis of two perspectives","Devaraj, Sarv and Vaidyanathan, Ganesh and Mishra, Abhay Nath","JOURNAL OF OPERATIONS MANAGEMENT","30","7-8","509-520","2012","NOV","E-Procurement;Frequency;Information Sharing;Purchase Volume Flexibility;Purchase Mix Flexibility;Performance;Supplier Customization;Trust","","Despite the widespread adoption of e-procurement by firms in recent years, academic research examining the mechanisms through which e-procurement applications lead to performance has been scarce. Anecdotal evidence points to numerous situations where companies have failed to harness the potential of e-procurement. In this paper, we argue that online purchase volume and mix flexibilities facilitated by these applications play a significant role in the ability of firms to benefit from e-procurement. We examine this tenet from both an economic as well as a social perspective. We propose that increased online purchase volume flexibility as well as online purchase mix flexibility can be facilitated by two mechanisms - supplier customization as explained by transaction costs perspective, and information sharing between supply chain partners using a social exchange theoretical perspective. The increased purchase volume and mix flexibility in turn leads to better performance along the dimensions of cost, quality, and delivery. We present and test a nuanced perspective where we argue that (i) the effect of supplier customization on both purchase volume and mix flexibilities will be moderated by the frequency of transactions conducted online, and (ii) the effect of information sharing on both purchase volume and mix flexibilities will be moderated by trust in the supplier. We estimate our research model using survey data collected from 130 purchasing and procurement managers. We find strong support for our proposed research model with results indicating that purchase volume and mix flexibilities play a vital mediating role in impacting e-procurement performance. Theoretical and practical implications of the findings are discussed. (c) 2012 Elsevier B.V. All rights reserved."
380,"The effects of Six Sigma on corporate performance: An empirical investigation","Shafer, Scott M. and Moeller, Sara B.","JOURNAL OF OPERATIONS MANAGEMENT","30","7-8","521-532","2012","NOV","Six Sigma;Event Study;Process Improvement;Corporate Performance","","The purpose of this study is to investigate the impact of adopting Six Sigma on corporate performance. Although there is a fairly large and growing body of anecdotal evidence associated with the benefits of implementing Six Sigma, there is very little systematic and rigorous research investigating these benefits. This research extends previous research in several important ways including utilizing a sample of 84 Six Sigma firms that represent a wide variety of industries and firm characteristics, utilizing rigorously constructed control groups to ensure the validity of our comparisons and conclusions, and investigating the impact of adopting Six Sigma on corporate performance over a ten year period. To carry out this investigation, the event study methodology is employed. The ten year period consists of three years prior to Six Sigma implementation, the event year corresponding to the year Six Sigma is adopted, and six years post Six Sigma implementation. To assess the impact of adopting Six Sigma on corporate performance we utilize commonly used measures including Operating Income/Total Assets (OI/A), Operating Income/Sales (OI/S), Operating Income/Number of Employees (OI/E), Sales/Assets (S/A), and Sales/Number of Employees (S/E). The sample Six Sigma firms are compared to different benchmarks including the overall industry performance and to the performance of carefully selected portfolios of control firms. The results of the study indicate that adopting Six Sigma positively impacts organizational performance primarily through the efficiency with which employees are deployed. More specifically, enhanced employee productivity results were observed in both static analyses that assessed the performance of the sample Six Sigma firms relative to their control groups at discrete points in time and dynamic analyses of the Six Sigma firms' rate of improvement relative to the rate of improvement of their control groups. Benefits in terms of improved asset efficiency were not observed. Finally, there was no evidence that Six Sigma negatively impacts corporate performance. (c) 2012 Elsevier B.V. All rights reserved."
381,"Six Sigma adoption: Operating performance impacts and contextual drivers of success","Swink, Morgan and Jacobs, Brian W.","JOURNAL OF OPERATIONS MANAGEMENT","30","6","437-453","2012","SEP","Six Sigma;Process Innovation;Operating Performance;Event Study","","We assess the operational impacts of Six Sigma program adoptions through an event study methodology, comparing financial data for 200 Six Sigma adopting firms against data for matched firms, which serve as control groups for the analyses. We employ various matching procedures using different combinations of pre-adoption return on assets (ROA), industry, and size as matching criteria. By comparing performance outcomes across a hierarchy of operating metrics, we establish a pattern of Six Sigma adoption effects that provides strong evidence of a positive impact on ROA. Interestingly, these ROA improvements arise mostly from significant reductions in indirect costs: significant improvements in direct costs and asset productivity are not evident. We also find small improvements in sales growth due to Six Sigma adoption. Cross-sectional analyses of the performance results reveal that distinctions in Six Sigma impacts across manufacturing and service firms are negligible. Interestingly, we find that the performance impact of Six Sigma adoption is negatively correlated to the firm's quality system maturity (indicated by prior ISO 9000 certification). Further analyses of manufacturing and service firms reveals that Six Sigma benefits are significantly correlated with intensity in manufacturing, and with financial performance before adoption in services. We discuss the implications of these findings for practice and for future research. (C) 2012 Published by Elsevier B.V."
382,"Emergent clustering methods for empirical OM research","Brusco, Michael J. and Steinley, Douglas and Cradit, J. Dennis and Singh, Renu","JOURNAL OF OPERATIONS MANAGEMENT","30","6","454-466","2012","SEP","Cluster Analysis;Multivariate Statistics;Empirical Research Methods","","To date, the vast majority of cluster analysis applications in OM research have relied on traditional hierarchical (e.g.. Ward's algorithm) and nonhierarchical (e.g., K-means algorithms) methods. Although these venerable methods should continue to be employed effectively in the OM literature, we also believe there is a significant opportunity to expand the scope of clustering methods to emergent techniques. We provide an overview of some alternative clustering procedures (including advantages and disadvantages), identify software programs for implementing them, and discuss the circumstances where they might be employed gainfully in OM research. The implementation of emergent clustering methods in the OM literature should enable researchers to offer implications for practice that might not have been uncovered with traditional methods. (C) 2012 Elsevier B.V. All rights reserved."
383,"Using partial least squares in operations management research: A practical guideline and summary of past research","Peng, David Xiaosong and Lai, Fujun","JOURNAL OF OPERATIONS MANAGEMENT","30","6","467-480","2012","SEP","Partial Least Squares (Pls);Structural Equation Modeling (Sem);Empirical Research Methods;Operations Management","","The partial least squares (PLS) approach to structural equation modeling (SEM) has been widely adopted in business research fields such as information systems, consumer behavior, and marketing. The use of PLS in the field of operations management is also growing. However, questions still exist among some operations management researchers regarding whether and how PLS should be used. To address these questions, our study provides a practical guideline for using PLS and uses examples from the operations management literature to demonstrate how the specific points in this guideline can be applied. In addition, our study reviews and summarizes the use of PLS in the recent operations management literature according to our guideline. The main contribution of this study is to present a practical guideline for evaluating and using PLS that is tailored to the operations management field. (C) 2012 Elsevier B.V. All rights reserved."
384,"How does justice matter in achieving buyer-supplier relationship performance?","Liu, Yi and Huang, Ying and Luo, Yadong and Zhao, Yang","JOURNAL OF OPERATIONS MANAGEMENT","30","5","355-367","2012","JUL","Buyer-Supplier Relationships;Justice;Loose Coupling Theory;Relationship Performance;Supply Chain Management","","This study presents an analysis exploring how four types of justice (distributive, procedural, interpersonal, and informational) influence dyadic relationship performance in the buyer-supplier context. Underpinned by loose coupling theory, we build a mediating framework in which we propose that a high level of justice (or fairness) as mutually perceived by both parties drives buyer-supplier relationship performance through bolstered coupling links in mutual knowledge sharing, continuous commitment, and relationship investment. Our survey of 216 paired manufacturers (suppliers) and distributors (buyers) in China generally supports this argument, leading to a conclusion that justice is not a direct determinant of buyer-supplier performance but a critical conduit that nourishes mid-range coupling behaviors, which in turn promotes a successful relationship. Based on findings from this study, firms are encouraged to endorse all four kinds of justice in managing supply chain relationships. However, when constrained by resources, the recommendation for managers is to focus on achieving a high level of perceptual convergence on procedural justice and informational justice with the exchange partner, because mutual perceptions of procedural and informational justice have the strongest effects on coupling behaviors and buyer-supplier relationship performance. (C) 2012 Elsevier B.V. All rights reserved."
385,"The effects of retail channel integration through the use of information technologies on firm performance","Oh, Lih-Bin and Teo, Hock-Hai and Sambamurthy, Vallabh","JOURNAL OF OPERATIONS MANAGEMENT","30","5","368-381","2012","JUL","Service Science;Service Operations Management;Retail Channel Integration;Multichannel Retailing;Service Delivery System;Resource Complementarities","","The ability of information technologies (ITs) to integrate activities and offerings across multiple channels offers a promising opportunity for retail firms to enhance their relationship with their customers and firm performance. Consumers value the flexibility to learn about the available offerings, complete their orders and obtain customer service across different channels in a convenient and integrated manner. Therefore, the retail industry has begun to use IT extensively to automate and integrate business processes across their traditional and online channels. This study examines the impacts of the use of IT by retail firms in integrating channel activities for selling to customers. Our research model argues that retail channel integration through IT should enhance the efficiency and innovation of a retail firm. In turn, these improvements should enhance their overall performance. We also propose that the environmental dynamism would moderate the effects of improvements in efficiency and innovation on firm performance. We draw upon recent theories in organizational resource integration and organizational learning to develop our research model and hypotheses. Based on survey data from 125 multichannel retailers in Singapore, we find that retail channel integration through the use of IT allows firms to not only be efficient in delivering the current offerings, but also be innovative in creating future offerings. Further, we find that environmental dynamism does positively moderate the effects of innovation ability on performance. Our results provide managerial insights for firms involved in digital integration not only in the retail sector but also in other service industries. These findings could also serve as a foundation for further research on service operations management for firms with both physical and online operations. (C) 2012 Elsevier B.V. All rights reserved."
386,"The influence of relational experience and contractual governance on the negotiation strategy in buyer-supplier disputes","Lumineau, Fabrice and Henderson, James E.","JOURNAL OF OPERATIONS MANAGEMENT","30","5","382-395","2012","JUL","Buyer-Supplier Relationships;Contractual Governance;Relational Experience;Supply Chain Governance;Negotiation;Dispute","","This paper theoretically refines and empirically extends the debate on the type of interplay between relational experience and contractual governance in an under-researched area: supply chain disputes. We define relational experience as either cooperative or competitive; distinguish between control and coordination functions of contractual governance; and assess their interplay on the negotiation strategy used in disputes. Using a unique data set of buyer-supplier disputes, we find, in particular that increasing contractual control governance weakens the positive effect of cooperative relational experience on cooperative negotiation strategy. However, increasing contractual control governance for a buyer-supplier dyad with competitive relational experience will increase cooperative negotiation strategy. Contractual coordination governance reinforces the positive effect of cooperative relational experience. Through this study, we reach a better understanding of how and when contractual and relational governance dimensions interact; rather than whether they act as substitutes or complements as has been studied in prior research. We discuss the implications of these findings for the field of supply chain management. (C) 2012 Elsevier B.V. All rights reserved."
387,"Valuing time in supply chains: Establishing limits of time-based competition","Blackburn, Joseph","JOURNAL OF OPERATIONS MANAGEMENT","30","5","396-405","2012","JUL","Time-Based Competition;Make-To Stock Supply Chains;Marginal Value Of Time;Inventory Costs","","Over the past two decades the growth in international trade and the offshore migration of US manufacturing have created global supply chains with longer lead-times and slower response. This suggests that traditional supply chains have encountered limits to time-based competition in which the cost of faster replenishment exceeds the benefits. This paper explores and quantifies those limits to time-based competition in make-to-stock supply chains for functional products (products with stable demand over relatively long life cycles). The marginal value of time is used to define the limits of time-based competition in a supply chain, and we define it as the change in total inventory costs per unit change in supply chain lead-time. To calculate the value of time, we develop a set of simple analytical expressions that apply to most standard reorder-point inventory policies under deterministic and variable lead-times. By not requiring optimal inventory policies and expressing the value of time in terms of the unit cost of the product, we obtain very general results that are essentially product-free. We validate the analytical expressions using data from actual supply chains to simulate the inventory cost effects of changes in the lead-time. The results show that the marginal value of time in a supply chain is surprisingly low: it generally falls within a range of 0.4-0.8% of product unit cost per week. Our analytical models explain why there has been expansive growth in global supply chains for functional products. The key tradeoff in outsourcing is between reduced variable production cost and the increased inventory cost of longer supply chain lead-times. The models show analytically that the incremental inventory cost is extremely small relative to the cost benefit. The growth in global supply chains with long lead-times is cost, rather than time, driven. (C) 2012 Elsevier B.V. All rights reserved."
388,"A contingent theory of supplier management initiatives: Effects of competitive intensity and product life cycle","Mahapatra, Santosh K. and Das, Ajay and Narasimhan, Ram","JOURNAL OF OPERATIONS MANAGEMENT","30","5","406-422","2012","JUL","Competitive Intensity;Product Life Cycle;Supplier Development Investments;Relational Orientation;Supplier Capability","","Direct investments in supplier development and close relationship building are the two major collaborative supplier management strategies for developing and accessing superior supplier capability. The impact of these two strategies, however, has not been uniform across firms, calling for a deeper examination of their relative effectiveness. Utilizing multiple theoretical frameworks, this study examines the relevance and effectiveness of the two collaborative strategies across the growth and maturity stages of the product life cycle (PLC). Specifically, the study analyzes the influence of competitive intensity as an antecedent to supplier development and relational initiatives, and the role of product life cycle as a moderator of the inter-relationships among competitive intensity, supplier development, relational initiatives, and supplier capability. Based on primary survey data, and discussion with practicing managers, the study finds that the individual and integrative effectiveness of supplier development investments (SDI) and relational orientation (RO) can be influenced differently by competitive intensity and PLC stage. In particular, RO can have a foundational role in motivating SDI for superior supplier capability, as also in safeguarding against supplier opportunism in the standardized product market context of the maturity stage. The managerial and theoretical implications of varied emphasis on the two collaborative supplier management strategies across the PLC stages are discussed. (C) 2012 Elsevier B.V. All rights reserved."
389,"Controls, service type and perceived supplier performance in interfirm service exchanges","Stouthuysen, Kristof and Slabbinck, Hendrik and Roodhooft, Filip","JOURNAL OF OPERATIONS MANAGEMENT","30","5","423-435","2012","JUL","Interfirm Service Exchanges;Control;Type Of Service Exchange;Perceived Supplier Performance","","Control offers a critical differentiator between successful and failed interfirm service exchanges. The application of informal control to improve supplier performance has been well established, but the effect of formal control appears profoundly equivocal. This study proposes that the actual effect of formal control depends on its mode (output Vs. behavior) and its relationship with the service type (mass vs. professional) and informal control. With survey data from 252 service buying organizations, the results indicate that output control interacts with service type to determine perceived supplier performance (PSP). Buyers' reliance on high output control has a positive effect on PSP in mass service exchanges; this effect becomes negative in professional service exchanges. The effect of the interaction of behavior control and service type also depends on the presence of informal control. Buyers' reliance on high behavior control exerts a more positive effect on PSP in professional service exchanges than in mass service exchanges, but only in the presence of informal control. These findings have key implications for both theory and practice. (C) 2012 Elsevier B.V. All rights reserved."
390,"Customer-facing supply chain practices-The impact of demand and distribution management on supply chain success","Rexhausen, Daniel and Pibernik, Richard and Kaiser, Gernot","JOURNAL OF OPERATIONS MANAGEMENT","30","4","269-281","2012","MAY","Supply Chain Performance;Supply Chain Management Practices;Demand Management;Distribution Management;Survey Research","","Traditionally, distribution has been viewed as the key ( physical) link between a company's internal supply chain activities and its customers. More recently, demand management has emerged as a new dimension at the customer interface. Although it has become increasing popular in industry, it has not yet been analyzed in depth with respect to its impact on supply chain performance. Both distribution management and demand management entail customer-facing processes and practices and that are interrelated and (may) jointly determine supply chain performance. In this paper we seek to extend the stream of research in supply chain management by systematically investigating the impact of customer-facing supply chain practices on supply chain performance. Specifically, the paper examines the relative impact of relevant practices associated with demand and distribution management. To this end, we collected data from 116 multi-national companies based in Europe and analyzed it using structural equation modeling techniques. Our results suggest that (i) high demand management performance has a substantial positive impact on the overall supply chain performance, (ii) this effect is stronger than that of distribution management performance, and (iii) there is no evidence that demand management might be an enabler for effective distribution management. Among the individual practices that constitute demand and distribution management, adherence to the demand and distribution management processes and demand segmentation emerged as the strongest performance levers. Based upon additional in-depth interviews conducted with selected companies from our sample, we shed light on some of the most important findings that emerged from our survey analysis. (C) 2012 Elsevier B.V. All rights reserved."
391,"The customer consequences of returns in online retailing: An empirical analysis","Griffis, Stanley E. and Rao, Shashank and Goldsby, Thomas J. and Niranjan, Tarikere T.","JOURNAL OF OPERATIONS MANAGEMENT","30","4","282-294","2012","MAY","Product Returns;Repurchase Behavior;Archival Data;Supply Chain;Logistics;Seemingly Unrelated Regression (Sur);Procedural Justice;Customer Satisfaction;Service Recovery;Transaction Cost","","Pressure continues to build on the operations management function to facilitate system and firm level benefits. In the online marketplace, one area of growing interest is that of product returns. Though commonly viewed as a cost center from an operations perspective, operations' actions have the potential to strongly influence future customer buying behavior in several ways. Using an archival database of actual purchase and returns history provided by a moderately sized online retailer, this study examines the relationship between a customer's experience of product returns, and subsequent shopping behavior. Employing transaction cost, consumer risk, and procedural justice theories, we demonstrate that the returns management process, rather than being regarded as an afterthought to the production and deployment of goods, can significantly and positively influence repurchase behavior. Additionally, we provide evidence that certain customers should be considered for prioritization in the returns process. We suggest ways through which operations managers can take care in discharging their responsibilities in this area - to make returns processing more than simply a necessary cost of doing business rather, using it to their advantage in engendering repeat and increased purchase behavior. (C) 2012 Elsevier B.V. All rights reserved."
392,"Relationship between quality management practices and innovation","Kim, Dong-Young and Kumar, Vinod and Kumar, Uma","JOURNAL OF OPERATIONS MANAGEMENT","30","4","295-315","2012","MAY","Quality Management Practices;Radical Product Innovation;Radical Process Innovation;Incremental Product Innovation;Incremental Process Innovation;Administrative Innovation","","The purpose of this study is to examine the associations among different quality management (QM) practices and investigate which QM practices directly or indirectly relate to five types of innovation: radical product, radical process, incremental product, incremental process, and administrative innovation. We test the proposed framework and hypotheses using empirical data from ISO 9001 certified manufacturing and service firms. The results show that a set of QM practices through process management has a positive relationship with all of these five types of innovation. It was found that process management directly and positively relates to incremental, radical, and administrative innovation. Organizational capability to manage processes may play a vital role in identifying routines, establishing a learning base, and supporting innovative activities. The findings also reveal that the value of an individual QM practice is tied to other QM practices. Therefore, highlighting just one or a few QM practices or techniques may not result in creative problem solving and innovation. (C) 2012 Elsevier B.V. All rights reserved."
393,"Too much of a good thing: The impact of product variety on operations and sales performance","Wan, Xiang and Evers, Philip T. and Dresner, Martin E.","JOURNAL OF OPERATIONS MANAGEMENT","30","4","316-324","2012","MAY","Product Variety;Fill Rate;Sales;Distributors","","We examine the impact of product variety decisions on an operational measure - unit fill rate - and on sales performance. Results are estimated using weekly data over three years from 108 distribution centers of a major soft drink bottler. Our results show that fill rates are negatively associated with product variety at a diminishing rate. In addition, we examine the total effect of product variety on sales including both the direct effect and the indirect effect through operations performance. The total impact of product variety on sales initially is positive, although at a diminishing rate. However, beyond a certain level, increased product variety actually results in lower sales; that is, too much of a good thing. Thus, the findings provide a comprehensive understanding of the impact of product variety on operations and sales performance. (C) 2012 Elsevier B.V. All rights reserved."
394,"Process quality improvement: An examination of general vs. outcome-specific climate and practices in hospitals","Boyer, Kenneth K. and Gardner, John W. and Schweikhart, Sharon","JOURNAL OF OPERATIONS MANAGEMENT","30","4","325-339","2012","MAY","Healthcare Operations;Service Operations","","Despite numerous efforts to foster quality improvement in healthcare, much of the extant data and research indicate that substantial shortcomings in the delivery of effective and reliable care remain. This research examines both general and outcome-specific operations management efforts and their impact on delivering quality healthcare. We empirically test a conceptual framework of safety culture that accounts for the use of general quality practices as well as outcome-specific approaches in light of the general and more focused climates in which those practices are embedded. We utilize structural equation modeling to analyze a unique pairing of primary data from a survey of quality improvement directors and chief nursing officers at 272 hospitals across the U.S. with secondary data on process of care performance publicly reported by the federal government's Center for Medicare and Medicaid Services (CMS). General safety climate and quality practices are found to establish an environment in which outcome-specific efforts enable process quality improvement. A split-group SEM analysis highlights significant differences in managing healthcare safety outcomes through climate and practices. In particular, the employment of practices focused on the specific outcome goals is found to relate to higher quality of patient care in smaller hospitals. In contrast, the development of a climate focused on specific outcome goals is found to relate to higher quality of patient care in larger hospitals. These findings suggest alternative approaches for small and large hospitals in the critical effort to improve patient safety and reduce healthcare costs. (C) 2012 Elsevier B.V. All rights reserved."
395,"The link between supply chain fit and financial performance of the firm","Wagner, Stephan M. and Grosse-Ruyken, Pan Theo and Erhun, Feryal","JOURNAL OF OPERATIONS MANAGEMENT","30","4","340-353","2012","MAY","Supply Chain Management;Operations Strategy;Supply Chain Fit;Empirical Analysis;Firm Performance","","The bottom-line financial impact of supply chain management has been of continuing interest. Building on the operations strategy literature, Fisher's (1997) conceptual framework, a survey of 259 U.S. and European manufacturing firms, and secondary financial data, we investigate the relationship between supply chain fit (i.e., strategic consistencies between the products' supply and demand uncertainty and the underlying supply chain design) and the financial performance of the firm. The findings indicate that the higher the supply chain fit, the higher the Return on Assets (ROA) of the firm, and that firms with a negative misfit show a lower performance than firms with a positive misfit. (C) 2012 Elsevier B.V. All rights reserved."
396,"Postponement strategy for international transfer of products in a global supply chain: A system dynamics examination","Choi, Kanghwa and Narasimhan, Ram and Kim, Soo Wook","JOURNAL OF OPERATIONS MANAGEMENT","30","3","167-179","2012","MAR","Global Supply Chain;Postponement;Decoupling Points;Dynamic Simulation","","This paper contributes to research on postponement strategy in the context of a global production-distribution system of an automobile manufacturer. It proposes a model that integrates multiple considerations germane to global supply chains. Postponement is important in this context because it is necessary to consider international transfers and tariffs, and it is important to appropriately account for the impact of postponement on total costs. Consideration of several key variables such as shipping point, customs tariff, and cost differences between countries is essential to derive full benefits from postponement strategy in global supply chains. International transfer of goods among countries in global automobile industry is complex and dynamic because of the multitude of factors that must be considered. The paper develops insights regarding postponement strategy in global supply chains via a system dynamics simulation model. The model draws on the experiences of a Korean automobile manufacturer with operations in developing and developed countries. The results of the system dynamics simulations show that the choice of optimal shipping point and the right level of postponement under the decoupling points strategy in global operations has a significant effect on overall cost efficiency, when decoupling point and postponement timing are considered simultaneously. The results also show that there are key differences in executing the postponement strategy when shipping to a developing country as opposed to a developed country. This insight has practical implications for global operations and is helpful in developing a sophisticated framework for executing the postponement strategy as manufacturing firms expand their operations globally. (C) 2012 Elsevier B.V. All rights reserved."
397,"Are internal manufacturing and external supply chain flexibilities complementary capabilities?","Malhotra, Manoj K. and Mackelprang, Alan W.","JOURNAL OF OPERATIONS MANAGEMENT","30","3","180-200","2012","MAR","Supply Chain Flexibility;Mix Flexibility;Modification Flexibility, New Product Flexibility;Complementarity;Delivery Performance","","Manufacturing flexibility is often viewed as a strategic capability that enables firms to more effectively meet heterogeneous market demands arising, in part, from increased product proliferation. However, recent studies suggest that the operational challenges associated with meeting this objective may be heavily dependent not only upon a firm's internal modification, mix, and new product flexibilities, but also upon the flexibility of its inbound and outbound supply chain partners. Drawing upon the theory of Complementarity, we examine if simultaneous utilization of both internal and external flexibilities does in fact create synergies that can improve a firm's delivery performance. Based on a sample of 158 U.S. manufacturing plants, we find that the extent to which performance enhancing synergies are generated is primarily dependent upon the type of internal flexibility that is paired with supply chain flexibilities. Additionally, we find that when synergies do exist, external supplier and logistics flexibilities generally tend to enhance the scope of flexible response, while internal flexibilities generally tend to enhance the achievability of a flexible response. Taken together, our findings suggest that the ability of firms to actually reap the synergistic benefits of an integrated system of supply chain flexibility is much more complex and nuanced than previously believed or expected. (C) 2012 Elsevier B.V. All rights reserved."
398,"Enhancing effects of manufacturing flexibility through operational absorptive capacity and operational ambidexterity","Patel, Pankaj C. and Terjesen, Siri and Li, Dan","JOURNAL OF OPERATIONS MANAGEMENT","30","3","201-220","2012","MAR","Environmental Uncertainty;Latent Moderated Structural Equations;Manufacturing Flexibility;Operational Absorptive Capacity;Operational Ambidexterity","","A large body of research investigates how manufacturing flexibility in uncertain environments leads to firm performance, with mixed results. The mixed findings could be due to differences across firms in terms of the capabilities to acquire, assimilate, and transform knowledge and to simultaneously pursue both the exploitation of existing operational capabilities and the exploration for new operational capabilities. Building on the literature that suggests that manufacturing flexibility mediates the relationship between environmental uncertainty and firm performance, we explore the applicability of two organizational learning contingencies to the operations environment: operational absorptive capability and operational ambidexterity. Absorptive capacity enables the recognition and assimilation of new knowledge. Ambidexterity determines whether this knowledge will be applied for both exploration and exploitation. Using a sample of 852 manufacturing firms, we find that environmental uncertainty affects firm performance directly and indirectly through manufacturing flexibility. Furthermore, both operational absorptive capacity and operational ambidexterity moderate the relationship between environmental uncertainty and manufacturing flexibility and the relationship between manufacturing flexibility and firm performance. Theoretical and practical implications are discussed. (C) 2011 Elsevier B.V. All rights reserved."
399,"How to learn new tasks: Shop floor performance effects of knowledge transfer and performance feedback","Letmathe, Peter and Schweitzer, Marcus and Zielinski, Marc","JOURNAL OF OPERATIONS MANAGEMENT","30","3","221-236","2012","MAR","Knowledge Transfer;Learning;Feedback;Manufacturing","","We investigate how learning and the task performance of individuals are affected by different forms of knowledge transfer. Whereas previous research has proven the positive performance impacts of knowledge transfer, self-observation and feedback mechanisms individually, we explore the cumulative effect of these factors on learning and performance. With the help of two laboratory experimental studies reproducing manufacturing tasks that are typical for industrial production, we show that explicit knowledge transfer is superior to other forms of knowledge transfer. Externally provided performance feedback in the form of cost information and non-financial performance indicators has no effect on the order of different forms of knowledge transfer. Moreover, external feedback does not even have an additional significant performance effect on learning new tasks irrespective of the type of knowledge transfer. (C) 2011 Elsevier B.V. All rights reserved."
400,"Imperatives of the science of operations and supply-chain management","Singhal, Kalyan and Singhal, Jaya","JOURNAL OF OPERATIONS MANAGEMENT","30","3","237-244","2012","MAR","Operations Management;Paradigm Shifts;Research;Supply-Chain Management;Triangulation","","Although knowledge in operations and supply-chain management (O&SCM) has advanced substantially during the last six decades, our community has not fully utilized the potential for radical innovations. We identify two sets of opportunities for pursuing radical innovations. First, there is an opportunity to pursue all phases of science, including exploratory and qualitative research, developing theories, causation and internal validity, and testing models and theories for external validity (the ability to generalize knowledge to other situations). This would broaden the domain covered by each research effort, minimize the bias resulting from the choice of research paradigm and research domain, to enhance external validity, and to minimize the gap between our research efforts and the real world our community seeks to reshape. Second, there is an opportunity to pursue multiple perspectives because a scientific conclusion valid for a narrow domain may prove to be partially true or even false if one obtains multiple perspectives. Multiple perspectives can be obtained by investigating different parts of the system, by employing different methods of analysis, by using different sources of data, or by using different subsets of the same data. Developing scientific knowledge requires pursuit of all phases of science and of multiple perspectives. In a separate paper, we propose and analyze ways to accomplish it. (C) 2011 Elsevier B.V. All rights reserved."
401,"Opportunities for developing the science of operations and supply-chain management","Singhal, Kalyan and Singhal, Jaya","JOURNAL OF OPERATIONS MANAGEMENT","30","3","245-252","2012","MAR","Meta-Analysis;Operations Management;Outliers;Research;Supply-Chain Management;Triangulation","","In a separate paper (Singhal and Singhal, 2011b), we identified two sets of opportunities for radical innovations in operations and supply-chain management (O&SCM): pursuing all phases of science and pursuing multiple perspectives. In this paper, we propose and analyze ways to accomplish this task. A network of research teams can be effective in obtaining multiple perspectives and discovering radical innovation if it conducts intensive research over an extended period. Outliers are a source of multiple perspectives and innovative ideas and can help in identifying and addressing risks. Similarly, meta-analyses and syntheses of published works can provide multiple perspectives and lead to radical innovations. (C) 2011 Elsevier B.V. All rights reserved."
402,"Mediated power and outsourcing relationships","Handley, Sean M. and Benton, Jr., W. C.","JOURNAL OF OPERATIONS MANAGEMENT","30","3","253-267","2012","MAR","Outsourcing;Inter-Organizational Power;Inter-Organizational Control;Strategic Sourcing","","Mediated power is often used by firms to control the behaviors or influence the decisions of other members of the value chain. Interestingly, significant contributions in the academic literature offer consistent evidence that the use of mediated power has a negative impact on the quality of inter-organizational relationships. Yet, there is a dearth of empirical research investigating the conditions under which the use of mediated power is more or less prevalent. Utilizing dyadic data collected on 102 outsourcing relationships, this study evaluates how the buying firm's dependence on the service provider, asserted importance of the outsourced activity, and difficulties with other inter-organizational control mechanisms are related to their reliance on mediated power. Results from our hierarchical regression analysis support the hypotheses that the use of mediated power is diminished when the buyer is currently more dependent on the service provider due to switching difficulties and the buyer has a higher expectation of future supply market consolidation. Similar hypotheses regarding the effect of the strategic importance of the outsourced activity and entry barriers to the service provider's market were not supported. The results also support the hypothesis that the use of mediated power is more pronounced when the buyer experiences contract management difficulties, but the same is not true when the buyer has difficulty in monitoring the provider. To our knowledge, these findings represent the first empirical explanation of conditions which either attenuate or exacerbate the use of mediated power by outsourcing organizations. (C) 2011 Elsevier B.V. All rights reserved."
403,"How different is professional service operations management?","Lewis, Michael A. and Brown, Andrew D.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","1-11","2012","JAN","Case/Field Study;Organisational Behavior;Productivity;Service Operations","","This paper presents detailed analysis of the operational and operations management characteristics of a professional service firm, a legal partnership. An in-depth study of customer interactions, service customization, process throughput and variability, professional employee behavior and managerial interventions provided the basis for confirmatory and exploratory research. The results suggested a number of refinements to existing conceptualizations of the professional service type operation and indicated areas where professional service operations management should be viewed as highly distinctive. First, professional-client exchange is variably asymmetrical - with significant implications for service package and process design. Second, professional service operations comprise a substantial number of less variable and faster throughput processes - creating a significant opportunity for commoditization. Third, professional status and corresponding organisational structures (e.g. the partnership model) need to be explicitly recognised in any typology - these factors introduce distinctive trade-offs when seeking greater efficiency and effectiveness. (C) 2011 Elsevier B.V. All rights reserved."
404,"The moderating role of contextual factors on quality management practices","Zhang, Dongli and Linderman, Kevin and Schroeder, Roger G.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","12-23","2012","JAN","Quality Management;Exploitation;Exploration;Organizational Structure;Environmental Uncertainty","","This study investigates how contextual factors influence the relationship between Quality Management (QM) practices and manufacturing performance. It contributes to the contingency theory of QM effectiveness. Drawing on the management literature, we differentiate two different groups of QM practices: Quality Exploitation and Quality Exploration. The analysis empirically investigates the internal fit with organizational structure and the external fit with environmental uncertainty on the relationship between Quality Exploration, Quality Exploitation, and operational performance. The data comes from a survey of 238 manufacturing plants in three industries across eight countries. Regression analyses show that both internal fit with the organizational structure and external fit with the environment affect performance. The findings also provide insights for managers on how to customize QM programs to achieve optimal performance benefits. In stable environments Quality Exploitation practices provide the best performance outcomes, while in a dynamic environment Quality Exploration practices with an organic organizational structure give the best results. (C) 2011 Elsevier B.V. All rights reserved."
405,"Impact factor as a metric to assess journals where OM research is published","Stonebraker, Jeffrey S. and Gil, Esther and Kirkwood, Craig W. and Handfield, Robert B.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","24-43","2012","JAN","Operations Management;Production Operations Management;Impact Factor;Citation Analysis;Journal Ranking","","This paper investigates impact factor as a metric for ranking the quality of journal outlets for operations management (OM) research. We review all prior studies that assessed journal outlets for OM research and compare all previous OM journal quality rankings to rankings based on impact factors. We find that rankings based on impact factors that use data from different time periods are highly correlated and provide similar rankings of journals using either two-year or five-year assessment periods, either with or without self-citations. However, some individual journals have large rank changes using different impact factor specifications. We also find that OM journal rankings based on impact factors are only moderately correlated with journal quality rankings previously determined using other methods, and the agreement among these other methods in ranking the quality of OM journals is relatively modest. Thus, impact factor rankings alone are not a replacement for the assessment methods used in previous studies, but rather they evaluate OM journals from another perspective. (C) 2011 Elsevier B.V. All rights reserved."
406,"Ten years after: Interference of hospital slack in process performance benefits of quality practices","Goldstein, Susan Meyer and Iossifova, Albena R.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","44-54","2012","JAN","Quality Management;Organizational Slack;Regression;Health Care Industry","","We investigate the long-term relationship between an organization's quality management practices and process-level performance. Further, we examine whether availability of organizational slack over the study interval interferes with the relationship between quality practices and process performance. Organizational slack consists of the available and accessible resources in an organization; we focus here on unabsorbed slack in the form of financial resources. We investigate the quality practices of U.S. general acute care hospitals, measured by their depth of implementation of practices characterizing a total quality management system, and use them to predict process performance related to four medical conditions. Analysis reveals differing effects that are dependent on hospital slack conditions. In hospitals with high slack, quality practices significantly predict three of four studied process performance measures. In contrast, in hospitals with low slack, quality practices predict only one of the four process performance measures, while other factors outweigh the effects of quality practices. This study lends support to management taking a long-term perspective related to implementation of quality management systems, and highlights the relevance of slack conditions in garnering the benefits of such systems. (C) 2011 Elsevier B.V. All rights reserved."
407,"The influence of exchange hazards and power on opportunism in outsourcing relationships","Handley, Sean M. and Benton, Jr., W. C.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","55-68","2012","JAN","Outsourcing;Inter-Organizational Power;Transaction Cost Theory;Opportunism","","Service provider opportunism is widely noted as a principal risk with outsourcing. Indeed, economic theory regarding the factors which influence the outsourcing decision, treats opportunism as a core behavioral assumption. It is assumed that if given the opportunity, outsourcing providers will act in a self-serving manner despite the potentially negative impact it may have on their customer. Other researchers have suggested that opportunism is not an unwavering human behavior, but rather can be substantively influenced by the management practices which define the relationship. Building on these arguments, this study investigates the validity of these divergent positions. Hierarchical linear regression is used to examine dyadic data on 102 information technology, logistics, and other business process outsourcing relationships. We test a model which hypothesizes that the buying firm's reliance on different bases of inter-firm power will have differing effects on the risk of opportunism (shirking and poaching). These hypotheses are evaluated while concurrently examining the influence of exchange hazards (relationship-specific investments and technological uncertainty) on provider shirking and poaching. The results offer strong evidence that buyer reliance on mediated forms of power (i.e. rewards, coercive, legal legitimate) enhance the risk of both provider shirking and poaching, while non-mediated power (i.e. expert, referent) is associated with a diminished level of opportunistic behavior. Interestingly, relationship-specific investments have a significant effect on some forms of opportunistic behavior but not on other forms of opportunistic behavior. Technological uncertainty did not have a significant impact on provider opportunism. (C) 2011 Elsevier B.V. All rights reserved."
408,"The competitive determinants of a firm's environmental management activities: Evidence from US manufacturing industries","Hofer, Christian and Cantor, David E. and Dai, Jing","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","69-84","2012","JAN","Environmental Management;Competition;Us Manufacturing Industries","","Environmental management (EM) issues have received substantial attention in operations management. While the link between EM practices and firm performance has been well studied, little is known about the competitive drivers of a firm's EM activities. In this research, a Schumpeterian economics perspective is adopted to investigate competitive interactions among leader and challenger firms in the domain of EM, with a particular focus on operational EM activities. Using econometric methods, the empirical analysis of panel data from a broad cross-section of US manufacturing firms reveals that such rivalry does exist and that the effect of a rival's past EM activity on a focal firm's EM activity is greater for more profitable and smaller firms. In addition, firm characteristics such as market leadership, firm size and firm profitability are found to significantly affect the magnitude of a firm's EM activities. This study presents theoretical and empirical evidence of rivalrous behaviors in the domains of EM and OM and, thus, has interesting implications for operations management research and practice. (C) 2011 Elsevier B.V. All rights reserved."
409,"The moderating effects of supplier portfolio characteristics on the competitive performance impacts of supplier-facing process capabilities","Tang, Xinlin and Rai, Arun","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","85-98","2012","JAN","Supplier Relationship Management;Supplier-Facing Process Capabilities;Supplier Portfolio;Competitive Performance","","We draw on the interorganizational relationship management literature to examine how contextual characteristics of the supplier portfolio (portfolio concentration, relationship length, and supplier substitutability) moderate the impacts of process alignment and partnering flexibility - two of a firm's key supplier-facing process capabilities to manage supplier relationships - on a product line's competitive performance. Our analysis of survey data on a firm's supplier portfolio for a major product line indicates that the impacts of process alignment and partnering flexibility on competitive performance are moderated by the three supplier portfolio characteristics. Specifically, while concentrated relationship portfolios, long-term relationships, and supplier substitutability amplify the positive effect of process alignment on competitive performance, concentrated relationship portfolios and long-term relationships attenuate the competitive benefits that firms derive from partnering flexibility. While long-term relationships and concentrated supplier portfolios enhance the competitive benefits of process alignment, operations managers also need to recognize the detrimental effects of these supplier portfolio characteristics on the competitive benefits of partnering flexibility. (C) 2011 Elsevier B.V. All rights reserved."
410,"Revisiting the arcs of integration: Cross-validations and extensions","Schoenherr, Tobias and Swink, Morgan","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","99-115","2012","JAN","Supply Chain Integration;Resource-Based View (Rbv);Information Processing Theory;Arcs Of Integration;Empirical Research","","This paper revisits Frohlich and Westbrook's arcs of integration concept [Arcs of integration: an international study of supply chain strategies. Journal of Operations Management 2001, 19 (2) pp. 185-200]. Using survey responses from 403 supply chain professionals, we compare the arcs of integration group memberships generated with our sample to the original study, rationalize the classification scheme, and assess the impact of supply chain integration strategies on quality, delivery, flexibility and cost performance. In doing so we cross-validate Frohlich and Westbrook's framework with a more recent and broader sample of data utilizing multi-dimensional performance measures collected from supply chain managers. We ground these relationships in the relational and resource-based views of the firm. We also extend Frohlich and Westbrook's study by investigating the moderating role of internal integration on the relationships between arcs of integration and performance. In accordance with information processing theory, the results indicate that internal integration strengthens the positive impacts of external integration on both delivery and flexibility performance. However, the theory is not supported for either quality or cost performance. Overall, our study confirms and extends the work of Frohlich and Westbrook, augments theories used to describe supply chain integration efforts, and provides practical implications for managers. (C) 2011 Elsevier B.V. All rights reserved."
411,"Designing e-government services: Key service attributes and citizens' preference structures","Venkatesh, Viswanath and Chan, Frank K. Y. and Thong, James Y. L.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","116-133","2012","JAN","It Service Management And Design;Technology-Based Self-Services;Public Management;Service Attributes;Web Survey;Conjoint Experiment","","Advances in Internet technologies have led to the popularity of technology-based self-services, with the design of such services becoming increasingly important. Using technology-based services in the public sector as the setting, we identified the key service attributes driving adoption and use of transactional e-government services, and citizens' preference structures across these attributes. After identifying four key attributes, i.e., usability, computer resource requirement, technical support provision and security provision, we conducted a Web-based survey and a conjoint experiment among 2465 citizens. In a two-stage Web-based survey, citizens reported their perceptions about a smartcard technology for transactional e-government services before use, and their use and satisfaction 4 months later. Results showed that the key attributes (noted above) influenced citizens' intentions, subsequent use and satisfaction. In the conjoint experiment, citizens reported their preferences for key service attributes for two transactional e-government services. Further, a cluster analysis uncovered four distinct citizen segments, i.e., balanced, usability-focused, risk-conscious and resource-conservative, that can inform efforts in designing e-government services. A post hoc analysis confirmed the appropriateness of the market segmentation in understanding citizens' adoption and use of transactional e-government services. (C) 2011 Published by Elsevier B.V."
412,"Antecedents to ambidexterity competency in high technology organizations","Chandrasekaran, Aravind and Linderman, Kevin and Schroeder, Roger","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","134-151","2012","JAN","Exploration;Exploitation;High Tech Organizations;R&D Project Management","","High tech organizations confront dual demands of exploring new products/processes and exploiting existing products/processes. Research shows that ambidextrous organizations can better manage these dual demands, but our understanding of the antecedents that lead to ambidexterity is still emerging. In addition, previous research has taken a piecemeal approach to understand ambidexterity and does not fully consider its multilevel nature. This research takes a multilevel perspective and argues that a competency in ambidexterity involves three capabilities at different organizational levels: decision risk (strategic level), structural differentiation (project level), and contextual alignment (meso level). After correcting for endogeneity we empirically examine the relationship between these antecedents and ambidexterity competency by collecting multi-level data from 34 high tech business units and 110 exploration and exploitation R&D projects. The results indicate that decision risk and contextual alignment affect ambidexterity competency for high tech organizations. Structural differentiation does not affect ambidexterity competency but has mixed effects on R&D project performance. (C) 2011 Elsevier B.V. All rights reserved."
413,"The perilous effects of capability loss on outsourcing management and performance","Handley, Sean M.","JOURNAL OF OPERATIONS MANAGEMENT","30","1-2","152-165","2012","JAN","Outsourcing;Organizational Capabilities;Firm Boundary Theory;Relational View Of Inter-Organizational Competitive Advantage","","The outsourcing of manufacturing activities and business processes has emerged as a prevalent business practice in many industries. Given this state, the lackluster performance of an alarmingly high proportion of outsourcing initiatives is somewhat surprising. In an effort to achieve aggressive cost savings objectives, many outsourcing engagements are associated with organizational resources being disposed of which can lead to a significant operational capability loss on the part of the outsourcing firm. Surprisingly little empirical research has dealt with the issues arising from this capability loss frequently associated with outsourcing. This study strives to address this void. Drawing on multiple theoretical perspectives, this study investigates the direct impact that capability loss has on outsourcing performance, and also the impact it has on the outsourcing firm's ability to effectively manage its relationship with the outsourcing provider. Results from our hierarchical regression analysis on 198 outsourcing initiatives suggest an inadequate capability evaluation up front can lead to a more substantive capability loss. Subsequently, we find that a more extensive capability loss has a direct negative effect on outsourcing performance. Prior studies have established the significant positive effect that developing a committed and cooperative relationship with the provider has on outsourcing performance. Our results corroborate these previous findings, and also demonstrate that capability loss inhibits the outsourcing firm's efforts to develop a committed and cooperative relationship with the outsourcing provider. (C) 2011 Elsevier B.V. All rights reserved."
414,"Doctors' orders--If they're electronic, do they improve patient satisfaction? A complements/substitutes perspective","Queenan, Carrie C. and Angst, Corey M. and Devaraj, Sarv","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","639-649","2011","NOV","Healthcare Operations;Computerized Physician Order Entry (Cpoe);Patient Satisfaction;Technology Value;Routines;Error Prevention","","Doctors' orders entered with Computerized Physician Order Entry (CPOE) systems are designed to enhance patient care by standardizing routines that are intended to improve quality of healthcare. As with other health information technology (IT) performance studies, literature shows conflicting results regarding the CPOE-performance relationship. By adopting a more nuanced perspective and employing not just adoption but extent of use of CPOE, we first examine whether or not CPOE use improves patient satisfaction. Next, given that CPOEs are implemented in the backdrop of other hospital IT infrastructure, we examine how IT infrastructure impacts the relationship between CPOE use and satisfaction, testing both a complementary and substitution perspective. Finally, we examine the differential impact of CPOE use between academic and non-academic hospitals. Using data from 806 hospitals nationwide, we find a positive relationship between extent of CPOE use and patient satisfaction. Contrary to extant research, our results suggest this relationship is stronger in non-academic hospitals. We also find evidence that a hospital's IT infrastructure substitutes for CPOE use in its effect on patient satisfaction. (C) 2011 Elsevier B.V. All rights reserved."
415,"Status and relationships in social dilemmas of teams","Wu, Yaozhong and Loch, Christoph and Ahmad, Ghufran","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","650-662","2011","NOV","Social Preferences;Behavioral Experiment;Status;Relationship;Social Dilemma;Group Performance","","A social dilemma occurs when it is optimal for each member of a team to act in his own interest but, if all participants do so, everyone is worse-off than if they had done otherwise. Social dilemmas are often observed in operational processes involving teamwork, such as developing new products or implementing total quality programs. The extent to which an employee cooperates with others is driven not only by material incentives but also by social preferences: individuals have an interest in the welfare of others as well as their own. Two known social preferences are status and relationship maintenance. Multiple studies have shown that status seeking leads team members to compete more whereas relationship building leads them to cooperate more. The question remains of whether these two preferences can coexist and complement one another (as when status seeking triggers effort and relationship building encourages cooperation) or whether they are at odds. In this experimental study we demonstrate that these two social preferences hinder one another: status reduces the collaboration benefit from relationships, and increases only individual, but not collaborative, effort. These results suggest that managerial interventions that promote status seeking and relationship building behavior cannot easily be used simultaneously when motivating teams to perform in situations involving social dilemmas. (C) 2011 Elsevier B.V. All rights reserved."
416,"Managing coopetition through horizontal supply chain relations: Linking dyadic and network levels of analysis","Wilhelm, Miriam M.","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","663-676","2011","NOV","Horizontal Supply Chain Relations;Strategic Supply Networks;Coopetition;Toyota;Case Studies","","A growing research stream has expanded the level of analysis beyond single buyer-supplier relations to the network, including supplier-supplier relations. These supplier-supplier relations may constitute a missing link between the traditional analysis of the dyadic and the network level of analysis that are often treated separately. This paper explores the interplay of the supplier-supplier and network of analysis by focusing on the inherent tension between cooperation and competition, using a multiple case study design in the Japanese and German automobile industries. It is argued that the buyer is able to exert influence not only on the coopetition level, so within horizontal supply chain relations, but that the coopetitive tension in the overall network can in fact be managed through the active establishment and maintenance of such relations. (C) 2011 Elsevier B.V. All rights reserved."
417,"Product portfolio architectural complexity and operational performance: Incorporating the roles of learning and fixed assets","Jacobs, Mark A. and Swink, Morgan","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","677-691","2011","NOV","Marketing/Operations Interface;Marketing/Manufacturing Interface;Product Development;Theory Development;Focused Factory;Product Portfolio Complexity;Learning","","Managers struggle to cope with complexity in their product portfolios. However, research into diversification, product platforms, and other issues related to product portfolio complexity has often produced inconsistent guidance. This situation is at least partially attributable to an incomplete definition of portfolio complexity, and to corresponding limitations of theories applied to date. To address these limitations, we define product portfolio complexity as a design state manifested by the multiplicity, diversity, and interrelatedness of products within the portfolio. We conceptually establish the three-dimensional nature of complexity and present a model to provide insights into how each dimension impacts operational performance. As an extension to prior theoretical perspectives, the model explicitly addresses the roles of organizational learning and the character of fixed assets (utilization and flexibility) as mediator and moderator of product portfolio architectural complexity's effects, respectively. We also incorporate the principle of diminishing returns to address potential non-linearities in the proposed relationships. Prior theories and research studies have neglected these issues. We conclude by discussing useful perspectives with which to view the model, and by presenting measures of portfolio complexity and approaches for testing the propositions developed herein. (C) 2011 Elsevier B.V. All rights reserved."
418,"Failure to deliver? Linking online order fulfillment glitches with future purchase behavior","Rao, Shashank and Griffis, Stanley E. and Goldsby, Thomas J.","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","692-703","2011","NOV","Order Fulfillment Glitch;Future Purchase Behavior;Online Retailing;Service Failure;Archival Data;Fill Rate","","This study investigates operations failures in online retailing. Specifically, it examines the relationship between an operations glitch (order fulfillment delay) and subsequent shopping behavior for previously loyal customers in an online retailing environment. Using archival data from a moderate-sized online retailer of printed material, this study employs expectancy disconfirmation and distributive justice theories to empirically show that adverse post-glitch reactions are seen in several dimensions of customer shopping behavior - order frequency and order size decrease, while customer anxiety level increases. The study thus demonstrates that online retailers need to deliver on order fulfillment promises, since a failure to live up to these promises can be detrimental. This study is unique in that, unlike previous studies on order fulfillment in online retailing investigating the tie between fulfillment success and future behavior, we examine the repercussions of order fulfillment failures upon future purchase behavior. (C) 2011 Elsevier B.V. All rights reserved."
419,"Product safety and security in the global supply chain: Issues, challenges and research opportunities","Marucheck, Ann and Greis, Noel and Mena, Carlos and Cai, Linning","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","707-720","2011","NOV","Product Safety;Traceability;Security Risk In Supply Chain;Regulation In Supply Chain;Product Recalls","","A number of high profile product safety events and recalls have heightened public attention to the safety and security of the products that people consume and use. While product safety isn't a new topic, the effect of the global supply chain in creating or exacerbating safety risks and vulnerabilities is both timely and relevant. In this essay we focus on how the field of operations management can provide fresh perspectives and insights in addressing the challenges of product safety and security in the global supply chain. We first examine the product safety issues and challenges that arise in five industries that are increasingly globalizing their supply chains: food, pharmaceuticals, medical devices, consumer products and automobiles. We describe four areas where operations management theory and methodologies can provide fresh insights and innovative solutions in addressing these problems: regulation and standards, product lifecycle management, traceability and recall management, and supplier relationships. (C) 2011 Elsevier B.V. All rights reserved."
420,"Global supply chain design considerations: Mitigating product safety and security risks","Speier, Cheri and Whipple, Judith M. and Closs, David J. and Voss, M. Douglas","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","721-736","2011","NOV","Supply Chain;Risk;Safety","","Supply chain disruptions pose an increasingly significant risk to supply chains. This research develops a framework to examine the threat of potential disruptions on supply chain processes and focuses on potential mitigation and supply chain design strategies that can be implemented to mitigate this risk. The framework was developed by integrating three theoretical perspectives-normal accident theory, high reliability theory, and situational crime prevention. The research uses a multi-method approach to identify key safety and security initiatives (process management, information sharing, and supply chain partner and service provider relationship management) that can be implemented and the conditions under which each initiative is best suited. The research results illustrate that the depth and breadth of security initiatives depends on top management mindfulness, operational complexity, product risk, and coupling. (C) 2011 Elsevier B.V. All rights reserved."
421,"Quality risk in offshore manufacturing: Evidence from the pharmaceutical industry","Gray, John V. and Roth, Aleda V. and Leiblein, Michael J.","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","737-752","2011","NOV","Delphi/Panels;Global Operations;Manufacturing And Sourcing Strategy;Quality Risk;Production Offshoring;Quality Management","","Does offshore production pose an added quality risk relative to domestic production? If so, what factors influence the quality risk? Progress addressing these deceptively simple questions has been hindered by the challenges associated with (1) difficulties in controlling for a wide range of factors that may potentially affect quality risk in offshore manufacturing and (2) the lack of available measures that are consistent across geographic regions. This paper contributes to the academic discourse by empirically assessing differences in quality risk across domestic and offshore plants in a setting that naturally controls for many confounding factors. Specifically, we employ a sample of 30 pairs of regulated drug manufacturing plants in the U.S. mainland and Puerto Rico matched both by parent firm and by product standard industrial code (SIC). Using a plant-level measure of quality risk that is measurement invariant, our findings indicate that Puerto Rican plants operate with a significantly higher quality risk than matching plants operated by the same firm located in the mainland U.S., on average. This finding persists above and beyond potentially important factors, such as geographic distance and the local population's general and industry-specific skills. Thus, challenges related to the transfer and maintenance of the knowledge required to operate with a low quality risk across non-geographic distance are left as the most plausible explanatory factors. Practically, our research highlights the need for manufacturing firms to carefully consider increased quality risk associated with the offshoring of production, particularly with regard to process-sensitive products like drugs. From a policy standpoint, our study highlights the need for the Food and Drug Administration (FDA) to continue to intensify its inspection focus on international manufacturing. (C) 2011 Elsevier B.V. All rights reserved."
422,"Accidents happen: The influence of safety-specific transformational leadership, safety consciousness, and hazard reducing systems on warehouse accidents","de Koster, Rene B. M. and Stam, Daan and Balk, Bert M.","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","753-765","2011","NOV","Warehouse Accidents;Transformational Leadership;Safety Consciousness;Safety Systems;Behavioral Operations","","The present research investigates antecedents of safety performance in warehouses. Specifically, we study what factors influence the number of accidents that have occurred in the past three and a half years in 78 Dutch warehouses. Based on prior research in (behavioral) operations management, safety management, and organizational behavior, we identify hazard reducing systems (HRS), safety-specific transformational leadership (SSTL), and safety consciousness (SC) as potential predictors of safety performance. Path analysis on data from a survey among 78 warehouse managers and 1033 warehouse employees shows, in line with prior research, that HRS is a strong predictor of safety performance. Importantly, our results also suggest that SSTL may be an even more important predictor of safety performance than HRS. SSTL affects safety performance directly (contrary to our expectations SC does not mediate this relationship) and strongly predicts safety performance even after controlling for the effects of HRS. SSTL also mediates some of the effects of HRS on safety performance. Subsequently, we propose that leaders are critical in fostering safety on the work floor. (C) 2011 Elsevier B.V. All rights reserved."
423,"Safety hazard and time to recall: The role of recall strategy, product defect type, and supply chain player in the U.S. toy industry","Hora, Manpreet and Bapuji, Hari and Roth, Aleda V.","JOURNAL OF OPERATIONS MANAGEMENT","29","7-8, SI","766-777","2011","NOV","External Failure Costs;Safety Hazard;Product Recalls;Toy Industry","","This research identifies and tests key factors that can be associated with time to recall a product. Product recalls due to safety hazards entail societal costs, such as property damage, injury, and sometimes death. For firms, the related external failure costs are many, including the costs of recalling the product, providing a remedy, meeting the legal liability, and repairing damage to the firm's reputation. The recent spate of product recalls has shifted attention from why products are recalled to why it takes so long to recall a defective product that poses a safety hazard. To address this, our research subjects to empirical scrutiny the time to recall and its relationship with recall strategies, source of the defect and supply chain position of the recalling firm. We develop and verify our conceptual arguments in the U.S. toy industry by analyzing over 500 product recalls during a 15-year period (1993-2008). The empirical results indicate that the time to recall, as measured by difference between product recall announcement date and product first sold date, is associated with (1) the recall strategy (preventive vs. reactive) adopted by the firm, (2) the type of product defect (manufacturing defect vs. design flaw), and (3) the supply chain entity that issues the recall (toy company vs. distributor vs. retailer). Our results provide cues that could trigger a firm's recognition of factors that increase the time to recall. Published by Elsevier B.V."
424,"The effects of supplier-to-buyer identification on operational performance-An empirical investigation of inter-organizational identification in automotive relationships","Corsten, Daniel and Gruen, Thomas and Peyinghaus, Marion","JOURNAL OF OPERATIONS MANAGEMENT","29","6","549-560","2011","SEP","Operations Strategy;Social Identity Theory;Buyer-Supplier Relationships;Trust;Information Exchange;Relation-Specific Investments;Operational Performance;Empirical Research;Survey;Automotive","","Over the past decade conceptual and empirical research in operations management has embraced the idea that collaborative supplier-buyer relationships are a source of competitive advantage for manufacturing firms. Anecdotal evidence from the Japanese and U.S. automotive industry and emerging research suggests that inter-organizational identification of suppliers with their buyers, termed supplier-to-buyer identification, is an unexplored factor of relational advantage. This study presents a model and empirical test that supplier-to-buyer identification fosters superior operational performance by enhancing trust, supplier relation-specific investments, and information exchange. Through a survey of 346 automotive supplier-buyer relationships, the findings show that supplier-to-buyer identification directly impacts supplier relationship-specific investments and information exchange, although most of the latter effect is mediated by trust. The findings also indicate that supplier relation-specific investments and information exchange play different but complementary roles in influencing operational performance. The results suggest new directions for supplier-buyer relationship research in operations management and important managerial implications. (C) 2010 Elsevier B.V. All rights reserved."
425,"The dark side of buyer-supplier relationships: A social capital perspective","Villena, Veronica H. and Revilla, Elena and Choi, Thomas Y.","JOURNAL OF OPERATIONS MANAGEMENT","29","6","561-576","2011","SEP","Buyer-Supplier Relationships;Value Creation;Performance;Social Capital","","The literature on supply chain management (SCM) has consistently promoted the bright side of collaborative buyer-supplier relationships (BSRs). Based on the social capital argument, SCM scholars have investigated how a buyer can gain access to and leverage resources through its collaborative BSRs. Our study extends this research stream by considering the dark side of social capital in BSRs. It evaluates how social capital in its cognitive, relational, and structural forms contributes to or impedes value creation within BSRs. Both primary survey measures and secondary objective measures have been used in data analysis. The results show the presence of both the bright side, confirming the existing literature, and the dark side, extending the literature. There is an inverted curvilinear relationship between social capital and performance: Either too little or too much social capital can hurt performance. This study confirms that building social capital in a collaborative BSR positively affects buyer performance, but that if taken to an extreme it can reduce the buyer's ability to be objective and make effective decisions as well as increase the supplier's opportunistic behavior. Our study also examines how a buyer can delay the emergence of the dark side. It opens up new research avenues in the collaborative BSR context and suggests directions for future research and practice. (C) 2010 Elsevier B.V. All rights reserved."
426,"Balancing priorities: Decision-making in sustainable supply chain management","Wu, Zhaohui and Pagell, Mark","JOURNAL OF OPERATIONS MANAGEMENT","29","6","577-590","2011","SEP","Green Supply Chain Management;Decision-Making;Sustainability","","The need for environmental protection and increasing demands for natural resources are forcing companies to reconsider their business models and restructure their supply chain operations. Scholars and proactive companies have begun to create more sustainable supply chains. What has not been fully addressed is how organizations deal with short-term pressures to remain economically viable while implementing these newly modeled supply chains. In this study, we use theory-building through case studies to answer the question: how do organizations balance short-term profitability and long-term environmental sustainability when making supply chain decisions under conditions of uncertainty? We present five sets of propositions that explain how exemplars in green supply chain management make decisions and balance short and long term objectives. We also identify four environmental postures that help explain the decisions organizations make when dealing with strategic trade-offs among the economic, environmental and social elements of the triple-bottom-line. (C) 2010 Elsevier B.V. All rights reserved."
427,"Capabilities that enhance outcomes of an episodic supply chain collaboration","Zacharia, Zach G. and Nix, Nancy W. and Lusch, Robert F.","JOURNAL OF OPERATIONS MANAGEMENT","29","6","591-603","2011","SEP","Collaboration;Absorptive Capacity;Collaborative Process Competence;Collaborative Engagement;Buyer-Supplier Relationships;Supply Chain Management;Knowledge-Based View, Relational View;Perceived Interdependence","","Firms are increasingly dependent on the knowledge and expertise in external organizations to innovate, problem-solve, and improve supply chain performance. This research examines two capabilities that enable firms to collaborate successfully as a means to combine knowledge and expertise in an episodic collaboration initiative. Building from two theoretical foundations, the knowledge-based and relational views of the firm, we examine the effects of absorptive capacity and collaborative process competence on the outcomes of an episodic collaboration initiative. Using structural equation modeling, we empirically validate the positive effect of absorptive capacity, collaborative process competence and level of engagement on the operational and relational success of a collaboration effort. Results show that collaborative process competence mediates the relationship between absorptive capacity and collaborative engagement, and positively influences both operational and relational outcomes. Finally, we offer suggestions for managers to improve the effectiveness of inter-firm collaboration initiatives and discuss future research opportunities. (C) 2011 Elsevier B.V. All rights reserved."
428,"The contingency effects of environmental uncertainty on the relationship between supply chain integration and operational performance","Wong, Chee Yew and Boon-itt, Sakun and Wong, Christina W. Y.","JOURNAL OF OPERATIONS MANAGEMENT","29","6","604-615","2011","SEP","Environmental Uncertainty;Contingency;Supply Chain Integration;Operational Performance","","This paper extends prior supply chain research by building and empirically testing a theoretical model of the contingency effects of environmental uncertainty (EU) on the relationships between three dimensions of supply chain integration and four dimensions of operational performance. Based on the contingency and organizational information processing theories, we argue that under a high EU the associations between supplier/customer integration, and delivery and flexibility performance, and those between internal integration, and product quality and production cost, will be strengthened. These theoretical propositions are largely confirmed by multi-group and structural path analyses of survey responses collected from 151 of Thailand's automotive manufacturing plants. This paper contributes to operations management contingency research and provides theory-driven and empirically proven explanations for managers to differentiate the effects of internal and external integration efforts under different environmental conditions. (C) 2011 Elsevier B.V. All rights reserved."
429,"Focus as emphasis: Conceptual and performance implications for hospitals","McDermott, Christopher M. and Stock, Gregory N.","JOURNAL OF OPERATIONS MANAGEMENT","29","6","616-626","2011","SEP","Focus;Hospitals;Strategy;Empirical","","Focus in hospitals has been heralded as the next frontier in improving its efficiency and efficacy (Herzlinger, 2004). However, there is scarce empirical work examining its effects in this setting. Focus in hospitals can take several different forms, ranging from standalone specialty centers to a hospital that chooses to emphasize in some operational way a particular specialty while still offering a full range of services. Although standalone facilities can be found in many locations, the vast majority of hospitals must follow the latter route to achieve focus. Current conceptualizations and measures of focus struggle to capture this construct in a way that does not assume a narrowing of range of offerings. In contrast to the traditional view of focus as narrowing, in this paper, we address the perspective of focus as emphasis. We select cardiology as the specialty and use secondary data for more than 264,000 patients in New York State to examine the relationship between focus as emphasis and hospital cost performance. Our results support the notion that such focus is associated with lower costs. Moreover, our results also show that focus in hospitals can be operationalized as a disproportionate emphasis on one line of service, without necessarily narrowing the overall range of services provided. (C) 2011 Elsevier B.V. All rights reserved."
430,"Content analytic approach to measuring constructs in operations and supply chain management","Tangpong, Chanchai","JOURNAL OF OPERATIONS MANAGEMENT","29","6","627-638","2011","SEP","Content Analysis;Convergence Study;Measurement;Research Methodology;Operations;Supply Chain Management","","This paper presents and illustrates the content analytic approach to measuring constructs in operations and supply chain management (OSCM). In this paper, a methodological review of OSCM empirical research in 2002-2007 is provided to highlight that OSCM empirical studies, unlike those in other business disciplines, have rarely used content analysis as a methodological tool. This paper then reviews the methodological strengths of content analysis, which lie primarily in its malleability, economy of data collection, repeatability, and unobtrusiveness. These strengths not only make content analysis a viable empirical method but also position it as a method that can be used in concert with other empirical methods in OSCM research, such as survey, case study, and secondary research methodologies. This paper also proposes a generic framework for a content analytic approach to measuring theoretical constructs, illustrates the application of the framework to a construct in the OSCM literature (buyer-supplier relationalism), and reports the satisfactory results of reliability and validity tests for the content analysis-based measure of buyer-supplier relationalism. In addition. this paper proposes and demonstrates that the use of convergence study in tandem with content analysis can substantially reduce the content analysis efforts needed in measuring the construct of interest, thus improving the overall efficiency of the process of content analysis. (C) 2010 Elsevier B.V. All rights reserved."
431,"Lean principles, learning, and knowledge work: Evidence from a software services provider","Staats, Bradley R. and Brunner, David James and Upton, David M.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","376-390","2011","JUL","Lean Production;Knowledge Work;Learning;Operations Strategy;Software","","In this paper, we examine the applicability of lean production to knowledge work by investigating the implementation of a lean production system at an Indian software services firm. We first discuss specific aspects of knowledge work task uncertainty, process invisibility, and architectural ambiguity that call into question the relevance of lean production in this setting. Then, combining a detailed case study and empirical analysis, we find that lean software projects perform better than non-lean software projects at the company for most performance outcomes. We document the influence of the lean initiative on internal processes and examine how the techniques affect learning by improving both problem identification and problem resolution. Finally, we extend the lean production framework by highlighting the need to (1) identify problems early in the process and (2) keep problems and solutions together in time, space, and person. (C) 2010 Elsevier B.V. All rights reserved."
432,"Creating value through returns management: Exploring the marketing-operations interface","Mollenkopf, Diane A. and Frankel, Robert and Russo, Ivan","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","391-403","2011","JUL","Cross-Functional Integration;Customer Value;Returns Management;Marketing-Operations Interface","","Managing the return flow of product is increasingly recognized as a strategically important activity that involves decisions and actions within and across firms. We focus specifically on returns management at the marketing-operations interface, by utilizing the conceptualization of customer value and its related drivers. In order to explore the phenomenon of returns management across a multi-disciplinary, managerial spectrum, a qualitative research methodology relying on individual managers' perceptions was chosen to generate depth of understanding given the limited current understanding of the research topic under consideration. Our results suggest that functional integration at the marketing-operations interface can lead to better alignment of corporate resources and thus create higher levels of customer value. We also found the external business environment to impact how and why a firm creates customer value through the returns management process. Overall, our results suggest that when returns management is recognized as a matter of a firm's competitiveness, the joint role of operations and marketing is imperative to success. (C) 2010 Elsevier B.V. All rights reserved."
433,"Field vehicle fleet management in humanitarian operations: A case-based approach","Martinez, Alfonso J. Pedraza and Stapleton, Orla and Van Wassenhove, Luk N.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","404-421","2011","JUL","Humanitarian;Case-Based;Transportation;Supply Chain","","Transportation is the second largest overhead cost to humanitarian organizations after personnel. Academic knowledge about fleet management in humanitarian operations is scarce. Using a multiple case research design we study Field Vehicle Fleet Management (Field VFM) in four large International Humanitarian Organizations (IHO): the International Committee of the Red Cross, the International Federation of Red Cross and Red Crescent Societies, the World Food Program and World Vision International. Our field research includes more than 40 interviews at headquarters, regional and national level in Africa, the Middle East and Europe. The paper answers three research questions: (1) How do IHO manage their field vehicle fleets? (2) What are the critical factors affecting IHO Field VFM? (3) How does Field VFM affect in-country program delivery? The contribution of this research is twofold. First, it helps to fill the existing gap in the humanitarian literature regarding Field VFM. Second, it expands the fleet management literature to a new and virtually unexplored area. (C) 2010 Elsevier B.V. All rights reserved."
434,"Lean service operations: Reflections and new directions for capacity expansion in outpatient clinics","LaGanga, Linda R.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","422-433","2011","JUL","Lean Process Improvement;Service Operations;Appointment Scheduling;Health Care Policy;No-Shows;Overbooking","","This field research in outpatient service operations examines original quantitative data on appointments and analyzes a lean process improvement project that was conducted to increase capacity to admit new patients into a healthcare service operation system. Analysis of 1726 intake appointments for the year preceding and the full year following the lean project showed a 27% increase in service capacity to intake new patients and a 12% reduction in the no-show rate as a result of the transformation of service processes achieved by the lean project. This study's action research methodology leverages the researcher's involvement in redesigning a service system that greatly improved performance and led to reflection on traditional operations management (OM) approaches to appointment scheduling. The study generates insights about effective alignment of resources, develops new strategies for service operations to respond to no-shows, reveals time-related variables that have been overlooked in appointment scheduling research, and challenges traditional OM scheduling performance measures. We provide recommendations for effective and appropriate use of overbooking and identify avenues for future research to continuously improve and increase the capacity of service operations. (C) 2010 Elsevier B.V. All rights reserved."
435,"Cross-functional alignment in supply chain planning: A case study of sales and operations planning","Oliva, Rogelio and Watson, Noel","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","434-448","2011","JUL","Operations Interface;Sales And Operations Planning;Supply Chain Planning;Case Study","","In most organizations, supply chain planning is a cross-functional effort. However, functional areas such as sales, marketing, finance, and operations traditionally specialize in portions of the planning activities, which results in conflicts over expectations, preferences, and priorities. We report findings from a detailed case analysis of a supply chain planning process that seemingly weathers these cross-functional conflicts. In contrast to traditional research on this area, which focuses on incentives, responsibilities, and structures, we adopt a process perspective and find that integration was achieved despite formal functional incentives that did not support it. By drawing a distinction between the incentive landscape and the planning process, we identify process as a mediator that can affect organizational outcomes. Thus, organizations may be capable of integration while functions retain different incentives and orientations to maintain focus on their stakeholders' needs. Through iterative coding, we identify the attributes of the planning process that can drive planning performance information, procedural, and alignment quality but also find evidence that achieving alignment in the execution of plans can be more important than informational and procedural quality. In addition to process attributes, we also identify social elements that influenced the performance of the planning process and place the information processing attributes within a broader social and organizational context. (C) 2010 Elsevier By. All rights reserved."
436,"Learning and relearning effects with innovative service designs: An empirical analysis of top golf courses","Heim, Gregory R. and Ketzenberg, Michael E.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","449-461","2011","JUL","Service Operations;Service Development;Innovation;Learning Curve;Window Of Opportunity","","This paper examines learning and relearning effects for initial service designs and later service redesigns. We analyze an experience-based service where external design firms typically perform service design and implementation tasks, while local service personnel manage daily operations. We examine whether the quality of service during routine operation periods exhibits learning effect patterns. We also examine window of opportunity effects after major redesigns. Examining Yearly data on top Texas golf courses, we observe learning across the lifespan of golf courses and relearning after golf course redesigns. The findings contribute to the literature on learning and experience-based services. The study provides managerial insight by demonstrating the extent of learning, illustrating how redesigns can affect service outcomes negatively, showing how relearning occurs, and discussing tactics for success when redesigning services. (C) 2010 Elsevier B.V. All rights reserved."
437,"The development and application of a process model for R&D project management in a high tech firm: A field study","Verma, Devesh and Mishra, Anant and Sinha, Kingshuk K.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","462-476","2011","JUL","Project Management;Process Model;Portfolio Management;Product Development;High Tech Firm;Field Study","","In R&D organizations of high tech firms, multiple R&D projects are executed concurrently and timeliness of project completion - i.e., developing the right products at the right times - is a matter of serious concern. Given that the priority of R&D projects and the interdependencies between the projects in a high tech firm change dynamically, high tech R&D project management is a complex and challenging endeavor. To improve the understanding and management of high tech R&D projects, this paper reports the findings of a field study where we, first, develop and empirically estimate a model that relates project priority over time with the generative mechanisms of market pull and technical challenge associated with R&D projects. Next, we develop and demonstrate the application of a process model within which the time-varying project priority model is embedded. The process model makes it possible to allocate fixed resources among competing projects with time-varying interdependencies, thereby improving the timeliness of project completion. This research was conducted in collaboration with a major U.S. high tech firm. The corporate R&D center of the firm served as the research setting for the field study. We present an application of the process model to delineate the evolution of the R&D organization with the merger of its (technology driven) parent firm with another (market driven) high tech manufacturing firm. The application of the process model generates theoretical insights that are used to develop testable propositions. Implications of the study findings and directions for future research are discussed. (C) 2010 Elsevier B.V. All rights reserved."
438,"Customization of the online purchase process in electronic retailing and customer satisfaction: An online field study","Thirumalai, Sriram and Sinha, Kingshuk K.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","477-487","2011","JUL","Customization;Online Purchase Process;Customer Satisfaction;Online Field Study;Electronic Retailing","","This paper investigates the customization of the online purchase process in electronic retailing. We conceptualize customization relevant to the two constituent sub-processes in the online purchase process: (i) decision customization the customization of the information content delivered to customers to help them in the decision-making sub-process; and (ii) transaction customization the customization of the purchase transaction sub-process for each customer. We draw on and synthesize the theoretical perspectives of Website Usability, Technology Acceptance Model, and Transaction Costs, to triangulate and deduce hypotheses linking customization of the online purchase process in electronic retailing and customer satisfaction. The hypotheses are tested by analyzing: (i) primary data on customization of the online purchase process collected from an online field study involving a direct observation and content analysis of the websites of 422 retailers; and (ii) secondary data on customer satisfaction with the online purchase process for the same set of 422 electronic retailers collected from a publicly available data source. The research method used for the empirical analysis is Multivariate Analyses of Covariance (MANCOVA). The results indicate that decision customization that provides choice assistance by way of personalized product recommendations is positively associated with customer satisfaction with the decision-making sub-process; and transaction customization, oriented towards making the transaction sub-process personal, convenient, and interactive is positively associated with customer satisfaction with the purchase transaction sub-process. Additionally, the results indicate that both decision customization and transaction customization are associated with overall customer satisfaction with the online purchase process of electronic retailers. The contributions, managerial implications, and limitations of the study, and directions for future research are discussed. (C) 2010 Elsevier B.V. All rights reserved."
439,"Common inventory modeling assumptions that fall short: Arborescent networks, Poisson demand, and single-echelon approximations","Cattani, Kyle D. and Jacobs, F. Robert and Schoenfelder, Jan","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","488-499","2011","JUL","Multi-Echelon;Inventory Modeling Assumptions;Centralized Versus Decentralized Control;Distribution Inventory","","Traditional multi-echelon inventory theory focuses on arborescent supply chains that use a central warehouse which replenishes remote warehouses. The remote warehouses serve customers in their respective regions. Common assumptions in the academic literature include use of the Poisson demand process and instantaneous unit-by-unit replenishment. In the practitioner literature, single-echelon approximations are advised for setting safety stock to deal with lead time, demand, and supply variations in these settings. Using data from a U.S. supplier of home improvement products, we find that neither the assumptions from the academic literature nor the approximations from the practitioner literature necessarily work well in practice. In a variation of the strictly arborescent supply chain, the central warehouse at our real company not only replenishes other warehouses but also meets demand from customers in the region near the central warehouse. In this paper, we study this dual-role central warehouse structure, which we believe is common in practice. Using high and low volume product demand data from this company, we use Monte Carlo simulations to study the impact of (1) the use of a dual-role centralized warehouse, (2) common demand assumptions made in multi-echelon research, and (3) single-echelon approximations for managing a multi-echelon supply chain. We explore each of these under both centralized and decentralized control logic. We find that the common assumptions of theoretical models impede their usefulness and that heuristics that ignore the actual supply chain structure fail to account for additional opportunities to utilize safety stock more effectively. Researchers should be aware of the gap between standard assumptions in traditional literature and actual practice, and critically evaluate their assumptions to find a reasonable balance between tractability and relevance. (C) 2010 Elsevier B.V. All rights reserved."
440,"Best practice interventions: Short-term impact and long-term outcomes","Done, Adrian and Voss, Chris and Rytter, Niels Gorm","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","500-513","2011","JUL","Best Practice;Capability Development;Small And Medium Sized Enterprises (Smes)","","This paper uses empirical field research to examine whether short-term best practice interventions (BPIs) can lead to improvements that are sustained in the long term. In addition, this research investigates the implied conflict between striving for short-term results and achieving long-term development of capabilities. It also examines the tension between the lack of resources of the typical small and medium sized enterprise (SME) users of BP's and the time required to develop a critical mass of capability. A longitudinal case-based study of eight SME contexts examined BPI outcomes and factors leading to short- and long-term success and sustaining best practices. The research identifies factors related to the intervention context, implementation and change-agent approach. The data indicate that in resource-limited SMEs BPIs are limited in their ability to develop adequate capability for long-term change. (C) 2010 Elsevier B.V. All rights reserved."
441,"Exploring internal and external supply chain linkages: Evidence from the field","Barratt, Mark and Barratt, Ruth","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","514-528","2011","JUL","Supply Chain Management;External Linkages;Internal Linkages;Case Studies","","In their pursuit of improved operational performance, organizations in supply chains have sought to develop external information-based linkages with their customers and vendors. Has this course of action been at the expense of developing similar internal information-based linkages? This research explores the specific roles of internal and external information-based linkages in achieving improved operational performance. Based on a single case study that comprises a supply chain containing twenty-four internal and fourteen external linkages this research develops a series of propositions. We find that the individual internal linkages may be useful for extending externally derived visibility, and for addressing to some extent, structural holes in the supply chain. Additionally, to extend visibility across the entire supply chain, organizations need to recognize the combining role of internal and external information-based linkages. Finally we offer some thoughts for future research in this area. (C) 2010 Elsevier B.V. All rights reserved."
442,"Toward a theory of managing context in Six Sigma process-improvement projects: An action research investigation","Nair, Anand and Malhotra, Manoj K. and Ahire, Sanjay L.","JOURNAL OF OPERATIONS MANAGEMENT","29","5, SI","529-548","2011","JUL","Process Improvement Projects;Project Success;Project Context;Configurations;Action Research;Theory Building","","In this paper, field studies, extant literature, and domain knowledge are used to develop a theory of managing context in Six Sigma process-improvement projects. By means of a participatory action research investigation involving ten projects in manufacturing and service firms, this paper examines the interrelationship among project context, elements, and success. Rich text-based information for each project was analyzed for the underlying patterns and relationships using the NVIVO 8 qualitative data analysis software package. The insights gained from this in-depth field investigation are presented in the form of 12 inductively derived research propositions that, when taken together, uniquely contribute to context-based theory-building in this area. (C) 2010 Elsevier B.V. All rights reserved."
443,"Social capital configuration, legal bonds and performance in buyer-supplier relationships","Carey, Sinead and Lawson, Benn and Krause, Daniel R.","JOURNAL OF OPERATIONS MANAGEMENT","29","4","277-288","2011","MAY","Buyer-Supplier Relationships;Social Capital Theory;Performance","","Academics have increasingly recognized the benefits derived from social networks embedded within companies' buyer-supplier relationships. However, prior research has only examined the influence of social capital elements on performance, either individually or in part. We propose an integrative model examining the relationships among relational, structural and cognitive dimensions of social capital, and between these dimensions and the cost and innovation performance of the firm. A sample of 163 buyer-supplier relationships is used to test the model. Regression results indicate that the relational dimension of social capital fully or partially mediates the effect of the cognitive dimension on performance, and partially mediates the link between the structural dimension, operationalized as social interaction ties, and innovation performance. Further, high levels of legal bonds were found to moderate the relationship between the relational dimension of social capital and performance outcomes. Implications for theory and managers are discussed. Crown Copyright (C) 2010 Published by Elsevier B.V. All rights reserved."
444,"The impact of a firm's make, pseudo-make, or buy strategy on product performance","Park, Jin-Kyu and Ro, Young K.","JOURNAL OF OPERATIONS MANAGEMENT","29","4","289-304","2011","MAY","Modular/Integral Product Architecture;Make/Pseudo-Make/Buy Sourcing Strategy;Us Bicycle Industry","","The bulk of the product architecture and make-buy choice literature deals with product architecture changes from integral to 'modular form. This development is often associated with a firm's tendency to change from a make to a buy strategy. However, a few studies investigate the change of product architecture in the reverse direction - from modular to integral form - and the subsequent change in the firm sourcing decision from a buy to a make strategy. These studies hold to the presumption that a firm following a make strategy will outperform firms following a buy strategy in dealing with integral product architectures. Based on the knowledge-based view, we argue for the viability of a sourcing strategy between the pure make and buy strategies - a pseudo-make strategy. We also argue that as product architecture changes from a modular to integral form, firms adopting this pseudo-make strategy are likely to show better product performance than firms following a pure make or buy strategy due to the relative knowledge advantages of the pseudo-make strategy in dealing with the integral product architecture. We examine the impact of the make/pseudo-make/buy strategies on product performance in the U.S. bicycle derailleur and freewheel market from 1980 to 1992 and provide theoretical and managerial implications of our results. Our findings highlight an important distinction between the pseudo-make and make-buy strategies that has not previously been fully appreciated in the extant literature, and as a result increases our understanding of why some firms do not switch strategies from a buy to a make strategy when product architecture changes from modular to integral form as previously expected. (C) 2011 Published by Elsevier B.V."
445,"Unlimited shelf space in Internet supply chains: Treasure trove or wasteland?","Rabinovich, Elliot and Sinha, Rajiv and Laseter, Timothy","JOURNAL OF OPERATIONS MANAGEMENT","29","4","305-317","2011","MAY","E-Commerce;Marketing-Operations Interface;Empirical Study","","Internet retailing offers merchants limitless shelf space. This has led experts to highlight the existence of a long tail of offerings on the web and assert that the future of online business is selling less of more. However, it is difficult for Internet retailers of physical goods to sell a large scope of products without having to handle potentially large amounts of product returns from customers. This is due to the fact that customers can and do get overwhelmed by excessive product variety and often make erroneous purchasing decisions. We shed light on this issue through an assessment of theoretical predictions based on data from sales and returns of almost 7000 products in a particular product category. While retailers can benefit from expanding the scope of their inventories to generate Internet sales, the success of this strategy will depend on the control of unjustified product returns by consumers and the management of recurrent execution errors and product fit failures in transactions with customers. Furthermore, from our results, the gains that this strategy will bring to retailers will be bound by the amount of time products have been available on the Internet retailer's site, as well as by other attributes such as product price and size. (C) 2010 Elsevier B.V. All rights reserved."
446,"The boundary spanning capabilities of purchasing agents in buyer-supplier trust development","Zhang, Chun and Viswanathan, Sridhar and Henke, Jr., John W.","JOURNAL OF OPERATIONS MANAGEMENT","29","4","318-328","2011","MAY","Boundary Spanners;Supplier Relations;Trust","","This study examines how individual purchasing agents function as boundary spanners with suppliers to influence trust development in themselves and the buying firms that employ them. Building upon boundary theory and supply chain cooperation research, we identify three boundary spanning capabilities of purchasing agents and empirically test how these capabilities shape buyer-supplier trust development. Using two samples of data collected from suppliers in the automotive industry and food industry, we found that a purchasing agent's effectiveness in strategic communication with suppliers affects a supplier's trust in the buying firm, while an agent's professional knowledge and ability to reach compromises with suppliers affect a supplier's trust in the purchasing agent representing the firm. Trust in the purchasing agent in turn affects trust in the buying firm. Theoretical and managerial implications are discussed. (C) 2010 Elsevier B.V. All rights reserved."
447,"Qualitative case studies in operations management: Trends, research outcomes, and future research implications","Barratt, Mark and Choi, Thomas Y. and Li, Mei","JOURNAL OF OPERATIONS MANAGEMENT","29","4","329-342","2011","MAY","Case Studies;Research Methods;Inductive;Deductive;Qualitative;Theory Building;Theory;Testing","","Our study examines the state of qualitative case studies in operations management. Five main operations management journals are included for their impact on the field. They are in alphabetical order: Decision Sciences. International journal of Operations and Production Management Journal of Operations Management. Management Science, and Production and Operations Management. The qualitative case studies chosen were published between 1992 and 2007. With an increasing trend toward using more qualitative case studies, there have been meaningful and significant contributions to the field of operations management, especially in the area of theory building. However, in many of the qualitative case studies we reviewed, sufficient details in research design, data collection, and data analysis were missing. For instance, there are studies that do not offer sampling logic or a description of the analysis through which research outcomes are drawn. Further, research protocols for doing inductive case studies are much better developed compared to the research protocols for doing deductive case studies. Consequently, there is a lack of consistency in the way the case method has been applied. As qualitative researchers, we offer suggestions on how we can improve on what we have done and elevate the level of rigor and consistency. Published by Elsevier B.V."
448,"Agile manufacturing: Relation to JIT, operational performance and firm performance","Inman, R. Anthony and Sale, R. Samuel and Green, Jr., Kenneth W. and Whitten, Dwayne","JOURNAL OF OPERATIONS MANAGEMENT","29","4","343-355","2011","MAY","Agile Manufacturing;Jit Systems;Organizational Performance;Structural Equation Modeling","","A structural model incorporating agile manufacturing as the focal construct is theorized and tested. The model includes the primary components of JIT (JIT-purchasing and JIT-production) as antecedents and operational performance and firm performance as consequences to agile manufacturing. Using data collected from production and operations managers working for large U.S. manufacturers, the model is assessed following a structural equation modeling methodology. The results indicate that JIT-purchasing has a direct positive relationship with agile manufacturing while the positive relationship between JIT-production and agile manufacturing is mediated by JIT-purchasing. The results also indicate that agile manufacturing has a direct positive relationship with the operational performance of the firm, that the operational performance of the firm has a direct positive relationship with the marketing performance of the firm, and that the positive relationship between the operational performance of the firm and the financial performance of the firm is mediated by the marketing performance of the firm. (C) 2010 Elsevier B.V. All rights reserved."
449,"Lean, leaner, too lean? The inventory-performance link revisited","Eroglu, Cuneyt and Hofer, Christian","JOURNAL OF OPERATIONS MANAGEMENT","29","4","356-369","2011","MAY","Inventory Management;Financial/Economic Analysis;Lean Manufacturing;Empirical Research Methods","","While firms increasingly adopt lean inventory practices, there is limited evidence that inventory leanness leads to improved firm performance. This study reexamines this relationship in an attempt to overcome some shortcomings of previous research. To that end, a theory-based measure of inventory leanness, which takes into account industry-specific inventory management characteristics, is proposed. The analysis of a large panel data set of U.S. manufacturing companies reveals that the significance and shape of the inventory-performance relationship varies substantially across industries. This relationship is significant in two-thirds of the 54 industries studied. In most of these instances, the relationship is concave, suggesting that there is an optimum level of inventory leanness beyond which firm performance deteriorates. A post-hoc analysis is conducted to identify industry-level characteristics that may determine the nature the inventory-performance relationship. Managerial implications are discussed and several opportunities for future research are outlined. (C) 2010 Elsevier B.V. All rights reserved."
450,"Supply chain collaboration: Impact on collaborative advantage and firm performance","Cao, Mei and Zhang, Qingyu","JOURNAL OF OPERATIONS MANAGEMENT","29","3","163-180","2011","MAR","Supply Chain Collaboration;Collaborative Advantage;Survey Research;Structural Equation Modeling","","Facing uncertain environments, firms have strived to achieve greater supply chain collaboration to leverage the resources and knowledge of their suppliers and customers. The objective of the study is to uncover the nature of supply chain collaboration and explore its impact on firm performance based on a paradigm of collaborative advantage. Reliable and valid instruments of these constructs were developed through rigorous empirical analysis. Data were collected through a Web survey of U.S. manufacturing firms in various industries. The statistical methods used include confirmatory factor analysis and structural equation modeling (i.e., LISREL). The results indicate that supply chain collaboration improves collaborative advantage and indeed has a bottom-line influence on firm performance, and collaborative advantage is an intermediate variable, that enables supply chain partners to achieve synergies and create superior performance. A further analysis of the moderation effect of firm size reveals that collaborative advantage completely mediates the relationship between supply chain collaboration and firm performance for small firms while it partially mediates the relationship for medium and large firms. (C) 2010 Elsevier B.V. All rights reserved."
451,"An empirical investigation of scheduling performance criteria","De Snoo, Cees and Van Wezel, Wout and Jorna, Rene J.","JOURNAL OF OPERATIONS MANAGEMENT","29","3","181-193","2011","MAR","Planning, Scheduling And Control;Scheduling Performance;Performance Measurement;Quality Of Planning;Uncertainty;Empirical Research Methods","","Planning and scheduling significantly influence organizational performance, but literature that pays attention to how organizations could or should organize and assess their planning processes is limited. We extend planning and scheduling theory with a categorization of scheduling performance criteria, based on a three-stage survey research design. Particularly, the results show that, next to schedule quality, the planning process factors timeliness, flexibility, communication, and negotiation are important performance criteria, and especially so in organizations that are faced with high levels of uncertainty. The results suggest that organizational and behavioral aspects of planning and scheduling cannot be mitigated with advanced models and software that solely focus on good schedules. Rather, high quality schedules and high quality scheduling processes need to be facilitated simultaneously to attain high planning and scheduling performance. (C) 2010 Elsevier B.V. All rights reserved."
452,"Structural investigation of supply networks: A social network analysis approach","Kim, Yusoon and Choi, Thomas Y. and Yan, Tingting and Dooley, Kevin","JOURNAL OF OPERATIONS MANAGEMENT","29","3","194-211","2011","MAR","Supply Networks;Supply Chain Management;Second-Tier Suppliers;Social Network Analysis;Network Structure;Structural Analysis;Network Indices","","A system of interconnected buyers and suppliers is better modeled as a network than as a linear chain. In this paper we demonstrate how to use social network analysis. to investigate the structural characteristics of supply networks. Our theoretical framework relates key social network analysis metrics to supply network constructs. We apply this framework to the three automotive supply networks reported in Choi and Hong (2002). Each of the supply networks is analyzed in terms of both materials flow and contractual relationships. We compare the social network analysis results with the case-based interpretations in Choi and Hong (2002) and conclude that our framework can both supplement and complement case-based analysis of supply networks. (C) 2010 Elsevier B.V. All rights reserved."
453,"Efficiency meets accountability: Performance implications of supply chain configuration, control, and capabilities","Parmigiani, Anne and Klassen, Robert D. and Russo, Michael V.","JOURNAL OF OPERATIONS MANAGEMENT","29","3","212-223","2011","MAR","Supply Management;Social Responsibility;Environmental Issues;International/Global Issues","","The public increasingly holds firms accountable for social and environmental outcomes, such as product toxicity problems and human rights violations, throughout their global supply chains. How can companies improve the social and environmental performance within their supply chains, particularly as other competitive pressures, such as cost and quality, continue to escalate? Starting from an efficient versus responsive supply chain framework, we develop an integrative model that blends together elements of supply chain configuration, stakeholder management, and capability development. Specifically, we spotlight the dimensions of control and accountability that collectively determine stakeholder exposure, and show how this new construct affects the linkages between supply chain capabilities, configuration, and performance. In particular, this analysis reveals that the nature of stakeholder exposure determines how social/environmental technical and relational capabilities impact social and environmental outcomes. We conclude with implications for research and practice, discussing how current supply chain theories must be extended to incorporate external stakeholders, to clarify strategies and identify potential pitfalls, and to better predict performance outcomes. Published by Elsevier B.V."
454,"Improving operational performance by influencing shopfloor behavior via performance management practices","de Leeuw, Sander and van den Berg, Jeroen P.","JOURNAL OF OPERATIONS MANAGEMENT","29","3","224-235","2011","MAR","Performance Management;Performance Measurement;Shopfloor Behavior;Survey Research","","It is generally believed that companies applying performance management practices outperform those that do not measure and manage their performance. Studies examining the link between performance management and performance improvement implicitly assume that performance management affects behavior of individuals in an organization, which then facilitates the achievement of organizational goals. This study takes a step towards understanding this implicit assumption. We investigate how performance management practices relate to improvement in performance by influencing behavior of individuals. We focus on operational performance management, i.e. the definition and use of performance measures on the shopfloor in production and distribution. We use a survey among 102 companies to identify the relations between performance management practices, shopfloor behavior and improvement in performance. We identified three independent clusters of operator behavior that positively correlate with performance improvement: Understanding, Motivation and Focus on Improvement. We show that 17 out of the 20 performance management practices found in literature have a significant and positive relation with one or more clusters of operator behavior. We furthermore found that there is a positive correlation between the number of performance management practices applied and performance improvement, suggesting that it is not only which practices are applied but also how many. Recommendations emerging from this study enable managers to identify which behavioral changes are desired to improve performance and to select those performance management practices that positively influence the desired behavior. (C) 2011 Elsevier B.V. All rights reserved."
455,"The effect of transaction costs, payment terms and power on the level of raw materials inventories","Emery, Gary W. and Marques, Manuela A.","JOURNAL OF OPERATIONS MANAGEMENT","29","3","236-249","2011","MAR","Inventories;Transaction Costs;Customer Power","","This paper proposes and tests an explanation for the level of raw materials inventories based on transaction cost economics theory and the role of power in a supply chain. According to this explanation, raw materials inventories are larger the higher a company's transaction costs and the lower its storage-related production and management costs. Factors that affect these costs are the company's vulnerability to opportunism, whether the input becomes more or less costly to store and manage as it moves through the supply chain, payment terms and the company's power in relation to its supplier. This explanation for the level of raw materials inventories was tested on a large sample of customer industries matched to their main supplier industries. Consistent with this theory, the empirical results show that companies hold larger raw materials inventories the more money their suppliers spend on research and development and the less important the customers are to their suppliers. These results are important because they indicate companies must consider a wider range of factors than previously thought necessary when establishing inventory policy. (C) 2011 Published by Elsevier B.V."
456,"What drives financial performance-resource efficiency or resource slack? Evidence from U.S. Based Manufacturing Firms from 1991 to 2006","Modi, Sachin B. and Mishra, Saurabh","JOURNAL OF OPERATIONS MANAGEMENT","29","3","254-273","2011","MAR","Inventory;Production;Marketing;Finance/Operations Interface;Mixed Models;Secondary Data","","Extant research in operations management has revealed divergent insights into the value potential of resource efficiency. While one view relates efficiency with good operations management and asserts that slack resources are a form of waste that should be minimized, the other view suggests that limited resource slack can impose heavy costs on firms by making them brittle. In this research, the authors build on these views to investigate the relationship of inventory, production, and marketing resource efficiency of firms with three metrics of financial performance (i.e., Stock-Returns, Tobin's Q, and Returns-on-Assets). The authors evaluate the theoretical framework using secondary information on all U.S. based publicly-owned manufacturing firms across the 16-year time period of 1991-2006. Analysis utilizing a mixed-model approach reveals that a focus on resource efficiency is positively associated with firm financial performance. However, findings also support the arguments favoring slack, indicating that the financial gains from resource efficiency exhibit diminishing returns. (C) 2011 Elsevier B.V. All rights reserved."
457,"The antecedents of process integration in business process outsourcing and its effect on firm performance","Narayanan, Sriram and Jayaraman, Vaidyanathan and Luo, Yadong and Swaminathan, Jayashankar M.","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","3-16","2011","JAN","Global Outsourcing Strategies;Information Technology Enabled Services;Emerging Markets;Bpo Integration","","As service processes become candidates for outsourcing, interest in the global business process outsourcing (BPO) industry has grown considerably. In this study, drawing on information processing theory, we examine the role of integration in BPO and its effect on BPO firm performance. BPO Integration is concerned with the overall coordination of business processes and activities across different units within the outsourced environment. It involves both internal process integration - effective integration of task execution within the BPO and external process integration - effective integration between the BPO and their clients. Using survey data gathered from 205 Indian BPO service providers, we analyze the antecedents of process integration and its impact on BPO performance. The antecedents we examine are task complexity, task security, end customer orientation of the client and IT capability of the BPO. Among other results, we find that both internal and external process integration partially mediate the impact of the antecedents on performance. We draw managerial implications of our research to practicing BPO and client managers on how BPO outsourcing can be made successful. (C) 2010 Elsevier B.V. All rights reserved."
458,"Through the service operations strategy looking glass: Influence of industrial sector, ownership, and service offerings on B2B e-marketplace failures","Rosenzweig, Eve D. and Laseter, Timothy M. and Roth, Aleda V.","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","33-48","2011","JAN","B2B E-Commerce;Service Operations Strategy;E-Services;Business Failure;Logistic Regression Analysis;Internet Service Delivery Systems","","This paper contributes to the emerging area of e-service strategy in the context of business-to-business (B2B) e-marketplaces, which we view as Internet-based service delivery systems that link sellers' offerings to buyers. Although a myriad of new B2B e-marketplaces were launched over the past decade, a substantial number failed shortly after the peak of the NASDAQ in 2000. The bursting of the Internet bubble provides a setting for assessing salient, theory-based determinants of failure and success. Accordingly, we apply a service operations strategy lens and complementary organizational theories to explain how three strategic factors industrial sector characteristics, ownership structure, and functionality of service offering may have influenced B2B e-marketplaces' odds of survival after the bubble. We empirically test these factors using logistic regression analysis on a sample of 854 B2B e-marketplaces. Consistent with emerging e-services literature, our empirical results indicate that B2B e-marketplaces serving industrial sectors that are a better fit with the Internet service delivery systems by high information dependence and low information tacitness have the highest likelihood of success, as do e-marketplaces with service offerings that facilitate collaboration among multiple buyers and sellers. We also demonstrate the positive influence of consortium ownership structure on B2B e-marketplace survival, albeit not for first-mover consortia-backed e-marketplaces. Our findings contribute to the service operations strategy literature and provide direction for managers in the areas of e-service strategy and investment. (C) 2010 Elsevier B.V. All rights reserved."
459,"Contingency theory of capacity planning: The link between process types and planning methods","Tenhiaelae, Antti","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","65-77","2011","JAN","Complexity;Fit;Strong Inference;Organization Theory;Mixed-Methods Research","","Although the reliability of production plans is crucial for the performance of manufacturing organizations, most practitioners use considerably simpler planning methods than what is recommended in the operations management literature. This article employs the contingency theory of organizations to explain the gap between the practice and the academic models of production planning. Arguments on the contingency effects of process complexity lead to a hypothesis that expects simple capacity planning methods to be most effective in certain production processes. A strong inference research setting is used to test the contingency hypothesis against a conventional hypothesis that expects the most sophisticated planning techniques to always be most effective. Multisource data from the machinery manufacturing industry support the contingency hypothesis and reject the universalistic hypothesis. The findings are explained using the concepts of task interdependence and bounded rationality. The results have several managerial implications, and they elaborate how classic concepts in organization theory can bring practically relevant insights to operations management research. (C) 2010 Elsevier B.V. All rights reserved."
460,"Resources, supplier investment, product launch advantages, and first product performance","Song, Lisa Z. and Song, Michael and Di Benedetto, C. Anthony","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","86-104","2011","JAN","Entrepreneurship;Innovation;Supplier;First Product","","Successfully launching its first product is critical to a new venture's continued success, yet the new venture has relatively few financial or human resources to support its marketing or R&D activities. It is thus important for the new venture to attract funding from external investors such as suppliers. Although the operations management (OM) literature addresses product development and supplier involvement in large firms, few studies have examined the relationship between suppliers and new ventures. This study examines how new ventures can complement their resources and experience with supplier investment, to build positional advantages for their first product and increase marketplace performance. We integrate the OM and entrepreneurship literatures to develop a model based on the resource-based view of the firm, in which the new venture uses external and internal resources to achieve positional advantages of product innovativeness, supplier involvement in production, and product launch quality. We also investigate how market potential moderates the relationship between positional advantages and performance. We empirically test our model using data from 711 new ventures. We find that it is beneficial for a new venture to involve suppliers in production of the first product, and that market potential positively moderates the relationship of product launch quality and performance. However, the results reported here also reveal several surprising results challenging traditional views. Developing a highly innovative first product is much less, not more, important than achieving a high quality first-product launch. Increasing product innovativeness does not necessarily lead to high product performance for new ventures. For a small market with low growth potential, product innovativeness has a negative, not positive, effect on first product performance. We discuss managerial implications of our findings. (C) 2010 Elsevier B.V. All rights reserved."
461,"Alliance diversity, environmental context and the value of manufacturing capabilities among new high technology ventures","Terjesen, Siri and Patel, Pankaj C. and Covin, Jeffrey G.","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","105-115","2011","JAN","Alliance;Environmental Context;Manufacturing Capability;New Ventures","","Manufacturing capabilities have often been shown to predict various indicators of firm performance. However, the association between manufacturing capabilities and firm performance has seldom been studied in the context of high technology new ventures. Using a sample of 167 UK-based, high technology manufacturing ventures, the current study examines the relationship between manufacturing capabilities (in particular, those contributing to low operating costs and product quality) and venture performance. Additionally, the moderating effects of the ventures' alliance portfolios and environmental contexts on the capability-performance relationships are explored. Results indicate that venture performance (as reflected in sales growth, return on sales (ROS), and return on assets (ROA)) is significantly predicted by manufacturing capabilities that promote low operating costs and product quality. Further, the data generally support the hypothesized moderating effects of two alliance diversity variables (alliance partner diversity and alliance geographic diversity) and two environmental context variables (environmental dynamism and environmental munificence) on the capability-performance relationships. Overall, the study supports the premise that the value of manufacturing capabilities (i.e., the strength of the capability-performance relationship) among high technology ventures is contingent upon the alliance and environmental contexts within which those ventures operate. Specifically, alliance partner diversity, alliance geographic diversity, and environmental munificence enhance the value of manufacturing capabilities that promote low operating costs. Alliance partner diversity, environmental munificence, and environmental stability enhance the value of manufacturing capabilities that promote product quality. The study's theoretical and practical implications are discussed. (C) 2010 Elsevier B.V. All rights reserved."
462,"Operations management and corporate entrepreneurship: The moderating effect of operations control on the antecedents of corporate entrepreneurial activity in relation to innovation performance","Goodale, John C. and Kuratko, Donald F. and Hornsby, Jeffrey S. and Covin, Jeffrey G.","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","116-127","2011","JAN","Operations Control;Corporate Entrepreneurship;Innovation","","Research on the topic of corporate entrepreneurship has expanded steadily over the last few decades, in large part due to the increasingly recognized linkages between product-market and technological innovation (i.e., consequences of corporate entrepreneurial activity) and firm success. Likewise, growing evidence suggests that effective operations control is a common quality of successful firms. On the surface the two phenomena corporate entrepreneurship and operations control may seem to be inherently at odds. That is, corporate entrepreneurship is aimed at taking the firm in new directions, while operations control is aimed at channeling and often restricting actions. As such, it would be useful to know how operations control variables act in concert with the determinants of corporate entrepreneurial activity to promote the innovation outcomes that facilitate long-term organizational success. In this study of 177 firms operating in a wide variety of industries, we investigate the effect on innovation performance of several commonly-acknowledged antecedents of corporate entrepreneurship, as measured by the Corporate Entrepreneurship Assessment Instrument (e.g., Hornsby et al., 2008, 2002); namely, management support, work discretion/autonomy, rewards/reinforcements, time availability, and organizational boundaries. More importantly, we examine the moderating effects of operations control variables specifically risk control and process control formality - on the relationships between the antecedents of corporate entrepreneurship and innovation performance. Results indicate that only two of the five antecedents to corporate entrepreneurship have main effects on innovation performance with moderate significance. However, each of the five antecedents significantly interacts with one or both of the operations control variables and, thereby, influences innovation performance. The implications of these results in relation to operations management and corporate entrepreneurship theory and practice are discussed. (C) 2010 Elsevier B.V. All rights reserved."
463,"Role of manufacturing flexibility in managing duality of formalization and environmental uncertainty in emerging firms","Patel, Pankaj C.","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","143-162","2011","JAN","Ventures;Manufacturing Flexibility;Formalization;Contingency Theory;Moderated Polynomial Regression","","Increased firm formalization helps emerging firms develop stable routines and processes to increase their chances of survival. However, uncertain and dynamic task environments of emerging firms require more flexible organizational structures. Such duality of structural prescriptions stems from competing demands of task and institutional environments. We propose that manufacturing flexibility could help decouple activities required in task environments from those required in institutional environments, thereby mitigating the conflict of adopting flexible and rigid structures at the same time. An emerging venture could meet demands of institutional environments through formalized structures, and use manufacturing flexibility to address needs of task environment in order to mitigate liabilities of newness. Using a sample of 167 high-technology manufacturing firms in the UK, we use a moderated polynomial regression approach to test the proposed framework. Results indicate that formalized structures in conjunction with manufacturing flexibility lead to enhanced performance. The findings extend literature on organizational structures in operations management and entrepreneurship. Published by Elsevier B.V."
464,"The impact of internal integration and relationship commitment on external integration","Zhao, Xiande and Huo, Baofeng and Selen, Willem and Yeung, Jeff Hoi Yan","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","17-32","2011","JAN","Relationship Commitment;Internal Integration;External Integration;Ownership;China","","Supply chain integration (SCI) among internal functions within a company, and external trading partners within a supply chain, has received increasing attention from academicians and practitioners in recent years. SCI consists of internal integration of different functions within a company and external integration with trading partners. While both supply chain internal and external integration have been studied extensively, our understanding of what influences SCI and the relationship between internal and external integration is still very limited. This paper argues that external integration with customers and suppliers is simultaneously influenced by internal integration and relationship commitment to customers and suppliers. Internal integration enables external integration because organizations must first develop internal integration capabilities through system-, data-, and process-integration, before they can engage in meaningful external integration. At the same time, before external integration can be successfully implemented, organizations must have a willingness to integrate with external supply chain partners, which is demonstrated by their relationship commitment. We propose and test a model that specifies the relationship between internal integration, relationship commitment, and external integration, using data collected from manufacturing firms in China. The results show that internal integration and relationship commitment improve external integration independently, and their interactive effect on external integration is not significant. However, internal integration has a much greater impact on external integration than relationship commitment. We also examine the model for companies with different ownerships, and the results indicate that for Chinese controlled companies where there is a strong collectivism culture and more reliance on Guanxi (relationship), relationship commitment has a significant impact on external integration with suppliers and customers. This is in stark contrast to foreign controlled companies, characterized by a more individualistic culture and more reliance on technological capabilities, where no significant relationship between relationship commitment and external integration could be found. The model is also tested across different industries and different regions in China, providing useful insights for Chinese companies in particular. This study makes significant contributions to the SCI literature by simultaneously studying the effects of internal integration and relationship commitment on external integration, and providing several future research directions. (C) 2010 Elsevier B.V. All rights reserved."
465,"A resource dependence theory perspective of ISO 9000 in managing organizational environment","Singh, Prakash J. and Power, Damien and Chuong, Sum Chee","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","49-64","2011","JAN","Iso 9000 Standard;Quality Management;Organizational Environment;Resource Dependence Theory","","More than 900,000 organizations worldwide have registered to the ISO 9000 quality management standard. Despite its growing popularity, few studies have offered a coherent theoretical basis for the standard's appeal. A theory-based explanation enhances understanding and appreciation for the standard, and provides clarity on how the standard benefits organizations. In this paper, we invoke the resource dependence theory (RDT) to purport that the standard is used by organizations as a tool to manage their organizational environment. It does this by specifying procedures that organizations need to manage their organization-environment boundary spanning processes. Using the RDT perspective, a model with three key constructs embodying ISO 9000 was developed: internal processes, relationships with customers and relationships with suppliers. The latter two were treated as being part of the task environment. We predicted that the external aspects of the standard affect operating performance (a measure of effectiveness), both directly and through internal processes. Empirical data from 416 ISO 9000 registered Australian manufacturing plants validated the RDT perspective, and suggest that the three constructs, individually and in isolation, are not as effective as when they are considered together. By invoking RDT, a new theoretical viewpoint to ISO 9000 has been developed that adds to other theoretical perspectives, and goes some way to explaining the growing popularity of this standard with organizations. (C) 2010 Elsevier B.V. All rights reserved."
466,"Co-opetition, distributor's entrepreneurial orientation and manufacturer's knowledge acquisition: Evidence from China","Li, Yuan and Liu, Yi and Liu, Heng","JOURNAL OF OPERATIONS MANAGEMENT","29","1-2, SI","128-142","2011","JAN","Supply Chain Knowledge Management;Knowledge Acquisition;Co-Opetition Relations;Entrepreneurial Orientation","","By viewing cooperation and different types of conflicts as co-opetition factors in a manufacturer-distributor supply chain, this paper provides a conceptual model for examining the effects of cooperation and conflicts on a manufacturer's knowledge acquisition process and for exploring the moderating effects of a distributor's entrepreneurial orientation on the relationships between co-opetition factors and the manufacturer's knowledge acquisition. This conceptual model is tested with 225 dyad samples from manufacturer-distributor supply chains in China. The results show that cooperation and the type of conflict have both individual and interactive effects on the manufacturer's knowledge acquisition, thus highlighting the importance of the co-opetition perspective on supply chain knowledge management. More importantly, the results show that the entrepreneurial orientation of a distributor positively moderates the relationships between co-opetition factors and a manufacturer's knowledge acquisition, implying that strengthening the distributor's entrepreneurial orientation can improve the efficiency of co-opetition and thereby affect the knowledge acquisition of the manufacturer, and highlighting the importance of blended analysis across the domains of supply chain management and entrepreneurship. (C) 2010 Elsevier B.V. All rights reserved."
467,"Operations and Finance Interactions","Birge, John R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","4-15","2015","WIN","Arbitrage;Systematic Risk;Production;Inventory Policy","","This paper, based on my remarks at the 2013 MSOM Distinguished Fellow Award ceremony, describes my views on the interface between operations and finance and the lessons that each field can gain from considering their interactions. The key points are that, whereas operational models often avoid financial considerations such as the role of investors and other market participants, both firm and market financial activity can have a significant effect on the impact of operational decisions. Some of these considerations, such as the implications of market arbitrage, can void the relevance of operational models that ignore financial issues. The paper discusses such operational areas where financial activity has significant potential for impact on operations, as well as points where operational considerations provide new perspectives on financial decisions. In particular, I review basic concepts, provide examples, and give some empirical observations in my work about the implications of the absence of arbitrage, the differences between systematic and idiosyncratic risk, the valuation of limited production resources, and the inclusion of imperfect market assumptions."
468,"Collaboration and Multitasking in Networks: Architectures, Bottlenecks, and Capacity","Gurvich, Itai and Van Mieghem, Jan A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","16-33","2015","WIN","Simultaneous Collaboration;Multitasking;Architecture;Work-Flow Design;Organizational Design;Capacity;Stability;Flexibility;Control;Priorities;Bottlenecks","","Motivated by the trend toward more collaboration in work flows, we study networks where some activities require the simultaneous processing by multiple types of multitasking human resources. Collaboration imposes constraints on the capacity of the process because multitasking resources have to be simultaneously at the right place. We introduce the notions of collaboration architecture and unavoidable bottleneck idleness to study the maximal throughput or capacity of such networks. Collaboration and multitasking introduce synchronization requirements that may inflict unavoidable idleness of the bottleneck resources: even when the network is continuously busy (processing at capacity), bottleneck resources can never be fully utilized. The conventional approach that equates network capacity with bottleneck capacity is then incorrect because the network capacity is below that of the bottlenecks. In fact, the gap between the two can grow linearly with the number of collaborative activities. Our main result is that networks with nested collaboration architectures have no unavoidable bottleneck idleness. Then, regardless of the processing times of the various activities, the standard bottleneck procedure correctly identifies the network capacity. We also prove necessity in the sense that, for any nonnested architecture, there are values of processing times for which unavoidable idleness persists. The fundamental trade-off between collaboration and capacity does not disappear in multiserver networks and has important ramifications to service-system staffing. Yet, even in multiserver networks, a nested collaboration architecture still guarantees that the bottleneck capacity is achievable. Finally, simultaneous collaboration, as a process constraint, may limit the benefits of flexibility. We study the interplay of flexibility and unavoidable idleness and offer remedies derived from collaboration architectures."
469,"Making Better Fulfillment Decisions on the Fly in an Online Retail Environment","Acimovic, Jason and Graves, Stephen C.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","34-51","2015","WIN","Online Retailing;Inventory Management;Dynamic Allocation;Fulfillment Policies","","Relative to brick-and-mortar retailers, online retailers have the potential to offer more options to their customers, with respect to both inventory as well as delivery times. To do this entails the management of a distribution network with more decision options than a traditional retailer. The online retailer, not the customer, decides from where items will ship, by what shipping method, and how or whether multiple-item orders will be broken up into multiple shipments. What is the best way to fulfill each customer's order to minimize average outbound shipping cost? We partner with an online retailer to examine this question. We develop a heuristic that makes fulfillment decisions by minimizing the immediate outbound shipping cost plus an estimate of future expected outbound shipping costs. These estimates are derived from the dual values of a transportation linear program (LP). In our experiments on industry data, we capture 36% of the opportunity gap assuming clairvoyance, leading to reductions in outbound shipping costs on the order of 1%. These cost savings are achieved without any deterioration in customer service levels or any increase in holding costs. The transportation LP also serves as the basis for a metric that provides information on the quality of the inventory position. Based on initial successful piloting, our industrial partner has implemented the metric as well as a version of the heuristic that it is applying to every fulfillment decision for each of its stock keeping units in North America."
470,"Advance Demand Information in a Multiproduct System","Bernstein, Fernando and DeCroix, Gregory A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","52-65","2015","WIN","Advance Demand Information;Capacity Planning And Investment;Multiproduct System;Flexible Resources","","In this paper we examine the impact of different types of advance demand information on firm profit and on the benefits of resource flexibility. Specifically, we consider a firm that must choose capacities of resources that will be used to satisfy stochastic demand for multiple products, where demands follow a multivariate normal distribution. Prior to the capacity decision, the firm receives information revealing either the total volume of demand across products or the mix of demand between products. We examine two different scenarios: a dedicated resource setting with product-specific resources and a common resource scenario with one flexible resource. For both scenarios we derive the distribution of the (possibly imperfect) volume or mix demand signal, as well as the conditional distributions of demand given the particular signal. We explore the impact of either type of information on optimal capacities and profit. We find that commonality and volume information are strategic complements-so that it is more valuable to obtain volume information in settings with a common resource. On the other hand, commonality and mix information are strategic substitutes. Moreover, we find that mix and volume information themselves are complements in systems with dedicated resources. Having either type of information is valuable in reducing uncertainty for each individual product demand, but having both of them together provides information on two different dimensions, allowing for a much greater reduction in demand uncertainty. In systems with a common resource, however, the two types of information are substitutes. Because volume information is well aligned with commonality (both focus on total demand), such information already provides much of the value that can be obtained-having mix information adds limited additional value."
471,"Demand Uncertainty and the Bayesian Effect in Markdown Pricing with Strategic Customers","Whang, Seungjin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","66-77","2015","WIN","Pricing And Revenue Management","","This paper studies the role of demand uncertainty in temporal discrimination when the retailer applies markdown pricing facing strategic customers. We consider a model in which a retail firm announces a pair of declining prices for two selling periods, and customers with heterogeneous valuations each decide whether to buy a unit early, later or never. In this model, if the demand function is linear and its parameters are common knowledge, there never exist any markdown prices that achieve temporal discrimination for any feasible model parameters. Either all buying customers wait, or all buy early. By contrast, if the demand level is unknown, there always exists a temporally discriminating markdown pricing scheme for all feasible model parameters. We derive qualitative insights to the way demand uncertainty and Bayesian updating contribute to temporal discrimination, which broadly apply to nonlinear demand functions as well. We also show that in case of demand uncertainty, there always exists a temporally discriminating pricing scheme that yields a strictly higher profit to the retailer than the optimal static pricing scheme. Ironically, however, the retailer cannot implement the optimal scheme due to the same demand uncertainty."
472,"The Impact of a Target on Newsvendor Decisions","Chen, Lucy Gongtao and Long, Daniel Zhuoyu and Perakis, Georgia","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","78-86","2015","WIN","Newsvendor;Risk Measure;Target Profit","","Goal achieving is a commonly observed phenomenon in practice, and it plays an important role in decision making. In this paper, we investigate the impact of a target on newsvendor decisions. We take into account the risk and model the effect of a target by maximizing the satisficing measure of a newsvendor's profit with respect to that target. We study two satisficing measures: (i) conditional value at risk (CVaR) satisficing measure that evaluates the highest confidence level of CVaR achieving the target; (ii) entropic satisficing measure that assesses the smallest risk tolerance level under which the certainty equivalent for exponential utility function achieves the target. For both satisficing measures, we find that the optimal ordering quantity increases with the target level. We determine an optimal order quantity for a target-based newsvendor and characterize its properties with respect to, for example, product's profit margin."
473,"No Claim? Your Gain: Design of Residual Value Extended Warranties Under Risk Aversion and Strategic Claim Behavior","Gallego, Guillermo and Wang, Ruxian and Hu, Ming and Ward, Julie and Beltran, Jose Luis","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","87-100","2015","WIN","Warranty;Service Pricing;Risk Aversion;Strategic Consumer Behavior;Market Segmentation","","Traditional one-price-for-all extended warranties do not differentiate customers according to their risk attitudes, usage rates, or operating environment. These warranties are priced to cover the cost of high-usage customers who have more failures and are willing to pay a risk premium for their risk aversion. That makes traditional warranties economically unattractive to low-usage customers and those who are less risk averse. These issues can be addressed by residual value warranties, which refund part of the up-front price to customers who have zero or few claims according to a predetermined refund schedule. Residual value warranties may induce strategic claim behavior, since customers may prefer to pay for small failures out of pocket rather than claim failures now and give up potential refunds later. We design and price residual value warranties to maximize expected profits, taking into account strategic claim behavior and risk attitudes. For the constant absolute risk aversion model, we characterize customers' optimal claim strategy as well as the net value and support cost for residual value warranties. Surprisingly, the total support cost to the service provider, including repair costs and refunds, is lower for more risk-averse customers under the residual value warranties, whereas their willingness to pay is higher. As contingent contracts, residual value warranties can better price discriminate customers than traditional warranties. We identify conditions under which residual value warranties are strictly more profitable than traditional warranties in a homogeneous market, as well as in heterogeneous markets that differ in various dimensions, such as risk attitude, failure rate, and repair cost."
474,"Toward Mass Adoption of Electric Vehicles: Impact of the Range and Resale Anxieties","Lim, Michael K. and Mak, Ho-Yin and Rong, Ying","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","101-119","2015","WIN","Electric Vehicles;Consumer Anxieties;Durable Goods;Secondary Market;Emission Savings","","Key to the mass adoption of electric vehicles (EVs) is the establishment of successful business models based on sound understanding of consumer behavior in adopting this new technology. In this paper, we study the impact of two major barriers to mass adoption of EVs: (i) range anxiety, the concern that the driving range of EVs may be insufficient to meet the driving needs, and (ii) resale anxiety, the concern that used values of EVs may deteriorate quickly. Using a stylized model calibrated to a data set based on the San Francisco Bay Area, we show that although both types of consumer anxieties typically harm the firm's profit, they often improve consumer surplus. In addition, we show that a business model that requires consumers to lease the EV batteries (rather than purchase them) may lead to a greater level of adoption and emission savings when the level of resale anxiety is high. Further, a business model that offers EV range improvement through enhanced charging infrastructure typically yields greater adoption and consumer surplus, but lowers the firm's profit, compared with one that offers enlarged batteries. Overall, we find that the combinations of battery owning/leasing with enhanced charging service, referred to as the (O, E) and (L, E) models in our paper, typically yield the best balance among the objectives of EV adoption, emission savings, profitability, and consumer surplus, when the degree of resale anxiety is low and high, respectively."
475,"Determining Optimal Parameters for Expediting Policies","Oezsen, Raik and Thonemann, Ulrich W.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","1","120-133","2015","WIN","Order Expediting;Lead Time Flexibility;Inventory Management","","We consider an inventory policy that expedites delivery times of open orders if the inventory level drops below a certain threshold. By expediting open orders, back orders can be reduced. Order expediting is costly, and we include various types of expediting costs in the model. We prove structural properties of the model and show how the optimal parameters of the expediting policy can be computed efficiently. The expediting policy is easy to implement and, for situations with variable expediting cost only, the structure of the policy is optimal. For situations with nonvariable expediting costs, the expediting policy that we consider is generally not optimal. The optimal policy can be computed by dynamic programming, but this approach is computationally feasible only for small-problem instances. We conduct numerical experiments that are based on data from the service division of a global equipment manufacturer to evaluate the performances of the expediting policy and the optimal policy. The results show that substantial cost savings can be achieved by order expediting and that the expediting policy realizes a great share of the cost-saving potential offered by order expediting."
476,"Pricing and Production Flexibility: An Empirical Analysis of the US Automotive Industry","Moreno, Antonio and Terwiesch, Christian","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","428-444","2015","FAL","Empirical Operations Management;Flexibility;Pricing;Automotive Industry","","We use a detailed data set from the U.S. auto industry spanning from 2002 to 2009 and a variety of econometric methods to characterize the relationship between the availability of production mix flexibility and firms' use of responsive pricing. We find that production mix flexibility is associated with reductions in observed manufacturer discounts, resulting from the increased ability to match supply and demand. Under the observed market conditions, mix flexibility accounts for substantial average savings by reducing price discounting by approximately 10% of the average industry discount. We test three supplementary hypotheses and find that the reduction in discounts for vehicles manufactured at flexible plants is (1) higher for higher demand uncertainty, (2) higher for vehicles coproduced with vehicles that belong to a different segment, and (3) lower in situations with higher local competition."
477,"Reliable Facility Location Design Under Uncertain Correlated Disruptions","Lu, Mengshi and Ran, Lun and Shen, Zuo-Jun Max","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","445-455","2015","FAL","Facility Location;Supply Chain Disruption;Distributional Uncertainty","","Most previous studies on reliable facility location design assume that disruptions at different locations are independent. In this paper, we present a model that allows disruptions to be correlated with an uncertain joint distribution, and we apply distributionally robust optimization to minimize the expected cost under the worst-case distribution with given marginal disruption probabilities. The worst-case distribution has a practical interpretation with disruption propagation, and its sparse structure allows solving the problem efficiently. Our numerical results show that ignoring disruption correlation could lead to significant loss that increases dramatically in key factors such as source disaster probability, disruption propagation effect, and service interruption penalty. On the other hand, the robust model results in very low regret, even when disruptions are independent, and starts to outperform the model assuming independence when disruptions are mildly correlated. Most of the benefit of the robust model can be captured with a very low additional cost, which makes it easy to implement. Given these advantages, we believe that the robust model can serve as a promising alternative approach for solving reliable facility location problems."
478,"Newsvendor Selling to Loss-Averse Consumers with Stochastic Reference Points","Baron, Opher and Hu, Ming and Najafi-Asadolahi, Sami and Qian, Qu","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","456-469","2015","FAL","Newsvendor;Behavioral Operations;Loss Aversion;Contingent Pricing;Marketing Promotion;Stochastic Reference Points","","We study a newsvendor who sells a perishable asset over repeated periods to consumers with a given consumption valuation for the product. The market size in each period is random, following a stationary distribution. Consumers are loss averse with stochastic reference points that represent their beliefs about possible price and product availability. Given the distribution of reference points, they choose purchase plans to maximize their expected total utility, including gain-loss utility, before visiting the store, and follow the plans in the store. In anticipation of consumers' purchase plans, in each period, before demand uncertainty resolves, the firm chooses an initial order quantity. After the uncertainty resolves, the firm chooses a contingent price depending on the demand realization, with the option of clearing inventory by charging a sale price, and otherwise, posting a full price. Over repeated periods, the interaction of the firm's operational decisions about ordering and contingent pricing and the consumers' purchase actions results in a distribution of reference points, and, in equilibrium, this distribution is consistent with consumers' beliefs. Under this framework of endogenized reference points, we fully characterize the firm's optimal inventory and contingent pricing policies. We identify conditions under which the firm's expected price and profit are increasing in the consumer loss aversion level. We also show that the firm can prefer demand variability over no-demand uncertainty. We obtain a set of insights into how consumers' loss aversion affects the firm's optimal operational policies that are in stark contrast to those obtained in classic newsvendor models. As examples, the optimal full price increases in the initial order quantity; and the optimal full price decreases, while the optimal sales frequency increases, in the procurement cost."
479,"Joint Selling of Complementary Components Under Brand and Retail Competition","He, Yuhong and Yin, Shuya","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","470-479","2015","FAL","Joint Selling;Complementary Components;Brand Competition;Retail Competition","","Suppliers of complementary goods often package their items together when selling to downstream retailers. One motivation behind this behavior is to reduce double marginalization through coordinated pricing so that system efficiency is improved and individual members can also benefit. The objective of this paper is to understand how competition in supply chains would impact such joint selling partnerships among complementary suppliers. We first model competition at the supply level, which is generated from the existence of multiple partially substitutable brands (or suppliers) for a particular component. We then extend the analysis to a model that also involves retail competition caused by decentralization among retailers who assemble suppliers' components into final products and sell to customers. The analysis of a model with two complementary components, one of which has multiple brands, indicates that the supply-level competition discourages joint selling of complementary goods. That is, when competing brands become more alike (or substitutable), complementary suppliers act more independently in pricing and selling their items. However, retail competition leads to an opposite effect: Competition among retailers would actually encourage complementary suppliers to package their goods together and act jointly."
480,"Capacity Investment in Renewable Energy Technology with Supply Intermittency: Data Granularity Matters!","Hu, Shanshan and Souza, Gilvan C. and Ferguson, Mark E. and Wang, Wenbin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","480-494","2015","FAL","Supply Intermittency;Renewable Energy;Capacity Investment;Sustainability","","We study an organization's one-time capacity investment in a renewable energy-producing technology with supply intermittency and net metering compensation. The renewable technology can be coupled with conventional technologies to form a capacity portfolio that is used to meet stochastic demand for energy. The technologies have different initial investments and operating costs, and the operating costs follow different stochastic processes. We show how to reduce this problem to a single-period decision problem and how to estimate the joint distribution of the stochastic factors using historical data. Importantly, we show that data granularity for renewable yield and electricity demand at a fine level, such as hourly, matters: Without energy storage, coarse data that does not reflect the intermittency of renewable generation may lead to an overinvestment in renewable capacity. We obtain solutions that are simple to compute, intuitive, and provide managers with a framework for evaluating the trade-offs of investing in renewable and conventional technologies. We illustrate our model using two case studies: one for investing in a solar rooftop system for a bank branch and another for investing in a solar thermal system for water heating in a hotel, along with a conventional natural gas heating system."
481,"Sales Force Behavior, Pricing Information, and Pricing Decisions","Elmaghraby, Wedad and Jank, Wolfgang and Zhang, Shu and Karaesmen, Itir Z.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","495-510","2015","FAL","B2B;Pricing;Decision Making;Sales Force;Regression;Logit Model;Two-Stage Model","","This paper focuses on salespeople behavior in business-to-business transactions. The paper investigates how salespeople use the information provided to them to set prices; of particular interest is how salespeople use price recommendations from a decision support tool. The investigation builds reduced-form models and tests them on a data set obtained by a grocery products distributor. The analysis shows that salespeople's decisions are explained well by a two-stage decision model whereby salespeople make an initial decision on whether or not to change the price (a binary decision) and then decide on the magnitude of change (a continuous response). We find that salespeople in our data set do not blindly adopt the recommended price change generated by the pricing tool. Rather, our two-stage model allows for us to uncover a nuanced association between the recommended price and the actual price change by identifying customer-specific and salesperson-specific market factors that moderate the influence of price recommendations."
482,"PBM Competition in Pharmaceutical Supply Chain: Formulary Design and Drug Pricing","Kouvelis, Panos and Xiao, Yixuan and Yang, Nan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","511-526","2015","FAL","Pharmacy Benefit Manager;Drug Distribution;Tiered-Formulary;Pricing;Competition","","We model the competition among multiple pharmacy benefit managers (PBMs) for the patronage of a client organization. Each PBM selects a list of prices to be charged to the client organization for each of the branded and generic drugs within a therapeutic class (price decision) and a formulary list that assigns branded drugs to preferred or nonpreferred tiers (formulary decision). Drug manufacturers offer rebates to PBMs for drugs on preferred tier of formularies. The individuals participating in the client's pharmacy benefit plan are the ones consuming the drugs and making purchasing decisions, whereas the client organization is paying the majority of drug cost. The choices of the individuals and the client organization are governed by different utility measures. For this complex drug distribution setting and for competing PBMs, we show the existence and uniqueness of a pure Nash equilibrium on aggregate formulary and price decisions, which represent the welfare-adjusted cost and welfare-adjusted price of each PBM's plan, respectively. We characterize each PBM's optimal formulary and equilibrium price decisions and discuss the impact of various model primitives. We apply our model to gain insights on the impact of mergers in the PBM industry."
483,"Consignment Contracts with Revenue Sharing for a Capacitated Retailer and Multiple Manufacturers","Lim, Yun Fong and Wang, Yunzeng and Wu, Yue","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","527-537","2015","FAL","Incentives And Contracting;Supply Chain Management;Capacity Planning And Investment;Game Theory;Retailing","","We consider a retailer with limited storage capacity selling n independent products. Each product is produced by a distinct manufacturer, who is offered a consignment contract with revenue sharing by the retailer. The retailer first sets a common revenue share for all products, and each manufacturer then determines the retail price and production quantity for his product. Under certain conditions on price elasticities and cost fractions, we find a unique optimal revenue share for all products. Surprisingly, it is optimal for the retailer not to charge any storage fee in many situations even if she is allowed to do so. Both the retailer's and manufacturers' profits first increase and then remain constant as the capacity increases, which implies that an optimal capacity exists. We also find that the decentralized system requires no larger storage space than the centralized system at the expense of channel profit. If products are complementary, as the degree of complementarity increases, the retailer will decrease her revenue share to encourage the manufacturers to lower their prices."
484,"Dynamic Assortment Customization with Limited Inventories","Bernstein, Fernando and Kok, A. Gurhan and Xie, Lei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","538-553","2015","FAL","Retailing;Dynamic Programming;Pricing And Revenue Management;Personalization;Online Retailing;Customer-Centric Retailing","","We consider a retailer with limited inventory of identically priced, substitutable products. The retailer faces a market with multiple segments of customers that are heterogeneous with respect to their product preferences. Customers arrive sequentially, and the firm decides which subset of products to offer to each arriving customer depending on the customer's preferences, the inventory levels, and the remaining time in the season. We show that it is optimal to limit the choice set of some customers ( even when the products are in stock), reserving products with low inventory levels for future customers who may have a stronger preference for those products. In certain settings, we prove that it is optimal to follow a threshold policy under which a product is offered to a customer segment if its inventory level is higher than a threshold value. The thresholds are decreasing in time and increasing in the inventory levels of other products. We introduce two heuristics derived by approximating the future marginal expected revenue by the marginal value of a newsvendor function that captures the substitution dynamics between products. We test the impact of assortment customization using data from a fashion retailer. We find that the potential revenue impact of assortment customization can be significant, especially when customer heterogeneity is high and when the products' inventory-to-demand ratios are asymmetric. Our findings suggest that assortment customization can be used as another lever for revenue maximization in addition to pricing."
485,"The Price of Nonabandonment: HIV in Resource-Limited Settings","Khademi, Amin and Saure, Denis R. and Schaefer, Andrew J. and Braithwaite, Ronald S. and Roberts, Mark S.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","554-570","2015","FAL","Hiv;Resistance;Nonabandonment Allocation Policy;Approximate Dynamic Programming","","The global fight against HIV/AIDS is hindered by a lack of drugs in the developing world. When patients in these countries initiate treatment, they typically remain on it until death; thus, policy makers and physicians follow nonabandonment policies. However, treated patients develop resistance to treatment, so in many cases untreated patients might benefit more from the drugs. In this paper we quantify the opportunity cost associated with restricting attention to nonabandonment policies. For this, we use an approximate dynamic programming framework to bound the benefit from allowing premature treatment termination. Our results indicate that in sub-Saharan Africa, the price associated with restricting attention to nonabandonment policies lies between 4.4% and 8.1% of the total treatment benefit. We also derive superior treatment allocation policies, which shed light on the role behavior and health progression play in prioritizing treatment initiation and termination."
486,"Parametric Forecasting and Stochastic Programming Models for Call-Center Workforce Scheduling","Gans, Noah and Shen, Haipeng and Zhou, Yong-Pin and Korolev, Nikolay and McCord, Alan and Ristock, Herbert","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","571-588","2015","FAL","Call-Center Management;Production Planning And Scheduling;Service Operations;Distributional Forecast Updating;Stochastic Programming With Recourse","","We develop and test an integrated forecasting and stochastic programming approach to workforce management in call centers. We first demonstrate that parametric forecasts, discretized using Gaussian quadrature, can be used to drive stochastic programs whose results are stable with relatively small numbers of scenarios. We then extend our approach to include forecast updates and two-stage stochastic programs with recourse and provide a general modeling framework for which recent, related models are special cases. In our formulations, the inclusion of multiple arrival-rate scenarios allows call centers to meet long-run average quality-of-service targets, and the use of recourse actions helps them to lower long-run average costs. Experiments with two large sets of call-center data highlight the complementary nature of these elements."
487,"Multicommodity Production Planning: Qualitative Analysis and Applications","Ciurria-Infosino, Iara and Granot, Daniel and Granot, Frieda and Veinott, Jr., Arthur F.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","589-607","2015","FAL","Convex Multicommodity Flows;Qualitative Analysis;Monotonicity;Substitutes And Complements;Dynamic Production Planning Problem","","We develop a qualitative analysis theory for the convex-cost dynamic multicommodity production planning problem, which can be used, without performing any computational work, to provide invaluable insight to managers when faced with the task of deciding how to respond to changes in problem environment. We first formulate the problem as a multicommodity flow problem with parameters associated with each arc-commodity pair. We then reduce the problem to an equivalent single-commodity flow problem and develop a complete characterization of conformality among production, sales, and inventory activities in various instances of the problem. By combining the conformality characterizations with the monotonicity theory of Granot and Veinott [Granot F, Veinott AF Jr (1985) Substitutes, complements and ripples in network flow. Math. Oper. Res. 10:471-497] for single-commodity problems, we study the effects of changes in problem environment on optimal production, sales, and inventory schedules in the multicommodity problem. Numerous applications are presented and analyzed."
488,"Optimal Vascular Access Choice for Patients on Hemodialysis","Skandari, M. Reza and Shechter, Steven M. and Zalunardo, Nadia","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","4","608-619","2015","FAL","Dynamic Programming;Medical Decision Making;Optimal Treatment Policies;Hemodialysis;Vascular Access","","Which vascular access to use is considered one of the most important questions in the care of patients on hemodialysis (HD). An arteriovenous fistula (AVF) is often considered the gold standard for delivering HD due to better patient survival, higher quality of life, and fewer complications. However, AVFs have some limitations: they require surgery, it takes approximately three months to know whether the surgery was successful, and a majority of these surgeries end in failure. Conversely, another common vascular access, the central venous catheter, can be inserted via a simple procedure and used immediately after placement. In this research, we address the question of whether and when to perform AVF surgery on incident and established HD patients, with the aim of finding individualized policies that maximize a patient's probability of survival and remaining quality-adjusted life expectancy. Using a continuous-time dynamic programming model and under certain data-driven assumptions, we establish structural properties of the optimal policy for each objective. We provide further insights for policy makers through our numerical experiments."
489,"Combating Strategic Counterfeiters in Licit and Illicit Supply Chains","Cho, Soo-Haeng and Fang, Xin and Tayur, Sridhar","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","273-289","2015","SUM","Game Theory;Global Operations Management;Supply Chain Management","","Counterfeit goods are becoming more sophisticated, from shoes to infant milk powder to aircraft parts, creating problems for consumers, firms, and governments. By comparing two types of counterfeiters-deceptive, so infiltrating a licit (but complicit) distributor, or nondeceptive in an illicit channel-we provide insights into the impact of anticounterfeiting strategies on a brand-name company, a counterfeiter, and consumers. Our analysis highlights that the effectiveness of these strategies depends critically on whether a brand-name company faces a nondeceptive or deceptive counterfeiter. For example, by improving quality, the brand-name company can improve her expected profit against a nondeceptive counterfeiter when the counterfeiter steals an insignificant amount of brand value. However, the same strategy does not work well against the deceptive counterfeiter unless high quality facilitates the seizure of deceptive counterfeits significantly. Similarly, reducing price works well in combating the nondeceptive counterfeiter, but it could be ineffective against the deceptive counterfeiter. Moreover, the strategies that improve the profit of the brand-name company may benefit the counterfeiter inadvertently and even hurt consumer welfare. Therefore, firms and governments should carefully consider a trade-off among different objectives in implementing an anticounterfeiting strategy."
490,"Incentive Contracts in Serial Stochastic Projects","Chen, Tony and Klastorin, Ted and Wagner, Michael R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","290-301","2015","SUM","Incentives And Contracting;Production Planning And Scheduling;Product Development And Design","","In this paper we propose an incentive payment contract for stochastic projects defined by a series of stages or tasks that are outsourced to independent subcontractors. Projects defined by sequentially completed independent stages are common in new product development and other high-risk projects. Our goal is to maximize the client's expected discounted profit. Our proposed contract reflects the convex time-cost trade-off that is well known in the project scheduling literature. We show that this type of contract dominates a fixed price contract with respect to expected client's profit and schedule performance, regardless of payment timing considerations. Using a piecewise linear approximation, we show that our contract is a generalization of an incentive/disincentive contract that is frequently used in practice. We show how our contract can be used to find the optimal due date and penalties/bonuses in an incentive/disincentive contract. We compare this contract with several variations and discuss implications for both the client and subcontractors."
491,"Merchant Commodity Storage and Term-Structure Model Error","Secomandi, Nicola and Lai, Guoming and Margot, Francois and Scheller-Wolf, Alan and Seppi, Duane J.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","302-320","2015","SUM","Model Error;Commodity And Energy Real Options;Natural Gas Storage;Futures Term Structures;Delta Hedging And Mean-Variance Hedging","","Merchant operations involves valuing and hedging the cash flows of commodity- and energy-conversion assets as real options based on stochastic models that inevitably embed model error. In this paper we quantify how empirically calibrated model errors concerning the futures term structure affect the valuation and hedging of natural gas storage. We find that even small model errors-on the order of 1%-2% of the empirical futures price variance-can have a disproportionate impact on storage valuation and hedging. In particular, theoretically equivalent hedging strategies have very different sensitivities to model error, with one natural strategy exhibiting potentially catastrophic performance in the presence of small model errors. We propose effective approaches to mitigate the negative effect of futures term-structure model error on hedging, also taking into account futures contract illiquidity, and provide theoretical justification for some of these approaches. Beyond commodity storage, our analysis has relevance for other real and financial options that depend on futures term-structure dynamics, as well as for inventory, production, and capacity investment policies that rely on demand-forecast term structures."
492,"Dynamic Pricing and Inventory Management Under Fluctuating Procurement Costs","Xiao, Guang and Yang, Nan and Zhang, Renyu","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","321-334","2015","SUM","Joint Pricing And Inventory Management;Fluctuating Procurement Cost;Dual Sourcing","","We consider a periodic review joint pricing and inventory control model in which a firm faces both stochastic demand and fluctuating procurement costs. To address procurement cost fluctuation, the firm adopts a dual-sourcing strategy, under which it procures from a spot market with immediate delivery and through a forward-buying contract with postponed delivery. Our analysis offers the unique insight that a risk-neutral firm may earn higher expected profit under a more volatile procurement cost process. This is because the firm makes its pricing and sourcing decisions in response to the realized cost in each period. Moreover, we characterize how the firm should dynamically adjust its pricing and sourcing decisions in accordance to cost evolution. For example, if sourcing through the forward-buying contract is less expensive than sourcing directly from the spot market, the optimal safety stock is decreasing in the current spot market purchasing cost. However, the optimal order quantity through the forward-buying contract is, in general, not monotone in the current spot-purchasing cost. Finally, we conduct extensive numerical experiments to show that dynamic pricing and dual sourcing may be either strategic complements or substitutes in the presence of fluctuating procurement costs and uncertain demand. This is because dynamic pricing mitigates demand uncertainty risk and exploits procurement cost fluctuation, whereas dual sourcing may either intensify or dampen demand risk."
493,"Demand Estimation from Censored Observations with Inventory Record Inaccuracy","Mersereau, Adam J.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","335-349","2015","SUM","Inventory Theory And Control;Demand Estimation;Retailing","","A retailer cannot sell more than it has in stock; therefore, its sales observations are a censored representation of the underlying demand process. When a retailer forecasts demand based on past sales observations, it requires an estimation approach that accounts for this censoring. Several authors have analyzed inventory management with demand learning in environments with censored observations, but the authors assume that inventory levels are known and hence that stockouts are observed. However, firms often do not know how many units of inventory are available to meet demand, a phenomenon known as inventory record inaccuracy. We investigate the impact of this unknown on demand estimation in an environment with censored observations. When the firm does not account for inventory uncertainty when estimating demand, we discover and characterize a systematic downward bias in demand estimation under typical assumptions on the distribution of inventory record inaccuracies. We propose and test a heuristic prescription that relies on a single error statistic and that sharply reduces this bias."
494,"Does Organizational Forgetting Affect Vendor Quality Performance? An Empirical Investigation","Agrawal, Anupam and Muthulingam, Suresh","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","350-367","2015","SUM","Quality Management;Process Improvement;Quality Assurance;Design Quality;Organizational Learning;Organizational Forgetting;Vendor Management","","The development of organizational knowledge and the depreciation of knowledge within organizations are processes that invariably occur concurrently. In the quality domain, many researchers have examined how the development of organizational knowledge (organizational learning) enhances quality performance. We build on this literature and investigate how the depreciation of organizational knowledge (organizational forgetting) affects quality performance. We analyze information on 2,732 quality improvement initiatives implemented by 295 vendors of a car manufacturer and find that organizational forgetting affects quality gains obtained from both learning-by-doing (autonomous learning) and quality improvement initiatives (induced learning); more than 16% of quality gains from autonomous learning and 13% of quality gains from induced learning depreciate every year. Furthermore, the impact of organizational forgetting (i) differs across the types of quality improvement efforts (quality gains from process improvement initiatives depreciate, whereas those from quality assurance initiatives do not), and (ii) depends on where quality knowledge was embedded (depreciation is lower for knowledge embedded in technology than for knowledge embedded in organizational routines or organizational members). Our results highlight the ubiquity of organizational forgetting and suggest the need for continued attention to sustain and enhance quality performance in supply chains."
495,"An Information Stock Model of Customer Behavior in Multichannel Customer Support Services","Jerath, Kinshuk and Kumar, Anuj and Netessine, Serguei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","368-383","2015","SUM","Multichannel Customer Behavior;Customer Service;Call Center;Empirical Operation Management;Probability Modeling","","We develop a model to understand and predict customers' observed multichannel behavior in a customer support setting. Using individual-level data from a U.S.-based health insurance firm, we model a customer's query frequency and choice of using the telephone or web channel for resolving queries as a stochastic function of her latent information stock. The information stock is a function of the customer's information needs (which arise when customers file health insurance claims) and information gains (which customers obtain when they resolve their queries through the telephone and web support channels), and other factors such as seasonal effects (for instance, queries that arise at the time of annual contract renewal). We find that average information gain from a telephone call is twice as much as that from visiting the web portal; customers prefer the telephone channel for health event-related information but prefer the web portal for structured seasonal information; and customers are polarized in their propensities of using the web channel and can be broadly classified into web avoiders and web seekers. Our model provides superior in-sample and out-of-sample fit than multiple benchmark models for aggregate and individual-level customer activity and has several managerial uses, such as capacity planning."
496,"Manufacturing Capacity Decisions with Demand Uncertainty and Tax Cross-Crediting","Xiao, Wenqiang and Hsu, Vernon N. and Hu, Qiaohai (Joice)","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","384-398","2015","SUM","Global Supply Chain Management;International Tax Planning;Foreign Tax Credit;Tax Cross-Crediting","","The U.S. tax law taxes the global income of multinational firms (MNFs) at their home country tax rate. To avoid double taxation, it permits tax cross-crediting. Through this strategy, global firms can use excess foreign tax credits (FTCs), the portion of foreign tax payments that exceed their home country tax liabilities, generated from a subsidiary located in a high-tax country to offset the tax liabilities of their low-tax divisions. This paper studies manufacturing capacity decisions in the subsidiary of an MNF with tax cross-crediting. Casting the problem on a newsvendor model, and assuming the objective of maximizing the global firm's worldwide after-tax profits, we show that the optimal capacity decision under the effects of tax cross-crediting can behave very differently from that of the traditional newsvendor model. In particular, we show that an improvement in the firm's after-tax profitability (through tax cross-crediting, an increased profit margin, or a reduced tax rate) might reduce the optimal capacity and that the optimal capacity decision under certain circumstances can be made without the knowledge of the demand distribution. We also discuss the issue of motivating the division manager to use an after-tax performance measure with a managerial tax rate."
497,"Price Commitments with Strategic Consumers: Why It Can Be Optimal to Discount More Frequently ... Than Optimal","Cachon, Gerard P. and Feldman, Pnina","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","399-410","2015","SUM","Consumer Behavior;Game Theory;Pricing And Revenue Management","","In many markets consumers incur search costs, and firms choose a long-run pricing strategy that determines how they respond to market conditions. A pricing strategy may involve commitments to take actions that do not optimize short-term revenue given the information the firm learns about demand. For example, as already suggested in the literature, the firm could commit to a single price no matter whether demand is strong or weak. We introduce a new strategy-charge a high price only if demand is indeed high, otherwise offer a discount. This strategy discounts more frequently than would maximize revenue conditional on demand. Nevertheless, the frequent discounts attract consumers. We show that (i) the discount-frequently strategy is optimal (whether capacity is adjustable or not), (ii) discount-frequently is often much better than other pricing strategies, especially if no price commitment is made, and (iii) overbuying capacity (e.g., inventory) to attract consumers (by signaling availability and the likelihood of discounts) is a poor strategy. Contrary to some recommendations in the literature to limit markdowns and to purchase ample capacity, our results provide support for a strategy that embraces frequent discounts and moderate capacity."
498,"Wine Futures and Advance Selling Under Quality Uncertainty","Noparumpa, Tim and Kazaz, Burak and Webster, Scott","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","3","411-426","2015","SUM","Wine Futures;Advance Selling;Quality Uncertainty;Pricing","","This study examines the use of wine futures (i.e., advance selling of wine before it is bottled) as a form of operational flexibility to mitigate quality rating risk. At the end of a harvest season, the winemaker obtains a certain number of barrels of wine that can be produced for a particular vintage. While the wine is aging in the barrel, expert reviewers taste the wine and create a barrel score, indicating the potential quality of the wine and offering clues as to whether, when bottled, it will be superior wine. Based on the barrel score, the wine producer determines (1) the percentage of its wine to be sold as futures and (2) the price of the wine futures. After one more year of aging, the wine is bottled, and the reviewers provide a second review of the wine and assign a bottle score that influences the market price of the wine. Our study makes three contributions. First, we develop an analytical model that incorporates uncertain consumer valuations of wine futures and bottled wine and the uncertain bottle rating that is assigned to the wine at the end of the production process. Our analysis provides insights into how the barrel score, consumer preference (through a conditional-value-at-risk perspective) and the winemaker's preference influence the winemaker's allocation and pricing decisions. Our second contribution relates to the impact of consumer heterogeneity on the optimal allocation and pricing decisions. Contrary to common belief that the winemaker may be better off when consumers are more homogeneous, our results demonstrate that the winemaker can achieve a higher level of profitability when the market is filled with consumers that are heterogeneous. Third, we test our findings using data collected from Bordeaux wineries engaging in wine futures. Our empirical analysis demonstrates that (1) barrel scores play a significant role in the two decisions regarding the quantity and price of wine futures, and (2) the wine futures market provides a sizable financial benefit to the winemakers. Our analysis yields recommendations for artisanal and boutique wineries that have limited or no experience selling wine futures."
499,"OM Forum The Service and Information Economy: Research Opportunities","Karmarkar, Uday","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","136-141","2015","SPR","Service Economy;Information Economy;Research;Service Industrialization","","The U.S. economy is already dominated by service and information-intensive industries in terms of both gross national product and jobs, and these trends are visible in all major world economies. These economic shifts are driven by productivity changes, which today often depend on new information and communication technologies. These changes can be thought of as service industrialization, which underlies productivity improvements. Industrialization is, in turn, closely related to the design and operation of service processes at the level of firms and sectors. Some of the implications for process economics, operations strategy, and process management are outlined, and the opportunities for research in operations and technology management related to these trends are discussed."
500,"Inventory Control in a Spare Parts Distribution System with Emergency Stocks and Pipeline Information","Howard, Christian and Marklund, Johan and Tan, Tarkan and Reijnen, Ingrid","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","142-156","2015","SPR","Emergency Shipments;Inventory;Multiechelon;Pipeline Information;Spare Parts","","Motivated by collaboration with a global spare parts service provider, we consider a two-echelon inventory system with multiple local warehouses, a so-called support warehouse, and a central warehouse with ample capacity. In case of stock-outs, the local warehouses can receive emergency shipments from the support warehouse or the central warehouse at an extra cost. Our focus is on using information on orders in the replenishment pipeline, i.e., pipeline information, to achieve cost-efficient policies for requesting emergency shipments. We introduce a policy where the request for an emergency shipment is based on the time until an outstanding order will reach the stock point considered. The goal is to determine how long one should wait for stock in the replenishment pipeline before requesting an emergency shipment, and the cost effects of using pipeline information in this manner. The analysis utilizes results from queuing theory and provides a decomposition technique for optimizing the policy parameters that reduces the complex multiechelon problem to more manageable single-echelon problems. The performance of our policy indicates that there can be a significant benefit in using pipeline information."
501,"Managing Hospital Inpatient Bed Capacity Through Partitioning Care into Focused Wings","Best, Thomas J. and Sandikci, Burhaneddin and Eisenstein, Donald D. and Meltzer, David O.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","157-176","2015","SPR","Hospital Bed Capacity Management;Care Partitioning;Focus","","We consider the partitioning of care types into wings from the perspective of a hospital administrator who wishes to optimize the use of a fixed number of beds that provide services for heterogeneous care types. The hospital administrator decides on the number of wings to form, the number of beds to allocate to each wing, and the set of care types to assign to each wing to maximize the total utility to the hospital. The administrator faces an inherent trade-off between forming large wings to pool demand and bed capacity, and forming specialized wings to focus on narrow ranges of care types. Specialized wings not only provide advantages from focused care but also allow the protection of beds for high-utility care types. We provide an optimization model for the wing formation decision and address the advantages of focus endogenously in our model. Using data from a large urban teaching hospital in the United States along with a national database, we report on a number of managerial insights. In particular, as the overall demand increases across all care types, wings are formed to reserve more beds for higher-utility types, which leads to higher overall hospital utility but also some disparity across types, such as increased hospital access for some and decreased access for others. Furthermore, overall bed occupancy decreases as the hospital is split into wings. However, if sufficient focus is attained, shorter lengths-of-stay associated with focused care may increase overall patient throughput. We also observe that when patients are willing to wait longer for admission, the hospital tends to form more wings. This implies that hospitals that garner longer waits can form more specialized wings and thereby benefit from focused care, whereas hospitals that cannot will tend to form fewer, if any, wings, choosing to pool demand and bed capacity."
502,"Dynamic Knowledge Transfer and Knowledge Development for Product and Process Design Teams","Ozkan-Seely, Gulru F. and Gaimon, Cheryl and Kavadias, Stylianos","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","177-190","2015","SPR","Product And Process Development And Design;Operations Management-Organizational Behavior Interface;Technology Management And Process Design","","We consider a manager who invests in knowledge development of a product and a process design team as well as knowledge transfer between teams throughout a new product development (NPD) project. Knowledge development at a particular time (e.g., prototyping and experimentation) increases a team's level of knowledge at that time. In contrast, the recipient's benefits from knowledge transfer may be lagged because of the difficulties in articulating and documenting knowledge as well as the challenges regarding its interpretation and application. Over time, as each team embeds knowledge in the NPD project, the levels of product and process performance increase, thereby increasing the net revenue earned at the product launch time. In a key contribution to the literature, analytic conditions are given that characterize the dynamic rates at which knowledge development and knowledge transfer occur throughout the project. We show that the investment in knowledge development for each team and knowledge transfer between teams may be constant, front-loaded, back-loaded, U-shaped, or the peak rate may be delayed over time. As such, we show how concurrent engineering is optimally pursued throughout the NPD project."
503,"Optimal Decentralization of Early Infant Diagnosis of HIV in Resource-Limited Settings","Deo, Sarang and Sohoni, Milind","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","191-207","2015","SPR","Point-Of-Care Testing;Resource-Limited Settings;Pediatric Hiv;Diagnosis Delay","","Early infant diagnosis (EID) programs in many resource-limited settings are aimed at diagnosing infants born to HIV-infected mothers. Because of the complexity of the diagnostic technology, EID programs are often highly centralized with few laboratories testing blood samples from a large network of health facilities. This leads to long diagnostic delays and consequent failure of patients to collect results in a timely manner. Several point-of-care (POC) devices that provide rapid diagnosis within the health facilities are being developed to mitigate these drawbacks of centralized EID networks. We study the decision of which facilities should receive the POC device (the placement plan) using the EID program in Mozambique as a case study. We argue that the choice of an appropriate plan is critical to maximizing the public health impact of POC devices in the presence of tight budget constraints. To formalize this argument, we develop a detailed simulation model to evaluate the impact of a placement plan. It comprises two parts: an operational model that quantifies the impact of a POC placement plan on the diagnostic delay and a behavioral part that quantifies the impact of diagnostic delay on the likelihood of result collection by infants' caregivers. We also develop an approximate version of these operational and patient behavior dynamics and embed them in an optimization model to generate candidate POC placement plans. We find that the optimization-based plan can result in up to 30% more patients collecting their results compared to rules of thumb that have practical appeal. Finally, we show that the effectiveness of POC devices is much higher than other operational improvements to the EID network such as increased laboratory capacity, reduced transportation delay, and more regularized transport."
504,"Production Smoothing and the Bullwhip Effect","Bray, Robert L. and Mendelson, Haim","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","208-220","2015","SPR","Production Smoothing;Bullwhip Effect;Demand Signal Processing;Generalized Order-Up-To Policy;Martingale Model Of Forecast Evolution","","The bullwhip effect and production smoothing appear antithetical because their empirical tests oppose one another: production variability exceeding sales variability for bullwhip, and vice versa for smoothing. But this is a false dichotomy. We distinguish between the phenomena with a new production smoothing measure, which estimates how much more variable production would be absent production volatility costs. We apply our metric to an automotive manufacturing sample comprising 162 car models and find 75% smooth production by at least 5%, despite the fact that 99% exhibit the bullwhip effect. Indeed, we estimate both a strong bullwhip (on average, production is 220% as variable as sales) and robust smoothing (on average, production would be 22% more variable without deliberate stabilization). We find firms smooth both production variability and production uncertainty. We measure production smoothing with a structural econometric production scheduling model, based on the generalized order-up-to policy."
505,"Hedging Commodity Procurement in a Bilateral Supply Chain","Turcic, Danko and Kouvelis, Panos and Bolandifar, Ehsan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","221-235","2015","SPR","Risk Management;Commodity Procurement;Supply Chain Contracting;Hedging","","This paper explores the merits of hedging stochastic input costs (i.e., reducing the risk of adverse changes in costs) in a decentralized, risk-neutral supply chain. Specifically, we consider a generalized version of the well-known selling-to-the-newsvendor model in which both the upstream and the downstream firms face stochastic input costs. The firms' operations are intertwined-i.e., the downstream buyer depends on the upstream supplier for delivery and the supplier depends on the buyer for purchase. We show that if left unmanaged, the stochastic costs that reverberate through the supply chain can lead to significant financial losses. The situation could deteriorate to the point of a supply disruption if at least one of the supply chain members cannot profitably make its product. To the extent that hedging can ensure continuation in supply, hedging can have value to at least some of the members of the supply chain. We identify conditions under which the risk of the supply chain breakdown will cause the supply chain members to hedge their input costs: (i) the downstream buyer's market power exceeds a critical threshold; or (ii) the upstream firm operates on a large margin, there is a high baseline demand for downstream firm's final product, and the downstream firm's market power is below a critical threshold. In absence of these conditions there are equilibria in which neither firm hedges. To sustain hedging in equilibrium, both firms must hedge and supply chain breakdown must be costly. The equilibrium hedging policy will (in general) be a partial hedging policy. There are also situations when firms hedge in equilibrium although hedging reduces their expected payoff."
506,"Priority Allocation in a Rental Model with Decreasing Demand","Jain, Apurva and Moinzadeh, Kamran and Dumrongsiri, Aussadavut","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","236-248","2015","SPR","Inventory Theory And Control","","We analyze a model of rental and return process where limited inventory of a product is rented to two customer classes that differ in their return behavior and penalty costs. The rental demand is a decreasing function of time. We consider two cases: where a demand that is not met is lost and where an unmet demand returns. We show that to minimize penalty cost, the optimal allocation policy may give priority to different classes at different points in time and may decline lower-class demand for some time. Computational results show the benefit of the optimal allocation policy over a priority scheme reportedly used in practice."
507,"Bundled Procurement for Technology Acquisition and Future Competition","Chu, Leon Yang and Wang, Yunzeng","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","17","2","249-261","2015","SPR","Procurement;Game Theory;Technology Transfer;China Policy","","Consider a buyer who would like to procure certain products for the current period and the underlying technologies so that he can become a supplier and compete with current suppliers in the future market. One potential procurement mechanism for such a buyer is to bundle the procurement project with technology acquisition. We propose a dynamic stochastic game-theoretic model that analyzes the optimal technology offer strategies of the asymmetric suppliers and highlights how the size of the current project, relative to the size of the future market, and supplier competition determine the effectiveness of the bundled procurement mechanism for the buyer. For the two-supplier case, we find that each supplier has a dominant technology offer strategy that is independent of the opponent's strategy. When the relative size of the project is small, suppliers only offer obsolete technologies even if their technologies are perfect substitutes. While suppliers offer better technologies as the project size increases, their responses in technology offers are not continuous with respect to the project size-once the project size reaches some threshold, suppliers' optimal responses jump to their best technologies. We also observe that the premium needed for technology acquisition under the bundled procurement mechanism can be negligible compared to the expected profit from the future market."
508,"Modeling Influenza Pandemic and Planning Food Distribution","Ekici, Ali and Keskinocak, Pinar and Swann, Julie L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","11-27","2014","WIN","Influenza Pandemic;Food Distribution Planning;Disease Spread Models;Multiperiod Facility Location;Dynamic Update","","Based on the recent incidents of H5N1, H1N1, and influenza pandemics in history (1918, 1957, and 1968) experts believe that a future influenza pandemic is inevitable and likely imminent. Although the severity of influenza pandemics vary, evidence suggests that an efficient and rapid response is crucial for mitigating morbidity, mortality, and costs to society. Hence, preparing for a potential influenza pandemic is a high priority of governments at all levels (local, state, federal), nongovernmental organizations (NGOs), and companies. In a severe pandemic, when a large number of people are ill, infected persons and their families may have difficulty purchasing and preparing meals. Various government agencies and NGOs plan to provide meals to these households. In this paper, in collaboration with the American Red Cross, we study food distribution planning during an influenza pandemic. We develop a disease spread model to estimate the spread pattern of the disease geographically and over time, combine it with a facility location and resource allocation network model for food distribution, and develop heuristics to find near-optimal solutions for large instances. We run our combined disease spread and facility location model for the state of Georgia and present the estimated number of infections and the number of meals needed in each census tract for a one-year period along with a design of the supply chain network. Moreover, we investigate the impact of voluntary quarantine on the food demand and the food distribution network and show that its effects on food distribution can be significant. Our results could help decision makers prepare for a pandemic, including how to allocate limited resources and respond dynamically."
509,"Optimal Pricing, Production, and Inventory for New Product Diffusion Under Supply Constraints","Shen, Wenjing and Duenyas, Izak and Kapuscinski, Roman","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","28-45","2014","WIN","Om-Marketing Interface;Retailing;Pricing;Bass Diffusion Model","","Management of new product introductions is critical for nearly all firms, and one of its most important dimensions is the management of demand during the introduction. Research analyzing this area predominantly uses versions of the diffusion model to capture the demand trajectory of a new product with a fixed potential market. The classic Bass model assumes that demand for innovative products is influenced both by external media influence and internal word-of-mouth effect, but it excludes price and assumes that capacity is unlimited. In reality, both factors critically influence firms' strategies. Price fluctuations for a new product are common, and price is often a critical lever that helps to shape the demand. Also, firms often have significant capacity constraints, which influence the feasibility of their strategies. In this paper, we consider how a capacity-constrained firm prices products during new product introductions. Thus, the demand rate is influenced by price and, when capacity is insufficient, we allow some customers to be either lost or backlogged, which slows down the word-of-mouth effect. To understand the effect of both pricing and capacity, we consider the integrated optimal pricing, production, and inventory decisions, using control-theory framework (a generalization of the classic Bass model). Most of our results are fairly robust and apply under the assumption of lost sales and partial backlogging, as well as make-to-order and make-to-stock environments. We show that in most cases, the optimal trajectory of demand is unimodal, as in the Bass model, but the optimal price trajectory and the corresponding pricing policy are more complicated when capacity is limited. Using a numerical study, we explore when pricing flexibility is most valuable and whether simple pricing policies may be effective. We find that benefits of pricing flexibility are highest when capacity is neither unlimited (very large) nor very small and when word-of-mouth effect dominates direct impact from media. The ability to adjust prices is significantly more important than the option of producing in advance and holding inventory. We also find that simple pricing policies, appropriately chosen for given capacity, perform very well. In a numerical study, we show that demand uncertainty and increases in capacity over time do not affect our main insights."
510,"Optimal Capacity Conversion for Product Transitions Under High Service Requirements","Li, Hongmin and Graves, Stephen C. and Huh, Woonghee Tim","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","46-60","2014","WIN","Capacity Planning;Product Transition;Equipment Conversion;Flexible Capacity;Risk Pooling","","We consider the capacity planning problem during a product transition in which demand for a new-generation product gradually replaces that for the old product. Capacity for the new product can be acquired both by purchasing new production lines and by converting existing production lines for the old product. Furthermore, in either case, the new product capacity is retrofitted to be flexible, i.e., to be able to also produce the old product. This capacity planning problem arises regularly at Intel, which served as the motivating context for this research. We formulate a two-product capacity planning model to determine the equipment purchase and conversion schedule, considering (i) time-varying and uncertain demand, (ii) dedicated and flexible capacity, (iii) inventory and equipment costs, and (iv) a chance-constrained service-level requirement. We develop a solution approach that accounts for the risk-pooling benefit of flexible capacity (a closed-loop planning approach) and compare it with a solution that is similar to Intel's current practice (an open-loop planning approach). We evaluate both approaches with a realistic but disguised example and show that the closed-loop planning solution leads to savings in both equipment and inventory costs and matches more closely the service-level targets for the two products. Our numerical experiments illuminate the cost trade-offs between purchasing new capacity and converting old capacity and between a level capacity plan versus a chase capacity plan."
511,"Ordering Behavior Under Supply Risk: An Experimental Investigation","Gurnani, Haresh and Ramachandran, Karthik and Ray, Saibal and Xia, Yusen","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","61-75","2014","WIN","Disruption Management;Supply Risk Management;Experiments;Ordering Behavior;Diversification Bias;Bounded Rationality","","As supply chains become increasingly complex and global in their scale, supplier selection and management in the face of disruption risk has become one of the most challenging tasks for modern managers. Several novel model-based approaches to managing such risks have been developed in the academic literature, but how behavioral tendencies may affect procurement decisions under such conditions has received relatively less attention. In this paper, we present results from a study where paid subjects were asked to place orders from two suppliers who differ in their costs and risks to satisfy a fixed amount of end-customer demand. We show that under such a scenario, it is theoretically optimal to sole source either from the more reliable (and more costly) supplier or from the more risky but cheaper supplier, depending on cost and risk parameters. Subjects in our experiment, however, show a systematic tendency to diversify their orders between the two sources. We document this diversification tendency in procurement decisions and its possible impact on profits under various cost and risk settings as well as comment on various ordering behavior observed during the experiments. We also establish that bounded rationality of subjects can provide a possible rationale for the above phenomenon."
512,"The Impact of the Manufacturer-Hired Sales Agent on a Supply Chain with Information Asymmetry","Khanjari, Neda Ebrahim and Iravani, Seyed and Shin, Hyoduk","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","76-88","2014","WIN","Game Theory;Incentives And Contracting;Supply Chain Management","","This paper studies the impact of a manufacturer-hired sales agent on a supply chain comprising a manufacturer and a retailer. The sales agent is working mainly at the retailer's location to boost demand. We focus on a wholesale price contract, under which the retailer decides how much to order from the manufacturer. The information structure within the supply chain and the efficiency of the sales agent affect the supply chain members' expected profits. We show that, because of the agency issue between the sales agent and the manufacturer, when the retailer's demand forecast accuracy is similar to the manufacturer's and the wholesale price is fixed, the retailer's profit decreases as his demand forecast accuracy improves. We also illustrate that when the retailer's forecast accuracy is much better than the manufacturer's and the wholesale price is endogenous, his expected profit decreases as his forecast accuracy improves. Moreover, we demonstrate that having a more efficient sales agent is beneficial for the retailer when the wholesale price is fixed, whereas this is not always the case when the wholesale price depends on the efficiency of the sales agent."
513,"Inventory Control with Multiple Setup Costs","Alp, Osman and Huh, Woonghee Tim and Tan, Tarkan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","89-103","2014","WIN","Inventory Control;Multiple Setups;Markov Decision Process","","We consider an infinite-horizon, periodic-review, single-item production/inventory system with random demand and backordering, where multiple setups are allowed in any period and a separate fixed cost is associated for each setup. Contrary to the majority of the literature on this topic, we do not restrict the order quantities to be integer multiples of the exogenously given batch size and instead allow the possibility of partial batches, in which case the fixed cost for ordering the batch is still fully charged. We build a model that particularly takes the batch-ordering cost structure into account. We introduce an alternative cost-accounting scheme to analyze the problem, which we use to develop a computationally efficient optimal solution method and several properties of the optimal solution. In addition, we propose two heuristic policies, both of which perform extremely well computationally."
514,"Speed-Quality Trade-Offs in a Dynamic Model","Kostami, Vasiliki and Rajagopalan, Sampath","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","104-118","2014","WIN","Service Operations;Quality Management;Dynamic Programming;Queuing Theory","","An important trade-off organizations face in many environments is one between quality and speed. Working faster may result in greater output and less delay, but may result in lower quality and dissatisfied customers. In this work, we consider dynamic models in a monopoly setting to explore the optimal balance among the multiple dimensions of speed, price, and wait time. The impact of quality is captured via the market demand potential, which is a function of the speed (quality) in the previous period. We obtain several results and insights. First, in scenarios where speed may be difficult to change over time (e. g., some automated production lines) but price can be changed, we show that the optimal price charged is such that the demand rate remains constant over time, even though the price and market potential are changing. Furthermore, we identify conditions when the firm will work at a speed that is higher or lower than a benchmark speed and characterize the behavior of prices over time. Second, in scenarios where a firm may not be able to change prices but can adjust the speed each period, the firm starts at a speed that may be faster or slower than a benchmark speed but converges to it over time. In this constant price case, as the benchmark speed increases, the initial speed adopted by the firm is actually lower but increases more quickly thereafter. We also characterize the behavior of price and speed in settings where both can be changed over time. Interestingly, a firm typically starts at a slow speed and increases the speed, price, and demand over time. Although our main model assumes that the firm internalizes the congestion cost, several of our results extend to a scenario where the demand rate is impacted by the congestion level."
515,"Time-Based Competition with Benchmark Effects","Yang, Liu and de Vericourt, Francis and Sun, Peng","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","119-132","2014","WIN","Waiting Time Competition;Benchmark Effect;Loss Aversion;Queues;Game Theory","","We consider a duopoly where firms compete on waiting times in the presence of an industry benchmark. The demand captured by a firm depends on the gap between the firm's offer and the benchmark. We refer to the benchmark effect as the impact of this gap on demand. The formation of the benchmark is endogenous and depends on both firms' choices. When the benchmark is equal to the shorter of the two offered delays, we characterize the unique Pareto optimal Nash equilibrium. Our analysis reveals a stickiness effect in which firms equate their delays at the equilibrium when the benchmark effect is sufficiently strong. When the benchmark corresponds to a weighted average of the two offered delays, we show the existence of a pure Nash equilibrium. In this case, we reveal a reversal effect, in which the market leader, i.e., the firm that offers a shorter delay, becomes the follower when the benchmark effect is sufficiently strong. In both cases, we show that customers' equilibrium waiting times are shorter with the benchmark effect than without it. Our models also capture customers' loss aversion, which, in our setting, states that demand is more sensitive to the gap between the delay and the benchmark when the delay is longer than the benchmark (loss) than when it is shorter (gain). We characterize the impact of this loss aversion on the equilibrium in both settings. Finally, we show numerically that the stickiness and reversal effects still exist when firms also compete on price."
516,"Contracts for Changing Times: Sourcing with Raw Material Price Volatility and Information Asymmetry","Zhang, Wei and Zhou, Deke and Liu, Liwen","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","133-148","2014","WIN","Raw Material Price Volatility;Information Asymmetry;Supply Chain Management;Contracting;Risk Aversion;Risk Sharing","","We analyze and compare five contract schemes used in a supply chain: fixed price (FP), cost reimbursement (CR), procurement control (PC), index-linked payment (IL), and relational (RL) contracts. From interviews, we learned that (1) FP and RL are the two most popular schemes; (2) PC is less popular, but it is used more often than CR and IL; and (3) a couple of firms are considering CR and IL and will probably use them in the future. By presenting a two-stage contracting model that incorporates a risk-neutral buyer and a risk-averse supplier under raw material price uncertainty and information asymmetry, we show that overhedging the supplier's risk with an IL contract can be optimal for the buyer in many cases. Using the model to study the effects of price trends, risk attitudes, information asymmetry, and constraints on purchase time, we find that each contract can be optimal in certain situations from certain standpoints. In particular, when a long-term relationship is considered, RL is equivalent to IL as long as the contract is self-enforcing, and RL can replace IL when no index is available. Connecting the analytical results to the interviews, we find that firms' choices and considerations can be well understood."
517,"Dynamic Inventory-Pricing Control Under Backorder: Demand Estimation and Policy Optimization","Feng, Qi and Luo, Sirong and Zhang, Dan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","1","149-160","2014","WIN","Inventory-Pricing;Generalized Additive Models;Dynamic Programming","","Inventory-based dynamic pricing has become a common operations strategy in practice and has received considerable attention from the research community. From an implementation perspective, it is desirable to design a simple policy like a base-stock list-price (BSLP) policy. The existing research on this problem often imposes restrictive conditions to ensure the optimality of a BSLP policy, which limits its applicability in practice. In this paper, we analyze the dynamic inventory and pricing control problem in which the demand follows a generalized additive model (GAM). The GAM overcomes the limitations of several demand models commonly used in the literature, but introduces analytical challenges in analyzing the dynamic program. Via a variable transformation approach, we identify a new set of technical conditions under which a BSLP policy is optimal. These conditions are easy to verify because they depend only on the location and scale parameters of demand as functions of price and are independent of the cost parameters or the distribution of the random demand component. Moreover, although a BSLP policy is optimal under these conditions, the optimal price may not be monotone decreasing in the inventory level. We further demonstrate our results by applying a constrained maximum likelihood estimation procedure to simultaneously estimate the demand function and verify the optimality of a BSLP policy on a retail data set."
518,"Cost-per-Click Pricing for Display Advertising","Najafi-Asadolahi, Sami and Fridgeirsdottir, Kristin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","482-497","2014","FAL","Queueing Systems;Online Advertising;Pricing;Markov Chains;Cost-Per-Click","","Display advertising is a $25 billion business with a promising upward revenue trend. In this paper, we consider an online display advertising setting in which a web publisher posts display ads on its website and charges based on the cost-per-click pricing scheme while promising to deliver a certain number of clicks to the ads posted. The publisher is faced with uncertain demand for advertising slots and uncertain traffic to its website as well as uncertain click behavior of visitors. We formulate the problem as a novel queueing system, where the slots correspond to service channels with the service rate of each server inversely related to the number of active servers. We obtain the closed-form solution for the steady-state probabilities of the number of ads in the publisher's system. We determine the publisher's optimal price to charge per click and show that it can increase in the number of advertising slots and the number of promised clicks. We show that the common heuristic used by many web publishers to convert between the cost-per-click and cost-per-impression pricing schemes using the so-called click-through-rate can be misleading because it may incur substantial revenue loss to web publishers. We provide an alternative explanation for the phenomenon observed by several publishers that the click-through-rate tends to drop when they switch from the cost-per-click to cost-per-impression pricing scheme."
519,"Kidney Exchange with Long Chains: An Efficient Pricing Algorithm for Clearing Barter Exchanges with Branch-and-Price","Glorie, Kristiaan M. and van de Klundert, J. Joris and Wagelmans, Albert P. M.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","498-512","2014","FAL","Kidney Exchange;Multicriteria Optimization;Math Programming;Branch-And-Price;Simulation","","Barter exchange markets are markets in which agents seek to directly trade their goods with each other. Exchanges occur in cycles or in chains in which each agent gives a good to the next agent. Kidney exchange is an important type of barter exchange market that allows incompatible patient-donor pairs to exchange kidneys so the involved patients can receive a transplant. The clearing problem is to find an allocation of donors to patients that is optimal with respect to multiple criteria. To achieve the best possible score on all criteria, long cycles and chains are often needed, particularly when there are many hard-to-match patients. In this paper we show why this may pose difficulties for existing approaches to the optimization of kidney exchanges. We then present a generic iterative branch-and-price algorithm that can deal effectively with multiple criteria, and we show how the pricing problem may be solved in polynomial time for a general class of criteria. Our algorithm is effective even for large, realistic patient-donor pools. Our approach and its effects are demonstrated by using simulations with kidney exchange data from the Netherlands and the United States."
520,"Dynamic Pricing Strategies in the Presence of Demand Shifts","Besbes, Omar and Saure, Denis","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","513-528","2014","FAL","Revenue Management;Dynamic Pricing;Nonstationary Demand;Model Uncertainty","","Many factors introduce the prospect of changes in the demand environment that a firm faces, with the specifics of such changes not necessarily known in advance. If and when realized, such changes affect the delicate balance between demand and supply and thus current prices should account for these future possibilities. We study the dynamic pricing problem of a retailer facing the prospect of a change in the demand function during a finite selling season with no inventory replenishment opportunity. In particular, the time of the change and the postchange demand function are unknown upfront, and we focus on the fundamental trade-off between collecting revenues from current demand and doing so for postchange demand, with the capacity constraint introducing the main tension. We develop a formulation that allows for isolating the role of dynamic pricing in balancing inventory consumption throughout the horizon. We establish that, in many settings, optimal pricing policies follow a monotone path up to the change in demand. We show how one may compare upfront the attractiveness of pre-and postchange demand conditions and how such a comparison depends on the problem primitives. We further analyze the impact of the model inputs on the optimal policy and its structure, ranging from the impact of model parameter changes to the impact of different representations of uncertainty about future demand."
521,"Joint Pricing and Production Decisions in an Assemble-to-Order System","Oh, Sechan and Sourirajan, Karthik and Ettl, Markus","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","529-543","2014","FAL","Assemble-To-Order System;Dynamic Pricing;Inventory Control;Heuristic Policy;Marketing-Operations Interface","","This paper studies coordinated pricing and production decisions in an assemble-to-order system. We first show that unlike in make-to-stock systems, a state-dependent base-stock list-price policy is optimal. The optimal state-dependent base-stock levels and list prices may increase or decrease as demand backlogs increase, whereas demand backlogs always improve the optimal expected profit. Because the problem easily becomes intractable under general system settings, we next develop a simple heuristic policy. The heuristic policy decouples inventory replenishment, pricing, and component allocation decisions in a coordinated way. We provide a sufficient condition that ensures the optimality of the heuristic policy, and present a numerical study to demonstrate its performance when the condition is not met. The numerical study also shows how the performance of the heuristic policy is affected by various market and operational conditions, and by the structure of the assemble-to-order system. By focusing on the simple W-model, we show how the heuristic pricing decisions are made in response to changes in inventory levels and various cost parameters."
522,"Dynamic Call Center Routing Policies Using Call Waiting and Agent Idle Times","Chan, Wyean and Koole, Ger and L'Ecuyer, Pierre","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","544-560","2014","FAL","Multiskill Call Centers;Contact Centers;Call Routing Policies;Simulation;Stochastic Optimization","","We study call routing policies for call centers with multiple call types and multiple agent groups. We introduce new weight-based routing policies where each pair (call type, agent group) is given a matching priority defined as an affine combination of the longest waiting time for that call type and the longest idle time or the number of idle agents in that agent group. The coefficients in this combination are parameters to be optimized. This type of policy is more flexible than traditional ones found in practice, and it performs better in many situations. We consider objective functions that account for the service levels, the abandonment ratios, and the fairness of occupancy across agent groups. We select the parameters of all considered policies via simulation-based optimization heuristics. This requires only the availability of a simulation model of the call center, which can be much more detailed and realistic than the models used elsewhere in the literature to study the optimality of certain types of routing rules. We offer a first numerical study of realistic routing rules that takes into account the complexity of real-life call centers."
523,"Exact Analysis of Capacitated Two-Echelon Inventory Systems with Priorities","Abouee-Mehrizi, Hossein and Baron, Opher and Berman, Oded","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","561-577","2014","FAL","Multiechelon Inventory Management;M/G/1 Queue;Strict Priority;Multilevel Rationing;Stochastic Production Times;Stochastic Transportation Times","","We consider a two-echelon inventory system with a capacitated centralized production facility and several distribution centers (DCs). Both production and transportation times are stochastic with general distributions. Demand arrives at each DC according to an independent Poisson process and is backlogged if the DC is out of stock. We allow different holding and backlog costs at the different DCs. We assume that inventory at DCs is managed using the one-for-one replenishment policy. The main objective of this paper is to investigate the control of the multiechelon M/G/1 setting with general transportation times. To achieve this objective, we analyze several decentralized allocation policies including the first-come, first-served (FCFS), strict priority (SP), and multilevel rationing (MR) policies. For our analytic results, we assume no order crossing. We derive the cost function for a capacitated two-echelon inventory system with general transportation times under these policies. Our numerical examples show that the FCFS policy may outperform the MR policy, even though the latter has been shown to be better in the centralized setting. This suggests that in decentralized settings there is a need to focus on policies that prioritize customers when there is backlog. This focus is in contrast to the centralized settings, where inventory rationing policies that focus on prioritization when there is available inventory are effective. We therefore introduce and analyze the generalized multilevel rationing (GMR) priority policy. We compare the GMR policy with other policies and show that the GMR policy outperforms the three policies used in the centralized setting. We also compare the GMR policy with the myopic (T), longest queue first (LQF), and the optimal (when order crossing is allowed during the transportation time) policies. Our results show that when the uncertainty of the transportation times is low, the GMR policy outperforms the myopic (T) and LQF policies and that the gap between the optimal policy and the GMR policy is not high."
524,"Optimal Design of Coproductive Services: Interaction and Work Allocation","Roels, Guillaume","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","578-594","2014","FAL","Operations Strategy;Service Operations;Joint Production;Monotone Comparative Statics","","In services, customers provide significant inputs into the production process. In particular, these inputs may be the customers themselves participating in the service delivery. Although many service firms have explored different ways of involving customers in their production process, there is no clear guideline for the design of such coproductive systems. In this paper, we develop an analytical model of joint production between a service provider and a customer and characterize how a service firm should design its coproductive system. We show that, as a task becomes more standard, it is desirable to decrease the degree of interaction between the provider and the customer by making their efforts more substitutable and to allocate most of the work to whoever is the most efficient. Conversely, as a task becomes less standard, it is optimal to increase interaction by making efforts more complementary and to balance the work allocation. Our analysis gives rise to a service-process framework with three archetypes of coproductive services: collaborative services, service factories, and self-services. We discuss the implications of our results for service process reengineering."
525,"Inventory Management in Humanitarian Operations: Impact of Amount, Schedule, and Uncertainty in Funding","Natarajan, Karthik V. and Swaminathan, Jayashankar M.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","4","595-603","2014","FAL","Inventory Management;Humanitarian Operations;Funding","","Funding for humanitarian operations in the global health sector is highly variable and unpredictable. We study the problem of managing inventory in the presence of funding constraints over a finite planning period. Our goal is to determine the optimal procurement policy given the complexities associated with funding and also to analyze the impact of funding amount, funding schedule, and uncertainty around the funding timing on operations. We use a multiperiod stochastic inventory model with financial constraints and demonstrate that despite the funding complexities, the optimal replenishment policy is a state-independent policy that can be easily implemented. We also provide analytical results and several insights based on our computational study regarding the effect of funding timing uncertainty and variability on the operating costs and fill rates. Among other results, we find that receiving funding early is beneficial in underfinanced systems while avoiding funding delays is critical in fully financed systems. Our analysis also indicates that receiving less overall funding in a timely manner might actually be better than delayed full funding."
526,"Complexity-Augmented Triage: A Tool for Improving Patient Safety and Operational Efficiency","Saghafian, Soroush and Hopp, Wallace J. and Van Oyen, Mark P. and Desmond, Jeffrey S. and Kronick, Steven L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","329-345","2014","SUM","Healthcare Operations;Emergency Department;Triage;Priority Queues;Patient Prioritization;Markov Decision Processes","","Hospital emergency departments (EDs) typically use triage systems that classify and prioritize patients almost exclusively in terms of their need for timely care. Using a combination of analytic and simulation models, we demonstrate that adding an up-front estimate of patient complexity to conventional urgency-based classification can substantially improve both patient safety (by reducing the risk of adverse events) and operational efficiency (by shortening the average length of stay). Moreover, we find that EDs with high resource (physician and/or examination room) utilization, high heterogeneity in the treatment time between simple and complex patients, and a relatively equal number of simple and complex patients benefit most from complexity-augmented triage. Finally, we find that (1) although misclassification of a complex patient as simple is slightly more harmful than vice versa, complexity-augmented triage is relatively robust to misclassification error rates as high as 25%; (2) streaming patients based on complexity information and prioritizing them based on urgency is better than doing the reverse; and (3) separating simple and complex patients via streaming facilitates the application of lean methods that can further amplify the benefit of complexity-augmented triage."
527,"An Empirical Analysis of Price, Quality, and Incumbency in Procurement Auctions","Tunca, Tunay I. and Wu, D. J. and Zhong, Fang (Vivian)","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","346-364","2014","SUM","Supply Chain Management;Service Operations;Operations Strategy;Auctions And Mechanism Design;Econometric Analysis","","The use of multiattribute auctions for procurement of products and services when both price and quality matter is becoming more frequent. Such auctions often employ scoring rules and are open ended in winner determination. Yet there is a significant gap in the literature on the efficiency of these procurement mechanisms. In this paper, providing a theoretical model and utilizing data from legal service procurement auctions, we study how open-ended scoring auctions can be used effectively in procurement and demonstrate the roles supplier quality and incumbency play in this process. We demonstrate that open-ended auctions can generate substantial savings to a buyer without compromising quality. We study the underlying mechanism and show how the auction format can work to achieve such performance. We find that the buyer's revealed preferences significantly differ from her stated preferences. Finally, we contribute to the understanding of the role of incumbency in procurement auctions by providing evidence that what may be perceived as incumbency bias can in fact be a revelation of preference for quality."
528,"Service Systems with Finite and Heterogeneous Customer Arrivals","Wang, Rowan and Jouini, Oualid and Benjaafar, Saif","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","365-380","2014","SUM","Queueing Systems;Finite Arrivals;Heterogeneous Interarrival And Service Times;Transient Analysis;Fluid Approximation","","We consider service systems with a finite number of customer arrivals, where customer interarrival times and service times are both stochastic and heterogeneous. Applications of such systems are numerous and include systems where arrivals are driven by events or service completions in serial processes as well as systems where servers are subject to learning or fatigue. Using an embedded Markov chain approach, we characterize the waiting time distribution for each customer, from which we obtain various performance measures of interest, including the expected waiting time of a specific customer, the expected waiting time of an arbitrary customer, and the expected completion time of all customers. We carry out extensive numerical experiments to examine the effect of heterogeneity in interarrival and service times. In particular, we examine cases where interarrival and service times increase with each subsequent arrival or service completion, decrease, increase and then decrease, or decrease and then increase. We derive several managerial insights and discuss implications for settings where such features can be induced. We validate the numerical results using a fluid approximation that yields closed-form expressions."
529,"Optimizing Colonoscopy Screening for Colorectal Cancer Prevention and Surveillance","Erenay, Fatih Safa and Alagoz, Oguzhan and Said, Adnan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","381-400","2014","SUM","Stochastic Modeling;Partially Observable Markov Decision Processes;Operations Research Applications In Healthcare;Cancer Screening;Colorectal Cancer Prevention And Surveillance;Colonoscopy","","Millions of Americans undergo colonoscopy screening for colorectal cancer (CRC) prevention and surveillance every year. The efficiency of colonoscopy operations depends on how often patients are screened, which is a complex and controversial decision, as reflected by the discrepancy between clinical practice and guidelines. We develop a partially observable Markov decision process to optimize colonoscopy screening policies for the objective of maximizing total quality-adjusted life years. Our model incorporates age, gender, and risk of having CRC into the screening decisions and therefore provides a novel framework for personalized CRC screening. In addition to deriving the maximum attainable benefit from colonoscopy screening, which reflects the opportunity cost of following current guidelines, our results have several policy implications. Using clinical data, we show that the optimal colonoscopy screening policies may be more aggressive than the guidelines under some conditions. Optimal screening policies recommend that females with CRC history undergo colonoscopy more frequently than males. In contrast, females without CRC history should be screened less frequently than males. This result, which was not recognized before, signifies the role of gender in optimal CRC screening decisions."
530,"Pricing in Queues Without Demand Information","Haviv, Moshe and Randhawa, Ramandeep S.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","401-411","2014","SUM","Static Pricing;Dynamic Pricing;Revenue Optimization;Robust Optimization","","We consider revenue optimization in an M/M/1 queue with price and delay sensitive customers, and we study the performance of demand-independent pricing that does not require any arrival rate information. We formally characterize the optimal demand-independent price and its performance relative to pricing with precise arrival rate knowledge. We find that demand-independent pricing can perform remarkably well and its performance improves as customers become more delay sensitive. In particular, for uniformly distributed customer valuations, under a large set of parameters, we find that demand-independent prices can capture more than 99% of the optimal revenue. We also study social optimization and find that demand-independent pricing can perform quite well; however, the performance is better under revenue optimization."
531,"Transparency of Information Acquisition in a Supply Chain","Li, Tian and Tong, Shilu and Zhang, Hongtao","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","412-424","2014","SUM","Transparency;Market Research;Confidentiality;Supply Chain","","A firm hires a consultant to acquire demand information. The outcome of information acquisition may turn out to be successful such that the firm learns much about the market demand, thus becoming informed, or unsuccessful such that it learns very little about the market demand, thus remaining uninformed. After the outcome becomes clear, the firm knows its information status, informed or uninformed, and the information content if informed. The client firm usually requires strict confidentiality that forbids the consultant to make any disclosure about the information acquisition, believing that greater informational advantage will surely be to its own benefits. As a result, neither the information content nor the information status is known to any third party. But should the firm always care so much about strict confidentiality? Will it be beneficial if the firm's information status, but not the information content, is known to its partners or any other firms? We investigate this issue in the context of a two-tier supply chain. A manufacturer offers a menu of contracts for supplying a product to a retailer who sells it in a market with random demand that has a known continuous distribution. The retailer hires a consultant to acquire demand information, with uncertain outcome. With probability t, the retailer becomes informed about the market demand, and with probability 1 - t, he remains uninformed, where the probability t can be regarded as representing the retailer's information acquisition capability. We find that disclosing its information status benefits the retailer if its information acquisition capability is less than stellar and the market variability is intermediate. Our investigation shows that there are benefits that are foregone by following strict confidentiality but can potentially be recovered by switching to a policy of partial confidentiality."
532,"Purchasing Scarce Products Under Dynamic Pricing: An Experimental Investigation","Mak, Vincent and Rapoport, Amnon and Gisches, Eyran J. and Han, Jiaojie","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","425-438","2014","SUM","Dynamic Pricing;Revenue Management;Consumer Behavior;Experiments;Behavioral Operations Management;Game Theory","","Whereas theoretical studies on dynamic pricing typically assume that consumers are either fully strategic or fully myopic, systematic empirical investigations into how consumers behave under dynamic pricing contexts are relatively rare. Focusing on scarce products, we constructed and experimentally tested a two-stage model in which a firm sells a seasonal good under exogenous inventory constraints to a market of strategic buyers. In our experiment, subjects assigned the role of buyers made purchase decisions in response to prices set by an automated seller. We find that equilibrium predictions assuming fully strategic buyers largely accounted for aggregate behavior in the experiment, and the ex post optimal decisions for subjects were overwhelmingly consistent with equilibrium prescriptions. Moreover, subjects tended to become individually more strategic as the session progressed. However, there were also nuanced systematic patterns of deviations from equilibrium that had profit and pricing implications for the seller. First, a nonnegligible minority of subjects exhibited completely myopic buying behavior even with practice. Second, when the product was relatively more scarce, myopic buying had a stronger impact on demand at higher prices; the upshot is that the seller's season-profit-maximizing price could be considerably higher than what would be optimal with fully strategic buyers."
533,"Nurse Absenteeism and Staffing Strategies for Hospital Inpatient Units","Wang, Wen-Ya and Gupta, Diwakar","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","439-454","2014","SUM","Absenteeism;Staffing;Hospital Operations","","Inpatient staffing costs are significantly affected by nurse absenteeism, which is typically high in U. S. hospitals. We use data from multiple inpatient units of two hospitals to study which factors, including unit culture, short-term workload, and shift type, explain nurse absenteeism. The analysis highlights the importance of paying attention to heterogeneous absentee rates among individual nurses. We then develop models to investigate the impact of demand and absentee rate variability on the performance of staffing plans and obtain some structural results. Utilizing these results, we propose and test three easy-to-use heuristics to identify near-optimal staffing strategies. Such strategies could be useful to hospitals that periodically reassign nurses with similar qualifications to inpatient units in order to balance workload and accommodate changes in patient flow. Although motivated by staffing of hospital inpatient units, the approach developed in this paper is also applicable to other team-based and labor-intensive service environments."
534,"Multimodularity and Its Applications in Three Stochastic Dynamic Inventory Problems","Li, Qing and Yu, Peiwen","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","455-463","2014","SUM","Dynamic Programming;Multimodularity;Substitutability And Complementarity;Stochastic Inventory Models","","We apply the concept of multimodularity in three stochastic dynamic inventory problems in which state and decision variables are economic substitutes. The first is clearance sales of perishable goods. The second is sourcing from multiple suppliers with different lead times. The third is transshipment under capacity constraints. In all three problems, we establish monotone optimal polices with bounded sensitivity. Multimodularity proves to be an effective tool for these problems because it implies substitutability, it is preserved under minimization, and it leads directly to monotone optimal policies with bounded sensitivity."
535,"Are Call Center and Hospital Arrivals Well Modeled by Nonhomogeneous Poisson Processes?","Kim, Song-Hee and Whitt, Ward","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","3","464-480","2014","SUM","Arrival Processes;Nonhomogeneous Poisson Process;Kolmogorov-Smirnov Statistical Test;Data Rounding;Overdispersion","","Service systems such as call centers and hospitals typically have strongly time-varying arrivals. A natural model for such an arrival process is a nonhomogeneous Poisson process (NHPP), but that should be tested by applying appropriate statistical tests to arrival data. Assuming that the NHPP has a rate that can be regarded as approximately piecewise-constant, a Kolmogorov-Smirnov (KS) statistical test of a Poisson process (PP) can be applied to test for a NHPP by combining data from separate subintervals, exploiting the classical conditional-uniform property. In this paper, we apply KS tests to banking call center and hospital emergency department arrival data and show that they are consistent with the NHPP property, but only if that data is analyzed carefully. Initial testing rejected the NHPP null hypothesis because it failed to account for three common features of arrival data: (i) data rounding, e.g., to seconds; (ii) choosing subintervals over which the rate varies too much; and (iii) overdispersion caused by combining data from fixed hours on a fixed day of the week over multiple weeks that do not have the same arrival rate. In this paper, we investigate how to address each of these three problems."
536,"Does Multitasking Improve Performance? Evidence from the Emergency Department","Singh, Diwas K. C.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","168-183","2014","SPR","Multitasking;Productivity;Quality;Emergency Department;Capacity Planning","","This paper examines the effect of multitasking on overall worker performance, as measured by processing time, throughput rate, and output quality using microlevel operational data from the field. Specifically, we study the multitasking behavior of physicians in a busy hospital emergency department (ED). By drawing on recent findings in the experimental psychology literature and the nascent work in cognitive neuroscience, we develop several hypotheses for the effect of multitasking on worker performance. We first examine how multitasking affects a physician's processing time. We find that the total time taken to discharge a given number of patients has a U-shaped response to the level of physician multitasking; that is, multitasking initially helps to reduce the time taken, but only up to a certain threshold level, after which it increases in the level of multitasking. In addition, multitasking significantly impacts quality of care. Although lower levels of multitasking are associated with improved quality of care, at higher levels, additional multitasking leads to a smaller number of detected diagnoses and an increased likelihood of a 24-hour revisit rate to the ED. These findings have important implications for the design and organization of work in general and for the delivery of critical care in particular."
537,"Estimation of Choice-Based Models Using Sales Data from a Single Firm","Newman, Jeffrey P. and Ferguson, Mark E. and Garrow, Laurie A. and Jacobs, Timothy L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","184-197","2014","SPR","Choice-Based Revenue Management;Discrete Choice Modeling;Censored Alternatives;Sampling Of Alternatives","","We develop a parameter estimation routine for multinomial logit discrete choice models in which one alternative is completely censored, i.e., when one alternative is never observed to have been chosen in the estimation data set. Our method is based on decomposing the log-likelihood function into marginal and conditional components. Our method is computationally efficient, provides consistent parameter estimates, and can easily incorporate price and other product attributes. Simulations based on industry hotel data demonstrate the superior computational performance of our method over alternative estimation methods that are capable of estimating price effects. Because most existing revenue management choice-based optimization algorithms do not include price as a decision variable, our estimation procedure provides the inputs needed for more advanced product portfolio availability and price optimization models."
538,"Data Set Online Pricing Data for Multiple US Carriers","Mumbower, Stacey and Garrow, Laurie A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","198-203","2014","SPR","Airline Pricing;Low-Cost Carriers;Online Pricing","","In this paper we describe a database of online airline prices collected from a major online travel agent and a low-cost carrier. The database provides detailed pricing data for all nonstop flights offered in a market. Data are provided for 42 domestic U. S. markets across a 28-day booking horizon for 21 departure dates. Each of the 42 markets is served by one or more low-cost carriers. These data can be used to investigate the evolution of prices and price dispersion for monopoly, duopoly, and oligopoly markets. The data can be used to create simulated data sets for benchmarking the performance of revenue management algorithms that consider competitors' prices. Analysis of the data may enable researchers to observe general patterns that would be useful to motivate research and/or teaching in revenue management."
539,"Strategic Safety Stock Placement in Supply Networks with Static Dual Supply","Klosterhalfen, Steffen T. and Minner, Stefan and Willems, Sean P.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","204-219","2014","SPR","Dual Sourcing;Guaranteed Service;Multiechelon Inventory System;Safety Stock Optimization","","Many real-world supply networks source required materials from multiple suppliers. Existing multiechelon inventory optimization approaches either restrict their scope to multiple supply sources in two-echelon systems or single suppliers in multiechelon systems. We develop an exact mathematical model for static dual supply in a general acyclic N-echelon network structure, which builds on the guaranteed-service framework for safety stock optimization. It is assumed that the suppliers are allocated static fractions of demand. We prove that for normally distributed demand an extreme point property holds. We present a real example from the industrial electronics industry consisting of five echelons and three dual-sourced materials. This example forms the basis for a numerical analysis. Compared with the only previously published approximate solution, our exact approach results in considerable cost savings because the exact model captures inventory pooling in a way that the approximation is unable to do. For a set of test problems, total safety stock cost savings are 9.1%, on average."
540,"Threshold Routing to Trade Off Waiting and Call Resolution in Call Centers","Zhan, Dongyuan and Ward, Amy R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","220-237","2014","SPR","Call Center Management;Queueing Theory;Stochastic Methods;Service Operations","","In a call center, agents may handle calls at different speeds, and also may be more or less successful at resolving customers' inquiries, even when only considering customers calling with similar requests. One common measure of successful call resolution is whether or not the call results in the customer calling back. This presents a natural trade-off between speed and quality, where speed is defined as the average time before an incoming call is answered (the average waiting time) and quality is defined as the percentage of all arriving calls that do not result in callbacks (the call resolution). The relevant control is the routing, that is, the decision concerning which agent should handle an arriving call when more than one agent is available. In an inverted-V model setting, we formulate an optimization problem with the dual performance objective of minimizing average customer waiting time and maximizing the call resolution. We solve this optimization problem asymptotically in the Halfin-Whitt many-server limit regime, interpret its solution as a routing control for the discrete-event system, and show via simulation that the interpreted routing control is on the efficient frontier. In particular, any routing control that has a lower average waiting time (higher call resolution) must also have a lower call resolution (higher average waiting time)."
541,"The Sourcing Hub and Upstream Supplier Networks","Agrawal, Anupam and Van Wassenhove, Luk N. and De Meyer, Arnoud","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","238-250","2014","SPR","Sourcing Hub;Raw Material Sourcing;Supplier Network","","In this paper, we explore how firms can better manage their sourcing by developing relationships not only with their suppliers but also with their suppliers' suppliers. We detail an empirical case study explaining how the firm developed relationships with its suppliers and raw material suppliers via a collaborative center, the sourcing hub. We then analytically model the scenarios encountered in our empirical work and examine two facets of upstream sourcing under uncertain demand scenarios: (a) firms can supply raw material directly to their suppliers, and this may be beneficial for the firm and its suppliers; and (b) firms can bring their suppliers together at the sourcing hub, and the resulting cooperation between suppliers is beneficial for the suppliers and the raw material suppliers. Overall, our work explores the market and economic conditions under which active management of upstream sourcing can add value to supply chains."
542,"Sequencing Appointments for Service Systems Using Inventory Approximations","Mak, Ho-Yin and Rong, Ying and Zhang, Jiawei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","251-262","2014","SPR","Appointment Scheduling;Service Operations;Stochastic Inventory Control;Serial Supply Chains;Stochastic Programming","","Managing appointments for service systems with random job durations is a challenging task. We consider a class of appointment planning problems that involve two sets of decisions: job sequencing, i.e., determining the order in which a list of jobs should be performed by the server, and appointment scheduling, i.e., planning the starting times for jobs. These decisions are interconnected because their joint goal is to minimize the expected server idle time and job late-start penalty costs incurred because of randomness in job durations. In this paper, we design new heuristics for sequencing appointments. The idea behind the development of these heuristics is the structural connection between such appointment scheduling problems and stochastic inventory control in serial supply chains. In particular, the decision of determining time allowances as buffers against random job durations is analogous to that of selecting inventory levels as buffers to accommodate random demand in a supply chain; having excess buffers in appointment scheduling and supply chain settings incurs idle time and excess inventory holding costs, respectively, and having inadequate buffers leads to delays of subsequent jobs and backorders, respectively. Recognizing this connection, we propose tractable approximations for the job sequencing problem, obtain several insights, and further develop a very simple sequencing rule of ordering jobs by duration variance to late-start penalty cost ratio. Computational results show that our proposed heuristics produce close-to-optimal job sequences with significantly reduced computation times compared with those produced using an exact mixed-integer stochastic programming formulation based on the sample-average approximation approach."
543,"Pooling and Dependence of Demand and Yield in Multiple-Location Inventory Systems","Mak, Ho-Yin and Shen, Zuo-Jun Max","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","263-269","2014","SPR","Supply Chain Design;Inventory Sharing;Stochastic Orders;Robust Optimization","","The benefits of inventory risk pooling are well known and documented. It has been proven in the literature that the expected costs of a centralized system are increasing in the degree of (positive) dependence of demand in an idealized newsvendor setting. Using the supermodular stochastic order to characterize dependence, we study a general two-tiered supply chain structure, in which both demand and supply yields are random, and prove that the expected costs are increasing in the degrees of positive dependence between demand and supply yield loss factors. Furthermore, using a distributionally robust optimization framework, we prove an analogous result for the case where demand and yield distributions are not precisely known."
544,"Optimal Energy Procurement in Spot and Forward Markets","Secomandi, Nicola and Kekre, Sunder","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","270-282","2014","SPR","Correlated Price And Demand Uncertainty;Energy And Commodities;Newsvendor Model;Om-Finance Interface;Procurement;Real Options;Spot And Forward Markets;Transaction Costs;Valuation","","Spot and forward purchases for delivery on the usage date play an important role in matching the supply and the uncertain demand of energy because storage capacity for energy, such as electricity, natural gas, and oil, is limited. Transaction costs tend to be larger in spot than forward energy markets near maturity. Partially procuring supply in the forward market, rather than entirely in the spot market, is thus a potentially valuable real option, which we call the forward procurement option. We investigate the optimal value and management of this real option as well as their sensitivities to parameters of interest. Our research quantifies the value of the forward procurement option on realistic natural gas instances, also suggesting that procuring the demand forecast in the forward market is nearly optimal. This policy greatly simplifies the management of this real option without an appreciable loss of value. We provide some theoretical support for this numerical finding. Beyond energy, our research has potential relevance for the procurement of other commodities, such as metals and agricultural products."
545,"Erlang-R: A Time-Varying Queue with Reentrant Customers, in Support of Healthcare Staffing","Yom-Tov, Galit B. and Mandelbaum, Avishai","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","283-299","2014","SPR","Healthcare;Queueing Networks;Modified Offered-Load;Time-Varying Queues;Halfin-Whitt Regime;Qed Regime;Ed Regime;Emergency Department Staffing;Mass Casualty Events;Patient Flow","","We analyze a queueing model that we call Erlang-R, where the R stands for reentrant customers. Erlang-R accommodates customers who return to service several times during their sojourn within the system, and its modeling power is most pronounced in time-varying environments. Indeed, it was motivated by healthcare systems, in which offered-loads vary over time and patients often go through a repetitive service process. Erlang-R helps answer questions such as how many servers (physicians/nurses) are required to achieve predetermined service levels. Formally, it is merely a two-station open queueing network, which, in a steady state, evolves like an Erlang-C (M/M/s) model. In time-varying environments, on the other hand, the situation differs: here one must account for the reentrant nature of service to avoid excessive staffing costs or undesirable service levels. We validate Erlang-R against an emergency ward (EW) operating under normal conditions as well as during a mass casualty event (MCE). In both scenarios, we apply time-varying fluid and diffusion approximations: the EW is critically loaded and the MCE is overloaded. In particular, for the EW we propose a time-varying square-root staffing policy, based on the modified offered-load, which is proved to perform well over small-to-large systems."
546,"Bid-Taker Power and Supply Base Diversification","Wan, Zhixi and Beil, Damian R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","300-314","2014","SPR","Supply Base Design;Procurement Auctions;Bid-Taker Power","","We study a buyer who periodically auctions off short-term supply contracts among her supply base. To mitigate significant cost shocks to procurement, the buyer can diversify her supply base by selecting suppliers from different regions. We find that the buyer's decision to diversify depends on her bid-taker power-that is, her ability to choose the auction mechanism. At one extreme, when the buyer has full bid-taker power and thus can dictatorially implement the optimal mechanism, she always prefers to diversify. At the other extreme, when the buyer uses a reverse English auction with no reserve price due to her lack of bid-taker power, she generally prefers to protect herself against potential price escalation from cost-advantaged suppliers by diversifying less. The managerial insight is that the more bid-taker power the buyer has to control price escalation from cost-advantaged suppliers the more she prefers a diversified supply base. This insight is shown to be robust to correlation between regional costs, ex ante asymmetry between regions, and intermediate levels of bid-taker power."
547,"On the Downs-Thomson Paradox in a Self-Financing Two-Tier Queuing System","Guo, Pengfei and Lindsey, Robin and Zhang, Zhe George","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","16","2","315-322","2014","SPR","Queuing System;Two-Tier Service System;Equilibrium Arrival Rates;Pricing And Capacity Decisions;Downs-Thomson Paradox","","We model a two-tier queuing system with free and toll service options as two parallel M/M/1 servers. We solve for the welfare-maximizing toll service capacity and toll subject to the constraint that the toll service cover its costs. If the free and toll services are both used in equilibrium, a larger free-service capacity implies longer expected waiting time for the free service and lower welfare: an analogue to the Downs-Thomson paradox in transportation economics. The paradox is caused by the presence of scale economies in the toll service combined with the requirement that it be self-financing."
548,"Three Rs of Operations Management: Research, Relevance, and Rewards","Van Mieghem, Jan A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","2-5","2013","WIN","Operations Management;Research;Relevance;Rewards;Research Relevance Matrix","","This article presents three personal experiences and reflections on the process and objective of research in operations management. This invited OM Forum contribution is based on my Manufacturing and Service Operations Management Distinguished Fellow inaugural lecture given at Columbia University on June 18, 2012."
549,"The Relationship Between Abnormal Inventory Growth and Future Earnings for U.S. Public Retailers","Kesavan, Saravanan and Mani, Vidya","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","6-23","2013","WIN","Econometric Analysis;Retailing;Operations Management-Accounting Interface","","In this paper, we examine the relationship between inventory levels and one-year-ahead earnings of retailers using publicly available financial data. We use benchmarking metrics obtained from operations management literature to demonstrate an inverted-U relationship between abnormal inventory growth and one-year-ahead earnings per share for retailers. We also find that equity analysts do not fully incorporate the information contained in retailers' abnormal inventory growth in their earnings forecasts, resulting in systematic biases. Finally, we show that an investment strategy based on abnormal inventory growth yields significant abnormal stock market returns."
550,"Process Flexibility Design in Unbalanced Networks","Deng, Tianhu and Shen, Zuo-Jun Max","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","24-32","2013","WIN","Process Flexibility Design;Unbalanced Networks;Chaining Guidelines","","Several design guidelines and flexibility indices have been developed in the literature to inform the design of flexible,production networks. In this paper, we propose additional flexibility design guidelines for unbalanced networks, where the numbers of plants and products are not equal, by refining the well-known Chaining Guidelines. We study symmetric networks, where all plants have the same capacity and product demands are independent and identically distributed, and focus mainly on the case where each product is built at two plants. We also briefly discuss cases where (1) each product is built at three plants and (2) some products are built at only one plant. An extensive computational study suggests that our refinements work very well for finding flexible configurations with minimum shortfall in unbalanced networks."
551,"Inventory Pooling to Deliver Differentiated Service","Alptekinoglu, Aydin and Banerjee, Arunava and Paul, Anand and Jain, Nikhil","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","33-44","2013","WIN","Inventory Pooling;Type 1 Service Level;Inventory Allocation Policy;Aftermarket Services;Spare Parts;Pooling Benefit;Demand Correlation","","Inventory pooling is at the root of many celebrated ideas in operations management. Postponement, component commonality, and resource flexibility are some examples. Motivated by our experience in the aftermarket services industry, we propose a model of inventory pooling to meet differentiated service levels for multiple customers. Our central research question is the following: What are the minimum inventory level and optimal allocation policy when a pool of inventory is used in a single period to satisfy individual service levels for multiple customers? We measure service by the probability of fulfilling a customer's entire demand immediately from stock. We characterize the optimal solution in several allocation policy classes; provide some structural results, formulas, and bounds; and also make detailed interpolicy comparisons. We show that the pooling benefit is always strictly positive, even when there are an arbitrary number of customers with perfectly positively correlated demands."
552,"Delegation vs. Control of Component Procurement Under Asymmetric Cost Information and Simple Contracts","Kayis, Enis and Erhun, Feryal and Plambeck, Erica L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","45-56","2013","WIN","Multitier Supply Chain;Delegation;Control;Asymmetric Information;Component Procurement;Contract Design;Price-Only Contracts;Quantity Discount Contracts;Robust Optimization","","A manufacturer must choose whether to delegate component procurement to her tier 1 supplier or control it directly. Because of information asymmetry about suppliers' production costs and the use of simple quantity discount or price-only contracts, either delegation or control can yield substantially higher expected profit for the manufacturer. Delegation tends to outperform control when (1) the manufacturer is uncertain about the tier 1 supplier's cost and believes that it is likely to be high; (2) the manufacturer and the tier 1 supplier know the tier 2 supplier's cost or at least that it will be high; (3) the manufacturer has an alternative to engaging the tier 1 and tier 2 suppliers, such as in-house production; and (4) the firms use price-only contracts as opposed to quantity discount contracts. These results shed light on practices observed in the electronics industry."
553,"Advance Demand Information, Price Discrimination, and Preorder Strategies","Li, Cuihong and Zhang, Fuqiang","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","57-71","2013","WIN","Preorder;Advance Demand Information;Price Discrimination;Strategic Consumer Behavior;Price Guarantee","","This paper studies the preorder strategy that a seller may use to sell a perishable. product in an uncertain market with heterogeneous consumers. By accepting preorders, the seller is able to obtain advance demand information for inventory planning and price discriminate the consumers. Given the preorder option, the consumers react strategically by optimizing the timing of purchase. We find that accurate demand information may improve the availability of the product, which undermines the seller's ability to charge a high preorder price. As a result, advance demand information may hurt the seller's profit due to its negative impact for the preorder season. This cautions the seller about a potential conflict between the benefits of advance demand information and price discrimination when facing strategic consumers. A common practice to contain consumers' strategic waiting is to offer Once guarantees that compensate preorder consumers in case of a later price cut. Under price guarantees, the seller will reduce price in the regular season only if the preorder demand is low; however, such advance information implies weak demand in the regular season as well. This means that the seller can no longer benefit from a high demand in the regular season. Therefore, under price guarantees, more accurate advance demand information may still hurt the seller's profit due to its adverse impact for the regular season. We also investigate the seller's strategy choice in such a setting (i.e., whether the preorder option should be offered and whether it should be coupled with price guarantees) and find that the answer depends on the relative sizes of the heterogeneous consumer segments."
554,"Forecasting Call Center Arrivals: Fixed-Effects, Mixed-Effects, and Bivariate Models","Ibrahim, Rouba and L'Ecuyer, Pierre","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","72-85","2013","WIN","Forecasting;Arrival Process;Dynamic Updating;Correlation;Call Centers","","We consider different statistical models for the call arrival process in telephone call centers. We evaluate the forecasting accuracy of those models by describing results from an empirical study analyzing real-life call center data. We test forecasting accuracy using different lead times, ranging from weeks to hours in advance, to mimic real-life challenges faced by call center managers. The models considered are (i) a benchmark fixed-effects model that does not exploit any dependence structures in the data; (ii) a mixed-effects model that takes into account both interday (day-to-day) and intraday (within-day) correlations; and (iii) two new bivariate mixed-effects models, for the joint distribution of the arrival counts to two separate queues, that exploit correlations between different call types. Our study shows the importance of accounting for different correlation structures in the data."
555,"Dynamic Pricing of Substitutable Products in the Presence of Capacity Flexibility","Ceryan, Obert and Sahin, Ozge and Duenyas, Izak","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","86-101","2013","WIN","Pricing And Revenue Management;Dynamic Pricing;Capacity Flexibility;Inventory Control;Substitutable Products","","Firms that offer multiple products are often susceptible to periods of inventory mismatches where one product may face shortages while the other has excess inventories. In this paper, we study a joint implementation of price- and capacity-based substitution mechanisms to alleviate the level of such inventory disparities. We consider a firm producing substitutable products via a capacity portfolio consisting of both product-dedicated and flexible resources and characterize the structure of the optimal production and pricing decisions. We then explore how changes in various problem parameters affect the optimal policy structure. We show that the availability of a flexible resource helps maintain stable price differences across products over time even though the price of each product may fluctuate over time. This result has favorable ramifications from a marketing standpoint because it suggests that even when a firm applies a dynamic pricing strategy, it may still establish consistent price positioning among multiple products if it can employ a flexible replenishment resource. We provide numerical examples for the price stabilization effect and discuss extensions of our results to a more general multiple product setting."
556,"Aligning Capacity Decisions in Supply Chains When Demand Forecasts Are Private Information: Theory and Experiment","Hyndman, Kyle and Kraiselburd, Santiago and Watson, Noel","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","102-117","2013","WIN","Communication;Coordination;Supply Chains;Experiment","","We study the problem of a two-firm supply chain in which firms simultaneously choose a capacity before demand is realized. We focus on the role that private information about demand has on firms' ability to align their capacity decisions. When forecasts are private information, there are at most two equilibria: a complete coordination failure or a monotone equilibrium. The former equilibrium always exists, whereas the latter exists only when the marginal cost of capacity is sufficiently low. We also show that both truthful information sharing and preplay communication have an equilibrium with higher profits. We then test the model's predictions experimentally. Contrary to our theoretical predictions, we show that private demand forecasts do not have a consistently negative effect on firm profits, though capacities are more misaligned. We show that preplay communication may be more effective at increasing profits than truthful information"
557,"Strategic Queueing Behavior and Its Impact on System Performance in Service Systems with the Congestion-Based Staffing Policy","Guo, Pengfei and Zhang, Zhe George","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","118-131","2013","WIN","Congestion-Based Staffing;Pricing;Delay Information;Strategic Customer","","We study strategic customer behavior in a multiserver stochastic service system with a congestion-based staffing (CBS) policy. With the CBS policy, the number of working servers is dynamically adjusted according to the queue length. Besides lining up for free service, customers have the option of paying a fee and getting faster service. Customers' equilibrium behavior is studied under two information scenarios: In the no information scenario, customers only know the long-term statistics, such as the expected waiting time; in the partial information scenario, customers observe the number of working servers and understand the staffing policy upon their arrival. Unlike a queueing system with a constant staffing level, a positive externality is associated with customers' joining the CBS system. Both avoid-the-crowd and follow-the-crowd customer behaviors are possible, and multiple equilibria could exist. We develop the stationary performance measures of the system by considering the customers' strategic behavior. Numerical analysis shows that information can either hurt or improve the performance of the system, depending on the staffing and pricing policy. Another important conclusion is that the system performance is more robust to setting a relatively high than a relatively low price."
558,"On the Equilibrium Behavior of a Supply Chain Market for Capacity","Sapra, Amar and Jackson, Peter L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","132-147","2013","WIN","Incentives And Contracting;Supply Chain Management;Stochastic Methods","","A capacity market is a business-to-business exchange in which equally capable suppliers compete with one another to satisfy generic orders from diverse buyers. The market is asymmetric because the buyers can carry inventory of the products ordered but the suppliers cannot store their capacity. In such a market, we might expect to see something like a price for capacity emerge to equilibrate demand and supply. The financial risk of participating in such a market will be driven by the volatility of the capacity price. In this paper we develop a model to explore the behavior of such a market and demonstrate, for example, that volatility of the price for capacity increases, to a point, when inflexibility of the capacity increases. We can also make statements about how the resolution of price uncertainty in the capacity market is related to the resolution of demand uncertainty faced by the buyers. Another contribution of the paper is to explain the role of market characteristics in how the market acts to minimize shortages caused by consumer demand uncertainty. We use continuous time stochastic optimal control techniques and numerical experiments to demonstrate these insights."
559,"Noncooperative Games for Subcontracting Operations","Vairaktarakis, George L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","1","148-158","2013","WIN","Operations Strategy;Production Planning And Scheduling;Supply Chain Management;Incentives And Contracting","","Consider a set of manufacturers, all of which can subcontract part of their workload to a third party. For simplicity, we assume that every manufacturer as well as the third party each possess a single production facility. Each manufacturer has to decide the amount of workload to be subcontracted so as to minimize the completion time of his in-house and subcontracted workloads. In an effort to provide good service to all, the third party gives priority to manufacturers whose subcontracted workload is small. This incentive scheme forces manufacturers to compete for position in the third-party processing sequence. We develop. pure Nash equilibria schedules under three distinct protocols for production."
560,"Introduction to the Special Issue on the Environment","Plambeck, Erica L. and Toktay, L. Beril","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","523-526","2013","FAL","Environmentally Sustainable Operations Management;Product Design;Energy Efficiency;Climate Change;Population;Adaptation;Chemical Toxicity","","Human population growth and increasing consumption per capita are causing environmental impacts that threaten the survival and well-being of humans and other species on Earth. To sustain natural ecosystems and human populations with a high standard of living, humanity must now reinvent our systems for the production and delivery of goods and services to dramatically reduce the environmental impacts associated with consumption. The operations management community can contribute critical know-how to do so, as demonstrated by the papers in this special issue."
561,"Operations Management Challenges for Some Cleantech Firms","Plambeck, Erica L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","527-536","2013","FAL","Environment;Energy;Process Innovation;Supply Chain Management;Capacity Investment;Bankruptcy;Public Policy","","A cleantech firm is one with an innovative technology and/or business model for serving an existing market with dramatically reduced environmental impact. This paper describes operations management (OM) challenges faced by five cleantech companies, and a few questions that these raise for OM and multidisciplinary research. It aims to fuel readers' motivation to identify and pursue others. The OM community has fundamental roles to play in the creation of an environmentally sustainable economy."
562,"Business Model Innovation for Sustainability","Girotra, Karan and Netessine, Serguei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","537-544","2013","FAL","Business Models;Sustainability;Innovation;Entrepreneurship;Business Model Innovation;Risk","","A systematic approach to innovating business models can help identify new business models that encourage sustainable use of products and services, or facilitate wider adoption of new environmentally friendly technologies. This paper provides a brief summary of a conceptual framework that we have developed to systematize the study and identification of new business models. Our approach advocates that the key to identifying new business models is understanding the context of decision making in existing models and the associated inefficiencies. We propose a three-step approach: First, existing business models must be audited for identifying information and incentive misalignment inefficiencies that destroy value. Next, new business models can be identified by changing the context of the decision associated with the most consequential of these inefficiencies. We conjecture that four elements of the decision context are most significant: WHAT decisions are made, WHEN they are made, WHO makes them, and WHY they are made. We provide a set of idea triggers to stimulate brainstorming of new business models by changing one of these four Ws. Finally, we advise that generated business models should be analyzed and experimented with to identify the most promising ones. We close the paper by describing the design of a pedagogical program based on this framework."
563,"Double Counting in Supply Chain Carbon Footprinting","Caro, Felipe and Corbett, Charles J. and Tan, Tarkan and Zuidwijk, Rob","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","545-558","2013","FAL","Carbon Footprint;Supply Chain;Sustainable Operations;Emissions Allocation","","Carbon footprinting is a tool for firms to determine the total greenhouse gas (GHG) emissions associated with their supply chain or with a unit of final product or service. Carbon footprinting typically aims to identify where best to invest in emission reduction efforts, and/or to determine the proportion of total emissions that an individual firm is accountable for, whether financially and/or operationally. A major and underrecognized challenge in determining the appropriate allocation stems from the high degree to which GHG emissions are the result of joint efforts by multiple firms. We introduce a simple but general model of joint production of GHG emissions in general supply chains, decomposing the total footprint into processes, each of which can be influenced by any combination of firms. We analyze two main scenarios. In the first scenario, the social planner allocates emissions to individual firms and imposes a cost on them (such as a carbon tax) in proportion to the emissions allocated. In the second scenario, a carbon leader voluntarily agrees to offset all emissions in the entire supply chain and then contracts with individual firms to recoup (part of) the costs of those offsets. In both cases, we find that, to induce the optimal effort levels, the emissions need to be overallocated, even if the carbon tax is the true social cost of carbon. This is in contrast to the usual focus in the life-cycle assessment (LCA) and carbon footprinting literatures on avoiding double counting. Our work aims to lay the foundation for a framework to integrate the economics-and LCA-based perspectives on supply chain carbon footprinting."
564,"Engaging Supply Chains in Climate Change","Jira, Chonnikarn (Fern) and Toffel, Michael W.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","559-577","2013","FAL","Econometric Analysis;Empirical Research;Environmental Operations;Sustainable Operations;Quality Management;Supply Chain Management;Risk Management","","Suppliers are increasingly being asked to share information about their vulnerability to climate change and their strategies to reduce greenhouse gas emissions. Their responses vary widely. We theorize and empirically identify several factors associated with suppliers being especially willing to share this information with buyers, focusing on attributes of the buyers seeking this information and of the suppliers being asked to provide it. We test our hypotheses using data from the Carbon Disclosure Project's Supply Chain Program, a collaboration of multinational corporations requesting such information from thousands of suppliers in 49 countries. We find evidence that suppliers are more likely to share this information when requests from buyers are more prevalent, when buyers appear committed to using the information, when suppliers belong to more profitable industries, and when suppliers are located in countries with greenhouse gas regulations. We find evidence that these factors also influence the comprehensiveness of the information suppliers share and their willingness to share the information publicly."
565,"Curtailing Intermittent Generation in Electrical Systems","Wu, Owen Q. and Kapuscinski, Roman","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","578-595","2013","FAL","Intermittent Generation;Wind Power;Economic Curtailment;Flexible Generation;Energy Storage Operations;Operations Management Practice","","Energy generation from intermittent renewable sources introduces additional variability into electrical systems, resulting in a higher cost of balancing against the increased variabilities. Ways to balance demand and supply for electricity include using flexible generation resources, storage operations, and curtailing intermittent generation. This paper focuses on the operational and environmental impact of curtailing intermittent generation. We construct a stochastic dynamic optimization model that captures the critical components of the system operating cost and analyze how various generation resources should operate with and without curtailing intermittent generation. We find that the system cost reduction per unit of curtailed energy is consistently significant and the presence of storage may increase the cost saving per unit of curtailed energy. We also find that curtailing intermittent generation often leads to system emission reductions."
566,"Energy Efficiency in Small and Medium-Sized Manufacturing Firms: Order Effects and the Adoption of Process Improvement Recommendations","Muthulingam, Suresh and Corbett, Charles J. and Benartzi, Shlomo and Oppenheim, Bohdan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","596-615","2013","FAL","Process Improvement;Energy Efficiency;Behavioral Operations;Order Effects;Econometric Analysis;Empirical Research;Energy-Related Operations;Environmental Operations","","In many manufacturing operations, profitable energy efficiency opportunities remain unexploited. Although previous studies have tried to explain the underinvestment, we focus on how the way in which a portfolio of opportunities is presented in a list affects adoption decisions. We use information on over 100,000 energy-saving recommendations made to more than 13,000 small and medium-sized manufacturing firms under the Industrial Assessment Centers program of the U.S. Department of Energy. We find that adoption rates are higher for initiatives appearing early in a list of recommendations. This sequence effect is consistent and large: simply moving a recommendation one position lower has the same effect on average as increasing up-front implementation cost by at least 17% from the average value. Given this impact of sequence on adoption of individual recommendations, we utilize variations within our data to examine how various sequencing approaches affect adoption at the portfolio level. Sequences in which recommendations are listed from best to worst payback achieve higher potential energy savings given the investments in energy efficiency made by the firms. We also observe a choice overload effect at the portfolio level, but the magnitude of this effect is small."
567,"Dynamic Capacity Investment with Two Competing Technologies","Wang, Wenbin and Ferguson, Mark E. and Hu, Shanshan and Souza, Gilvan C.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","616-629","2013","FAL","Sustainable Operations;Dynamic Capacity Investment;Technology Choice","","With the recent focus on sustainability, firms making adjustments to their production or distribution capacity levels often have the option of investing in newer technologies with lower carbon footprints and/or energy consumption. These more sustainable technologies typically require a higher up-front investment but have lower operating (fuel or energy) costs. What complicates this decision is the fact that the projected dollar savings from the more sustainable technologies fluctuate considerably due to uncertainty in fuel prices, and the total capacity may not be utilized at 100% because of fluctuations in the demand for the product. We consider the firm's capacity adjustments over time given a portfolio of technology options when the demand and the fuel costs are stochastic and possibly dependent. Our model also allows for usage-based capacity deterioration. We provide the analytical structure of the optimal policy, which assigns different control limits for investing, staying put, and disinvesting in the capacities of the competing technology choices for each realization of demand and fuel costs at each period. We also present an application of our model to the problem of designing a delivery truck fleet for a beverage distributor."
568,"On the Value of Input Efficiency, Capacity Efficiency, and the Flexibility to Rebalance Them","Plambeck, Erica L. and Taylor, Terry A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","630-639","2013","FAL","Energy Efficiency;Process Improvement;Flexibility;Environment","","A common characteristic of basic material manufacturers (which account for 85% of all industrial energy use) and of cleantech manufacturers is that they are price takers in their input and output markets. Variability in those prices has implications for how much a manufacturer should invest in three fundamental types of process improvement. Input price variability reduces the value of improving input efficiency (output produced per unit input) but increases that of capacity efficiency (the rate at which a production facility can convert input into output). Output price variability increases the value of capacity efficiency, but it increases the value of input efficiency if and only if the expected margin is small. Moreover, as the expected input cost rises, the value of input efficiency decreases. A third type of process improvement is to develop flexibility in input efficiency versus capacity efficiency (the ability to respond to a rise in input cost or fall in output price by increasing input efficiency at the expense of capacity efficiency). The value of this flexibility decreases with variability in input and output prices if and only if the expected margin is thin. Together, these results suggest that a carbon tax or cap-and-trade system may reduce investment by basic material manufacturers in improving energy efficiency."
569,"The Role of Modular Upgradability as a Green Design Strategy","Agrawal, Vishal V. and Uelkue, Sezer","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","640-648","2013","FAL","Modularity;Green Product Design;Sustainability;New Product Development;Sustainable Operations","","Modular upgradability has been suggested as a strategy for improving environmental performance: as technology improves, it allows for independent replacement of improving subsystems, instead of replacing the entire product. This may extend the useful life of stable subsystems, reducing production and disposal impact. However, this argument ignores the effect of modular upgradability on a firm's development and introduction decisions and the environmental impact during the use phase. In this paper, we investigate when modular upgradability leads to lower environmental impact and higher profits. We do so by endogenizing a firm's development and introduction decisions and considering the product's environmental impact during its entire life cycle. Our results show that although modular upgradability may accelerate the replacement of some subsystems, it delays the replacement of others. We find that modular upgradability can increase the environmental impact for some product categories due to accelerated obsolescence arising from more frequent introduction and replacement. However, we also find that accelerated obsolescence, under some conditions, can actually make modular upgradability greener."
570,"The NGO's Dilemma: How to Influence Firms to Replace a Potentially Hazardous Substance","Kraft, Tim and Zheng, Yanchong and Erhun, Feryal","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","649-669","2013","FAL","Nongovernmental Organizations;Environmental Regulations;Substances Of Concern;Public Politics;Private Politics;Game Theory","","We study a nongovernmental organization's (NGO's) decisions when it attempts to remove a potentially hazardous substance from commercial use in a market with competing firms. Specifically, we determine under what market and regulatory conditions an NGO should target the industry versus the regulatory body to influence firms to replace the substance. We examine how the NGO's strategy changes as the NGO's pragmatism (i.e., the extent to which the NGO incorporates firms' profits into its decision making) increases. Our results demonstrate that when the NGO is less pragmatic, it should examine the existing market structure to determine whether to target the industry or the regulatory body. However, as the pragmatism of the NGO increases, the NGO should increasingly leverage the competition between firms to ensure that a replacement is available to consumers. We examine multiple extensions including varying the competition dynamics, the NGO targeting both the industry and the regulatory body, the time discounting of replacement costs, and a firm potentially lobbying to counteract an NGO's activism. We show that the potential for a firm to lobby can benefit consumers by motivating the NGO to exert more effort and increase the market sensitivity to a substance, thereby forcing the firm to replace."
571,"Plant Networks for Processing Recyclable Materials","Demeester, Lieven and Qi, Mei and Van Wassenhove, Luk N.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","670-688","2013","FAL","Recycling;Material Versatility;Localization;Minimills;Operations Strategy;Plant Networks;Optimal Market Area","","We use a modified optimal market area model to examine how links between material recycling and other aspects of operations strategy can shape plant networks for the processing of recyclable materials. We characterize the complementarity of the recyclate ratio, defined as the maximum recycled content, with material versatility and miniscaling of recycling plants. We also observe that it is beneficial to coordinate investments in recycling-and production-related competencies because colocated recycling and production plants (minimills) eliminate recyclate transport. We therefore consider versatile miniplants, defined as a competency that factors in both material versatility and coordinated miniscaling of recycling and production plants, and capture how it complements both the recyclate ratio and localization of production plants, a competency that takes advantage of local adaptation and customer proximity. In numerical examples for rolled aluminum and nylon resin plant networks in Europe, we find that the complementarity effects are large, as they are for nylon resins, if recycling is nascent and challenging economically and if the plant network is too centralized at first to benefit much from an increased recyclate ratio or increased localization. We find that, for the nylon resin network, considering an investment in the recyclate ratio as part of a coordinated investment plan drives the emergence of a decentralized and localized minimill network, even though an increased recyclate ratio does not link directly with either decentralization or localization. We conclude that material recycling, versatile miniplants, and localization can fit well together in a forward-looking, sustainable operations strategy."
572,"Sustainable Operations Management: An Enduring Stream or a Passing Fancy?","Drake, David F. and Spinler, Stefan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","4, SI","689-700","2013","FAL","Sustainable Operations Management;Sustainability;Environment;Paul Kleindorfer","","Paul Kleindorfer was among the first to weigh in on and nurture the stream of sustainable operations management. The thoughts laid out here are based on conversations we had with Paul relating to the drivers underlying sustainability as a management issue: population and per capita consumption growth, the limited nature of resources and sinks, and the responsibility and exposure of firms to ensuing ecological risks and costs. We then discuss how an operations management lens contributes to the issue and criteria to help the sustainable operations management perspective endure. This paper relates to a presentation delivered by Morris Cohen for Paul's Manufacturing and Service Operations Management Distinguished Fellows Award, given at Columbia University, June 18, 2012. We wrote this paper at Paul's request."
573,"A Population-Growth Model for Multiple Generations of Technology Products","Li, Hongmin and Armbruster, Dieter and Kempf, Karl G.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","343-360","2013","SUM","Product Transitions;Forecasting;Multiple-Generation Demand Model;Diffusion","","In this paper, we consider the demand for multiple, successive generations of products and develop a population-growth model that allows demand transitions across multiple product generations and takes into consideration the effect of competition. We propose an iterative-descent method for obtaining the parameter estimates and the covariance matrix, and we show that the method is theoretically sound and overcomes the difficulty that the units-in-use population of each product is not observable. We test the model on both simulated sales data and Inters high-end desktop processor sales data. We use two alternative specifications for product strength in this market: performance and performance/price ratio. The former demonstrates better fit and forecast accuracy, likely due to the low price sensitivity of this high-end market. In addition, the parameter estimate suggests that, for the innovators in the diffusion of product adoption, brand switchings are more strongly influenced by product strength than within-brand product upgrades in this market. Our results indicate that compared with the Bass model, Norton-Bass model, and Jun-Park choice-based diffusion model, our approach is a better fit for strategic forecasting that occurs many months or years before the actual product launch."
574,"Resource-Based Patient Prioritization in Mass-Casualty Incidents","Mills, Alex F. and Argon, Nilay Tanik and Ziya, Serhan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","361-377","2013","SUM","Health Operations;Emergency Response;Triage","","T he most widely used standard for mass-casualty triage, START, relies on a fixed-priority ordering among different classes of patients, and does not explicitly consider resource limitations or the changes in survival probabilities with respect to time. We construct a fluid model of patient triage in a mass-casualty incident that incorporates these factors and characterize its optimal policy. We use this characterization to obtain useful insights about the type of simple policies that have a good chance to perform well in practice, and we demonstrate how one could develop such a policy. Using a realistic simulation model and data from emergency medicine literature, we show that the policy we developed based on our fluid formulation outperforms START in all scenarios considered, sometimes substantially."
575,"Fixed vs. Random Proportions Demand Models for the Assortment Planning Problem Under Stockout-Based Substitution","Honhon, Dorothee and Seshadri, Sridhar","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","378-386","2013","SUM","Assortment Planning;Inventory Management;Bounds;Stockout-Based Substitution","","We consider the problem of determining the optimal assortment of products to Offer in a given product category when each customer is characterized by a type, which is a list of products he is willing to buy in decreasing order of preference. We assume consumer-driven, dynamic, stockout-based substitution and random proportions of each type. No efficient method to obtain the optimal solution for this problem is known to our knowledge. However, if the number of customers of each type is a fixed proportion of demand, there exists an efficient algorithm for solving for the optimal assortment. We show that the fixed proportions model gives an upper bound to the optimal expected profit for the random proportions model. This bound allows us to obtain a measure of the absolute performance of heuristic solutions. We also provide a bound for the component-wise absolute difference in expected sales between the two models, which is asymptotically tight as the inventory vector is made large, while keeping the number of products fixed. This result provides us with a lower bound to the optimal expected profit and a performance guarantee for the fixed proportions solution in the random proportions model."
576,"Optimal Dynamic Assortment Planning with Demand Learning","Saure, Denis and Zeevi, Assaf","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","387-404","2013","SUM","Assortment Planning;Online Algorithm;Demand Learning","","We study a family of stylized assortment planning problems, where arriving customers make purchase decisions among offered products based on maximizing their utility. Given limited display capacity and no a priori information on consumers' utility, the retailer must select which subset of products to offer. By offering different assortments and observing the resulting purchase behavior, the retailer learns about consumer preferences, but this experimentation should be balanced with the goal of maximizing revenues. We develop a family of dynamic policies that judiciously balance the aforementioned trade-off between exploration and exploitation, and prove that their performance cannot be improved upon in a precise mathematical sense. One salient feature of these policies is that they quickly recognize, and hence limit experimentation on, strictly suboptimal products."
577,"Can Financial Markets Inform Operational Improvement Efforts? Evidence from the Airline Industry","Ramdas, Kamalini and Williams, Jonathan and Lipson, Marc","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","405-422","2013","SUM","Econometric Analysis;Empirical Research;Service Operations;Quality Management;Om-Finance Interface","","We investigate whether stock price movements can inform operations managers as to where they should focus improvement efforts. We examine how unexpected performance along several dimensions of service quality-on-time performance, long delays and cancellations, lost bags, and denied boardings-impacts contemporaneous stock returns. Prior research suggests that airlines buffer their flight schedules and engage in expensive employee incentive programs to increase the likelihood of on-time arrival. We find that only long delays are penalized by the market, and we identify a number of carrier-specific factors that alter the financial impact of long delays. We find that the penalty a carrier faces for long delays is significantly higher if it operates a high percentage of short-haul or connecting flights, or if its competitors incur fewer long delays in the same time period. Our findings suggest that developing ways to curtail long delays is a useful future research area."
578,"Incentive-Compatible Revenue Management in Queueing Systems: Optimal Strategic Delay","Afeche, Philipp","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","423-443","2013","SUM","Congestion;Delay;Incentives;Lead Times;Mechanism Design;Pricing;Priorities;Quality Of Service;Queueing Systems;Revenue Management;Scheduling;Service Differentiation","","How should a firm design a price/lead-time menu and scheduling policy to maximize revenues from heterogeneous time-sensitive customers with private information about their preferences? We consider this question for a queueing system with two customer types and provide the following results. First, we develop a novel problem formulation and solution method that combines the achievable region approach with mechanism design. This approach extends to menu design problems for other systems. Second, the work conserving c mu priority rule, known to be delay cost minimizing, incentive-compatible, and socially optimal, need not be revenue maximizing. A strategic delay policy may be optimal: It prioritizes impatient customers, but artificially inflates the lead times of patient customers. This suggests a broader guideline: Revenue-maximizing firms that lack customer-level demand information should also consider customer incentives, not only operational constraints, in their scheduling policies. Third, we identify general necessary and sufficient conditions for optimal strategic delay: a price, a lead-time, and a segment-size condition. We translate these into demand and capacity parameter conditions for cases with homogeneous and heterogeneous valuations for each type. In some cases strategic delay is optimal if capacity is relatively abundant, in others if it is relatively scarce."
579,"Supply Streams","Song, Jing-Sheng and Zipkin, Paul","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","444-457","2013","SUM","Inventory/Production;Multiechelon;Uncertainty;Probability;Diffusion;Partial Differential Equations","","A supply stream is a continuous version of a supply chain. It is like a series inventory system, but stock can be held at any point along a continuum, not just at discrete stages. We assume stationary parameters and aim to minimize the long-run average total cost. We show that a stationary continuous-stage echelon base-stock policy is optimal. That is, at each geographic point along the supply stream, there is a target echelon inventory level, and the optimal policy at all times is to order and dispatch material so as to move the echelon inventory position as close as possible to this target. We establish this result by showing that the solutions to certain discrete-stage systems converge monotonically to a limit, as the distances between the stages become small, and this limit solves the continuous-stage system. With demand approximated by a Brownian motion, we show that, in the continuous-stage limit, the supply stream model is equivalent to one describing first-passage times. This linkage leads to some interesting and useful results. Specifically, we obtain a partial differential equation that characterizes the optimal cost function, and we find a closed-form expression for the optimal echelon base-stock levels in a certain special case, the first in the inventory literature. These expressions demonstrate that the well-known square-root law for safety stock does not apply in this context."
580,"Horizontal Capacity Coordination for Risk Management and Flexibility: Pay Ex Ante or Commit a Fraction of Ex Post Demand?","Wu, Xiaole and Kouvelis, Panos and Matsuo, Hirofumi","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","458-472","2013","SUM","Capacity Planning And Investment;Incentives And Contracting;Risk Management;Supply Chain Management","","Motivated by the dual-sourcing and contracting practices in the semiconductor industry, we study two prevailing types of contracts that deal with horizontal-capacity-coordination issues between two possible sources: an integrated device manufacturer (IDM) and a foundry IDMs both design and manufacture semiconductor devices, whereas foundries concentrate only on manufacturing. Because production capacity is capital intensive, IDMs often make decisions on whether to manufacture each device internally or subcontract to foundries. Two types of contracts are most frequently used in such settings. Under a-contracts, a fixed fraction a of ex post realized demand is committed to subcontract to the foundry and serves as an incentive for the foundry to build capacity Under reservation contracts, an ex ante capacity reservation fee is paid to the foundry as an incentive to build capacity Because of the different nature of incentives under these contracts, it is unclear which type of contract maximizes the IDM's expected profit. Furthermore, IDMs and their customers often prefer dual sourcing to sole sourcing for risk-management purposes. This paper studies the relationship between the two types of contracts, both with and without dual-sourcing constraints and shows the effect of a dual-sourcing preference on contract selection. Our analysis offers supporting rationale for the coexistence of a-contracts and reservation contracts in practice and provides insights on horizontal capacity coordination beyond the semiconductor industry"
581,"Linking Cyclicality and Product Quality","Sosa, Manuel E. and Mihm, Juergen and Browning, Tyson R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","473-491","2013","SUM","Product Architecture;Cycles;Modularity;Iterative Problem Solving;Defects","","This paper examines the impact of architectural decisions on the level of defects in a product. We view products as collections of components linked together to work as an integrated whole. Previous work has established modularity (how decoupled a component is from other product components) as a critical determinant of defects, and we confirm its importance. Yet our study also provides empirical evidence for a relationship between product quality and cyclicality (the extent to which a component depends on itself via other product components). We find cyclicality to be a determinant of quality that is distinct from, and no less important than, modularity. Extending this main result, we show how the cyclicality quality relationship is affected by the centrality of a component in a cycle and the distribution of a cycle across product modules. These findings, which are based on an analysis of open source software development projects, have implications for the study and design of complex systems."
582,"Pricing Time-Sensitive Services Based on Realized Performance","Afeche, Philipp and Baron, Opher and Kerner, Yoav","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","492-506","2013","SUM","Delay;Lead Times;Pricing;Queueing Systems;Revenue Management;Risk Aversion","","Services such as FedEx charge up-front fees but reimburse customers for delays. However, lead-time pricing studies ignore such delay refunds. This paper contributes to filling this gap. It studies revenue-maximizing tariffs that depend on realized lead times for a provider serving multiple time-sensitive customer types. We relax two key assumptions of the standard model in the lead-time pricing literature. First, customers may be risk averse (RA) with respect to payoff uncertainty, where payoff equals valuation, minus delay cost, minus payment. Second, tariffs may be arbitrary functions of realized lead times. The standard model assumes risk-neutral (RN) customers and restricts attention to flat rates. We report three main findings: (1) With RN customers, flat-rate pricing maximizes revenues but leaves customers exposed to payoff variability. (2) With RA customers, flat-rate pricing is suboptimal. If types are distinguishable, the optimal lead-time-dependent tariffs fully insure delay cost risk and yield the same revenue as under optimal flat rates for RN customers. With indistinguishable RA types, the differentiated first-best tariffs may be incentive-compatible even for uniform service, yielding higher revenues than with RN customers. (3) Under price and capacity optimization, lead-time-dependent pricing yields higher profits with less capacity compared to flat-rate pricing."
583,"Managing Storable Commodity Risks: The Role of Inventory and Financial Hedge","Kouvelis, Panos and Li, Rong and Ding, Qing","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","3","507-521","2013","SUM","Stochastic Inventory;Commodity Markets;Futures;Options;Risk Management;Hedging;Risk Aversion","","We study how to manage commodity risks (price and consumption volume) via physical inventory and financial hedge in a multiperiod problem (with an interperiod utility function) for a risk-averse firm procuring a storable commodity from a spot market at a random price and a long-term supplier at a fixed price. The firm also has access to financial contracts written on the commodity price, such as futures contracts and call and put options. We examine different cases of financial hedging, for example, single-contract and multicontract hedges. For each case, we dynamically maximize the mean-variance utility of the firm's cash flow and characterize an optimal integrated policy of inventory and hedging, which is easy to compute and implement. We find that as long as futures are used in each period, alone or not, the optimal inventory policy is myopic. The optimal hedging policy, however, is never myopic, but depends on all the future optimal decisions. This is contrary to findings of the literature using intraperiod utility functions, which finds myopic hedging to be optimal. Moreover, we find that hedging may lead to inventory reduction in multiperiod problems. Thus the insights from the single-period studies in the literature hedging leads to inventory increase do not apply. Finally, insights are offered on the role and impact of inventory and financial hedge on profitability, variance control, and service level, using both analytical and numerical results."
584,"Offered Load Analysis for Staffing","Whitt, Ward","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","166-169","2013","SPR","Offered Load Analysis;Capacity Planning;Server Staffing;Time-Varying Arrival Rates;Infinite-Server Queues","","This essay, based on my 2012 MSOM Fellow Lecture, discusses an idea that has been useful for developing effective methods to set staffing levels in service systems: offered load analysis. The main idea is to tackle a hard problem by first seeking an insightful simplification. For capacity planning to meet uncertain exogenous demand, offered load analysis looks at the amount of capacity that would be used if there were no constraints on its availability. This simplification is helpful because the stochastic model becomes much more tractable. Offered load analysis can be especially helpful when the demand is not only uncertain but also time varying, as in many service systems. Given the distribution of the stochastic offered load, we often can set staffing levels to stabilize performance at target levels, even in face of a strongly time-varying arrival rate, long service times, and network structure."
585,"Prioritizing Burn-Injured Patients During a Disaster","Chan, Carri W. and Green, Linda V. and Lu, Yina and Leahy, Nicole and Yurt, Roger","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","170-190","2013","SPR","Healthcare;Disaster Planning;Triage","","The U. S. government has mandated that, in a catastrophic event, metropolitan areas need to be capable of caring for 50 burn-injured patients per million population. In New York City, this corresponds to 400 patients. There are currently 140 burn beds in the region, which can be surged up to 210. To care for additional patients, hospitals without burn centers will be used to stabilize patients until burn beds become available. In this work, we develop a new system for prioritizing patients for transfer to burn beds as they become available and demonstrate its superiority over several other triage methods. Based on data from previous burn catastrophes, we study the feasibility of being able to admit 400 patients to burn beds within the critical three- to five-day time frame. We find that this is unlikely and that the ability to do so is highly dependent on the type of event and the demographics of the patient population. This work has implications for how disaster plans in other metropolitan areas should be developed."
586,"Impact of Variety and Distribution System Characteristics on Inventory Levels at U.S. Retailers","Rajagopalan, Sampath","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","191-204","2013","SPR","Retailing;Empirical Research;Econometric Analysis;Supply Chain Management;Inventory","","Over the past six decades, numerous analytical models have been developed to determine optimal inventory levels. These models predict that inventories carried by a retailer should be a function of the product variety carried by the retailer, distribution system characteristics, economies of scale, etc. A few recent empirical studies have explored the impact of some of these factors on aggregate inventories at U. S. retailers. Building on these works, this study empirically explores the role of key factors such as product variety, number of stores, and number of warehouses in explaining inventory levels at U. S. retailers using data obtained from both primary and secondary sources. We find that variety as measured by the number of stock-keeping units carried and number of stores is associated with higher inventories, whereas scale economies are associated with lower inventories. We do not find the number of warehouses to be significant in explaining inventory levels. Increased demand fluctuations are also associated with higher inventories, although the effects are less robust. The significant variables together with retailer segment identifiers explain a substantial fraction of the variance in inventory levels and can be potentially useful to managers in benchmarking their inventory levels."
587,"A Dispatching Model for Server-to-Customer Systems That Balances Efficiency and Equity","McLay, Laura A. and Mayorga, Maria E.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","205-220","2013","SPR","Emergency Medical Services;Server-To-Customer Systems;Public Health;Equity;Markov Decision Processes;Linear Programming","","The decision about which servers to dispatch to which customers is an important aspect of service systems. This decision is complicated when servers must be equitably-as well as efficiently-dispatched to customers. In this paper, we formulate a model for determining how to optimally dispatch distinguishable servers to prioritized customers given a set of equity constraints. These issues are examined through the lens of emergency medical service (EMS) dispatch, for which a Markov decision process model is developed that captures how to dispatch ambulances (servers) to prioritized patients (customers). It is assumed that customers arrive sequentially, with the priority and location of each customer becoming known upon arrival. Four types of equity constraints are considered-two of which reflect customer equity and two of which reflect server equity-all of which draw upon the decision analytic and social science literature to compare the effects of different notions of equity on the resulting dispatching policies. The Markov decision processes are formulated as equity-constrained linear programming models. A computational example is applied to an EMS system to compare the different equity models."
588,"Efficient Distribution of Water Between Head-Reach and Tail-End Farms in Developing Countries","Dawande, Milind and Gavirneni, Srinagesh and Mehrotra, Mili and Mookerjee, Vijay","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","221-238","2013","SPR","Logistics And Transportation;Nonprofit Management;Incentives And Contracts","","The necessity of surface water for irrigation and its increasing scarcity in developing economies motivate the need for its efficient distribution. The inequity in the distribution of surface water arises because of the relative physical locations of the farms. Head-reach (primary) farms are close to the source, whereas tail-end (secondary) farms are relatively farther. The lack of physical infrastructure implies that water allocated to secondary farms must pass through primary farms. Left to their individual incentives, primary farmers use more than their fair share of water by denying its release to secondary farmers. Such an inequitable sharing results in significantly suboptimal productivity of the farming community as a whole. We propose decentralized, individually rational mechanisms to achieve socially optimal distribution of surface water for a farming community under uncertainty in rainfall, choice of multiple crops, and differing risk-bearing abilities of primary and secondary farmers. We show that the mechanisms can be efficiently computed and highlight the impact of the improved sharing of surface water. We also study the movement of the price of water with its scarcity. Ideas that can help administer the mechanisms in practice are briefly discussed."
589,"Facility Location Decisions with Random Disruptions and Imperfect Estimation","Lim, Michael K. and Bassamboo, Achal and Chopra, Sunil and Daskin, Mark S.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","239-249","2013","SPR","Logistics And Transportation;Supply Chain Disruptions;Facility Network Design;Estimation Error;Correlated Disruptions;Continuous Approximation","","Supply chain disruptions come with catastrophic consequences in spite of their low probability of occurrence. In this paper, we consider a facility location problem in the presence of random facility disruptions where facilities can be protected with additional investments. Whereas most existing models in the literature implicitly assume that the disruption probability estimate is perfectly accurate, we investigate the impact of misestimating the disruption probability. Using a stylized continuous location model, we show that underestimation in disruption probability results in greater increase in the expected total cost than overestimation. In addition, we show that, when planned properly, the cost of mitigating the misestimation risk is not too high. Under a more generalized setting incorporating correlated disruptions and finite capacity, we numerically show that underestimation in both disruption probability and correlation degree result in greater increase in the expected total cost compared to overestimation. We, however, find that the impact of misestimating the correlation degree is much less significant relative to that of misestimating the disruption probability. Thus, managers should focus more on accurately estimating the disruption probability than the correlation."
590,"When Gray Markets Have Silver Linings: All-Unit Discounts, Gray Markets, and Channel Management","Hu, Ming and Pavlin, J. Michael and Shi, Mengze","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","250-262","2013","SPR","Gray Markets;Channel Management;Inventory;Quantity Discounts;Supplier Pricing","","Gray markets are unauthorized channels of distribution for a supplier's authentic products. We study a distribution channel that consists of a supplier who offers all-unit quantity discounts for batch orders to enjoy cost savings, and a reseller who may divert some goods to the gray markets. We show that the impact of gray markets depends on the reseller's inventory holding cost. When the reseller's inventory holding cost is high, diversion to the gray markets improves the channel performance by enabling the reseller to make batch orders. Because the reseller's order costs decrease through quantity discounts, diversion to the gray markets reduces the resale price and expands sales to the authorized channel. On the other hand, when the reseller's inventory holding cost is low, the reseller would make the batch orders even without the gray markets. In this case the diversion to the gray markets may improve the reseller's performance by shortening the order cycles and reducing the inventory holding costs. Interestingly, because diversion to the gray markets decreases the reseller's cycle inventory volume, the reseller has the reduced incentive to push its inventory, and, consequently, the resale price rises and sales volume decreases in the authorized channel. Moreover, there exists a range of reseller's inventory holding cost and supplier's cost of scale economy such that it is optimal for the supplier to induce reseller's gray market diversion through an all-unit discount. We show that these results are robust when the gray market overlaps with the authorized channel or when the gray market price is sensitive to reseller's diversion volume."
591,"Bounded Rationality in Service Systems","Huang, Tingliang and Allon, Gad and Bassamboo, Achal","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","263-279","2013","SPR","Behavioral Operations;Service Operations;Bounded Rationality;Queueing;Consumer Behavior","","The traditional operations management and queueing literature typically assumes that customers are fully rational. In contrast, in this paper we study canonical service models with boundedly rational customers. We capture bounded rationality using a model in which customers are incapable of accurately estimating their expected waiting time. We investigate the impact of bounded rationality from both a profit-maximizing firm's perspective and a social planner's perspective. For visible queues with the optimal price, bounded rationality results in revenue and welfare loss; with a fixed price, bounded rationality can lead to strict social welfare improvement. For invisible queues, bounded rationality benefits the firm when its level is sufficiently high. Ignoring bounded rationality, when present yet small, can result in significant revenue and welfare loss."
592,"Multiresource Allocation Scheduling in Dynamic Environments","Huh, Woonghee Tim and Liu, Nan and Van-Anh Truong","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","280-291","2013","SPR","Multiresource Allocation;Markov Decision Process;Healthcare Operations Management","","Motivated by service capacity-management problems in healthcare contexts, we consider a multiresource allocation problem with two classes of jobs (elective and emergency) in a dynamic and nonstationary environment. Emergency jobs need to be served immediately, whereas elective jobs can wait. Distributional information about demand and resource availability is continually updated, and we allow jobs to renege. We prove that our formulation is convex, and the optimal amount of capacity reserved for emergency jobs in each period decreases with the number of elective jobs waiting for service. However, the optimal policy is difficult to compute exactly. We develop the idea of a limit policy starting at a particular time, and use this policy to obtain upper and lower bounds on the decisions of an optimal policy in each period, and also to develop several computationally efficient policies. We show in computational experiments that our best policy performs within 1.8% of an optimal policy on average."
593,"Bayesian Dynamic Pricing in Queueing Systems with Unknown Delay Cost Characteristics","Afeche, Philipp and Ata, Baris","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","292-304","2013","SPR","Bayesian Learning;Delay;Dynamic Pricing;Revenue Management;Queueing","","The revenue management literature for queues typically assumes that providers know the distribution of customer demand attributes. We study an observable M/M/1 queue that serves an unknown proportion of patient and impatient customers. The provider has a Bernoulli prior on this proportion, corresponding to an optimistic or pessimistic scenario. For every queue length, she chooses a low or a high price, or turns customers away. Only the high price is informative. The optimal Bayesian price for a queue state is belief-dependent if the optimal policies for the underlying scenarios disagree at that queue state; in this case the policy has a belief-threshold structure. The optimal Bayesian pricing policy as a function of queue length has a zone (or, nested-threshold) structure. Moreover, the price convergence under the optimal Bayesian policy is sensitive to the system size, i.e., the maximum queue length. We identify two cases: prices converge (1) almost surely to the optimal prices in either scenario or (2) with positive probability to suboptimal prices. Only Case 2 is consistent with the typical incomplete learning outcome observed in the literature."
594,"Advance Selling in a Supply Chain Under Uncertain Supply and Demand","Cho, Soo-Haeng and Tang, Christopher S.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","305-319","2013","SPR","Game Theory;Healthcare Management;Supply Chain Management","","We examine three selling strategies of a manufacturer who produces and sells a seasonal product to a retailer under uncertain supply and demand: (1) advance selling-presells the product before observing uncertain supply and demand; (2) regular selling-sells the product after supply and demand are realized; and (3) dynamic selling-combines both advance and regular selling strategies. We model the first two strategies as single-period Stackelberg games, and we model the last strategy as a two-period dynamic Stackelberg game. By comparing the equilibria of these games, we formalize our understanding of several intuitive results. For example, from the manufacturer's perspective, dynamic selling dominates advance selling and regular selling: having more selling opportunities is beneficial to the manufacturer. However, from the retailer's perspective, we find two counterintuitive results: (a) postponing the ordering decision can be detrimental-the retailer can be worse off under regular selling than under advance selling; and (b) more ordering opportunities can be detrimental-the retailer can be worse off under dynamic selling than under advance selling. In addition, we analyze the impact of supply and demand uncertainties under these strategies and find that both types of uncertainties can be beneficial to the retailer."
595,"Salesforce Contracting Under Demand Censorship","Chu, Leon Yang and Lai, Guoming","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","15","2","320-334","2013","SPR","Salesforce Contracting;Demand Censorship;Newsvendor","","We study salesforce contracting in an environment where excess demand results in lost sales and the demand information is censored by the inventory level. In our model, a firm contracts with a risk-neutral sales agent with limited liability whose effort increases the demand stochastically. The firm designs the incentive contract and invests in inventory; the agent decides the sales effort. We find that the sales-quota-based bonus contract is optimal in such an environment, and the quota should be set equal to the inventory level when the first-best solution is not attainable. We further reveal that demand censorship can introduce peculiar effects on the optimal sales effort and service level that the firm implements. From our analysis of the additive and multiplicative effort cases, we find that in the additive effort case, it can be optimal, under demand censorship, for the firm to induce an effort and maintain a service level both greater than those under the first-best solution. Scenarios also exist where the firm should induce zero effort. For the multiplicative effort case, the optimal sales effort under demand censorship is lower than the first-best effort, whereas the optimal service level is higher than the first-best service level. The agent earns zero rent in the additive effort case but may earn a positive rent in the multiplicative effort case. Finally, our numerical analysis shows that demand censorship can have a significant negative impact on the value of contracting with the sales agent, especially when the sales margin is low and the market uncertainty is high."
596,"Some Lessons on Operations Management Model Implementation Drawn from the RAND Fire Project","Kolesar, Peter J.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","1-6","2012","WIN","Om Practice;Om Implementation;Public Sector Applications","","This article examines the contributions and historical context of the fire project that was undertaken in the early 1970s by the New York City-RAND Institute on behalf of the New York City Fire Department. We identify a number of technical and nontechnical factors that contributed to the high impact of this operations modeling effort. We hypothesize that these factors, though derived from the experiences in a particular public sector engagement, are applicable to other large-scale operations modeling efforts. This invited contribution is based on the author's inaugural Manufacturing and Service Operations Management (MSOM) Distinguished Fellows address that was given at the June 2011 MSOM conference at the University of Michigan."
597,"The Impact of Group Purchasing Organizations on Healthcare-Product Supply Chains","Hu, Qiaohai (Joice) and Schwarz, Leroy B. and Uhan, Nelson A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","7-23","2012","WIN","Supply-Chain Management;Healthcare Products;Group Purchasing Organizations","","This paper examines the impact of group purchasing organizations (GPOs) on healthcare-product supply chains. The supply chain we study consists of a profit-maximizing manufacturer with a quantity-discount schedule that is nonincreasing in quantity and ensures nondecreasing revenue, a profit-maximizing GPO, a competitive source selling at a fixed unit price, and n providers (e.g., hospitals) with fixed demands for a single product. Each provider seeks to minimize its total purchasing cost (i.e., the cost of the goods plus the provider's own fixed transaction cost). Buying through the GPO offers providers possible cost reductions but may involve a membership fee. Selling through the GPO offers the manufacturer possibly higher volumes, but requires that the manufacturer pay the GPO a contract administration fee (CAF), i.e., a percentage of all revenue contracted through it. Using a game-theoretic model, we examine questions about this supply chain, including how the presence of a GPO affects the providers' total purchasing costs. We also address the controversy about whether Congress should amend the Social Security Act, which, under current law, permits CAFs. Among other things, we conclude that although CAFs affect the distribution of profits between manufacturers and GPOs, they do not affect the providers' total purchasing costs."
598,"Capacity Allocation over a Long Horizon: The Return on Turn-and-Earn","Lu, Lauren Xiaoyuan and Lariviere, Martin A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","24-41","2012","WIN","Capacity Allocation;Turn-And-Earn;Dynamic Stochastic Game;Markov-Perfect Equilibrium","","We consider a supply chain in which a supplier sells products to multiple retailers. When orders from the retailers exceed the supplier's capacity, she must employ an allocation mechanism to balance supply and demand. In particular, we consider a commonly used allocation scheme in the automobile industry: turn-and-earn, which uses past sales to allocate capacity. In essence, retailers earn an allotment of a vehicle after they sell one. In contrast to turn-and-earn, fixed allocation ignores past sales and gives each retailer an equal share of the capacity. Earlier work has demonstrated that turn-and-earn induces more sales in a two-period setting compared to fixed allocation. The question remains unanswered whether turn-and-earn induces similar behaviors over a long horizon when retailers possess private demand information. We construct a dynamic stochastic game of order competition over an infinite horizon to track the order dynamics of the supply chain. We obtain a richer set of equilibrium behaviors than existing models predict. Instead of a symmetric allocation outcome, we observe that sales leadership may arise in equilibrium and that retailers with different past sales adopt distinct ordering strategies to respond to demand uncertainty. Transient sales dynamics suggest that sales leadership may not be persistent and can be eliminated by the occurrence of extremely low demand. This provides a theoretical explanation for several behavioral observations of some U.S. automobile dealers. In addition to the sales-inducing effect, interestingly, turn-and-earn also causes the retailers to absorb local demand variability."
599,"Good and Bad News About the (S, T) Policy","Liu, Fang and Song, Jing-Sheng","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","42-49","2012","WIN","Inventory/Production;Periodic Review;Order-Up-To Policy;Convexity;Submodularity;Unimodality;Brownian Motion;Gamma Process;Compound Poisson Process","","This paper studies the optimization of the (S, T) inventory policy, where T is the replenishment interval and S is the order-up-to level. First, we demonstrate that the previously established joint convexity of the long-run average cost is false. Hence, the optimization is not straightforward. We then point out that the joint convexity concept depends on whether S and T are continuous or discrete variables, and in some situations it may not even be well defined. Nonetheless, we are able to identify several useful properties of the cost function, such as submodularity and coordinatewise convexity. Based on these properties, we develop efficient algorithms to compute the optimal policy for continuous and discrete demands."
600,"An Econometric Analysis of Patient Flows in the Cardiac Intensive Care Unit","Singh, Diwas K. C. and Terwiesch, Christian","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","50-65","2012","WIN","Patient Flow;Health-Care Operations;Capacity Management;Rework","","This paper explores the rationing of bed capacity in a cardiac intensive care unit (ICU). We find that the length of stay for patients admitted to the ICU is influenced by the occupancy level of the ICU. In particular, a patient is likely to be discharged early when the occupancy in the ICU is high. This in turn leads to an increased likelihood of the patient having to be readmitted to the ICU at a later time. Such bounce-backs have implications for the overall ICU effective capacity an early discharge immediately frees up capacity, but at the risk of a (potentially much higher) capacity requirement when the patient needs to be readmitted. We analyze these capacity implications, shedding light on the question of whether an ICU should apply an aggressive discharge strategy or if it should follow the old quality slogan and do it right the first time. By comparing the total capacity usage for patients who were discharged early versus those who were not, we show that an aggressive discharge policy applied to patients with lower clinical severity levels frees up capacity in the ICU. However, we find that an increased number of readmissions of patients with high clinical severity levels occur when the ICU is capacity constrained, thereby effectively reducing peak bed capacity."
601,"Routing to Manage Resolution and Waiting Time in Call Centers with Heterogeneous Servers","Mehrotra, Vijay and Ross, Kevin and Ryder, Geoff and Zhou, Yong-Pin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","66-81","2012","WIN","Contact Centers;Call Resolution;Skill-Based Routing;Performance Management","","In many call centers, agents are trained to handle all arriving calls but exhibit very different performance for the same call type, where we define performance by both the average call handling time and the call resolution probability. In this paper, we explore strategies for determining which calls should be handled by which agents, where these assignments are dynamically determined based on the specific attributes of the agents and/or the current state of the system. We test several routing strategies using data obtained from a medium-sized financial service firm's customer service call centers and present empirical performance results. These results allow us to characterize overall performance in terms of customer waiting time and overall resolution rate, identifying an efficient frontier of routing rules for this contact center."
602,"The Value of Collaborative Forecasting in Supply Chains","Kurtulus, Muemin and Uelkue, Sezer and Toktay, Beril L.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","82-98","2012","WIN","Supply Chain Management;Collaborative Forecasting;Information Sharing","","Motivated by the mixed evidence concerning the adoption level and value of collaborative forecasting (CF) implementations in retail supply chains, in this paper, we explore the conditions under which CF offers the highest potential. We consider a two-stage supply chain with a single supplier selling its product to consumers through a single retailer. We assume that both the supplier and the retailer can improve the quality of their demand forecasts by making costly forecasting investments to gather and analyze information. First, we consider a noncollaborative model where the supplier and the retailer can invest in forecasting but do not share forecast information. Next, we examine a collaborative forecasting model where the supplier and the retailer combine their information to form a single shared demand forecast. We investigate the value of CF by comparing each party's profits in these scenarios under three contractual forms that are widely used in practice (two variations of the simple wholesale price contract as well as the buyback contract). We show that for a given set of parameters, CF may be Pareto improving for none to all three of the contractual structures, and that the Pareto regions under all three contractual structures can be expressed with a unifying expression that admits an intuitive interpretation. We observe that these regions are limited and explain how they are shaped by the contractual structure, power balance, and relative forecasting capability of the parties. To determine the specific value of collaborative forecasting as a function of different factors, we carry out a numerical analysis and observe the following. First, under noncoordinating contracts, improved information as a result of CF has the added benefit of countering the adverse effects of double marginalization in addition to reducing the cost of supply demand mismatch. Second, one may expect the value of CF to increase with bargaining power, however this does not hold in general: The value of CF for the newsvendor first increases and then decreases in his bargaining power. Finally, whereas one may expect CF to be more valuable under coordinating contracts, rather than a simple wholesale price contract that is prone to double marginalization, the magnitude of the gain from CF is in many cases higher in the absence of quantity coordination."
603,"The Timing of Staffing Decisions in Hospital Operating Rooms: Incorporating Workload Heterogeneity into the Newsvendor Problem","He, Biyu and Dexter, Franklin and Macario, Alex and Zenios, Stefanos","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","99-114","2012","WIN","Econometric Analysis;Health-Care Management;Service Operations","","We study the problem of setting nurse staffing levels in hospital operating rooms when there is uncertainty about daily workload. The workload is the number of operating room hours used by a medical specialty on a given day to perform surgical procedures. Variable costs consist of wages at a regular (scheduled) rate and at an overtime rate when the realized workload exceeds the scheduled time. Using a newsvendor framework, we consider the problem of determining optimal staffing levels with different information sets available at the time of decision: no information, information on number of cases, and information on number and types of cases. We develop empirical models for the daily workload distribution in which the mean and variance change with the information available. We use these models to derive optimal staffing rules based on historical data from a U.S. teaching hospital and prospectively test the performance of these rules. Our numerical results suggest that hospitals could potentially reduce their staffing costs by up to 39%-49% by deferring staffing decisions until procedure type information is available. The results demonstrate how data availability can affect a newsvendor's performance. The systematic approach of empirical modeling presented in the paper can be applied to other newsvendor problems with heterogeneous sources of demand."
604,"Turning Waste into By-Product","Lee, Deishin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","115-127","2012","WIN","Operations Management;Sustainability;Environment;By-Product Synergy","","This paper studies how a firm can create and capture value by converting a waste stream into a useful and saleable by-product (i.e., implementing by-product synergy (BPS)). We show that BPS creates an operational synergy between two products that are jointly produced. In essence, BPS is a process innovation that reduces the marginal cost of the original product and/or the by-product. The firm creates value through this process innovation and can capture this value by capturing newly created market opportunities, taking market share from competitors, or licensing the innovation to its competitors. We determine the optimal operating and licensing strategies for the firm and find market conditions under which the firm would benefit most from. implementing BPS. We show that the optimal operating and licensing strategies are driven by the size of the cost reduction enabled by the BPS process innovation. We also show that leveraging the synergies between the original product and by-product can lead to counterintuitive profit-maximizing operating strategies such as increasing the amount of waste generated, and strategically increasing the quantity of original product above the business as usual production volume. We present a framework for assessing the environmental impact of BPS that incorporates the impact of the optimal operating and licensing strategies."
605,"A Laboratory Investigation of Rank Feedback in Procurement Auctions","Elmaghraby, Wedad J. and Katok, Elena and Santamaria, Natalia","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","128-144","2012","WIN","Procurement Auctions;Bidding Behavior;Laboratory Experiments;Rank;Feedback","","A popular procurement auction format is one in which bidders compete during a live auction event but observe only the rank of their own bid and not the price bids of their competitors. We investigate the performance of auctions with rank feedback in a simple setting for which analytical benchmarks are readily available. We test these benchmarks in the laboratory by comparing the performance of auctions with rank-based feedback to auctions with full-price feedback as well as to auctions with no price feedback (sealed-bid auctions). When bidders are risk-neutral expected-profit maximizers, the buyer's expected costs should be the same under rank and full-price feedback; moreover, expected buyer costs should be the same as in a sealed-bid auction. However, when we test this theoretical equality in a controlled laboratory setting we find that, consistent with practitioners' beliefs but contrary to our model, rank feedback results in lower average prices than full-price feedback. We identify two behavioral reasons for the difference. The first explanation is based on the similarity of the bidders' problem in a sealed-bid first-price auction and an open-bid auction with rank feedback. The second explanation incorporates the use of jump bids motivated by bidder impatience."
606,"Effect of Traffic on Sales and Conversion Rates of Retail Stores","Perdikaki, Olga and Kesavan, Saravanan and Swaminathan, Jayashankar M.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","1","145-162","2012","WIN","Store Performance;Traffic Variability;Traffic Uncertainty;Store Labor Management;Retail Operations","","Attracting shoppers to stores and converting the incoming traffic into sales profitably are vital for the financial health of retailers. In this paper, we use proprietary data pertaining to an apparel retailer to study the relationship between store traffic, labor, and sales performance. We decompose sales volume into conversion rate (defined as the ratio of number of transactions to traffic) and basket value (defined as the ratio of sales volume to number of transactions) and analyze the impact of traffic on sales and its components. We find that store sales volume exhibits diminishing returns to scale with respect to traffic, and labor moderates the impact of traffic on sales. For example, we find that for values of traffic and labor corresponding to the mean, increasing average traffic per hour by one unit increases average sales volume per hour by $9.97. Further, we find that the marginal returns to traffic increases from $10.00 to $11.32 when labor increases by one standard deviation. In addition, we find that the conversion rate declines with increasing traffic and a lower conversion rate is associated with a decrease in future traffic growth. Our study underscores the importance of in-store operations in driving the financial performance of retailers."
607,"The Vital Role of Operations Analysis in Improving Healthcare Delivery","Green, Linda V.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","488-494","2012","FAL","Healthcare;Information Technology;Data Analysis;Capacity Planning;Flexibility;Coordination;Practice Variation","","There is now a broad consensus among healthcare professionals that the U.S. healthcare delivery system is woefully inefficient and needs to be radically redesigned. Healthcare costs have always been a driving force in policy and management, but quality has become equally important in driving decisions, particularly since emerging payment systems include metrics on clinical and operational performance. With the increasing use of information technology to capture financial, operational, and clinical data and to coordinate care across time and different venues, there is a growing demand for operations analysts to examine processes of care and provide much-needed insights on how to better utilize resources to improve outcomes while reducing costs. In this paper, I describe some of the essential features of the U.S. healthcare system and some critical issues that provide opportunities for operations researchers to make important contributions."
608,"Physician Workload and Hospital Reimbursement: Overworked Physicians Generate Less Revenue per Patient","Powell, Adam and Savin, Sergei and Savva, Nicos","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","512-528","2012","FAL","Empirical;Hospital Operations;Healthcare Reimbursement;Workload Management","","We study the impact of physician workload on hospital reimbursement utilizing a detailed data set from the trauma department of a major urban hospital. We find that the proportion of patients assigned a high-severity status for reimbursement purposes, which maps, on average, to a 47.8% higher payment for the hospital, is substantially reduced as the workload of the discharging physician increases. This effect persists after we control for a number of systematic differences in patient characteristics, condition, and time of discharge. Furthermore, we show that it is unlikely to be caused by selection bias or endogeneity in either discharge timing or allocation of discharges to physicians. We attribute this phenomenon to a workload-induced reduction in diligence of paperwork execution. We estimate the associated monetary loss to be approximately 1.1% (95% confidence interval, 0.4%-1.9%) of the department's annual revenue."
609,"Optimization of Prostate Biopsy Referral Decisions","Zhang, Jingyu and Denton, Brian T. and Balasubramanian, Hari and Shah, Nilay D. and Inman, Brant A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","529-547","2012","FAL","Partially Observable Markov Decision Process;Psa Screening;Biopsy;Control-Limit Policy;Stopping Time Problem","","prostate cancer is the most common solid tumor in American men and is screened for using prostate-specific antigen (PSA) tests. We report on a nonstationary partially observable Markov decision process (POMDP) for prostate biopsy referral decisions. The core states are the patients' prostate cancer related health states, and PSA test results are the observations. Transition probabilities and rewards are inferred from the Mayo Clinic Radical Prostatectomy Registry and the medical literature. The objective of our model is to maximize expected quality-adjusted life years. We solve the POMDP model to obtain an age and belief (probability of having prostate cancer) dependent optimal biopsy referral policy. We also prove a number of structural properties including the existence of a control-limit type policy for the biopsy referral decision. Our empirical results demonstrate a nondecreasing belief threshold in age, and we provide sufficient conditions under which PSA screening should be discontinued for older patients. Finally, the benefits of screening under the optimal biopsy referral policy are estimated, and sensitivity analysis is used to prioritize the model parameters that would benefit from additional data collection."
610,"Process Management Impact on Clinical and Experiential Quality: Managing Tensions Between Safe and Patient-Centered Healthcare","Chandrasekaran, Arayind and Senot, Claire and Boyer, Kenneth K.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","548-566","2012","FAL","Healthcare Operations;Process Management;Clinical And Experiential Quality;Empirical Research","","This research investigates the effect of process management on clinical and experiential quality. Clinical quality measures hospitals' performance on patient safety, i.e., adherence to standards, whereas experiential quality relates to patient centeredness, i.e., responsiveness to the needs and preferences of the patient. Drawing from the organizational learning literature, we argue for a trade-off between clinical and experiential quality as hospitals emphasize process management. We also study how external and internal forces, i.e., state legislation and hospital leadership, influence this relationship. A combination of primary data and secondary data collected at various time intervals is employed to test our hypotheses. Four important implications emerge from this work. First, we find that hospitals' emphasis on process management is associated with an increase in clinical quality but a decrease in experiential quality. Second, we find that state legislation initially reinforces this trade-off but, overtime, facilitates a positive impact of process management on both quality outcomes. Third, a post hoc analysis suggests that a specific type of hospital leadership, namely, patient-centered leadership, helps mitigate the negative association between process management and experiential quality. Finally, our research provides preliminary evidence regarding the relationship between clinical quality and patient satisfaction contingent on experiential quality. Implications for theory and practice are discussed."
611,"Integrated Block Sharing: A Win-Win Strategy for Hospitals and Surgeons","Day, Robert and Garfinkel, Robert and Thompson, Steven","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","567-583","2012","FAL","Healthcare Management;Math Programming;Production Planning And Scheduling;Service Operations","","We consider the problem of balancing two competing objectives in the pursuit of efficient management of operating rooms in a hospital: providing surgeons with predictable, reliable access to the operating room and maintaining high utilization of capacity. The common solution to the first problem (in practice) is to grant exclusive block time, in which a portion of the week in an operating room is designated to a particular surgeon, barring other surgeons from using this room/time. As a major improvement over this existing approach, we model the possibility of shared block time, which need only satisfy capacity constraints in expectation. We reduce the computational difficulty of the resulting NP-hard block-scheduling problem by implementing a column-generation approach and demonstrate the efficacy of this technique using simulation, calibrated to a real hospital's historical data and objectives. Our simulations illustrate substantial benefits to hospitals under a variety of circumstances and demonstrate the advantages of our new approach relative to a benchmark method taken from the recent literature."
612,"A Queueing Model to Evaluate the Impact of Patient Batching on Throughput and Flow Time in a Medical Teaching Facility","Dobson, Gregory and Lee, Hsiao-Hui and Sainathan, Arvind and Tilson, Vera","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","584-599","2012","FAL","Tandem Queues;Concurrent Service;Finite Buffer;Batching;Flow Time Versus Throughput","","We consider the work flow in a medical teaching facility, examining the process that involves an initial patient exam by a resident physician, a subsequent conference between the resident and the attending physician, and the attending physician's visit with the patient. We create an analytical model of a tandem queue with finite buffer space to analyze the impact of different work prioritization policies on the throughput and the flow time of patients in the facility-measures that influence both the facility's finances and patients' satisfaction. We derive throughput-optimal policies and show that these policies involve dynamic batching. This finding is interesting because our model does not include any setup times, and setup times normally imply batching; rather it is the uncertain service times and the requirement for simultaneous service in the conference step that make batching optimal. The optimal dynamic batching policy is complex, so we consider a simpler static batching policy. We show that, in systems with limited buffer space, large batches can sometimes degrade efficiency by simultaneously increasing flow time and decreasing throughput. However, in general, both flow time and throughput increase with batch size. Flow time increases at a faster rate than throughput, so hospital management may want to consider what batch size is optimal given the value it places on the two measures."
613,"The Effect of Budgetary Restrictions on Breast Cancer Diagnostic Decisions","Ayvaci, Mehmet U. S. and Alagoz, Oguzhan and Burnside, Elizabeth S.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","600-617","2012","FAL","Markov Decision Processes;Linear Programming;Mixed-Integer Programming;Constrained Mdps;Breast Cancer;Diagnostic Decisions;Cost-Effectiveness;Medical Decision Making;Mammography;Service Operations","","We develop a finite-horizon discrete-time constrained Markov decision process (MDP) to model diagnostic decisions after mammography where we maximize the total expected quality-adjusted life years (QALYs) of a patient under resource constraints. We use clinical data to estimate the parameters of the MDP model and solve it as a mixed-integer program. By repeating optimization for a sequence of budget levels, we calculate incremental cost-effectiveness ratios attributable to consecutive levels of funding and compare actual clinical practice with optimal decisions. We prove that the optimal value function is concave in the allocated budget. Comparing to actual clinical practice, using optimal thresholds for decision making may result in approximately 22% cost savings without sacrificing QALYs. Our analysis indicates short-term follow-ups are the immediate target for elimination when budget becomes a concern. Policy change is more drastic in the older age group with the increasing budget, yet the gains in total expected QALYs related to larger budgets are predominantly seen in younger women along with modest gains for older women."
614,"Accumulating a Portfolio of Experience: The Effect of Focal and Related Experience on Surgeon Performance","Singh, Diwas K. C. and Staats, Bradley R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","618-633","2012","FAL","Healthcare;Knowledge Work;Learning;Quality;Specialization;Variety","","One key driver of improvement in surgical outcomes is a surgeon's prior experience. However, research notes that not all experience provides equal value for performance. How, then, should surgeons accumulate experience to improve quality outcomes? In this paper, we investigate the differential effects of focal and related (i.e., tasks similar to, but not identical to, the focal task) experience. We open up the black box of the volume-outcome relationship by going beyond just dividing experience into focal and related categories, but also considering how subtasks and context (i.e., the organization in which the work takes place) affect performance. To understand these issues, we assemble a novel data set on 71 cardiothoracic surgeons who performed more than 6,500 procedures during a period of 10 years after the introduction of a breakthrough surgical procedure. We find that, as compared to related experience, surgeon focal experience has a greater effect on surgeon performance. We also demonstrate that subtask experience has different, nonlinear performance relationships for focal and related experience. Finally, we find that focal experience is more firm specific than related experience and that nonfirm experience reduces the learning rate for both focal and related experience. We discuss implications of our findings for healthcare delivery and operations management."
615,"Information Hang-overs in Healthcare Service Systems","Lahiri, Atanu and Seidmann, Abraham","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","634-653","2012","FAL","Medical Information Systems;Clinical Workflow;Workflow Design;Hang-Over;Feedback Queue","","The literature on business process design has focused on issues such as bottlenecks, workflow configuration (series versus parallel), replacing an existing workflow with a shorter one, etc. One important issue that has not received adequate attention is the information-intensive nature of medical service systems. Performance of clinical workflows depends not only on how various steps are carried out but also on when certain information items are collected. We report the results of a long-term empirical study that looked at the implementation of a radiology information system (RIS) at a large regional network of radiology clinics. We find that a failure to gather necessary clinical background information in earlier steps significantly delays later steps and causes them to hang over, with a significant impact on the total turnaround time of diagnostic reports. We show that information systems can solve this problem by separating the task of gathering information from its usage and relocating that task upstream in the workflow. We argue that such unbundling can lead to shorter report turnaround times even if it significantly increases the utilization of the bottleneck server. These results have broader implications for the optimal design of other clinical workflows, such as the process of filling prescriptions in pharmacies or the typical surgical preanesthesia evaluation in hospitals. Finally, we explain why the impact of addressing hang-over is often nonuniform across clinical modalities, providers, and patient types."
616,"Performance-Based Contracts for Outpatient Medical Services","Jiang, Houyuan and Pang, Zhan and Savin, Sergei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","654-669","2012","FAL","Healthcare;Performance-Based Contracting;Principal-Agent Theory;Queueing Theory","","In recent years, the performance-based approach to contracting for medical services has been gaining popularity across different healthcare delivery systems, both in the United States (under the name of pay for performance) and abroad (payment by results in the United Kingdom). The goal of our research is to build a unified performance-based contracting (PBC) framework that incorporates patient access-to-care requirements and that explicitly accounts for the complex outpatient care dynamics facilitated by the use of an online appointment scheduling system. We address the optimal contracting problem in a principal agent framework where a service purchaser (the principal) minimizes her cost of purchasing the services and achieves the performance target (a waiting-time target) while taking into account the response of the provider (the agent) to the contract terms. Given the incentives offered by the contract, the provider maximizes his payoff by allocating his outpatient service capacity among three patient groups: urgent patients, dedicated advance patients, and flexible advance patients. We model the appointment dynamics as that of an M/D/1 queue and analyze several contracting approaches under adverse selection (asymmetric information) and moral hazard (private actions) settings. Our results show that simple and popular schemes used in practice cannot implement the first-best solution and that the linear performance-based contract cannot implement the second-best solution. To over-come these limitations, we propose a threshold-penalty PBC approach and show that it coordinates the system for an arbitrary patient mix and that it achieves the second-best performance for the setting where all advance patients are dedicated."
617,"Appointment Scheduling Under Patient No-Shows and Service Interruptions","Luo, Jianzhe and Kulkarni, Vidyadhar G. and Ziya, Serhan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","670-684","2012","FAL","Healthcare Operations Management;Service Operations;Stochastic Methods","","We consider an appointment-based service system (e.g., an outpatient clinic) for which appointments need to be scheduled before the service session starts. Patients with scheduled appointments may or may not show up for their appointments. The service of scheduled patients can be interrupted by emergency requests that have a higher priority. We develop a framework that can be utilized in determining the optimal appointment policies under different assumptions regarding rewards, costs, and decision variables. We propose two methods to evaluate the objective function for a given appointment schedule. We specifically consider two different formulations, both of which aim to balance the trade-off between the patient waiting times and server utilization and carry out a numerical study to provide insights into optimal policies. We find that policies that ignore interruptions perform quite badly, especially when the number of appointments to be scheduled is also a decision variable. We also find that policies that require equally spaced appointments perform reasonably well when the interruption rate is constant. However, their performance worsens significantly when the interruption rate is time dependent."
618,"Fee-for-Service Contracts in Pharmaceutical Distribution Supply Chains: Design, Analysis, and Management","Zhao, Hui and Xiong, Chuanhui and Gavirneni, Srinagesh and Fein, Adam","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","4, SI","685-699","2012","FAL","Healthcare Management;Supply Chain Management;Pharmaceutical Supply Chains;Contracts","","Free-for-service (FFS) contracts, first introduced in 2004, dramatically changed the way the pharmaceutical distribution supply chains are designed, managed, and operated. Investment buying (IB), forward buying in anticipation of drug price increases, used to be the way the distributors made most of their profits. FFS contracts limit the amount of inventory distributors can carry at any time (by imposing an inventory cap) and require inventory information sharing from the distributors to the manufacturers while compensating the distributors with a per-unit fee. In spite of its widespread popularity, the FFS model has never been rigorously analyzed or its effectiveness carefully tabulated. In this paper, we formulate the multiperiod stochastic inventory problems faced by the manufacturer and the distributor under the FFS and IB models, derive their optimal policies, and develop procedures to compute the policy parameters. We show that FFS contracts can improve the total supply chain profit-the manufacturer and distributor are now able to share a larger pie. Thus, there exists a range of the per-unit fees that leads to Pareto improvement. Simulation results show that such improvement is approximately 1.7% on average, and as much as 5.5%, and the improvement increases as the inventory cap decreases. Determining the Pareto-improving per-unit fees is a source of contention in FFS contract negotiation, and we propose a simple yet effective heuristic for computing them. Furthermore, supply chain transparency facilitated by the FFS contracts can significantly reduce the manufacturer's supply-demand mismatch costs (by approximately 3.63% on average and as much as 13.01%) and we show that the manufacturer should take advantage of this transparency especially when the inventory cap and drug price increase are high and demand variance is low. We believe that these results have the potential to improve the efficiency of pharmaceutical distribution supply chains, thus reducing the healthcare costs that are such a big burden on the U.S. economy."
619,"Markdown Pricing with Unknown Fraction of Strategic Customers","Mersereau, Adam J. and Zhang, Dan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","355-370","2012","SUM","Consumer Behavior;Pricing And Revenue Management;Retailing","","A growing segment of the revenue management and pricing literature assumes strategic customers who are forward-looking in their pursuit of utility. Recognizing that such behavior may not be directly observable by a seller, we examine the implications of seller uncertainty over strategic customer behavior in a markdown pricing setting. We assume that some proportion of customers purchase impulsively in the first period if the price is below their willingness to pay, while other customers strategically wait for lower prices in the second period. We consider a two-period selling season in which the seller knows the aggregate demand curve but not the proportion of customers behaving strategically. We show that a robust pricing policy that requires no knowledge of the extent of strategic behavior performs remarkably well. We extend our model to a setting with stochastic demand, and show that the robust pricing policy continues to perform well, particularly as capacity is loosened or the problem is scaled up. Our results underscore the need to recognize strategic behavior, but also suggest that in many cases effective performance is possible without precise knowledge of strategic behavior."
620,"The Value of Product Variety When Selling to Strategic Consumers","Parlaktuerk, Ali K.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","371-385","2012","SUM","Strategic Customer Behavior;Product Variety;Dynamic Pricing","","We consider a firm that sells two vertically (quality) differentiated products to strategically forward-looking consumers over two periods, setting the prices dynamically in each period. The consumers are heterogeneous in their evaluations of quality, and strategic in that they decide not only whether and which product variant to buy, but also when to buy, choosing the option that maximizes their utility. We derive the equilibrium of the pricing-purchasing game between the firm and the consumers. We find that the loss due to strategic customer behavior can be less with two product variants compared to the single-product benchmark, which indicates that product variety can serve as a lever when dealing with strategic customers. This benefit exists when the additional product has an inferior cost-to-quality ratio. Because of this benefit, a firm may find it attractive to sell a product variant that would be unprofitable otherwise. However, product variety can also hurt profitability due to strategic customer behavior: A product variant that would be profitable absent strategic customers can in fact be unprofitable. This can happen when customer impatience and firm costs are moderate."
621,"Robust Design and Control of Call Centers with Flexible Interactive Voice Response Systems","Tezcan, Tolga and Behzad, Banafsheh","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","386-401","2012","SUM","Call Center Management;Queueing Theory;Stochastic Methods","","We consider the robust design and control of call center systems with flexible interactive voice response (IVR) systems. In a typical call center equipped with an IVR system, customers are handled first by the IVR system, which is a computerized system that often enables customers to self-serve. Those customers whose service cannot be handled by the IVR system are sent to the second stage to be served by agents. To address the design of a call center with a flexible IVR system, we consider a call center whose IVR system can operate in two different service delivery modes that have statistically different outcomes. We formulate a stochastic program to determine the number of agents needed in the second stage as well as the proportion of customers that should be selected for each IVR service mode under different demand levels with the objective of minimizing the total staffing and abandonment costs. We also propose dynamic control policies to achieve the optimal proportions without the knowledge of the exact arrival rate. We show that the staffing levels found by the stochastic program combined with the proposed routing policies are asymptotically optimal in large systems. We present extensive numerical and simulation results to illustrate the effectiveness of the proposed solutions."
622,"Service-Level Variability of Inbound Call Centers","Roubos, Alex and Koole, Ger and Stolletz, Raik","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","402-413","2012","SUM","Call Centers;Service Level;Normal Distribution;Simulations;Staffing","","In practice, call center service levels are reported over periods of finite length that are usually no longer than 24 hours. In such small periods the service level has a large variability. It is therefore not sufficient to base staffing decisions only on the expected service level. In this paper we consider the classical M/M/s queueing model that is often used in call centers. We develop accurate approximations for the service-level distribution based on extensive simulations. This distribution is used for a service-level variability-controlled staffing approach to circumvent the shortcomings of the traditional staffing based on the expected service level."
623,"Single-Stage Approximations for Optimal Policies in Serial Inventory Systems with Nonstationary Demand","Shang, Kevin H.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","414-422","2012","SUM","Multiechelon;Single-Stage Heuristic;Nonstationary Demand;Myopic Solution","","Companies often face nonstationary demand due to product life cycles and seasonality, and nonstationary demand complicates supply chain managers' inventory decisions. This paper proposes a simple heuristic for determining stocking levels in a serial inventory system. Unlike the exact optimization algorithm, the heuristic generates a near-optimal solution by solving a series of independent single-stage systems. The heuristic is constructed based on three results we derive. First, we provide a new cost decomposition scheme based on echelon systems. Next, we show that the optimal base-stock level for each echelon system is bounded by those of two revised echelon systems. Last, we prove that the revised echelon systems are essentially equivalent to single-stage systems. We examine the myopic solution for these single-stage systems. In a numerical study, we find that the change of direction of the myopic solution is consistent with that of the optimal solution when system parameters vary. We then derive an analytical expression for the myopic solution and use it to gain insights into how to manage inventory. The analytical expression shows how future demand affects the current optimal local base-stock level; it also explains an observation that the safety stock at an upstream stage is often stable and may not increase when the demand variability increases over time. Finally, we discuss how the heuristic leads to a time-consistent coordination scheme that enables a decentralized supply chain to achieve the heuristic solution."
624,"The Impact of Airline Flight Schedules on Flight Delays","Deshpande, Vinayak and Arikan, Mazhar","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","423-440","2012","SUM","Flight Delays;Flight Schedules;Newsvendor Model;Forecasting","","Airline flight delays have come under increased scrutiny lately in the popular press, with the Federal Aviation Administration data revealing that airline on-time performance was at its worst level in 13 years in 2007. Flight delays have been attributed to several causes such as weather conditions, airport congestion, airspace congestion, use of smaller aircraft by airlines, etc. In this paper, we examine the impact of the scheduled block time allocated for a flight, a factor controlled by airlines, on on-time arrival performance. We analyze empirical flight data published by the Bureau of Transportation Statistics to estimate the scheduled on-time arrival probability of each commercial domestic flight flown in the United States in 2007 by a major carrier. The structural estimation approach from econometrics is then used to impute the overage to underage cost ratio of the newsvendor model for each flight. Our results show that airlines systematically underemphasize flight delays, i.e., the flight delay costs implied by the newsvendor model are less than the implied costs of early arrivals for a large fraction of flights. Our results indicate that revenue drivers (e.g., average fare) and competitive measures (e.g., market share) have a significant impact on the scheduled on-time arrival probability. We also show that the scheduled on-time arrival probability is not positively affected by the total number of passengers on the aircraft rotation who could be affected by a flight delay, or the number of incoming and outgoing connecting passengers on a flight. Operational characteristics such as the hub and spoke network structure also have a significant impact on the scheduled on-time arrival probability. Finally, full-service airlines put a higher weight on the cost of late arrivals than do low-cost carriers, and flying on the lowest fare flight on a route results in a drop in the scheduled on-time arrival probability."
625,"A Computational Approach to the Real Option Management of Network Contracts for Natural Gas Pipeline Transport Capacity","Secomandi, Nicola and Wang, Mulan X.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","441-454","2012","SUM","Capacity Valuation;Commodity And Energy Conversion Assets;Energy-Related Operations;Heuristics;Math Programming;Monte Carlo Simulation;Operations Management/Finance Interface;Operations Management Practice;Natural Gas Pipelines;Petroleum/Natural Gas Industries;Real Options;Sensitivities;Spread Options","","Commodity merchants use real option models to manage their operations. A central element of such a model is its underlying operating policy. We focus on network contracts for the transport capacity of natural gas pipelines, specific energy conversion assets. Practitioners commonly manage these contracts as portfolios of spread options. Although computationally fast, we show that this approach in general is heuristic because of the suboptimality of its operating policy. We propose a different computationally efficient real option approach based on an optimal operating policy, integrating linear optimization and Monte Carlo simulation. We use our approach to benchmark the spread option approach in a numerical study based on market data and realistic instances. We find that our approach can substantially improve on the contract valuations computed by the spread option approach, especially for contracts with flexibility in their allowed capacity usage. We also show that the optimal operating policy of contracts with this flexibility is of the greedy type, whereas the one of contracts without it in general is not. However, we observe that greedy optimization yields a near-optimal operating policy for the latter type of contracts with a substantially reduced computational effort. A version of our model was recently implemented by a major international energy trading company. Our model can also be employed to efficiently estimate the contract value sensitivities (the Greeks), which merchants use for financial hedging purposes. Potentially, our work has wider significance for the merchant management of other commodity conversion assets with payoffs determined by solving capacity constrained optimization models."
626,"Seasonal Energy Storage Operations with Limited Flexibility: The Price-Adjusted Rolling Intrinsic Policy","Wu, Owen Q. and Wang, Derek D. and Qin, Zhenwei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","455-471","2012","SUM","Energy Storage Operations;Real Options;Om Practice;Natural Gas Industry","","The value of seasonal energy storage depends on how the firm operates storage to capture seasonal price spreads. Energy storage operations typically face limited operational flexibility characterized by the speed of storing and releasing energy, which makes the optimal policy, in general, difficult to compute. A widely used practice-based heuristic, the rolling intrinsic (RI) policy, generally performs well compared with an optimal policy but can significantly underperform in some cases. In this paper, we aim to understand the gap between the RI policy and the optimal policy and leverage the resulting insights to improve the RI policy. A new heuristic policy, the price-adjusted rolling intrinsic (PARI) policy, is developed based on theoretical analysis of storage options. This heuristic adjusts certain prices before applying the RI policy to provide the RI policy with estimates of the values of various storage options. We evaluate the performance of the RI and PARI polices using actual data from the natural gas industry. Our results show that, on average, the PARI policy recovers about 67% of the value loss of the RI policy. Furthermore, when the value loss of the RI policy is larger, the PARI policy tends to recover a higher fraction of that value loss."
627,"A Multiordering Newsvendor Model with Dynamic Forecast Evolution","Wang, Tong and Atasu, Atalay and Kurtulus, Muemin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","3","472-484","2012","SUM","Newsvendor;Mmfe;Forecast Evolution;Dynamic Ordering","","We consider a newsvendor who dynamically updates her forecast of the market demand over a finite planning horizon. The forecast evolves according to the martingale model of forecast evolution (MMFE). The newsvendor can place multiple orders with increasing ordering cost over time to satisfy demand that realizes at the end of the planning horizon. In this context, we explore the trade-off between improving demand forecast and increasing ordering cost. We show that the optimal ordering policy is a state-dependent base-stock policy and analytically characterize that the base-stock level depends on the information state in a linear (log-linear) fashion for additive (multiplicative) MMFE. We also study a benchmark model where the newsvendor is restricted to order only once. By comparing the multiordering and single-ordering models, we quantify the impact of the multiordering strategy on the newsvendor's expected profit and risk exposure."
628,"What Is Interesting in Operations Management?","Cachon, Gerard P.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","166-169","2012","SPR","Operations Management;Interesting;Impact","","This essay discusses my view of the essential characteristics of interesting research in general and in operations management in particular. It is based on my Manufacturing and Service Operations Management Distinguished Fellows presentation given at the University of Michigan, June 27, 2011."
629,"Capacity Planning in the Semiconductor Industry: Dual-Mode Procurement with Options","Peng, Chen and Erhun, Feryal and Hertzler, Erik F. and Kempf, Karl G.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","170-185","2012","SPR","Capital-Intensive Industries;Equipment Procurement;Capacity Expansion;Forecast Revision;Dual-Mode Procurement;Dual Sourcing;Option Contracts;Heuristic;Om Practice","","To help a firm reduce inefficiencies associated with equipment capacity planning, we propose a dual-mode equipment procurement (DMEP) framework. DMEP combines dual-source (i.e., a less-expensive-but-slower base mode and a faster-but-more-expensive flexible mode) procurement with option contracts in three layers: a contract negotiation layer, where the firm chooses the best combination of lead time and price for each mode from the supply contract menu; a capacity reservation layer, where the firm reserves total equipment procurement quantities from the two supply modes before the planning horizon starts; and an execution layer, where the firm orders equipment from the two supply modes based on the updated demand information. We first investigate the execution layer as a dynamic dual-source capacity expansion problem with demand backlogging and demonstrate that the optimal policy lacks structure even under the simplest setting. Thus, we propose a heuristic solution for the execution-layer problem, which also serves as a building block for the other two layers. Through numerical analysis, we quantify the value of the added flexibility of DMEP for the firm. The DMEP framework has been implemented at Intel Corporation and has resulted in savings of tens of millions of dollars for one process technology."
630,"Operational Compliance Levers, Environmental Performance, and Firm Performance Under Cap and Trade Regulation","Kroes, James and Subramanian, Ravi and Subramanyam, Ramanath","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","186-201","2012","SPR","Environmental Operations;Public Policy;Environmental Compliance;Cap And Trade;Empirical Research","","Cap and trade programs impose limits on industry emissions but offer individual firms the flexibility to choose among different operational levers toward compliance, including inputs, process changes, and the use of allowances to account for emissions. In this paper, we examine the relationships among (1) levers for compliance (at-source pollution prevention, end-of-pipe pollution control, and the use of allowances); (2) environmental performance; and (3) firm market performance for the context of stringent cap and trade regulation with allowance grandfathering (i.e., the allocation of allowances for free). To investigate these relationships, we use data on publicly traded utility firms operating coal-fired generating units regulated by the U. S. Acid Rain Program from three principal sources: the U. S. Energy Information Administration, the U. S. Environmental Protection Agency, and the Compustat database. Our results indicate a significant relationship between better environmental performance and lower firm market performance over at least a three-year period. From a regulatory perspective, our results show a negative association between allowance grandfathering and firm environmental performance. Overall, by explicitly considering the context of stringent regulation, we find a counter-example to the view that better environmental performance generally associates with better economic performance."
631,"Using a Dual-Sourcing Option in the Presence of Asymmetric Information About Supplier Reliability: Competition vs. Diversification","Yang, Zhibin (Ben) and Aydin, Goeker and Babich, Volodymyr and Beil, Damian R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","202-217","2012","SPR","Auctions And Mechanism Design;Incentives And Contracting;Supply Chain Management","","We study a buyer's strategic use of a dual-sourcing option when facing suppliers possessing private information about their disruption likelihood. We solve for the buyer's optimal procurement contract. We show that the optimal contract can be interpreted as the buyer choosing between diversification and competition benefits. Better information increases diversification benefits and decreases competition benefits. Therefore, with better information the buyer is more inclined to diversify. Moreover, better information may increase or decrease the value of the dual-sourcing option, depending on the buyer's unit revenue: for large revenue, the buyer uses the dual sourcing option for diversification, the benefits of which increase with information; for small revenue, the buyer uses the dual sourcing option for competition, the benefits of which decrease with information. Surprisingly, as the reliability of the entire supply base decreases, the buyer may stop diversifying under asymmetric information (to leverage competition), whereas it would never do so under symmetric information. Finally, we analyze the effect of codependence between supply disruptions. We find that lower codependence leads the buyer to rely less on competition. Because competition keeps the information costs in check, a reduction in supplier codependence increases the buyer's value of information. Therefore, strategic actions to reduce codependence between supplier disruptions should not be seen as a substitute for learning about suppliers' reliabilities."
632,"Are Reservations Recommended?","Alexandrov, Alexei and Lariviere, Martin A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","218-230","2012","SPR","Service Management;Reservations;Restaurants;Capacity Management","","We examine the role of reservations in capacity-constrained services with a focus on restaurants. Although customers value reservations, restaurants typically neither charge for them nor impose penalties for failing to keep them. However, reservations impose costs on firms offering them. We offer a novel motivation for offering reservations that emphasizes the way in which reservations can alter customer behavior. We focus on a market in which demand is uncertain and the firm has limited capacity. There is a positive chance that the firm will not have enough capacity to serve all potential customers. Customers are unable to observe how many potential diners are in the market before incurring a cost to request service. Hence, if reservations are not offered, some may choose to stay home rather than risk being denied service. This lowers the firm's sales when realized demand is low. Reservations increase sales on a slow night by guaranteeing reservations holders service. However, some reservation holders may choose not to use their reservations resulting in no-shows. The firm must then trade off higher sales in a soft market with sales lost to no-shows on busy nights. We consequently evaluate various no-show mitigation strategies, all of which serve to make reservations more likely in equilibrium. Competition also makes reservations more attractive; when there are many small firms in the market, reservations are always offered."
633,"Optimizing Organic Waste to Energy Operations","Ata, Baris and Lee, Deishin and Tongarlak, Mustafa H.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","231-244","2012","SPR","Organic Waste To Energy;Sustainability;Environment;Operating Strategy;Regulation","","A waste-to-energy firm that recycles organic waste with energy recovery performs two environmentally beneficial functions: it diverts waste from landfills and it produces renewable energy. At the same time, the waste-to-energy firm serves and collects revenue from two types of customers: waste generators who pay for waste disposal service and electricity consumers who buy energy. Given the process characteristics of the waste-to-energy operation, the market characteristics for waste disposal and energy, and the mechanisms regulators use to encourage production of renewable energy, we determine the profit-maximizing operating strategy of the firm. We also show how regulatory mechanisms affect the operating decisions of the waste-to-energy firm. Our analyses suggest that if the social planner's objective is to maximize landfill diversion, offering a subsidy as a per kilowatt-hour for electricity is more cost effective, whereas if the objective is to maximize renewable energy generation, giving a subsidy as a lump sum to offset capital costs is more effective. This has different regulatory implications for urban and rural settings where the environmental objectives may differ."
634,"Unit-Contingent Power Purchase Agreement and Asymmetric Information About Plant Outage","Wu, Owen Q. and Babich, Volodymyr","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","245-261","2012","SPR","Electricity Industry;Unit-Contingent Contract;Spot Market;Risk Allocation","","This paper analyzes a unit-contingent power purchase agreement between an electricity distributor and a power plant. Under such a contract the distributor pays the plant a fixed price if the plant is operational and nothing if plant outage occurs. Pricing a unit-contingent contract is complicated by the fact that the plant's true status is its private information. The difference between the electricity spot price and the unit-contingent contract price provides an incentive for the plant to misreport its status and earn profit at the distributor's expense. To prevent misreporting, the distributor may inspect the plant and levy penalties if misreporting is discovered. We find that some type of misreporting under certain circumstances can benefit both the plant and the distributor, because it serves as a risk-allocation mechanism between the two parties. We show that such a risk-allocation mechanism is equivalent to using state-contingent options and prohibiting misreporting."
635,"The Impact of Dependent Service Times on Large-Scale Service Systems","Pang, Guodong and Whitt, Ward","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","262-278","2012","SPR","Large-Scale Service Systems;Dependence Among Service Times;Stochastic Models;Infinite-Server Queueing Models;Peakedness;Time-Varying Arrival Rates","","This paper investigates the impact of dependence among successive service times on the transient and steady-state performance of a large-scale service system. This is done by studying an infinite-server queueing model with time-varying arrival rate, exploiting a recently established heavy-traffic limit, allowing dependence among the service times. This limit shows that the number of customers in the system at any time is approximately Gaussian, where the time-varying mean is unaffected by the dependence, but the time-varying variance is affected by the dependence. As a consequence, required staffing to meet customary quality-of-service targets in a large-scale service system with finitely many servers based on a normal approximation is primarily affected by dependence among the service times through this time-varying variance. This paper develops formulas and algorithms to quantify the impact of the dependence among the service times on that variance. The approximation applies directly to infinite-server models but also indirectly to associated finite-server models, exploiting approximations based on the peakedness (the ratio of the variance to the mean in the infinite-server model). Comparisons with simulations confirm that the approximations can be useful to assess the impact of the dependence."
636,"Optimal Algorithms for Assortment Selection Under Ranking-Based Consumer Choice Models","Honhon, Dorothee and Jonnalagedda, Sreelata and Pan, Xiajun Amy","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","279-289","2012","SPR","Assortment Selection;Ranking-Based Choice Model","","A retailer's product selection decisions are largely driven by her assumptions on how consumers make choices. We use a ranking-based consumer choice model to represent consumer preferences: every customer has a ranking of the potential products in the category and purchases his highest ranked product (if any) offered in the assortment. We consider four practically motivated special cases of this model, namely, the one-way substitution, the locational choice, the outtree, and the intree preference models, and we study the retailer's product selection problem when products have different price and cost parameters. We assume that the retailer incurs a fixed carrying cost per product offered, a goodwill penalty for each customer who does not purchase his first choice and a lost sale penalty for each customer who does not find an acceptable product to buy. For the first three models, we obtain efficient solution methods that simplify to either a shortest path method or a dynamic program. For the fourth model, we construct an effective algorithm and show numerically that, in practice, it is much faster than enumeration. We also obtain valuable insights on the structure of the optimal assortment."
637,"In-Season Transshipments Among Competitive Retailers","Comez, Nagihan and Stecke, Kathryn E. and Cakanyildirim, Metin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","290-300","2012","SPR","Dynamic Transshipment Policy;Demand Overflow;Decentralized Distribution System","","A decentralized system of competing retailers that order and sell the same product in a sales season is studied. When a customer demand occurs at a stocked-out retailer, that retailer requests a unit to be transshipped from another retailer who charges a transshipment price. If this request is rejected, the unsatisfied customer may go to another retailer with a customer overflow probability. Each retailer decides on the initial order quantity from a manufacturer and on the acceptance/rejection of each transshipment request. For two retailers, we show that retailers' optimal transshipment policies are dynamic and characterized by chronologically nonincreasing inventory holdback levels. We analytically study the sensitivity of holdback levels to explain interesting findings, such as smaller retailers and geographically distant retailers benefit more from transshipments. Numerical experiments show that retailers substantially benefit from using optimal transshipment policies compared to no sharing. The expected sales increase in all but a handful of over 3,000 problem instances. Building on the two-retailer optimal policies, we suggest an effective heuristic transshipment policy for a multiretailer system."
638,"Managing Opportunistic Supplier Product Adulteration: Deferred Payments, Inspection, and Combined Mechanisms","Babich, Volodymyr and Tang, Christopher S.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","301-314","2012","SPR","Operations Strategy;Incentives And Contracting;Operations And Finance Interface;Supply Risk Management;Trade Credit","","Recent cases of product adulteration by foreign suppliers have compelled many manufacturers to rethink approaches to deterring suppliers from cutting corners, especially when manufacturers cannot fully monitor and control the suppliers' actions. In this paper, we study three mechanisms for dealing with product adulteration problems: (a) the deferred payment mechanism-the buyer pays the supplier after the deferred payment period only if no adulteration has been discovered by the customers; (b) the inspection mechanism-the buyer pays the supplier immediately, contingent on product passing the inspection; and (c) the combined mechanism-a combination of the deferred payment and inspection mechanisms. We show that the inspection mechanism cannot completely deter the suppliers from product adulteration, whereas the deferred payment mechanism can. Surprisingly, the combined mechanism is redundant: either the inspection or the deferred payment mechanisms perform just as well. Finally, we identify four factors that determine the dominance of deferred payment mechanism over the inspection mechanism: (a) the inspection cost relative to inspection accuracy, (b) the buyer's liability for adulterated products, (c) the difference in financing rates for the buyer and the supplier relative to the defects discovery rate by customers, and (d) the difference in production costs for adulterated and unadulterated product. We find that the deferred payment mechanism is preferable to inspection if the threats of adulteration (either incentive to adulterate or the consequences) are low."
639,"Key Factors in the Market for Remanufactured Products","Subramanian, Ravi and Subramanyam, Ramanath","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","315-326","2012","SPR","Environmental Operations;Empirical Research;Closed-Loop Supply Chains;Remanufacturing;Seller Reputation;Ebay;Om-Marketing Interface;Om-Information Systems Interface","","Measures to extend the economic lives of products-such as remanufacturing carried out by closed-loop supply chains-are receiving increased attention because of various economic and regulatory factors. In this paper, we examine drivers of price differentials between new and remanufactured products using data on purchases made on eBay. Our analysis shows that seller reputation significantly explains the price differentials between new and remanufactured products. We also find that products remanufactured by original equipment manufacturers or their authorized factories are purchased at relatively higher prices than products remanufactured by third parties. However, in the presence of these reputation signals (seller reputation and remanufacturer identity), we find that stronger warranties are not significantly associated with higher prices paid for remanufactured products. Our work contributes to the closed-loop supply chain research stream in operations management by empirically examining market factors that have not been studied before."
640,"Supply Chain Dynamics and Channel Efficiency in Durable Product Pricing and Distribution","Chiang, Wei-yu Kevin","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","14","2","327-343","2012","SPR","Supply Chain Management;Dynamic Pricing;Differential Game;Channels Of Distribution;New Product Diffusion;Operations-Marketing Interface","","This study extends the single-period vertical price interaction in a manufacturer-retailer dyad to a multi-period setting. A manufacturer distributes a durable product through an exclusive retailer to an exhaustible population of consumers with heterogeneous reservation prices. In each period, the manufacturer and retailer in turn set wholesale and retail prices, respectively, and customers with valuation above the retail price adopt the product at a constant (hazard) rate. We derive the open-loop, feedback, and myopic equilibria for this dynamic pricing game and compare it to the centralized solution. Although in an integrated supply chain a forward-looking dynamic pricing strategy is always desirable, we show that this is not the case in a decentralized setting, because of vertical competition. Our main result is that both supply chain entities are better off in the long run when they ignore the impact of current prices on future demand and focus on immediate-term profits. A numerical study confirms that this insight is robust under various supply-and demand-side effects. We use the channel efficiency corresponding to various pricing rules to further derive insights into decisions on decentralization and disintermediation."
641,"Market Heterogeneity and Local Capacity Decisions in Services","Campbell, Dennis and Frei, Frances","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","2-19","2011","WIN","Service Operations;Capacity;Om-Accounting Interface;Empirical Research","","We empirically document factors that influence how local operating managers use discretion to balance the trade-off between service capacity costs and customer sensitivity to service time. Our findings, using data from one of the largest financial services providers in the United States, indicate that customer sensitivity to service time varies widely and predictably with observable market characteristics. In turn, we find evidence that local operating managers account for market-specific customer sensitivities to service times by deviating frequently and in predictable ways from the recommendations offered by a centralized capacity-planning model. Finally, we document that these discretionary capacity supply decisions exhibit a strong learning effect whereby experienced operating managers place more weight than their less-experienced counterparts on the market-specific trade-off between service capacity costs and customer sensitivity to service times. Overall, our results demonstrate both the importance of local knowledge as an input in service operations and the potential for incorporating richer data on customer behavior and preferences into service cost and productivity standard metrics."
642,"Optimal Control of Inventory Systems with Multiple Types of Remanufacturable Products","Zhou, Sean X. and Tao, Zhijie and Chao, Xiuli","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","20-34","2011","WIN","Inventory System;Product Returns;Reverse Logistics;Remanufacturing;Optimal Manufacturing And Remanufacturing Strategies;Base-Stock Policies","","Product returns have become a significant feature of many manufacturing systems. Because products are returned under different operational conditions, they usually require different remanufacturing effort/costs. Motivated by a project with a major energy company that manages its inventory through options of ordering and remanufacturing returned products (cores) in various condition, in this paper, we study a single-product, periodic-review inventory system with multiple types of cores. The serviceable products used to fulfill stochastic customer demand can be either manufactured from new parts or remanufactured from the cores, and the objective is to minimize the expected total discounted cost over a finite planning horizon. We show that the optimal manufacturing remanufacturing disposal policy has a simple structure and can be completely characterized by a sequence of constant control parameters when manufacturing and remanufacturing leadtimes are the same. To demonstrate the value of the optimal policy, we conduct a numerical study that compares its performance with two simple heuristics, namely, pull policy without and with sorting. The results show that the reduction in system cost by using the optimal policy can be significant. When manufacturing and remanufacturing leadtimes are different, we develop a heuristic method for computing the near-optimal control policy that performs quite well as demonstrated numerically."
643,"An Improved Dynamic Programming Decomposition Approach for Network Revenue Management","Zhang, Dan","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","35-52","2011","WIN","Network Revenue Management;Choice Behavior;Multinomial Logit Choice Model;Dynamic Programming","","We consider a nonlinear nonseparable functional approximation to the value function of a dynamic programming formulation for the network revenue management (RM) problem with customer choice. We propose a simultaneous dynamic programming approach to solve the resulting problem, which is a nonlinear optimization problem with nonlinear constraints. We show that our approximation leads to a tighter upper bound on optimal expected revenue than some known bounds in the literature. Our approach can be viewed as a variant of the classical dynamic programming decomposition widely used in the research and practice of network RM. The computational cost of this new decomposition approach is only slightly higher than the classical version. A numerical study shows that heuristic control policies from the decomposition consistently outperform policies from the classical decomposition."
644,"Estimating the Implied Value of the Customer's Waiting Time","Robinson, Lawrence W. and Chen, Rachel R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","53-57","2011","WIN","Health-Care Management;Service Operations","","Almost all research in appointment scheduling has focused on the trade-off between customer waiting times and server idle times. In this paper, we present an observation-based method for estimating the relative cost of the customer waiting time, which is a critical parameter for finding the optimal appointment schedule."
645,"Asymmetric Information and Economies of Scale in Service Contracting","Akan, Mustafa and Ata, Baris and Lariviere, Martin A.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","58-72","2011","WIN","Service Outsourcing;Call Centers;Order Fulfillment Operations;Economies Of Scale;Information Asymmetry;Screening","","We consider outsourcing in two important service settings: call center and order fulfillment operations. An important factor in both is the inherent economies of scale. Therefore, we advance a unifying model covering both applications and study the associated contracting problem under information asymmetry. At the time of contracting, the outsourcing firm, the originator, faces uncertainty regarding the demand volume but has private information about its probability distribution. The true demand is quickly observed once the service commences. The service provider invests in capacity before the start of the operation and offers a menu of contracts to screen different types of the originator. Adopting a mechanism design approach, we prove that a menu of two-part tariffs achieves the full-information solution. Hence, it is optimal among all possible contracts (in both settings) because of economies of scale and contractibility of realized demand."
646,"Achieving a Long-Term Service Target with Periodic Demand Signals: A Newsvendor Framework","Bensoussan, Alain and Feng, Qi and Sethi, Suresh P.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","73-88","2011","WIN","Newsvendor Model;In-Stock Probability;Fill Rate;Demand Signal;Service Constraint;Kuhn-Tucker Conditions","","We deal with the problem of a profit-maximizing vendor selling a perishable product. At the beginning of a planning cycle, the vendor determines a minimum committed order per period. During the cycle, he may also place a supplemental order in each period based on the observed demand signal in that period. Moreover, the vendor is committed to a specific service target evaluated over the planning cycle. This is a complex problem, and we, as an approximation, offer a single-period, two-stage modeling approach. Under this approach, the vendor determines a first-stage order as the minimum committed order with the possibility of supplementing it based on a demand signal observed at the second stage. The problem is to maximize his expected profit subject to a constraint on his overall service performance across all possible values of the demand signal. We characterize the optimal policy for in-stock rate and fill-rate targets, and make comparisons. Whereas in the classical newsvendor model a service target can be replaced by a single unit shortage cost, it is not so in our model. Instead, a set of unit shortage costs are imputed-one for each demand signal. The imputed shortage costs reflect trade-offs among the profits under different demand signals in meeting the service targets. We also show that under a given ordering policy, the in-stock rate is lower (higher) than the fill rate when the demand has an increasing (decreasing) hazard rate. This result suggests that the vendor can infer a fill-rate measure from the corresponding in-stock rate without the difficult task of tracking lost sales. Furthermore, we analyze how the order quantity varies according to the observed signal, which allows us to formalize the notion of a valuable demand signal."
647,"Strategic Capacity Rationing when Customers Learn","Liu, Qian and van Ryzin, Garrett","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","89-107","2011","WIN","Consumer Behavior;Pricing And Revenue Management;Dynamic Programming","","Consider a firm that sells products over repeated seasons, each of which includes a full-price period and a markdown period. The firm may deliberately understock products in the markdown period to induce high-value customers to purchase early at full price. Customers cannot perfectly anticipate availability. Instead, they use observed past capacities to form capacity expectations according to a heuristic smoothing rule. Based on their expectations of capacity, customers decide to buy either in the full-price period or in the markdown period. We embed this customer learning process in a dynamic program of the firm's capacity choices over time. One main result demonstrates the existence of a monotone optimal path of customers' expectations, which converges to either a rationing equilibrium or a low-price-only equilibrium. Further, there exists a critical value of capacity expectation such that the market converges to a rationing equilibrium if customers' initial expectations are less than that critical value; otherwise, a low-price-only equilibrium is the limiting outcome. These results show how firms can be stuck with unprofitable selling strategies from incumbent customer expectations. We also examine numerically how this critical value is affected by the firm's discount factor and customers' learning speed and risk aversion. Last, we show that the equilibrium under adaptive learning converges to that under rational expectations as the firm's discount factor approaches one."
648,"Managing Trade-in Programs Based on Product Characteristics and Customer Heterogeneity in Business-to-Business Markets","Li, Kate J. and Fong, Duncan K. H. and Xu, Susan H.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","108-123","2011","WIN","Empirical Research;Trade-In Programs;Signal-Based Forecast;Count Regression Models;Cluster Analysis;Customer Segmentation","","Trade-in programs are offered extensively in business-to-business (B2B) markets. The success of such programs depends on well-designed and executed trade-in policies as well as accurate prediction of return flow to support operational decisions. Motivated by a real problem facing a high-tech company, this paper develops methods to segment customers and forecast product returns based on return merchandise authorization information. Noisy, yet proven to be valuable, returned quantity signals are adjusted by taking product characteristics and customer heterogeneity into account, and the resulting forecast outperforms two benchmark strategies that represent the high-tech company's current practice and a widely adopted method in the literature, respectively. In addition, our methods can serve as tools for companies to uncover the root causes of return merchandise authorization discrepancy, monitor and analyze customer behavior, design segment-specific trade-in policies, and evaluate the effectiveness and efficiency of trade-in programs on a continuous basis."
649,"Retail Assortment Planning Under Category Captainship","Kurtulus, Muemin and Nakkas, Alper","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","1, SI","124-142","2011","WIN","Retail Supply Chains;Category Management;Category Captainship;Assortment Planning;Game Theory","","Retail assortment planning can have a tremendous impact on a retailer's bottom-line performance. Over the past years, retailers have increasingly relied on their leading manufacturers for recommendations regarding the assortment to be offered to the consumers in a particular category, a practice often referred to as category captainship. Our research investigates the consequences of using category captains for assortment selection decisions. We develop a game-theoretic model where multiple manufacturers sell their products to consumers through a single retailer. We compare a model where the retailer selects the assortment in the category with a model where the retailer relies on a category captain for assortment decisions in return for a target category profit. We show that category captainship can, in some circumstances, benefit not only the retailer and the category captain, but also the noncaptain manufacturers. Our results have implications regarding the implementation of category captainship practices."
650,"Inventory Management of Platelets in Hospitals: Optimal Inventory Policy for Perishable Products with Regular and Optional Expedited Replenishments","Zhou, Deming and Leung, Lawrence C. and Pierskalla, William P.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","420-438","2011","FAL","Perishable Inventory Management;Dual Sourcing;Stochastic Dynamic Programming","","Platelets are short-life blood components used in hospital blood transfusion centers. Excluding time for transportation, testing, and arrangement, clinically transfusable platelets have a mere three-day life span. This paper analyzes a periodic review inventory system for such a perishable product under two replenishment modes. Regular orders are placed at the beginning of a cycle. Within the cycle, the manager has an option of placing an additional order, referred to as an expedited order, characterized by an order-up-to level policy. For this platelet inventory problem, we prove the existence and uniqueness of an optimal policy that minimizes the expected cost. We then derive the necessary and sufficient conditions for the policy, based on which an algorithm is developed. Using real-life data, we provide a numerical illustration and a sensitivity analysis followed by extensive simulation experiments to examine the dynamics of platelet inventory management. It is shown that the optimal cost is significantly affected by demand uncertainty, lead times, seasonality, and vintage of expedited orders. Given a hospital's demand profile and the cost parameters, we are able to determine whether the hospital should order daily or every other day (i.e., adopting a combined use of regular and optional expedited orders). We also show that the analytical solution is a good approximation of the optimal policy obtained from simulation experiments, where more realistic features are incorporated. This inventory research problem can be classified as a fixed-lifetime perishable problem with dual modes of replenishments."
651,"Supplier Diversification Strategies in the Presence of Yield Uncertainty and Buyer Competition","Tang, Sammi Yu and Kouvelis, Panos","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","439-451","2011","FAL","Supply Uncertainty;Random Yield;Cournot Competition;Dual Sourcing;Equilibrium","","The benefits of supplier diversification are well established for price-taking firms. In this paper, we investigate the benefits from supplier diversification for dual-sourcing duopolists. We consider a two-echelon supply chain in which suppliers sell components to buyers who produce and sell substitutable products. The suppliers' output processes are uncertain and modeled as having a proportional random yield. Buyers engage in a quantity-based Cournot competition. We find that an increase in supplier correlation leads to more correlated buyers' outputs and a decrease in their profits. In the presence of end-market competition, dual sourcing still brings value by reducing the inefficiency caused by random yield: Namely, when the suppliers' yield processes are strongly negatively correlated, dual sourcing increases the expected market output and improves the firms' profits over sole sourcing. However, unlike a monopolist firm, a duopolist does not necessarily allocate its supplier orders to minimize output variability. We generalize the main results to a two-stage order-quantity-output-quantity game and to one with asymmetric suppliers."
652,"Computing Bid Prices for Revenue Management Under Customer Choice Behavior","Chaneton, Juan M. and Vulcano, Gustavo","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","452-470","2011","FAL","Stochastic Gradient Methods;Simulation-Based Optimization;Choice Behavior;Network Capacity Control","","We consider a choice-based, network revenue management (RM) problem in a setting where heterogeneous customers consider an assortment of products offered by a firm (e. g., different flight times, fare classes, and/or routes). Individual choice decisions are modeled through an ordered list of preferences, and minimal assumptions are made about the statistical properties of this demand sequence. The firm manages the availability of products using a bid-price control strategy, and would like to optimize the control parameters. We formulate a continuous demand and capacity model for this problem that allows for the partial acceptance of requests. The model admits a simple calculation of the sample path gradient of the revenue function. This gradient is then used to construct a stochastic steepest ascent algorithm. We show that the algorithm converges (w.p.1) to a stationary point of the expected revenue function under mild conditions. The procedure is relatively efficient from a computational standpoint, and in our synthetic and real-data experiments performs comparably to or even better than other choice-based methods that are incompatible with the current infrastructure of RM systems. These features make it an interesting candidate to be pursued for real-world applications."
653,"Efficient Funding: Auditing in the Nonprofit Sector","Privett, Natalie and Erhun, Feryal","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","471-488","2011","FAL","Public Sector;Nonprofit Sector;Audit Contracts;Adverse Selection;Principal-Agent Framework;Resource Allocation;Operational Transparency","","Nonprofit organizations are a critical part of society as well as a growing sector of the economy. For funders there is an increasing and pressing need to ensure that society reaps the most social benefit for their money while also developing the nonprofit sector as a whole. By routinely scrutinizing nonprofit reports in an effort to deduce whether a nonprofit organization is efficient, funders may believe that they are, in fact, giving responsibly. However, we find that these nonprofit reports are unreliable, supporting a myriad of empirical research and revealing that report-based funding methods do not facilitate efficient allocation of funds. In response, we develop audit contracts that put funders in a position to enact change. Auditing, perhaps obviously, supports funders; however, we find that it also benefits the population of nonprofits. Moreover, auditing results in improved efficiency for the nonprofit sector overall. Indeed, our conclusions indicate that nonprofits may want to work with funders to increase the use of auditing, consequently increasing efficiency for the sector overall and impacting society as a whole."
654,"How Much Is a Reduction of Your Customers' Wait Worth? An Empirical Study of the Fast-Food Drive-Thru Industry Based on Structural Estimation Methods","Allon, Gad and Federgruen, Awi and Pierson, Margaret","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","489-507","2011","FAL","Service Competition;Structural Estimation;Operations Marketing Interface;Choice Models;Queueing","","In many service industries, companies compete with each other on the basis of the waiting time their customers experience, along with other strategic instruments such as the price they charge for their service. The objective of this paper is to conduct an empirical study of an important industry to measure to what extent waiting time performance impacts different firms' market shares and price decisions. We report on a large-scale empirical industrial organization study in which the demand equations for fast-food drive-thru restaurants in Cook County are estimated based on so-called structural estimation methods. Our results confirm the belief expressed by industry experts, that in the fast-food drive-thru industry customers trade off price and waiting time. More interestingly, our estimates indicate that consumers attribute a very high cost to the time they spend waiting."
655,"Value of Local Cash Reuse: Inventory Models for Medium-Size Depository Institutions Under the New Federal Reserve Policy","Zhu, Yunxia and Dawande, Milind and Sriskandarajah, Chelliah","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","508-524","2011","FAL","Cash Supply Chain;Reuse Of Cash;Cross Shipping;Algorithms","","The effective local reuse of physical cash by depository institutions (DIs) is the primary goal of the new cash recirculation policy of the Federal Reserve System (Fed) of the United States. These guidelines, implemented since July 2007, encourage the reuse of cash by (i) penalizing a DI for the practice of cross shipping, the near-simultaneous deposit of used cash to-and withdrawal of fit cash from-the Fed; and (ii) offering a custodial inventory program that enables a DI to transfer fit cash to the Fed's books, but physically hold it within the DI's secured facility. The effective management of the inventory of cash under these new guidelines is both a challenging and important issue for DIs. We introduce two new multiperiod models-designed specifically to capture the operations of a medium-size DI-that emerge from the DI's objective to minimize the total cost incurred in managing the inventory of cash over a finite planning horizon. The Basic Model (BM) captures the DI's mode of operations if it chooses not to locally reuse cash and, instead, incur the cross-shipping penalty. Using two important structural properties, we provide a polynomial-time dynamic programming algorithm for BM. The Reuse Model (RM) represents the DI's actions when it locally recirculates cash. We first prove the hardness of RM and then develop an integer programming formulation. A comprehensive test bed-based on our interaction with a leading secure-logistics provider-helps us to develop several useful insights into the relative impacts of the DI-specific parameters and the Fed's cross-shipping fee on the effective management of cash. In particular, we show that the Value of Local Reuse for a DI, measured as the percentage cost saving between the optimal solutions of BM and RM, is substantial, and we analyze the forces that influence the volume of cross shipping. We also develop a rolling-horizon procedure to adapt the optimal solutions of BM and RM for obtaining near-optimal real-time solutions in the presence of a modest amount of uncertainty. Finally, we provide a comparative analysis of a DI's decisions under the Fed's mechanism and those under a socially optimal mechanism."
656,"A Censored-Data Multiperiod Inventory Problem with Newsvendor Demand Distributions","Bisi, Arnab and Dada, Maqbool and Tokdar, Surya","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","525-533","2011","FAL","Inventory;Stochastic Demand;Lost Sales;Scalability;Optimal Policy","","We study the stochastic multiperiod inventory problem in which demand in excess of available inventory is lost and unobserved so that demand data are censored. A Bayesian scheme is employed to dynamically update the demand distribution for the problem with storable or perishable inventory and with exogenous or endogenous price. We show that the Weibull is the only newsvendor distribution for which the optimal solution can be expressed in scalable form. Moreover, for Weibull demand the cost function is not convex in general. Nevertheless, in all but the storable case, sufficient structure can be discerned so that the optimal solution can be easily computed. Specifically, for the perishable inventory case, the optimal policy can be found by solving simple recursions, whereas the perishable case with pricing requires solutions to more complex one-step look-ahead recursions. Interestingly, for the special case of exponential demand the cost function is convex, so that for the storable inventory case, the optimal policy can be found using simple one-step look-ahead recursions whereas for the perishable case the optimal policy can be expressed by exact closed-form formulas."
657,"Call Centers with Delay Information: Models and Insights","Jouini, Oualid and Aksin, Zeynep and Dallery, Yves","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","534-548","2011","FAL","Queues;Telephone Call Centers;Customer Behavior;Impatient Customers;Balking;State-Dependent Analysis;Predicting And Announcing Delays","","In this paper, we analyze a call center with impatient customers. We study how informing customers about their anticipated delays affects performance. Customers react by balking upon hearing the delay announcement and may subsequently renege, particularly if the realized waiting time exceeds the delay that has originally been announced to them. The balking and reneging from such a system are a function of the delay announcement. Modeling the call center as an M/M/s+M queue with endogenized customer reactions to announcements, we analytically characterize performance measures for this model. The analysis allows us to explore the role announcing different percentiles of the waiting time distribution, i.e., announcement coverage, plays on subsequent performance in terms of balking and reneging. Through a numerical study, we explore when informing customers about delays is beneficial and what the optimal coverage should be in these announcements. We show how managers of a call center with delay announcements can control the trade-off between balking and reneging through their choice of announcements to be made."
658,"Pricing Multiple Products with the Multinomial Logit and Nested Logit Models: Concavity and Implications","Li, Hongmin and Huh, Woonghee Tim","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","4","549-563","2011","FAL","Multinomial Logit Model;Nested Logit Model;Consumer Choice;Multiproduct Pricing;Price Competition With Differentiated Products;Quantity Competition With Differentiated Products","","We consider the problem of pricing multiple differentiated products with the nested logit model and, as a special case, the multinomial logit model. We prove that concavity of the total profit function with respect to market share holds even when price sensitivity may vary with products. We use this result to analytically compare the optimal monopoly solution to oligopolistic equilibrium solutions. To demonstrate further applications of the concavity result, we consider several multiperiod dynamic models that incorporate the pricing of multiple products in the context of inventory control and revenue management, and establish structural results of the optimal policies."
659,"The Newsvendor Problem with Advertising Revenue","Wu, Zhengping and Zhu, Wanshan and Crama, Pascale","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","281-296","2011","SUM","Newsvendor Model;Pricing;Advertising;Mechanism Design;Value Of Information","","We study a modified newsvendor model in which the newsvendor obtains a revenue from sales to end users as well as from an advertiser paying to obtain access to those end users. We study the optimal decisions for both a price-taking and a price-setting newsvendor when the advertiser has private information about its willingness to pay for advertisements. We find that the newsvendor's optimal policy excludes advertisers with low willingness to pay and distorts the price and quantity from its system-efficient level to screen the advertiser. Our analysis reveals the different roles that pricing and production quantity play as screening instruments. We perform a numerical analysis to investigate the value of information and the impact of the model parameters."
660,"Improved Inventory Targets in the Presence of Limited Historical Demand Data","Akcay, Alp and Biller, Bahar and Tayur, Sridhar","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","297-309","2011","SUM","Expected Total Operating Cost;Inventory Management;Johnson Translation System;Maximum Likelihood Policy;Statistical Estimation","","Most of the literature on inventory management assumes that the demand distribution and the values of its parameters are known with certainty. In this paper, we consider a repeated newsvendor setting where this is not the case and study the problem of setting inventory targets when there is a limited amount of historical demand data. Consequently, we achieve the following objectives: (1) to quantify the inaccuracy in the inventory-target estimation as a function of the length of the historical demand data, the critical fractile, and the shape parameters of the demand distribution; and (2) to determine the inventory target that minimizes the expected cost and accounts for the uncertainty around the demand parameters estimated from limited historical data. We achieve these objectives by using the concept of expected total operating cost and representing the demand distribution with the highly flexible Johnson translation system. Our procedures require no restrictive assumptions about the first four moments of the demand random variables, and they can be easily implemented in practical settings with reduced expected total operating costs."
661,"Fluid Tasks and Fluid Teams: The Impact of Diversity in Experience and Team Familiarity on Team Performance","Huckman, Robert S. and Staats, Bradley R.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","310-328","2011","SUM","Diversity;Knowledge Work;Project Flexibility;Task Change;Team Familiarity","","In this paper, we consider how the structures of tasks and teams interact to affect team performance. We study the effects of diversity in experience on a team's ability to respond to task changes by separately examining interpersonal team diversity (i.e., differences in experience across the entire team) and intrapersonal team diversity (i.e., whether individuals on the team are more or less specialized). We also examine whether team familiarity-team members' prior experience working with one another-helps teams to better manage challenges created by task changes and greater interpersonal team diversity. Using detailed project-and individual-level data from an Indian software services firm, we find that the interaction of task change with intrapersonal diversity is related to improved project performance, whereas the interaction of task change with interpersonal diversity is related to diminished performance. Additionally, the interaction of team familiarity with interpersonal diversity is related to improved project performance in some cases. Our results highlight a need for more nuanced approaches to leveraging experience in team management."
662,"Herding in Queues with Waiting Costs: Rationality and Regret","Veeraraghavan, Senthil K. and Debo, Laurens G.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","329-346","2011","SUM","Herd Behavior;Queueing Games;Learning;Regret;Bounded Rationality","","We study how consumers with waiting cost disutility choose between two congested services of unknown service value. Consumers observe an imperfect private signal indicating which service facility may provide better service value as well as the queue lengths at the service facilities before making their choice. If more consumers choose the same service facility because of their private information, longer queues will form at that facility and indicate higher quality. On the other hand, a long queue also implies more waiting time. We characterize the equilibrium queue-joining behavior of arriving consumers and the extent of their learning from the queue information in the presence of such positive and negative externalities. We find that when the arrival rates are low, utility-maximizing rational consumers herd and join the longer queue, ignoring any contrary private information. We show that even when consumers treat queues as independently evolving, herd behavior persists with consumers joining longer queues above a threshold queue difference. However, if the consumers seek to minimize ex post regret when making their decisions, herd behavior may be dampened."
663,"Product Customization and Customer Service Costs: An Empirical Analysis","Kumar, Anuj and Telang, Rahul","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","347-360","2011","SUM","Product Customization;Product Cocreation;Health Insurance;Field Study;Customer Service;Product Familiarity;Call Center","","We conduct a field study in a U. S. health insurance firm to examine how product customization affects the firm's cost to serve customers through its call center. In our setting, the product is a complex health insurance plan. The firm incurs substantial costs in serving the customers through its call center and in adjudicating the claims using its information systems. The firm sells either standard plans or in some instances allows customer groups to customize their plans by adding and modifying certain aspects in active collaboration with the firm. Such a collaboration process is akin to the firm cocreating products with its customers. This cocreation process should increase customers' familiarity with their coverage and improve the fit with their medical needs. Better fit and familiarity in turn, reduces customers' incentives to contact the call center for clarifications regarding the firm's product coverage. In particular, we show that customers with a customized plan call 21% less frequently than customers with a standard plan. Our results account for possible self-selection of customers to customized plans. We also show no difference in the claims adjudication cost between a standard and a customized plan exists. Overall, our results suggest customized plans may be operationally cheaper to serve than standard plans. Thus, our paper provides a link between a growing business concern (customer support cost via call centers) and a prevalent business strategy (product customization via cocreation)."
664,"Incentives for Transshipment in a Supply Chain with Decentralized Retailers","Shao, Jing and Krishnan, Harish and McCormick, S. Thomas","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","361-372","2011","SUM","Supply Chain Incentives;Transshipment;Decentralized Retailers;Chain Store Retailer","","We examine transshipment incentives in a decentralized supply chain where a monopolist distributes a product through independent retailers. A key insight is that the transshipment price determines whether the firms benefit from, or are hurt by, transshipment. In particular, we show that the manufacturer prefers to set the transshipment price as high as possible, whereas retailers prefer a lower transshipment price. Given the important role of the transshipment price in determining the benefits that each firm gets from transshipment, it is useful to consider transshipment in the case where retailers are under joint ownership (a chain store) and the transshipment price does not play a role. This comparison yields two surprising results. First, if decentralized retailers control the transshipment price, they will choose a relatively low transshipment price as a way to mitigate the manufacturer's ability to extract profits by increasing wholesale prices; therefore, the manufacturer may prefer dealing with the chain store, which does not have a transshipment price, rather than with decentralized retailers. Similarly, the decentralized retailers can use a low transshipment price to achieve higher total profits than a chain store."
665,"Adaptive Appointment Systems with Patient Preferences","Wang, Wen-Ya and Gupta, Diwakar","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","373-389","2011","SUM","Appointment Scheduling;Health Care;Probability: Stochastic Model Applications","","Patients' satisfaction with an appointment system when they attempt to book a nonurgent appointment is affected by their ability to book with a doctor of choice and to book an appointment at a convenient time of day. For medical conditions requiring urgent attention, patients want quick access to a familiar physician. For such instances, it is important for clinics to have open slots that allow same-day (urgent) access. A major challenge when designing outpatient appointment systems is the difficulty of matching randomly arriving patients' booking requests with physicians' available slots in a manner that maximizes patients' satisfaction as well as clinics' revenues. What makes this problem difficult is that booking preferences are not tracked, may differ from one patient to another, and may change over time. This paper describes a framework for the design of the next generation of appointment systems that dynamically learn and update patients' preferences and use this information to improve booking decisions. Analytical results leading to a partial characterization of an optimal booking policy are presented. Examples show that heuristic decision rules, based on this characterization, perform well and reveal insights about trade-offs among a variety of performance metrics important to clinic managers."
666,"Product Variety and Capacity Investments in Congested Production Systems","Chayet, Sergio and Kouvelis, Panos and Yu, Dennis Z.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","390-403","2011","SUM","Capacity Investments;Flexible Or Dedicated Facilities;Statistical Scale Economies;Product Variety;Product Line Design;Vertical Differentiation;Segmentation","","We investigate a firm's product line design and capacity investment problem for vertically differentiated products along design quality levels. Customers arrive according to a Poisson process and are heterogeneous in their marginal valuation of the quality level. Customers make product choices to maximize a linear utility function of price, quality level, and waiting cost. Resulting product demands are met through capacity investments in production processes, which are modeled as queuing systems. We consider two different types of production processes: product-focused, dedicated to the production of a single-product variant; and product-flexible, processing all product variants in the product line. Capacity investment and variable production costs are functions of the processed product's quality. We develop an integrated marketing-operations model that provides insights on the factors determining the right level of product variety to offer, the relative quality positioning of the products in the line, the resulting market coverage and segmentation, and the effects on production costs and congestion levels of the processes. We show that the statistical economies of scale resulting from the congestion phenomena in the production system impose limits on the optimal product variety. For product-focused processes the market size promotes a higher optimal product variety, whereas the per-unit capacity investment and customer waiting costs act as deterrents for higher product variety. For product-flexible processes optimal product variety also depends on the specific type of flexibility and the ratio of capacity investment to variable production costs."
667,"The Impact of Yield-Dependent Trading Costs on Pricing and Production Planning Under Supply Uncertainty","Kazaz, Burak and Webster, Scott","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","3","404-417","2011","SUM","Supply Uncertainty;Risk Aversion;Yield-Dependent Trading Costs;Pricing;Fruit Futures","","This paper studies the role of the yield-dependent trading cost structure influencing the optimal choice of the selling price and production quantity for a firm that operates under supply uncertainty in the agricultural industry. The firm initially leases farm space, but its realized amount of fruit supply fluctuates because of weather conditions, diseases, etc. At the end of the growing season, the firm has three options: convert its crop supply to the final product, purchase additional supplies from other growers, and sell some (or all) of its crop supply in the open market without converting to the finished product. We consider the problem both from a risk-neutral and a risk-averse perspective with varying degrees of risk aversion. The paper offers three sets of contributions: (1) It shows that the use of a static cost exaggerates the initial investment in the farm space and the expected profit significantly, and the actual value gained from a secondary (emergency) option for an agricultural firm is lower under the yield-dependent cost structure. (2) It proves that although the risk-neutral firm does not benefit from fruit futures, a sufficiently risk-averse firm can benefit from the presence of a fruit futures market. The same risk-averse firm does not purchase fruit futures when it operates under static costs. Thus, fruit futures can only add value under yield-dependent trading costs. (3) Contrary to the results presented for the newsvendor problem under demand uncertainty, the firm does not always commit to a lower initial quantity (leased farm space) under risk aversion. Rather, the firm might lease a larger farm space under risk aversion."
668,"Centralizing Inventory in Supply Chains by Using Shapley Value to Allocate the Profits","Kemahlioglu-Ziya, Eda and Bartholdi, III, John J.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","146-162","2011","SPR","Supply Chain Management;Incentives And Contracting","","How should the excess profit because of inventory pooling be shared amongst firms at different levels along the supply chain? Suppose each of several retailers observes local demand for a common item and places an order at the supplier, which is immediately filled if the supplier has the item in stock. The supplier can fill retailer orders either from their reserved inventories or from a shareable pool of inventory. Using terminology from cooperative game theory, we say that the supplier and the retailers whose orders are filled from the common pool have formed an inventory-pooling coalition and study the use of Shapley value to allocate the expected excess profit because of pooling. We find that under Shapley value allocations the retailers have incentive to join the inventory-pooling coalition, and the supplier carries the level of inventory that is optimal for the coalition. Shapley value allocations might not lie within the core of the game, but the grand coalition of all players is stable in the farsighted sense. And, although the supplier's share of the expected excess profit is largest when all the retailers participate in the inventory-pooling coalition, the allocations to the retailers may diminish as the coalition grows. Colluding against the supplier (by merging and forming larger retailers) may seem like an appealing strategy for the retailers to increase their share of the total supply chain profit, but we find that the total expected after-pooling profits of retailers may instead go down because of collusion."
669,"Tax-Effective Supply Chain Decisions Under China's Export-Oriented Tax Policies","Hsu, Vernon N. and Zhu, Kaijie","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","163-179","2011","SPR","Tax-Effective Supply Chain Management;International Tax And Tariff;Supply Chain Structures","","In this paper, we study the impacts of a set of China's export-oriented tax and tariff rules on the optimal supply chain design and operations for a firm that produces its product in China and sells it in markets both inside and outside China. We develop an analytical framework to evaluate four major supply chain structures that we observed in practice. We derive the optimal supply chain decisions for each structure and investigate various business environments under which one of the structures is preferred over the others. Our analysis indicates that the ultimate purpose of a product sold in the China market (i.e., whether it will be consumed domestically or be assembled in another exported product) may have a significant impact on the structure preference. In addition, threshold values exist for several key business parameters over (or under) which certain supply chain structures are favored over others. Managerial insights based on such results are useful for multinational firms who are challenged to develop effective supply chain strategies in the region's increasingly volatile business environment."
670,"Volume Flexibility, Product Flexibility, or Both: The Role of Demand Correlation and Product Substitution","Goyal, Manu and Netessine, Serguei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","180-193","2011","SPR","Capacity Planning And Investment;Operations Strategy;Technology Management","","We analyze volume flexibility-the ability to produce above/below the installed capacity for a product-under endogenous pricing in a two-product setting. We discover that the value of volume flexibility is a function of demand correlation between products, an outcome that cannot be explained by classical risk-pooling arguments. Furthermore, whereas the value of product flexibility always decreases in demand correlation, we show that the value of volume flexibility can increase or decrease in demand correlation depending on whether the products are strategic complements or substitutes. We further find that volume flexibility better combats aggregate demand uncertainty for the two products, whereas product flexibility is better at mitigating individual demand uncertainty for each product. Our results thus underscore the necessity of analyzing volume flexibility with more than one product and emphasize the contrast with product flexibility. Furthermore, we highlight the possible pitfalls of combining flexibilities: we show that although adding volume flexibility to product flexibility never hurts performance, adding product flexibility to volume flexibility is not always beneficial, even when such an addition is costless."
671,"Regret in Overbooking and Fare-Class Allocation for Single Leg","Lan, Yingjie and Ball, Michael O. and Karaesmen, Itir Z.","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","194-208","2011","SPR","Revenue Management;Worst-Case Analysis;Regret;Overbooking;Fare-Class Allocation","","Focusing on a seller's regret in not acting optimally, we develop a model of overbooking and fare-class allocation in the multifare, single-resource problem in revenue management. We derive optimal static overbooking levels and booking limits, in closed form, that minimize the maximum relative regret (i.e., maximize competitive ratio). We prove that the optimal booking limits are nested. Our work addresses a number of important issues. (i) We use partial information, which is critical because of the difficulty in forecasting fare-class demand. Demand and no-shows are characterized using interval uncertainty in our model. (ii) We make joint overbooking and fare-class allocation decisions. (iii) We obtain conservative but practical overbooking levels that improve the service quality without sacrificing profits. Using computational experiments, we benchmark our methods to existing ones and show that our model leads to effective, consistent, and robust decisions."
672,"Now Playing: DVD Purchasing for a Multilocation Rental Firm","Baron, Opher and Hajizadeh, Iman and Milner, Joseph","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","209-226","2011","SPR","Service Operations;Supply Chain Management;Inventory Theory And Control","","This paper studies the problem of purchasing and allocating copies of movies to multiple stores of a movie rental chain. A unique characteristic of this problem is the return process of rented movies. We formulate this problem for new movies as a newsvendor-like problem with multiple rental opportunities for each copy. We provide demand and return forecasts at the store-day level based on comparable movies. We estimate the parameters of various demand and return models using an iterative maximum-likelihood estimation and Bayesian estimation via Markov chain Monte Carlo simulation. Test results on data from a large movie rental firm reveal systematic underbuying of movies purchased through revenue-sharing contracts and overbuying of movies purchased through standard ( nonrevenue-sharing) ones. For the movies considered, our model estimates an increase in the average profit per title for new movies by 15.5% and 2.5% for revenue sharing and standard titles, respectively. We discuss the implications of revenue sharing on the profitability of the rental firm."
673,"Optimal Procurement Design in the Presence of Supply Risk","Chaturvedi, Aadhaar and Martinez-de-Albeniz, Victor","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","227-243","2011","SPR","Auctions;Supply Risk;Information Asymmetry","","This paper analyzes optimal auction design when delivery of supply is uncertain. We consider a buyer facing multiple potential suppliers, each having an associated (exogenous) reliability that quantifies its risk of supply failure. We design optimal mechanisms that depend on the buyer's level of information regarding the suppliers' cost of production and reliability. When supplier reliability is known, we find that the optimal allocation resembles the allocation under full information, but with inflated production costs. When it is unknown, the same result is true when cost and reliability of a supplier are independent. Furthermore, the buyer does not have to pay any rent for information on suppliers' reliability. Moreover, we assess the benefits of the optimal mechanism compared to traditional auctions that ignore supply risk."
674,"Pricing Services Subject to Congestion: Charge Per-Use Fees or Sell Subscriptions?","Cachon, Gerard P. and Feldman, Pnina","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","244-260","2011","SPR","Service Operations;Operations Strategy;Pricing And Revenue Management;Game Theory;Queueing Theory","","Should a firm charge on a per-use basis or sell subscriptions when its service experiences congestion? Queueing-based models of pricing primarily focus on charging a fee per use for the service, in part because per-use pricing enables the firm to regulate congestion-raising the per-use price naturally reduces how frequently customers use a service. The firm has less control over usage with subscription pricing (by definition, with subscription pricing customers are not charged proportional to their actual usage), and this is a disadvantage when customers dislike congestion. However, we show that subscription pricing is more effective at earning revenue. Consequently, the firm may be better off with subscription pricing, even, surprisingly, when congestion is intuitively most problematic for the firm: e. g., as congestion becomes more disliked by consumers. We show that the absolute advantage of subscription pricing relative to per-use pricing can be substantial, whereas the potential advantage of per-use pricing is generally modest. Subscription pricing becomes relatively more attractive if consumers become more heterogeneous in their service rates (e. g., some know they are heavy users and others know they are light users) as long as capacity is fixed, the potential utilization is high, and the two segments have substantially different usage rates. Otherwise, heterogeneity in usage rates makes subscription pricing less attractive relative to per-use pricing. We conclude that subscription pricing can be effective even if congestion is relevant for the overall quality of a service."
675,"The Role of Component Commonality in Product Assortment Decisions","Bernstein, Fernando and Koek, A. Guerhan and Xie, Lei","M&SOM-MANUFACTURING & SERVICE OPERATIONS MANAGEMENT","13","2","261-270","2011","SPR","Supply Chain Management;Om-Marketing Interface;Product Variety;Consumer Choice;Inventory Management","","We consider a firm that produces multiple variants of a product. Products are assembled using a combination of common and dedicated components. We characterize the optimal assortment and derive the optimal inventory levels for the common and dedicated components under various bill-of-material configurations. We investigate the effect of commonality on product variety and compare its benefits under different demand characteristics. Commonality always leads to increased profits, but its effect on the level of product variety depends on the type of commonality. If all common components are used for the production of the entire set of products, then the optimal variety level increases relative to the system with no commonality. However, if the common components are used by a subset of the final products, then the optimal variety level may decrease with commonality. We find that the effects of commonality on profit and variety level are stronger under a demand model in which product demands are more variable and exhibit pairwise negative correlation relative to a model with independent demands."
676,"Does Corporate Social Responsibility Lead to Superior Financial Performance? A Regression Discontinuity Approach","Flammer, Caroline","MANAGEMENT SCIENCE","61","11","2549-2568","2015","NOV","Corporate Social Responsibility;Financial Performance;Regression Discontinuity;Shareholder Proposals","","This study examines the effect of shareholder proposals related to corporate social responsibility (CSR) on financial performance. Specifically, I focus on CSR proposals that pass or fail by a small margin of votes. The passage of such close call proposals is akin to a random assignment of CSR to companies and hence provides a quasi-experiment to study the effect of CSR on performance. I find that the adoption of close call CSR proposals leads to positive announcement returns and superior accounting performance, implying that these proposals are value enhancing. When I examine the channels through which companies benefit from CSR, I find that labor productivity and sales growth increase after the vote. Finally, I document that close call CSR proposals differ from non-close proposals along several dimensions. Accordingly, although my results imply that adopting close call CSR proposals is beneficial to companies, they do not necessarily imply that CSR proposals are beneficial in general."
677,"Can Noise Create the Size and Value Effects?","Arnott, Robert D. and Hsu, Jason C. and Liu, Jun and Markowitz, Harry","MANAGEMENT SCIENCE","61","11","2569-2579","2015","NOV","Noise;Size Effect;Value Effect","","If the price of a stock differs from its intrinsic value by a random noise, then value stocks are more likely to have negative noise; they are thus more likely undervalued and have higher expected return than justified by risk. The same intuition applies to small capitalization stocks. We formally verify and explore this intuition by using a standard noise-in-price model. This intuition is different from the Jensen's inequality effect studied by Blume and Stambaugh [Blume ME, Stambaugh RF (1983) Biases in computed returns: An application to the size effect. J. Financial Econom. 12(3):387-404]. Our model is parsimonious: the value premium as well as size premium are computed in closed form and depend on only four parameters: mean of stock return, volatility of stock return, volatility of the price-to-dividend ratio, and noise volatility. We emphasize that only a moderate volatility of price noise is needed to generate the observed value premium. However, the model cannot generate the observed size premium."
678,"Financing Investment: The Choice Between Bonds and Bank Loans","Morellec, Erwan and Valta, Philip and Zhdanov, Alexei","MANAGEMENT SCIENCE","61","11","2580-2602","2015","NOV","Debt Choice;Capital Structure;Investment;Credit Supply;Competition","","We build a model of investment and financing decisions to study the choice between bonds and bank loans in a firm's marginal financing decision and its effects on corporate investment. We show that firms with more growth options, with higher bargaining power in default, operating in more competitive product markets, or facing lower credit supply are more likely to issue bonds. We also demonstrate that, by changing the cost of financing, these characteristics affect the timing of investment. We test these predictions using a sample of U.S. firms and present new evidence that supports our theory."
679,"Aging and Financial Decision Making","Gamble, Keith Jacks and Boyle, Patricia A. and Yu, Lei and Bennett, David A.","MANAGEMENT SCIENCE","61","11","2603-2610","2015","NOV","Economics;Behavior And Behavioral Decision Making;Microeconomic Behavior;Finance;Aging;Financial Literacy;Retirement","","This study examines how cognitive changes associated with aging impact the financial decision-making capability of older Americans. We find that a decrease in cognition is associated with a decrease in financial literacy. Decreases in episodic memory and visuospatial ability are associated with a decrease in numeracy, and a decrease in semantic memory is associated with a decrease in financial knowledge. A decrease in cognition also predicts a drop in self-confidence in general, but importantly, it is not associated with a drop in confidence in managing one's own finances. Participants experiencing decreases in cognition do show an increased likelihood of getting help with financial decisions; however, many participants experiencing significant drops in cognition still do not get help."
680,"Performance Information, Production Uncertainty, and Subjective Entitlements in Bargaining","Karagozoglu, Emin and Riedl, Arno","MANAGEMENT SCIENCE","61","11","2611-2626","2015","NOV","Bargaining;Performance Information;Noisy Production Process;Subjective Entitlements;Reference Points;Experiments","","We experimentally explore the effect of performance information and production uncertainties on (i) subjective entitlements derived from the production process and (ii) bargaining over the jointly produced surplus. We hypothesize that performance information and details of the production process affect entitlements, which in turn influence bargaining behavior. We find that, without performance information, subjective entitlements are mostly mutually consistent, and bargaining mainly ends with an equal split. In stark contrast, negotiators derive strong, mutually inconsistent, subjective entitlements when there is performance information. These subjective entitlements affect opening proposals, concessions, and bargaining duration and lead to asymmetric agreements. Moreover, given performance information, endogenous variations in entitlements influence bargaining, suggesting an independent role of subjective entitlements. Production uncertainties influence bargaining, especially when performance information is present, but do not substantially mitigate the effect of entitlements. Theoretical bargaining models allowing for reference points or fairness principles can partly account for the empirical results. Yet, important aspects are left unexplained and our results suggest ways for extending these models."
681,"Legitimacy, Communication, and Leadership in the Turnaround Game","Brandts, Jordi and Cooper, David J. and Weber, Roberto A.","MANAGEMENT SCIENCE","61","11","2627-2645","2015","NOV","Leadership;Job Selection;Coordination Failure;Experiments;Communication","","We study the effectiveness of leaders for inducing coordinated organizational change to a more efficient equilibrium, i.e., a turnaround. We compare communication from leaders to incentive increases and also compare the effectiveness of randomly selected and elected leaders. Although all interventions yield shifts to more efficient equilibria, communication from leaders has a greater effect than incentives. Moreover, leaders who are elected by followers are significantly better at improving their group's outcome than randomly selected leaders. The improved effectiveness of elected leaders results from sending more performance-relevant messages. Our results are evidence that the way in which leaders are selected affects their legitimacy and the degree to which they influence followers. Finally, we observe that a combination of factors-specifically, incentive increases and communication from elected leaders-yields near-universal turnarounds to full efficiency."
682,"Expectations as Reference Points: Field Evidence from Professional Soccer","Bartling, Bjoern and Brandes, Leif and Schunk, Daniel","MANAGEMENT SCIENCE","61","11","2646-2661","2015","NOV","Reference Points;Expectations;Field Data","","We show that professional soccer players and their coaches exhibit reference-dependent behavior during matches. Controlling for the state of the match and for unobserved heterogeneity, we show on a minute-by-minute basis that players breach the rules of the game, measured by the referee's assignment of cards, significantly more often if their teams are behind the expected match outcome, measured by preplay betting odds of large professional bookmakers. We further show that coaches implement significantly more offensive substitutions if their teams are behind expectations. Both types of behaviors impair the expected ultimate match outcome of the team, which shows that our findings do not simply reflect fully rational responses to reference-dependent incentive schemes of favorite teams to falling behind. We derive these results in a data set that contains more than 8,200 matches from 12 seasons of the German Bundesliga and 12 seasons of the English Premier League."
683,"On the Effectiveness of Patenting Strategies in Innovation Races","Mihm, Juergen and Sting, Fabian J. and Wang, Tan","MANAGEMENT SCIENCE","61","11","2662-2684","2015","NOV","Patent Strategies;Innovation Races;Nk Modeling;Games On Nk Landscapes;Strategic Interaction On Nk Landscapes","","Which, if any, of a firm's inventions should it patent? Should it patent at all? Many companies engaged in an innovation race seek a patenting strategy that balances protection of their intellectual property against the knowledge spillovers resulting from disclosure requirements. Not much is known about factors that determine the patenting strategy best able to resolve this trade-off. Although scholars in various management, economics, and engineering disciplines have researched patents and patenting regimes, little work has addressed the normative issues that pertain to forming an appropriate firm-level patenting strategy. We develop an inventory of real-life patenting strategies and integrate them into a coherent framework. Our simulation model characterizes the optimal patenting choices for different environmental and firm-level contingencies while capturing the dynamics between competing firms. We identify the firm's research and development strategy as the most salient determinant of its optimal patenting strategy. Our research contributes to establishing a contingency theory of patenting strategies."
684,"Evaluating Venture Technical Competence in Venture Capitalist Investment Decisions","Aggarwal, Rohit and Kryscynski, David and Singh, Harpreet","MANAGEMENT SCIENCE","61","11","2685-2706","2015","NOV","Econometrics;Vc Funding;Technical Competence;Vc Assessment","","Although much research emphasizes the importance of venture technical competence for venture success and, therefore, the importance of venture technical competence in venture capitalist (VC) investment decisions, we know little about why some VCs may be better than others at assessing the technical competence of ventures. We gathered unique and proprietary data from 33 VCs and 308 ventures that sought Series A funding from those VCs. We show that VC assessment of ventures predicts VC investment, and venture technical competence predicts subsequent venture failure. This means that VCs that overassess ventures are more likely to invest in firms that are more likely to fail. We then show that higher VC technical competence leads to lower errors in assessment, but that greater similarity between the VC and venture in technical competence leads to higher assessments, ceteris paribus. We thus conclude that VC competence enhances the accuracy of VC assessments, but similarity in technical competence between VCs and ventures may lead to positive assessment bias."
685,"Standardization and the Effectiveness of Online Advertising","Goldfarb, Avi and Tucker, Catherine E.","MANAGEMENT SCIENCE","61","11","2707-2719","2015","NOV","Online Advertising;Standards;Marketing Regulation","","The technological transformation and automation of digital content delivery has revolutionized the media industry. Increased reliance on automation has also led to requirements for standardization of content-delivery formats. This paper examines how the memorability of banner advertising changed with the introduction of new standards regularizing its format. Using data from randomized field tests, we find evidence that for most ads, ad effectiveness falls as the use of standard formats rises. The decline is smaller when a standardized ad appears to be more original (such as ads created by an ad agency). Therefore, a likely explanation is that increased use of a standard format makes it harder for basic ads to distinguish themselves from their competition because the ad format commands less attention."
686,"An Interproduct Competition Model Incorporating Branding Hierarchy and Product Similarities Using Store-Level Data","Voleti, Sudhir and Kopalle, Praveen K. and Ghosh, Pulak","MANAGEMENT SCIENCE","61","11","2720-2738","2015","NOV","Competition;Nested Dirchlet Process;Brand-Sku Clustering;Product Similarity;Spatial Models","","We develop and implement a Bayesian semiparametric model of demand under interproduct competition that enables us to assess the respective contributions of brand-SKU (stock keeping unit) hierarchy and interproduct similarity to explaining and predicting demand. To incorporate brand-SKU hierarchy effects, we use Bayesian hierarchical clustering inherent in a nested Dirichlet process to simultaneously partition brands, and SKUs conditional on brands, into groups of similarity clusters. We examine cluster memberships and postprocess the Markov chain Monte Carlo output to infer cluster properties by accounting for parameter uncertainty. Our proposed approach lends to a spatial competition interpretation in latent attribute space and helps uncover the extent to which competition across SKUs in the latent attribute space is local or global. In a related vein, we discuss the implications of well-defined groups of similar SKUs as subcategory or submarket boundaries in latent attribute space. We empirically test our model using aggregate beer category sales data from a midsize U.S. retail chain. We find that branding hierarchy effects dominate those from product similarity. We find that the model partitions the 15 brands in the data into 4 brand clusters and the 96 SKUs into 25 SKU clusters conditional on brand cluster membership. In estimating a set of models of spatial interproduct competition, we find that SKU competition is more local than global in that only subsets of products compete within groups of comparable products. Finally, we discuss the substantive implications of our results."
687,"Service Quality Variability and Termination Behavior","Sriram, S. and Chintagunta, Pradeep K. and Manchanda, Puneet","MANAGEMENT SCIENCE","61","11","2739-2759","2015","NOV","Marketing;Service Quality;Economics;Econometrics;Dynamic Programming;Applications;Customer Retention","","We investigate the roles of the level and variability in quality in driving customer retention for a new service. We present model-free evidence that whereas high average quality helps in retaining customers, high variability leads to higher termination rates. Apart from these main effects, we use model-free evidence to document the presence of (a) an interaction effect between average service quality and its variability on termination rates, (b) customer learning about service quality over time, and (c) a slower rate of learning among households that experience high variability. We postulate a mechanism involving risk aversion and learning, which can induce this interaction effect, and test this against several alternative explanations. We show that it is important to consider variability in quality while inferring the impact of improvements to average quality-ignoring the interaction effect between average quality and variability leads to an 18%-64% (5%-31%) overestimation (underestimation) of quality improvement elasticities among high-variability (low-variability) households. Given that responsiveness to quality decreases with variability, it is better for the firm to focus quality improvement efforts on customers experiencing low variability; increasing average quality by 1% lowers termination by 1.1% for low-variability households, but only by 0.41% for high-variability households."
688,"Colocation Still Matters: Conformance Quality and the Interdependence of R&D and Manufacturing in the Pharmaceutical Industry","Gray, John V. and Siemsen, Enno and Vasudeva, Gurneeta","MANAGEMENT SCIENCE","61","11","2760-2781","2015","NOV","Colocation;Knowledge Interdependence;Organizational Design;Intraorganizational Learning;Quality Management;Pharmaceutical Manufacturing;Information Technology","","This study investigates the conformance quality benefits of colocating manufacturing with research and development (R&D) activities. Findings from a panel data set of U.S.-based pharmaceutical plants over a 13-year period reveal that colocation of manufacturing and R&D relates to better conformance quality, on average, across the entire sample. We find that these benefits of colocation persist throughout the time period we study (1994-2007), which is surprising, given the rapid development of information and communication technologies during that time. These benefits are particularly enhanced for manufacturing plants operating with processes that involve a high level of tacit process knowledge and that belong to large firms. Our findings highlight the importance of matching organizational design with process and firm characteristics in settings involving knowledge interdependence. They also highlight the continued value of physical proximity through geographical colocation between manufacturing and R&D activities to achieve desired quality outcomes."
689,"Propagation of Financial Shocks: The Case of Venture Capital","Townsend, Richard R.","MANAGEMENT SCIENCE","61","11","2782-2802","2015","NOV","Intermediation;Contagion;Venture Capital;Technology Bubble;Internet;Lock-In","","This paper investigates how venture-backed companies are affected when others sharing the same investor suffer a negative shock. In theory, companies may be helped or hurt in this scenario. To examine the topic empirically, I estimate the impact of the collapse of the technology bubble on non-information-technology (non-IT) companies that were held alongside IInternet companies in venture portfolios. Using a difference-indifferences framework, I find that the end of the bubble was associated with a significantly larger decline in the probability of raising continuation financing for these non-IT companies in comparison to others. This does not appear to be driven by unobservable company characteristics such as company quality or IT relatedness; for the same portfolio company receiving capital from multiple venture firms, investors with greater Internet exposure were significantly less likely to continue to participate in follow-on rounds."
690,"Information Sharing in Supply Chains: An Empirical and Theoretical Valuation","Cui, Ruomeng and Allon, Gad and Bassamboo, Achal and Van Mieghem, Jan A.","MANAGEMENT SCIENCE","61","11","2803-2824","2015","NOV","Supply Chain;Information Sharing;Signal Propagation;Decision Deviation;Time Series;Empirical Forecasting;Autoregressive Integrated Moving Average Process","","We provide an empirical and theoretical assessment of the value of information sharing in a two-stage supply chain. The value of downstream sales information to the upstream firm stems from improving upstream order fulfillment forecast accuracy. Such an improvement can lead to lower safety stock and better service. Based on the data collected from a consumer packaged goods company, we empirically show that, if the company includes the downstream sales data to forecast orders, the improvement in the mean squared forecast error ranges from 7.1% to 81.1% across all studied products. Theoretical models in the literature, however, suggest that the value of information sharing should be zero for over half of our studied products. To reconcile the gap between the literature and the empirical observations, we develop a new theoretical model. Whereas the literature assumes that the decision maker strictly adheres to a given inventory policy, our model allows him to deviate, accounting for private information held by the decision maker, yet unobservable to the econometrician. This turns out to reconcile our empirical findings with the literature. These decision deviations lead to information losses in the order process, resulting in a strictly positive value of downstream information sharing. Furthermore, we empirically quantify and show the significance of the value of operations knowledge-the value of knowing the downstream replenishment policy."
691,"Can Private Money Buy Public Science? Disease Group Lobbying and Federal Funding for Biomedical Research","Hegde, Deepak and Sampat, Bhaven","MANAGEMENT SCIENCE","61","10","2281-2298","2015","OCT","Research And Development;Lobbying;Earmarks;National Institutes Of Health","","Private interest groups lobby politicians to influence public policy. However, little is known about how lobbying influences the policy decisions made by federal agencies. We study this through examining lobbying by advocacy groups associated with rare diseases for funding by the National Institutes of Health (NIH), the world's largest funder of biomedical research. Disease group lobbying for NIH funding has been controversial, with critics alleging that it distorts public funding toward research on diseases backed by powerful groups. Our data reveal that lobbying is associated with higher political support, in the form of congressional soft earmarks for the diseases. Lobbying increases with disease burden and is more likely to be associated with changes in NIH funding for diseases with higher scientific opportunity, suggesting that it may have a useful informational role. Only special grant mechanisms that steer funding toward particular diseases, which comprise less than a third of the NIH's grants, are related to earmarks. Thus, our results suggest that lobbying by private groups influences federal funding for biomedical research. However, the channels of political influence are subtle, affect a small portion of funding, and may not necessarily have a distortive effect on public science."
692,"Cleaning House: The Impact of Information Technology Monitoring on Employee Theft and Productivity","Pierce, Lamar and Snow, Daniel C. and McAfee, Andrew","MANAGEMENT SCIENCE","61","10","2299-2319","2015","OCT","Organizational Studies;Personnel;Productivity;Information Systems;It Policy And Management;Judicial/Legal;Crime Prevention;Marketing;Sales Force;Service Operations","","This paper examines how firm investments in technology-based employee monitoring impact both misconduct and productivity. We use unique and detailed theft and sales data from 392 restaurant locations from five firms that adopt a theft monitoring information technology (IT) product. We use difference-in-differences models with staggered adoption dates to estimate the treatment effect of IT monitoring on theft and productivity. We find significant treatment effects in reduced theft and improved productivity that appear to be primarily driven by changed worker behavior rather than worker turnover. We examine four mechanisms that may drive this productivity result: economic and cognitive multitasking, fairness-based motivation, and perceived increases of general oversight. The observed productivity results represent substantial financial benefits to both firms and the legitimate tip-based earnings of workers. Our results suggest that employee misconduct is not solely a function of individual differences in ethics or morality, but can also be influenced by managerial policies that can benefit both firms and employees."
693,"The Supply Chain Effects of Bankruptcy","Yang, S. Alex and Birge, John R. and Parker, Rodney P.","MANAGEMENT SCIENCE","61","10","2320-2338","2015","OCT","Operations-Finance Interface;Supply Chain Interaction;Operational Competitiveness;Bankruptcy;Chapter 11;Reorganization;Liquidation;Externality","","This paper examines how a firm's financial distress and the legal environment regarding the ease of bankruptcy reorganization can alter product market competition and supplier-buyer relationships. We identify three effects-predation, bail-out, and abetment-that can change firms' behavior from their actions in the absence of financial distress. The predation effect increases competition before potential bankruptcy as the nondistressed competitor behaves as if it has some first-mover advantage that could benefit a supplier with price control. The bail-out effect reflects the supplier's incentive to grant the distressed firm concessions to preserve competition, improving supply chain efficiency and providing support for the exclusivity rule in Chapter 11 of the United States Bankruptcy Code when the supplier and the distressed firm are financially linked. The abetment effect is that the supplier may deliberately abet the competitor's predation, leading to increased operational disadvantages for the distressed firm before bankruptcy. Together these effects stress that a firm's bankruptcy potential can hurt its competitors and benefit its suppliers/customers. They also provide guidelines for firms' operational decisions in such situations, a rationale for observed firm actions surrounding bankruptcies, and motivation for policies supporting reorganization and relaxing broad enforcement of nondiscriminatory pricing regulations."
694,"Gender Differences in the Willingness to Compete Emerge Early in Life and Persist","Sutter, Matthias and Glaetzle-Ruetzler, Daniela","MANAGEMENT SCIENCE","61","10","2339-2354","2015","OCT","Competition;Gender Gap;Experiment;Children;Teenagers;Risk Aversion","","Gender differences in the willingness to compete have been identified as one important factor in explaining gender differences in labor markets and within organizations. We present three experiments with a total of 1,570 subjects, ages three to 18 years, to investigate the origins of this gender gap. In a between-subjects design we find that boys are more likely to compete than girls as early as kindergarten and that this gap prevails throughout adolescence. Re-examining the behavior of 316 subjects in a within-subjects design two years later, we show that these gender differences also largely persist over a longer time period and can thus be considered stable. Controlling for subjects' abilities in the different tasks, their risk attitudes, and expected performance, the gender gap in the willingness to compete is estimated in the range of 10-20 percentage points. We discuss the implications of our findings for policy interventions and organizational management. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1981."
695,"Of Age, Sex, and Money: Insights from Corporate Officer Compensation on the Wage Inequality Between Genders","Newton, David and Simutin, Mikhail","MANAGEMENT SCIENCE","61","10","2355-2375","2015","OCT","Gender;Officer Compensation;Inequality;Pay Gap","","This paper shows that the gender and age of the wage setter are crucial determinants of the disparity in wages between sexes. We document our findings using a data set on compensation of corporate officers that is uniquely suited for this analysis because officer wages are set by chief executive officers (CEOs). We show that CEOs pay officers of the opposite gender less than officers of their own gender, even when controlling for job characteristics. Older and male CEOs exhibit the greatest propensity to differentiate on the basis of sex. Female officers receive smaller raises if the firm is headed by a man. Our results suggest that CEO gender and age are economically more important determinants of officer compensation than are firm stock performance, stock volatility, or return on assets."
696,"Trading as Gambling","Dorn, Anne Jones and Dorn, Daniel and Sengmueller, Paul","MANAGEMENT SCIENCE","61","10","2376-2393","2015","OCT","Trading Volume;Individual Investors;Gambling;Lotteries","","This paper offers evidence from three different samples consistent with investors substituting between playing the lottery and gambling in financial markets. In the United States, increases in the jackpots of the multistate lotteries Powerball and Mega Millions are associated with significant reductions in small trade participation in the stock market. California-based discount brokerage clients and German discount brokerage clients are significantly less likely to trade during weeks with larger lottery prizes in the California and German lotteries, respectively. Variation in lottery prizes affects speculative trading in more lottery-like securities such as individual stocks and options, but not trading in bonds and mutual funds. Trading that is likely associated with long-term savings motives, such as trading in retirement accounts, does not respond to lottery jackpots, either. The negative relation between trading activity and jackpots is stronger for individuals who are more likely to play the lottery."
697,"Uncommon Value: The Characteristics and Investment Performance of Contrarian Funds","Wei, Kelsey D. and Wermers, Russ and Yao, Tong","MANAGEMENT SCIENCE","61","10","2394-2414","2015","OCT","Mutual Funds;Contrarian Investing;Herding Behavior","","Motivated by extant theories of herding behavior, this paper empirically identifies contrarian mutual funds as those trading most frequently against the crowd. We find that contrarian funds generate superior performance both when they trade against and with the herd, indicating that they possess superior private information. Furthermore, contrarians do not trade in a particularly correlated fashion with each other, consistent with these funds having disparate information. Our fund-level contrarian measure is largely unrelated to existing measures of fund strategy uniqueness, as both contrarian and herding funds score highly on such measures. Building on our finding of superior alphas for contrarian funds, we construct a stock-level contrarian score that reflects the aggregate stock selection information possessed by contrarian managers. This stock-level contrarian score significantly predicts stock returns after controlling for measures of stock-level herding, as well as a battery of return-predictive investment signals documented in prior studies."
698,"The Value of Funds of Hedge Funds: Evidence from Their Holdings","Aiken, Adam L. and Clifford, Christopher P. and Ellis, Jesse","MANAGEMENT SCIENCE","61","10","2415-2429","2015","OCT","Investment;Financial Institutions;Markets;Finance","","We examine the portfolio holdings of funds of hedge funds (FoFs) to identify the channels through which FoFs add value for their clients. FoFs offer access to a diversified portfolio of funds that would be costly for constrained investors to manage on their own. Although we find only limited evidence that FoFs exhibit skill when selecting hedge funds, we find strong evidence that FoFs make skillful termination decisions. After FoFs divest from a hedge fund, those hedge funds subsequently underperform and fail more often. Our evidence indicates that FoFs learn and skillfully process information about their portfolio funds after they become investors, enabling them to forecast poor future performance. Our study suggests that FoFs serve an important role as intermediaries in a market characterized by significant frictions and transactions costs."
699,"Do Stock Analysts Influence Merger Completion? An Examination of Postmerger Announcement Recommendations","Becher, David A. and Cohn, Jonathan B. and Juergens, Jennifer L.","MANAGEMENT SCIENCE","61","10","2430-2448","2015","OCT","Mergers;Analysts;Merger Success;Valuation","","This paper investigates the effects of analyst recommendations issued after a merger announcement on deal completion. We find the probability of completion increases (decreases) with the favorability of acquirer (target) recommendations. Results from instrumental variables tests support causality running from recommendations to merger outcomes. Additional tests suggest that these relations are driven by target shareholders reassessing the merger offer in response to movements in acquirer and target valuations. We also find that favorably recommended firms in a proposed merger underperform following deal resolution, suggesting that investors overreact to postmerger announcement recommendations."
700,"On Product-Level Uncertainty and Online Purchase Behavior: An Empirical Analysis","Kim, Youngsoo and Krishnan, Ramayya","MANAGEMENT SCIENCE","61","10","2449-2467","2015","OCT","Product-Level Uncertainty;Intangibility Level;Online Shopping Experience;Reputation Transfer;Digitized Video Commercial","","Online consumers are uncertain about subjective product quality (e.g., fit and feel of clothing and texture of materials) because of the absence of experiential information. In this paper, we examine the dynamic change of the products purchased online over time in the presence of this type of uncertainty. Using individual-level transaction data, we find that consumers purchase products with a high degree of product uncertainty as their online shopping experiences help them better estimate product quality. Our results also show that the average and highest prices of market baskets decrease (around 1%) when online shopping experience increases (10%). This implies that online consumers are reluctant to buy expensive products with only digitally transferred information, whereas they tend to purchase more of the cheaper products online along with their accumulated online shopping experience. We also verify the interaction effects of product uncertainty and product price on online consumers' purchase decision. When online consumers buy products priced under $50, they readily buy products with a high degree of product uncertainty regardless of their online shopping experience. But consumers are unlikely to buy expensive products online if there is a high degree of product uncertainty, even when they have accumulated much online shopping experience. In addition, we find that online vendors can effectively overcome product-level uncertainty by taking advantage of retailer reputation in the physical world and through the use of digitized video commercials. Our study on the dynamics in the set of products purchased online expands the understanding of consumer purchase behavior under uncertainty."
701,"Bias Blind Spot: Structure, Measurement, and Consequences","Scopelliti, Irene and Morewedge, Carey K. and McCormick, Erin and Min, H. Lauren and Lebrecht, Sophie and Kassam, Karim S.","MANAGEMENT SCIENCE","61","10","2468-2486","2015","OCT","Bias Blind Spot;Judgment And Decision Making;Metacognition;Self-Awareness;Advice Taking;Debiasing","","People exhibit a bias blind spot: they are less likely to detect bias in themselves than in others. We report the development and validation of an instrument to measure individual differences in the propensity to exhibit the bias blind spot that is unidimensional, internally consistent, has high test-retest reliability, and is discriminated from measures of intelligence, decision-making ability, and personality traits related to self-esteem, self-enhancement, and self-presentation. The scale is predictive of the extent to which people judge their abilities to be better than average for easy tasks and worse than average for difficult tasks, ignore the advice of others, and are responsive to an intervention designed to mitigate a different judgmental bias. These results suggest that the bias blind spot is a distinct metabias resulting from naive realism rather than other forms of egocentric cognition, and has unique effects on judgment and behavior."
702,"Increasing Quality Sequence: When Is It an Optimal Product Introduction Strategy?","Pedram, Mahmood and Balachander, Subramanian","MANAGEMENT SCIENCE","61","10","2487-2494","2015","OCT","New Product Introduction;Game Theory;Marketing Strategy;Market Segmentation;Product Differentiation;Durable Products;Pricing","","In this paper, we analyze the optimal introduction timing of a seller's products targeted at segments that differ in their willingness to pay for quality. Past studies suggest that an introduction sequence of a high-quality product followed by a lower-quality version of the product may mitigate the cannibalization effects of the low-quality product on profits from the high-quality product. We show that if customers who value quality more possess an outside option such as a substitute product, as may be the case with replacement buyers, a seller may find it optimal to follow a low-quality product with a higher-quality one, the latter being targeted at replacement buyers. Furthermore, the ability of the seller to commit to future qualities accentuates the sequential increase in quality in the presence of such buyers. Thus, we show that conditions other than uncertainty or technological improvements occurring over time may justify a seller adopting a strategy of sequentially increasing quality."
703,"Correcting for Misspecification in Parameter Dynamics to Improve Forecast Accuracy with Adaptively Estimated Models","Kolsarici, Ceren and Vakratsas, Demetrios","MANAGEMENT SCIENCE","61","10","2495-2513","2015","OCT","Long-Range Forecasting;Marketing;Marketing Mix;Statistics;Time Series","","Adaptive estimation methods have become a popular tool for capturing and forecasting changing conditions in dynamic environments. Although adaptive models can provide superior one-step-ahead forecasts, their application to multiperiod forecasting is challenging when the underlying parameter variation process is not correctly specified. The authors propose a methodology based on the Chebyshev approximation method (CAM), which provides a parsimonious substitute for the measurement updating process in the forecasting period, to help forecasters improve multiperiod accuracy in the case of parameter variation misspecification. In two empirical applications concerning the sales growth of new brands, CAM exhibits superior forecasting performance compared to a variety of benchmarks. CAM's properties are further explored through extensive simulations, which suggest that the proposed method is more likely to increase forecast accuracy when parameter variation is more systematic but misspecified because of uncertainty regarding its exact functional form."
704,"The Dynamic Impact of Product-Harm Crises on Brand Preference and Advertising Effectiveness: An Empirical Analysis of the Automobile Industry","Liu, Yan and Shankar, Venkatesh","MANAGEMENT SCIENCE","61","10","2514-2535","2015","OCT","Advertising;Brand Preference;Product-Harm Crisis;Kalman Filter;Generalized Method Of Moments (Gmm)","","Product-harm crises (recalls) carry negative product information that adversely affects brand preference and advertising effectiveness. This negative impact of product-harm crises may differ across recall events depending on media coverage of the event, crisis severity, and consumers' prior beliefs about product quality. We develop a state space model to capture the dynamics in brand preference, advertising effectiveness, and consumer response to product recalls; integrate it with a random coefficient demand model; and estimate it using a unique data set containing 35 automobile brands, 193 auto sub-brands, and 359 recalls during 1997-2002. Our results reveal that consumers respond more negatively to product recalls with greater media attention, more severe consequences, and higher perceived product quality. Furthermore, they show that sub-brand advertising effectiveness declines by a greater amount than parent-brand advertising and the decline in effectiveness of the recalled sub-brand's advertising spills over to other sub-brands under the same parent brand."
705,"Peers and Network Growth: Evidence from a Natural Experiment","Hasan, Sharique and Bagde, Surendrakumar","MANAGEMENT SCIENCE","61","10","2536-2547","2015","OCT","Social Networks;Peer Effects;Randomized Experiment;Peer Influence","","Much research suggests that social networks affect individual and organizational success. However, a strong assumption underlying this research is that network structure is not reducible to the individual attributes of social actors. In this article, we test this assumption by examining whether interacting with random peers causes exogenous growth of a person's network. Using three years of network data for students at an Indian college, we evaluate the effect of peers on network growth. We find strong evidence that interacting with random, but well-connected, roommates causes significant growth of a focal student's network. Further, we find that this growth also implies an increase in how close an actor moves to a network's center and whether that actor is likely to serve as a network bridge. Fundamentally, our results demonstrate that exogenous factors beyond individual agency-i. e., random peers-can shape network structure. Our results also provide a useful model for causally identifying the determinants of network structure and dynamics."
706,"Do Women Avoid Salary Negotiations? Evidence from a Large-Scale Natural Field Experiment","Leibbrandt, Andreas and List, John A.","MANAGEMENT SCIENCE","61","9","2016-2024","2015","SEP","Negotiation;Field Experiment;Gender;Labor Market;Sorting","","One explanation advanced for the persistent gender pay differences in labor markets is that women avoid salary negotiations. By using a natural field experiment that randomizes nearly 2,500 job seekers into jobs that vary important details of the labor contract, we are able to observe both the extent of salary negotiations and the nature of sorting. We find that when there is no explicit statement that wages are negotiable, men are more likely to negotiate for a higher wage, whereas women are more likely to signal their willingness to work for a lower wage. However, when we explicitly mention the possibility that wages are negotiable, these differences disappear completely. In terms of sorting, we find that men, in contrast to women, prefer job environments where the rules of wage determination are ambiguous. This leads to the gender gap being much more pronounced in jobs that leave negotiation of wage ambiguous."
707,"Threshold Effects in Online Group Buying","Wu, Jiahua and Shi, Mengze and Hu, Ming","MANAGEMENT SCIENCE","61","9","2025-2040","2015","SEP","Threshold Effects;Group Buying","","This paper studies two types of threshold-induced effects: a surge of new sign-ups around the time when the thresholds of group-buying deals are reached, and a stronger positive relation between the number of new sign-ups and the cumulative number of sign-ups before the thresholds are reached than afterward. This empirical study uses a data set that records the intertemporal cumulative number of sign-ups for group-buying deals in 86 city markets covered by Groupon, during a period of 71 days when Groupon predominantly used a deal a day format for each local market and posted the number of sign-ups in real time. We find that the first type of threshold effect is significant in all product categories and in all markets. The second type of threshold effect varies across product categories and markets. Our results underscore the importance of considering product and market characteristics in threshold design decisions for online group buying."
708,"Do Tips Increase Workers' Income?","Shy, Oz","MANAGEMENT SCIENCE","61","9","2041-2051","2015","SEP","Tipping;Hourly Wage;Tip-Inclusive Hourly Income;Tipping As A Social Norm","","This paper constructs a model of service providers who compete in service and labor markets simultaneously to analyze the effects of tipping on hourly wages and total tip-inclusive hourly worker compensation. An increase in the tipping rate reduces hourly wages. Total worker compensation increases at different rates depending on the market structure, market coverage, and employment level, with the exception of price-taking (competitive) service providers, where the tip-inclusive hourly income declines with the tipping rate. The paper develops an index of effective tipping that measures the net percentage change in total hourly worker compensation associated with each tipping rate."
709,"A Dollar for Your Thoughts: Feedback-Conditional Rebates on eBay","Cabral, Luis and Li, Lingfang (Ivy)","MANAGEMENT SCIENCE","61","9","2052-2063","2015","SEP","Feedback;Rebates;Field Experiment","","We run a series of controlled field experiments on eBay where buyers are rewarded for providing feedback. Our results provide little support for the hypothesis of buyers' rational economic behavior: the likelihood of feedback barely increases as we increase feedback rebate values; also, the speed of feedback, bid levels, and the number of bids are all insensitive to rebate values. By contrast, we find evidence consistent with reciprocal buyer behavior. Lower transaction quality leads to a higher probability of negative feedback as well as a speeding up of such negative feedback. However, when transaction quality is low (as measured by slow shipping), offering a rebate significantly decreases the likelihood of negative feedback. All in all, our results are consistent with the hypothesis that buyers reciprocate the sellers' good deeds (feedback rebate, high transaction quality) with more frequent and more favorable feedback. As a result, sellers can buy feedback, but such feedback is likely to be biased."
710,"Branding Conspicuous Goods: An Analysis of the Effects of Social Influence and Competition","Amaldoss, Wilfred and Jain, Sanjay","MANAGEMENT SCIENCE","61","9","2064-2079","2015","SEP","Conspicuous Goods;Reference Groups;Product Line;Behavioral Economics;Game Theory","","Branding decisions are critical for the success of new products. Prior research on branding and brand extension has primarily focused on how branding influences consumers' perceptions of product quality. However, consumers of conspicuous goods care not only about product quality but also about the profile of its users. For example, high-end consumers prefer an exclusive brand. On the other hand, low-end consumers may find a brand more attractive if high-end consumers use it. In this paper, we analyze how social effects and market structure can influence the branding of conspicuous goods. Consistent with intuition, our theoretical analysis shows that a monopolist would prefer not to use umbrella branding when consumers' desire for uniqueness is high. By contrast, in a competitive market, umbrella branding is more profitable than individual branding when consumers have a high level of desire for uniqueness. We also identify conditions in which it is optimal for marketers of conspicuous goods to adopt either an individual branding strategy or asymmetric branding strategies. Furthermore, competing firms may offer umbrella branding even when both firms may be better off if they could commit to using individual branding. Finally, we extend the model to consider a market where consumers' product preference is not related to social status. Again, if consumers are sufficiently snobbish, competing firms earn more profits by adopting an umbrella branding strategy instead of an individual branding strategy."
711,"Global Dual Sourcing and Order Smoothing: The Impact of Capacity and Lead Times","Boute, Robert N. and Van Mieghem, Jan A.","MANAGEMENT SCIENCE","61","9","2080-2099","2015","SEP","Inventory;Capacity;Dual Sourcing;Production Smoothing;Mixed-Mode Transportation","","After decades of offshoring production across the world, companies are rethinking their global networks. Local sourcing is receiving more attention, but it remains challenging to balance the offshore sourcing cost advantage against the increased inventories, because of its longer lead time, and against the cost and (volume) flexibility of each source's capacity. To guide strategic allocation in this global network decision, this paper establishes reasonably simple prescriptions that capture the key drivers. We adopt a conventional discrete-time inventory model with a linear control rule that smoothes orders and allows an exact and analytically tractable analysis of single-and dual-sourcing policies under normal demand. Distinguishing features of our model are that it captures each source's lead time, capacity cost, and flexibility to work overtime. We use Lagrange's inversion theorem to provide exact and simple square-root bound formulae for the strategic sourcing allocations and the value of dual sourcing. The formulae provide structural insight on the impact of financial, operational, and demand parameters, and a starting point for quantitative decision making. We investigate the robustness of our results by comparing the smoothing policy with existing single-and dual-sourcing models in a simulation study that relaxes model assumptions."
712,"Advance Selling: Effects of Interdependent Consumer Valuations and Seller's Capacity","Yu, Man and Kapuscinski, Roman and Ahn, Hyun-Soo","MANAGEMENT SCIENCE","61","9","2100-2117","2015","SEP","Advance Selling;Interdependent Valuation;Capacity Rationing","","We examine the impact of consumer valuation interdependence and capacity on a firm's optimal selling strategies. We consider a seller who can offer a single product to consumers twice, in advance and in spot. Consumers choose whether and when to buy, but if they buy in advance, they are uncertain about their own valuations. Whether they buy in advance or in spot, consumers' valuations are realized in the spot period and they may range from fully independent to perfectly correlated, creating markets with different characteristics of aggregate demand for the seller. Facing these consumers, the seller chooses a portion of the total capacity to offer in advance and prices in both periods. We describe how the optimal strategy and benefits of advance selling depend on the interdependence of consumer valuation, as well as capacity level and other market parameters. We find that a change in valuation interdependence can lead to dramatically different policies for the seller. For example, when individual valuations are highly diverse and the consumer population is large, the seller must offer a discount during advance selling but may limit the advance sales. On the other hand, when valuations are highly correlated, the seller can charge a premium price during advance selling. For the same valuation interdependence, the qualitative nature of the optimal strategy changes with available capacity."
713,"An Empirical Investigation of Dynamic Ordering Policies","Larson, Chad R. and Turcic, Danko and Zhang, Fuqiang","MANAGEMENT SCIENCE","61","9","2118-2138","2015","SEP","Inventory Policies;Stochastic Models;Forecasting;Arima Processes;Nonstationary Demand","","Adaptive base stock policy is a well-known tool for managing inventories in nonstationary demand environments. This paper presents empirical tests of this policy using aggregate, firm-level data. First, we extend a single-item adaptive base stock policy in previous literature to a multi-item case. Second, we transform the policy derived for the multi-item case to a regression model that relates firm-level inventory purchases to firm-level sales and changes in sales forecasts. We focus on two research questions: Can the adaptive base stock policy explain cross-sectional ordering behaviors under sales growth? To the extent that the adaptive base stock policy fails to explain ordering behaviors under sales growth, are there frictions that explain such a finding? Our empirical results demonstrate disparities in ordering behaviors between firms experiencing high and moderate sales growth. Contrary to theoretical prediction, this implies that inventory purchases are a function of not only current sales and changes in sales forecast but also past sales growth. As potential explanations for this departure from theoretical prediction, we show that both future demand dynamics and inventory holding risks depend on past sales growth. In addition, we find that firms' inventory holding risks may also be affected by purchasing constraints imposed by supply chain contracts. Our results provide managerial implications for practitioners and inform future theoretical research."
714,"Resource Allocation Decisions Under Imperfect Evaluation and Organizational Dynamics","Schlapp, Jochen and Oraiopoulos, Nektarios and Mak, Vincent","MANAGEMENT SCIENCE","61","9","2139-2159","2015","SEP","New Product Development;Resource Allocation Processes;Product Evaluation;Incentives;R&D Portfolio","","Research and development (R&D) projects face significant organizational challenges, especially when the different units who run these projects compete among each other for resources. In such cases, information sharing among the different units is critical, but it cannot be taken for granted. Instead, individual units need to be incentivized to not only exert effort in evaluating their projects, but also to truthfully reveal their findings. The former requires an emphasis on individual performance, whereas the latter relies on the existence of a common goal across the organization. Motivated by this commonly observed tension, we address the following question: How should a firm balance individual and shared incentives, so that vital information is both acquired, and equally importantly, disseminated to the entire organization? Our model captures two key characteristics of R&D experimentation: information is imperfect and it is also costly. Our analysis yields several important implications for the design of such incentive schemes and the management of R&D portfolios."
715,"Founder or Joiner? The Role of Preferences and Context in Shaping Different Entrepreneurial Interests","Roach, Michael and Sauermann, Henry","MANAGEMENT SCIENCE","61","9","2160-2184","2015","SEP","Entrepreneurship;Joiners;Human Capital;Academic Entrepreneurship;Scientists And Engineers","","Entrepreneurial ventures rely not only on founders but also on joiners-start-up employees who are attracted to entrepreneurship, but who do not want to be founders themselves. Drawing on both preference and contextual theories of entrepreneurship, we examine how individuals' interest in being a founder, a joiner, or neither forms prior to the first career transition. We find that although individuals with founder and joiner interests share similar preferences for entrepreneurial job attributes such as autonomy and risk, their preferences for these attributes also differ in significantly meaningful ways. Contextual factors such as norms, role models, and opportunities exhibit very different relationships with founder and joiner interests. Most interestingly, our results suggest that preferences and context interrelate in unique ways to shape different entrepreneurial interests. In particular, an interest in being a founder is most strongly associated with individuals' preferences for entrepreneurial job attributes, whereas contextual factors do little to shape a founder interest in individuals who lack these preferences. An interest in being a joiner, on the other hand, is associated with both preferences and context, and this relationship is most pronounced for individuals with preferences that predispose them toward entrepreneurship. This study highlights joiners as a distinct type of entrepreneurial actor and demonstrates the importance of considering the interplay between preferences and context in the study of entrepreneurship."
716,"Long-Term Strategic Asset Allocation: An Out-of-Sample Evaluation","Diris, Bart and Palm, Franz and Schotman, Peter","MANAGEMENT SCIENCE","61","9","2185-2202","2015","SEP","Strategic Asset Allocation;Out-Of-Sample Analysis;Performance Evaluation;Finance;Portfolio","","We evaluate the out-of-sample performance of a long-term investor who follows an optimized dynamic trading strategy. Although the dynamic strategy is able to benefit from predictability out-of-sample, a short-term investor using a single-period market timing strategy would have realized an almost identical performance. The value of intertemporal hedge demands in strategic asset allocation appears negligible. The result is caused by the estimation error in predicting the predictors. A myopic investor only needs to predict one-period-ahead expected returns, but hedge demands also require accurate predictions of the predictor variables. To reduce the problem of errors in optimized portfolio weights, we consider Bayesian procedures. Myopic and dynamic portfolios are similarly affected by such modifications, and differences in performance become even smaller."
717,"Asset Pricing in a Monetary Economy with Heterogeneous Beliefs","Croitoru, Benjamin and Lu, Lei","MANAGEMENT SCIENCE","61","9","2203-2219","2015","SEP","Finance;Asset Pricing;Heterogeneous Beliefs;Monetary Economics","","In this paper, we shed new light on the role of monetary policy in asset pricing by examining the case in which investors have heterogeneous expectations about future monetary policy. This case is realistic because central banks are typically less than perfectly open about their intentions. Accordingly, surveys of economists reveal that they frequently disagree in their expectations. Under heterogeneity in beliefs, investors place speculative bets against each other on the evolution of the money supply, and as a result the sharing of wealth in the economy evolves stochastically. Employing a continuous-time equilibrium model, we show that these fluctuations majorly affect the prices of all assets, as well as inflation. Our model could help explain some empirical puzzles. In particular, we find that the volatility of bond yields and stock market volatility could be significantly increased by the heterogeneity in beliefs, a conclusion supported by our empirical analyses."
718,"Collateral Valuation and Borrower Financial Constraints: Evidence from the Residential Real Estate Market","Agarwal, Sumit and Ben-David, Itzhak and Yao, Vincent","MANAGEMENT SCIENCE","61","9","2220-2240","2015","SEP","Collateral Valuation;Lending;Banks;Loans;Default;Financial Crisis","","Financially constrained borrowers have the incentive to influence the appraisal process in order to increase borrowing or reduce the interest rate. We document that the average valuation bias for residential refinance transactions is above 5%. The bias is larger for highly leveraged transactions, around critical leverage thresholds, and for transactions mediated through a broker. Mortgages with inflated valuations default more often. Lenders account for 60%-90% of the bias through pricing."
719,"Do I Follow My Friends or the Crowd? Information Cascades in Online Movie Ratings","Lee, Young-Jin and Hosanagar, Kartik and Tan, Yong","MANAGEMENT SCIENCE","61","9","2241-2258","2015","SEP","Online Word Of Mouth;Ratings;Social Influences;Informational Cascades;Latent Variables;Multilevel Models;Online Social Media","","Online product ratings are widely available on the Internet and are known to influence prospective buyers. An emerging literature has started to look at how ratings are generated and, in particular, how they are influenced by prior ratings. We study the social influence of prior ratings and, in particular, investigate any differential impact of prior ratings by strangers (crowd) versus friends. We find evidence of both herding and differentiation behavior in crowd ratings wherein users' ratings are influenced positively or negatively by prior ratings depending on movie popularity. In contrast, friends' ratings always induce herding. Further, the presence of social networking reduces the likelihood of herding on prior ratings by the crowd. Finally, we find that an increase in the number of friends who can potentially observe a user's rating (audience size) has a positive impact on ratings. These findings raise questions about the reliability of ratings as unbiased indicators of quality and advocate the need for techniques to de-bias rating systems."
720,"The Effect of Self-Control on the Construction of Risk Perceptions","Jia, Jayson S. and Khan, Uzma and Litt, Ab","MANAGEMENT SCIENCE","61","9","2259-2280","2015","SEP","Perceived Risk;Self-Control;Weighting Bias;Risk Estimation And Information Processing;Risky Behavior Mitigation","","We show that the way decision makers construct risk perceptions is systematically influenced by their level of self-control: low self-control results in greater weighting of probability and reduced weighting of consequences of negative outcomes in formulating overall threat perceptions. Seven studies demonstrate such distorted risk construction in wide-ranging risk domains. The effects hold for both chronic and manipulated levels of perceived self-control and are observed only for risks involving high personal agency (e.g., overeating, smoking, drinking). As an important implication of our results, we also demonstrate that those lower (higher) in self-control show relatively less (more) interest in products and lifestyle changes reducing consequences (e.g., a pill that heals liver damage from drinking) than those reducing likelihood of risks (e.g., a pill that prevents liver damage from drinking). We also explore several possible underlying processes for the observed effect and discuss the theoretical and managerial relevance of our findings."
721,"The Effectiveness of Field Price Discretion: Empirical Evidence from Auto Lending","Phillips, Robert and Simsek, A. Serdar and van Ryzin, Garrett","MANAGEMENT SCIENCE","61","8","1741-1759","2015","AUG","Customized Pricing;Sales Force Price Discretion;Price Sensitivity Estimation;Endogeneity;Consumer Lending","","In many markets, it is common for headquarters to create a price list but grant local salespeople discretion to negotiate prices for individual transactions. How much (if any) pricing discretion headquarters should grant is a topic of debate within many firms. We investigate this issue using a unique data set from an indirect lender with local pricing discretion. We estimate that the local sales force adjusted prices in a way that improved profits by approximately 11% on average. A counterfactual analysis shows that using a centralized, data-driven pricing optimization system could improve profits even further, up to 20% over those actually realized. This suggests that centralized pricing-if appropriately optimized-can be more effective than field price discretion. We discuss the implications of these findings for auto lending and other industries with similar pricing processes."
722,"Are Good-Looking People More Employable?","Ruffle, Bradley J. and Shtudiner, Ze'ev","MANAGEMENT SCIENCE","61","8","1760-1776","2015","AUG","Beauty;Discrimination;Job Interview;Jealousy;Field Experiment","","We investigate the role of physical attractiveness in the hiring process. We sent 5,312 curricula vitae (CVs) in pairs to 2,656 advertised job openings. In each pair, one CV was without a picture, whereas the second, otherwise almost identical CV contained a picture of either an attractive male or female or a plain-looking male or female. Employer callbacks to attractive men are significantly higher than to men with no picture and to plain-looking men, nearly doubling the latter group. Strikingly, attractive women do not enjoy the same beauty premium. In fact, women with no picture have a significantly higher rate of callback than attractive or plain-looking women. We explore a number of explanations for this discrimination against attractive women and provide evidence that female jealousy and envy are likely reasons."
723,"Fair Wages and Effort Provision: Combining Evidence from a Choice Experiment and a Field Experiment","Cohn, Alain and Fehr, Ernst and Goette, Lorenz","MANAGEMENT SCIENCE","61","8","1777-1794","2015","AUG","Fairness Perceptions;Reciprocity;Field Experiment","","The presence of workers who reciprocate higher wages with greater effort can have important consequences for firms and labor markets. Knowledge about the extent and determinants of reciprocal effort choices is, however, incomplete. We investigate the role of fairness perceptions and social preferences in a field experiment in which workers were hired for a one-time job. We show that workers who perceive being underpaid at the base wage increase their performance if the hourly wage increases, whereas those who feel adequately paid or overpaid at the base wage do not change their performance. Moreover, we find that only the workers who display reciprocity in a choice experiment show reciprocal effort responses in the field. The workers who lack reciprocity in the choice experiment do not respond to the wage increase, even if they feel underpaid at the base wage. Our findings suggest that fairness perceptions and social preferences are key in workers' performance response to wage increases. In our study, the wage increase affects effort mainly through the removal of perceived unfairness, i.e., the elimination of negative reciprocity toward the firm, rather than positive reciprocity. These results are the first direct evidence of the fair-wage effort hypothesis in the field and also help interpret previous contradictory findings in the literature."
724,"Corporate Philanthropy and Productivity: Evidence from an Online Real Effort Experiment","Tonin, Mirco and Vlassopoulos, Michael","MANAGEMENT SCIENCE","61","8","1795-1811","2015","AUG","Financial Incentives;Social Incentives;Prosocial Behavior;Real Effort Experiment;Corporate Philanthropy;Corporate Social Responsibility;Gender","","Contributing to a social cause can be an important driver for workers in the public and nonprofit sectors as well as in firms that engage in corporate philanthropy or other corporate social responsibility policies. This paper compares the effectiveness of a social incentive that takes the form of a donation received by a charity of the subject's choice to a financial incentive. We find that social incentives lead to a 13% rise in productivity, regardless of their form (lump sum or related to performance) or strength. The response is strong for subjects with low initial productivity (30%), whereas high-productivity subjects do not respond. When subjects can choose the mix of incentives, half sacrifice some of their private compensation to increase social compensation, with women more likely to do so than men. Furthermore, offering subjects some discretion in choosing their own payment schemes leads to a substantial improvement in performance. Comparing social incentives to equally costly increases in private compensation for low-productivity subjects reveals that the former are less effective in increasing productivity, but the difference is small and not statistically significant."
725,"Signaling New Product Reliability with After-Sales Service Contracts","Bakshi, Nitin and Kim, Sang-Hyun and Savva, Nicos","MANAGEMENT SCIENCE","61","8","1812-1829","2015","AUG","Signaling Games;Performance-Based Contracting;Product Reliability;Aerospace Sector;After-Sales Services","","Prior studies on performance-based contracting (PBC) for after-sales services have highlighted its advantages over traditional resource-based contracting (RBC), when products are established and their reliability is known to all parties. We develop a game theoretic model to investigate how these insights are affected when the vendor is privately informed about the reliability of a newly developed product. A novel feature of our model is the interaction between reliability signaling (private information) and the vendor's discretionary investment in spares inventory (private action), which arises naturally in the setting we consider. We find that this interaction leads to contrasting equilibrium outcomes under the two contracts: RBC induces the vendor to focus on inventory savings, leading to underinvestment in spares, whereas PBC induces the vendor to focus on reliability signaling, achieved through overinvestment in inventory. As a result, neither contract is efficient. We investigate two means to mitigate this inefficiency, but either approach has caveats: (a) making inventory verifiable removes the trade-off between reliability signaling and inventory investment, but results in diverging contract preferences between the vendor and the buyer; (b) pooling inventories across multiple buyers saves inventory costs but it also hinders reliability signaling, potentially exacerbating inefficiency."
726,"Mechanism Design for Capacity Planning Under Dynamic Evolutions of Asymmetric Demand Forecasts","Oh, Sechan and Ozer, Ozalp","MANAGEMENT SCIENCE","59","4","987-1007","2013","APR","Martingale Model Of Forecast Evolution;Mechanism Design;Mechanism-Dependent Reservation Profit;Capacity Planning;Information Sharing;Optimal Stopping;Real Options","","This paper investigates the role of time in forecast information sharing and decision making under uncertainty. To do so, we provide a general framework to model the evolutions of forecasts generated by multiple decision makers who forecast demand for the same product. We also model the evolutions of forecasts when decision makers have asymmetric demand information and refer to it as the Martingale Model of Asymmetric Forecast Evolutions. This model helps us study mechanism design problems in a dynamic environment. In particular, we consider a supplier's (principal's) problem of eliciting credible forecast information from a manufacturer (agent) when both firms obtain asymmetric demand information for the end product over multiple periods. The supplier uses demand information to better plan for a capacity investment decision. When the supplier postpones building capacity and screening the manufacturer's private information, the supplier and the manufacturer can obtain more information and update their forecasts. This delay, however, may increase (respectively, decrease) the degree of information asymmetry between the two firms, resulting in a higher (respectively, lower) cost of screening. The capacity building cost may also increase because of a tighter deadline for building capacity. Considering all such trade-offs, the supplier has to determine (i) when to stop obtaining new demand information and build capacity, (ii) whether to offer a screening contract to credibly elicit private forecast information or to determine the capacity level without information sharing, (iii) how much capacity to build, and (iv) how to design the overall mechanism so that both firms benefit from this mechanism. This paper provides an answer to these questions. In doing so, we develop a new solution approach for a class of dynamic mechanism design problems. In addition, this paper provides a framework to quantify the option value of time for a strategic investment decision under the dynamic evolutions of asymmetric forecasts."
727,"Diversity and Performance","Li, Feng and Nagar, Venky","MANAGEMENT SCIENCE","59","3","529-544","2013","MAR","Utility;Preference;Applications;Multiattribute;Finance;Management","","This study measures the performance of U.S. firms initiating same-sex domestic partnership benefit (SSDPB) policies. The results show that holding these firms upon their SSDPB initiation in a calendar portfolio earns a four-factor annualized excess return (alpha) of approximately 10% over the 1995-2008 sample period, beating 95% of all professional mutual funds in the United States. This finding is robust to several tests of reverse causality. SSDPB adopters also show significant improvement in operating performance relative to nonadopters."
728,"Multiple-Unit Holdings Yield Attenuated Endowment Effects","Burson, Katherine and Faro, David and Rottenstreich, Yuval","MANAGEMENT SCIENCE","59","3","545-555","2013","MAR","Endowment Effect;Loss Aversion;Prospect Theory;Value Function;Query Theory","","Previous endowment effect experiments have examined circumstances in which people encounter a single unit of a good (e.g., one chocolate). We contrast single-unit treatments with multiple-unit treatments in which participants encounter several units of a good (e.g., five chocolates). We observe endowment effects of typical magnitude for singleton holdings but attenuated endowment effects for multiple-unit holdings. Moreover, endowment effects consistently arise for singletons even as the definition of a unit is altered. For instance, participants holding one piece of chocolate show an endowment effect of standard size, but so do participants holding one box of chocolates. Yet the box contains about 20 individual pieces of chocolate, and participants given that many separate pieces show a substantially attenuated endowment effect. We thus propose the property of unit dependence: the definition of a unit can change, but contingent on any given definition, a pronounced endowment effect may emerge for singletons but not multiples."
729,"Revenue Sharing and Information Leakage in a Supply Chain","Kong, Guangwen and Rajagopalan, Sampath and Zhang, Hao","MANAGEMENT SCIENCE","59","3","556-572","2013","MAR","Games-Group Decisions;Game Theory And Bargaining Theory;Supply Chain Management;Information Asymmetry","","This work explores the potential of revenue-sharing contracts to facilitate information sharing in a supply chain and mitigate the negative effects of information leakage. We consider a supplier who offers a revenue-sharing contract to two competing retailers, one of whom has private information about uncertain market potential and orders first. This order information may be leaked to the uninformed retailer by the supplier to realize higher profits. We show that the incentives of the supplier and retailers are better aligned under a revenue-sharing contract, as opposed to under a wholesale-price contract, reducing the supplier's incentive to leak. This is true for a wide range of wholesale prices and revenue-share percentages and is more likely when the revenue-share percentage is higher and when variation in demand is greater. Preventing information leakage may result in higher profits not only for the informed retailer and supplier but surprisingly even for the uninformed retailer. Our results are robust when the model is generalized along various dimensions."
730,"Biased Judgment in Censored Environments","Feiler, Daniel C. and Tong, Jordan D. and Larrick, Richard P.","MANAGEMENT SCIENCE","59","3","573-591","2013","MAR","Inference;Heuristics And Biases;Demand Estimation;Inventory Decisions;Risky Choice;Learning","","Some environments constrain the information that managers and decision makers can observe. We examine judgment in censored environments where a constraint, the censorship point, systematically distorts the observed sample. Random instances beyond the censorship point are observed at the censorship point, whereas uncensored instances are observed at their true value. Many important managerial decisions occur in censored environments, such as inventory, risk taking, and employee evaluation decisions. In this research, we demonstrate a censorship bias-individuals tend to rely too heavily on the observed censored sample, biasing their belief about the underlying population. We further show that the censorship bias is exacerbated for higher degrees of censorship, higher variance in the population, and higher variability in the censorship points. In four studies, we find evidence of the censorship bias across the domains of demand estimation and sequential risk taking. The bias causes individuals to make costly decisions and behave in an overly risk-averse manner."
731,"Dynamic Capacity Allocation to Customers Who Remember Past Service","Adelman, Daniel and Mersereau, Adam J.","MANAGEMENT SCIENCE","59","3","592-612","2013","MAR","Dynamic Programming;Approximate;Behavioral Operations;Customer Relationship Management;Capacity Allocation","","We study the problem faced by a supplier deciding how to dynamically allocate limited capacity among a portfolio of customers who remember the fill rates provided to them in the past. A customer's order quantity is positively correlated with past fill rates. Customers differ from one another in their contribution margins, their sensitivities to the past, and in their demand volatilities. By analyzing and comparing policies that ignore goodwill with ones that account for it, we investigate when and how customer memory effects impact supplier profits. We develop an approximate dynamic programming policy that dynamically rationalizes the fill rates the firm provides to each customer. This policy achieves higher rewards than margin-greedy and Lagrangian policies and yields insights into how a supplier can effectively manage customer memories to its advantage."
732,"Dynamic Experiments for Estimating Preferences: An Adaptive Method of Eliciting Time and Risk Parameters","Toubia, Olivier and Johnson, Eric and Evgeniou, Theodoros and Delquie, Philippe","MANAGEMENT SCIENCE","59","3","613-640","2013","MAR","Prospect Theory;Time Discounting;Bayesian Statistics;Adaptive Experimental Design;Revealed Preference","","We present a method that dynamically designs elicitation questions for estimating risk and time preference parameters. Typically these parameters are elicited by presenting decision makers with a series of static choices between alternatives, gambles, or delayed payments. The proposed method dynamically (i.e., adaptively) designs such choices to optimize the information provided by each choice, while leveraging the distribution of the parameters across decision makers (heterogeneity) and capturing response error. We explore the convergence and the validity of our approach using simulations. The simulations suggest that the proposed method recovers true parameter values well under various circumstances. We then use an online experiment to compare our approach to a standard one used in the literature that requires comparable task completion time. We assess predictive accuracy in an out-of-sample task and completion time for both methods. For risk preferences, our results indicate that the proposed method predicts subjects' willingness to pay for a set of out-of-sample gambles significantly more accurately, while taking respondents about the same time to complete. For time preferences, both methods predict out-of-sample preferences equally well, while the proposed method takes significantly less completion time. For risk and time preferences, average completion time for our approach is approximately three minutes. Finally, we briefly review three applications that used the proposed methodology with various populations, and we discuss the potential benefits of the proposed methodology for research and practice."
733,"Human Capital Investments and Employee Performance: An Analysis of IT Services Industry","Bapna, Ravi and Langer, Nishtha and Mehra, Amit and Gopal, Ram and Gupta, Alok","MANAGEMENT SCIENCE","59","3","641-658","2013","MAR","Training And Productivity;It Services;Dynamic Panel Model;Employee Performance;Indian It Industry;Human Capital Theory","","The rapid pace of technological innovation necessitates that information technology ( IT) services firms continually invest in replenishing the skills of their key asset base, the human capital. We examine whether human capital investments directed toward employee training are effective in improving employee performance. Our rich employee level panel data set affords us the opportunity to link formal training with performance at the individual employee level. Using a dynamic panel model, we identify a significant positive impact of training on employee performance. A unit increase in training is linked to a 2.14% increase in an employee's performance. Interestingly, we find that in the IT sector, skills atrophy and consequently high-experience employees reap higher returns from training, which highlights the uniquely dynamic nature of IT knowledge and skills. We also find that general training that an employee can utilize outside the focal firm improves employee performance. However, specific training pertinent to the focal firm is not positively linked to performance. On the other hand, although domain and technical training both enhance employee performance individually, the interaction between the two suggests a substitutive relationship. Thus, our findings suggest that the value of training is conditional on a focused curricular approach that emphasizes a structured competency development program. Our findings have both theoretical and practical significance. Most important, they justify increased human capital investments to fuel future growth in this important component of the global economy."
734,"The Pitfalls of Subsystem Integration: When Less Is More","Erat, Sanjiv and Kavadias, Stylianos and Gaimon, Cheryl","MANAGEMENT SCIENCE","59","3","659-676","2013","MAR","Technology Introduction;Technology Licensing;Technological Value Appropriation;Subsystem Functionality","","In various industries end-product manufacturers acquire core subsystems from upstream technology provider firms and focus primarily on efficient end-product integration. We examine the strategic interactions between a technology firm that introduces a new subsystem and the respective end-product manufacturers (integrators). We analyze how the fraction of end-product functionalities prepackaged into the subsystem impacts the optimal introduction strategy and the relative value appropriation power across the industries. Offering a subsystem that performs many end-product functions has a dual effect on the provider's profits. On the positive side, the provider extracts a higher ease-of-use rent from the integrators because of the easier/cheaper integration. On the negative side, such subsystems may curtail the adopters' ability for competitive differentiation and render adoption less valuable. We discuss the role of subsystem functionality in value appropriation in technology markets, and we highlight the perils of subsystem overintegration."
735,"Clustering, Agency Costs and Operating Efficiency: Evidence from Nursing Home Chains","Lu, Susan F. and Wedig, Gerard J.","MANAGEMENT SCIENCE","59","3","677-694","2013","MAR","Clustering;Horizontal Integration;Monitoring;Healthcare Markets","","Models of horizontal integration typically describe a trade-off between multiunit efficiencies and managerial agency costs. In extreme cases where managers cannot be incented contractually, private ownership is thought to be the primary organizational substitute. In this paper we explore geographic clustering as an alternative strategy for controlling managerial agency costs within the chain form of organization. Clustering may facilitate scale efficiencies in both monitoring and supervision, resulting in reduced agency costs and improved application of the chain's business model. We test this hypothesis in the nursing home industry, which is characterized by managerial contract costs resulting from multitask models of production. We find that clustered nursing homes achieve higher quality, conditional on labor inputs and patient characteristics. The clustering effect is concentrated on reductions in minor/potential harm violations, which are difficult to observe without close monitoring. Several proxies for local organizational experience (local learning) cannot account for our findings, which are robust to a variety of alternative clustering definitions and competing explanations based on gaming behavior. Further tests indicate that chains endogenously pursue clustering, presumably to realize the benefits of improved quality outcomes."
736,"Price Discovery in the U.S. Treasury Market: Automation vs. Intermediation","Man, Kasing and Wang, Junbo and Wu, Chunchi","MANAGEMENT SCIENCE","59","3","695-714","2013","MAR","Price Discovery;Electronic Trading;Information Share;Liquidity;Error Correction","","This paper examines the contribution to price discovery by electronic and voice-based trading systems in the U.S. Treasury market. Evidence shows that the electronic trading system has more price discovery and that trading automation increases the speed of incorporating information into prices. However, human trading generates significant price discovery, though its volume is low. The relative contribution of a trading system to price discovery depends on liquidity, volatility, volume, trade size, and order imbalance. The voice-based trading system contributes more to price discovery when trade size is large and liquidity is low. These findings provide important implications for the design of electronic markets for securities with different characteristics and trading environments."
737,"Market Crashes, Correlated Illiquidity, and Portfolio Choice","Liu, Hong and Loewenstein, Mark","MANAGEMENT SCIENCE","59","3","715-732","2013","MAR","Market Crashes;Portfolio Choice;Correlated Illiquidity","","The recent financial crisis highlights the importance of market crashes and the subsequent market illiquidity for optimal portfolio selection. We propose a tractable and flexible portfolio choice model where market crashes can trigger switching into another regime with a different investment opportunity set. We characterize the optimal trading strategy in terms of coupled integro-differential equations and develop a quite general iterative numerical solution procedure. We conduct an extensive analysis of the optimal trading strategy. In contrast to standard portfolio choice models, changes in the investment opportunity set in one regime can affect the optimal trading strategy in another regime even in the absence of transaction costs. In addition, an increase in the expected jump size can increase stock investment even when the expected return remains the same and the volatility increases. Moreover, we show that misestimating the correlation between market crashes and market illiquidity can be costly to investors."
738,"The Effect of CRM Outsourcing on Shareholder Value: A Contingency Perspective","Kalaignanam, Kartik and Kushwaha, Tarun and Steenkamp, Jan-Benedict E. M. and Tuli, Kapil R.","MANAGEMENT SCIENCE","59","3","748-769","2013","MAR","Information Systems;It Policy And Management;Outsourcing;Application Contexts/Sectors;Marketing","","One central business activity that companies increasingly outsource is the information systems (IS) function. Previous research has shown that outsourcing of back-office IS generally has a positive effect on shareholder value of the outsourcing firm. Much less is known about the performance implications of outsourcing of another important IS function, namely, front-office customer relationship management (CRM) systems, where the vendor uses its own personnel and software to perform several CRM tasks. Previous, largely anecdotal evidence shows that the performance implications of outsourcing CRM range from very negative to very positive. To address this unsatisfactory state of knowledge, we provide and empirically test a contingency perspective on the performance implications of outsourcing CRM processes. We do so using the event-study methodology. The results are largely consistent with our contingency model. CRM outsourcing is more beneficial to firms that are high on information technology capabilities and low on marketing capabilities, and less beneficial when it concerns presales CRM. Similarly, although vendor economic distance has a positive influence on the outsourcing firm's shareholder value, vendor cultural distance has a negative influence. These effects are in turn significantly moderated by the type of CRM process outsourced."
739,"Engineering Trust: Reciprocity in the Production of Reputation Information","Bolton, Gary and Greiner, Ben and Ockenfels, Axel","MANAGEMENT SCIENCE","59","2","265-285","2013","FEB","Market Design;Reputation;Trust;Reciprocity;Ebay","","Reciprocity in feedback giving distorts the production and content of reputation information in a market, hampering trust and trade efficiency. Guided by feedback patterns observed on eBay and other platforms, we run laboratory experiments to investigate how reciprocity can be managed by changes in the way feedback information flows through the system, leading to more accurate reputation information, more trust, and more efficient trade. We discuss the implications for theory building and for managing the redesign of market trust systems."
740,"Earnings Effects of Entrepreneurial Experience: Evidence from the Semiconductor Industry","Campbell, Benjamin A.","MANAGEMENT SCIENCE","59","2","286-304","2013","FEB","Start-Ups;Experience;Human Capital;Compensation;Careers;Entrepreneurship;Risk Preferences","","Although previous studies have examined the rewards available to individuals inside entrepreneurial firms, entrepreneurial experience may provide rewards that are independent of the entrepreneurial context. Building on human capital theory, this study provides theoretical explanations for the effects of experience at a start-up on earnings across an individual's career and then examines these implications in the context of California's semiconductor industry Comparing the career trajectories of employees who join start-ups with a matched control group of comparable workers without start-up experience, I perform a counterfactual analysis and find that start-up experience in this context has a persistent positive effect on earnings that extend outside the entrepreneurial environment. The results from the matched sample are consistent with the development and revelation of valuable general human capital through entrepreneurial experience and suggest that the rewards to entrepreneurship are not limited to just the rewards available inside entrepreneurial firms."
741,"A Nonparametric Approach to Modeling Choice with Limited Data","Farias, Vivek F. and Jagabathula, Srikanth and Shah, Devavrat","MANAGEMENT SCIENCE","59","2","305-322","2013","FEB","Nonparametric Choice;Choice Models;Revenue Prediction;Utility Preference;Preference List;Marketing Mix","","Choice models today are ubiquitous across a range of applications in operations and marketing. Real-world implementations of many of these models fire the formidable stumbling block of simply identifying the right model of choice to use. Because models of choice are inherently high-dimensional objects, the typical approach to dealing with this problem is positing, a priori, a parametric model that one believes adequately captures choice behavior. This approach can be substantially suboptimal in scenarios where one cares about using the choice model learned to make fine-grained predictions; one must contend with the risks of mis-specification and overfitting/underfitting. Thus motivated, we visit the following problem: For a generic model of consumer choice (namely, distributions over preference lists) and a limited amount of data on how consumers actually make decisions (such as marginal information about these distributions), how may one predict revenues from offering a particular assortment of choices? An outcome of our investigation is a nonparametric approach in which the data automatically select the right choice model for revenue predictions. The approach is practical. Using a data set consisting of automobile sales transaction data from a major U.S. automaker, our method demonstrates a 20% improvement in prediction accuracy over state-of-the-art benchmark models; this improvement can translate into a 10% increase in revenues from optimizing the offer set. We also address a number of theoretical issues, among them a qualitative examination of the choice models implicitly learned by the approach. We believe that this paper takes a step toward automating the crucial task of choice model selection."
742,"The Role of Experience Sampling and Graphical Displays on One's Investment Risk Appetite","Kaufmann, Christine and Weber, Martin and Haisley, Emily","MANAGEMENT SCIENCE","59","2","323-340","2013","FEB","Risk Taking;Asset Allocation;Risk Perception;Experience-Description Gap;Presentation Format","","Financial professionals have a great deal of discretion concerning how to relay information about the risk of financial products to their clients. This paper introduces a new risk tool to communicate the risk of investment products, and it examines how different risk-presentation modes influence risk-taking behavior and investors' recall ability of the risk-return profile of financial products. We analyze four different ways of communicating risk: (i) numerical descriptions, (ii) experience sampling, (iii) graphical displays, and (iv) a combination of these formats in the risk tool. Participants receive information about a risky and a risk-free fund and make an allocation between the two in an experimental investment portfolio. We find that risky allocations are elevated in both the risk tool and experience sampling conditions. Greater risky allocations in the risk tool condition are associated with decreased risk perception, increased confidence in the risky fund, and a lower estimation of the probability of a loss. In addition to these favorable perceptions of the risky fund, participants in the risk tool condition are more accurate on recall questions regarding the expected return and the probability of a loss. We find no evidence of greater dissatisfaction with returns in these conditions, and we observe a willingness to take on similar levels of risk in subsequent allocations."
743,"Robust Solutions of Optimization Problems Affected by Uncertain Probabilities","Ben-Tal, Aharon and den Hertog, Dick and De Waegenaere, Anja and Melenberg, Bertrand and Rennen, Gijs","MANAGEMENT SCIENCE","59","2","341-357","2013","FEB","Robust Optimization;Phi-Divergence;Goodness-Of-Fit Statistics","","In this paper we focus on robust linear optimization problems with uncertainty regions defined by phi-divergences (for example, chi-squared, Hellinger, Kullback-Leibler). We show how uncertainty regions based on phi-divergences arise in a natural way as confidence sets if the uncertain parameters contain elements of a probability vector. Such problems frequently occur in, for example, optimization problems in inventory control or finance that involve terms containing moments of random variables, expected utility, etc. We show that the robust counterpart of a linear optimization problem with phi-divergence uncertainty is tractable for most of the choices of phi typically considered in the literature. We extend the results to problems that are nonlinear in the optimization variables. Several applications, including an asset pricing example and a numerical multi-item newsvendor example, illustrate the relevance of the proposed approach."
744,"Optimal Decision Stimuli for Risky Choice Experiments: An Adaptive Approach","Cavagnaro, Daniel R. and Gonzalez, Richard and Myung, Jay I. and Pitt, Mark A.","MANAGEMENT SCIENCE","59","2","358-375","2013","FEB","Experimental Design;Active Learning;Choice Under Risk;Model Discrimination","","Collecting data to discriminate between models of risky choice requires careful selection of decision stimuli. Models of decision making aim to predict decisions across a wide range of possible stimuli, but practical limitations force experimenters to select only a handful of them for actual testing. Some stimuli are more diagnostic between models than others, so the choice of stimuli is critical. This paper provides the theoretical background and a methodological framework for adaptive selection of optimal stimuli for discriminating among models of risky choice. The approach, called adaptive design optimization, adapts the stimulus in each experimental trial based on the results of the preceding trials. We demonstrate the validity of the approach with simulation studies aiming to discriminate expected utility, weighted expected utility, original prospect theory, and cumulative prospect theory models."
745,"Pricing and Hedging with Discontinuous Functions: Quasi-Monte Carlo Methods and Dimension Reduction","Wang, Xiaoqun and Tan, Ken Seng","MANAGEMENT SCIENCE","59","2","376-389","2013","FEB","Option Pricing;Greeks Estimation;Quasi-Monte Carlo Methods;Dimension Reduction;Effective Dimension;Brownian Bridge;Principal Component Analysis;Discontinuity","","Quasi-Monte Carlo (QMC) methods are important numerical tools in the pricing and hedging of complex financial instruments. The effectiveness of QMC methods crucially depends on the discontinuity and the dimension of the problem. This paper shows how the two fundamental limitations can be overcome in some cases. We first study how path-generation methods (PGMs) affect the structure of the discontinuities and what the effect of discontinuities is on the accuracy of QMC methods. The insight is that the discontinuities can be QMC friendly (i.e., aligned with the coordinate axes) or not, depending on the PGM. The PGMs that offer the best performance in QMC methods are those that make the discontinuities QMC friendly. The structure of discontinuities can affect the accuracy of QMC methods more significantly than the effective dimension. This insight motivates us to propose a novel way of handling the discontinuities. The basic idea is to align the discontinuities with the coordinate axes by a judicious design of a method for simulating the underlying processes. Numerical experiments demonstrate that the proposed method leads to dramatic variance reduction in QMC methods for pricing options and for estimating Greeks. It also reduces the effective dimension of the problem."
746,"Vertical Differentiation with Variety-Seeking Consumers","Zeithammer, Robert and Thomadsen, Raphael","MANAGEMENT SCIENCE","59","2","390-401","2013","FEB","Marketing;Competitive Strategy;Pricing","","We analyze price and quality competition in a vertically differentiated duopoly in which consumers have a preference for variety. The preference for variety is a consequence of diminishing marginal utility for repeated experiences with the same product. We find consumer variety seeking can either soften or intensify price competition, depending on the difference in firm qualities and the strength of consumer preference for variety When the qualities are similar (or the consumer preference for variety is strong), prices and profits are higher than would be obtained in the absence of variety seeking. On the other hand, if qualities differ enough (or the preference for variety is weak), stronger preferences for variety are associated with more intense price competition and lower profits. When firms set their qualities before competing on price and the range of feasible qualities is restricted such that variety seeking softens competition, competing firms choose to minimally differentiate themselves from each other. The preference for variety can drive the firms to offer multiunit discounts, and the greater price flexibility from these discounts does not necessarily reduce profits relative to simple unit pricing."
747,"Industry Structure, Executive Pay, and Short-Termism","Thanassoulis, John","MANAGEMENT SCIENCE","59","2","402-419","2013","FEB","Myopia;Moral Hazard;Compensation;Bonuses;Bankers' Pay;Deferred Pay;Vested Pay;Remuneration","","This study outlines a new theory linking industry structure to optimal employment contracts and executive short-termism. Firms hire their executives using optimal contracts derived within a competitive labour market. To motivate effort, firms must use some variable remuneration. Such remuneration introduces a myopia problem: an executive would wish to inflate early expected earnings at some risk to future profits. To manage this short-termism, some bonus pay is deferred. Convergence in size among firms makes the cost of managing the myopia problem grow faster than the cost of managing the effort problem. Eventually, the optimal contract jumps from one deterring myopia to one tolerating myopia. Under some conditions, the industry partitions: the largest firms hire executives on contracts tolerant of myopia; smaller firms ensure myopia is ruled out."
748,"Services and the Business Models of Product Firms: An Empirical Analysis of the Software Industry","Suarez, Fernando F. and Cusumano, Michael A. and Kahl, Steven J.","MANAGEMENT SCIENCE","59","2","420-435","2013","FEB","Computer Software And Services;Business Models;Services Operations Strategy","","Some product firms increasingly rely on service revenues as part of their business models. One possible explanation is that they turn to services to generate additional profits when their product industries mature and product revenues and profits decline. We explore this assumption by examining the role of services in the financial performance of firms in the prepackaged software products industry (Standard Industrial Classification code 7372) from 1990 to 2006. We find a convex, nonlinear relationship between a product firm's fraction of total sales coming from services and its overall operating margins. As expected, firms with a very high level of product sales are most profitable, and rising services are associated with declining profitability We find, however, that additional services start to have a positive marginal effect on the firm's overall profits when services reach a majority of a product firm's sales. We show that traditional industry maturity arguments cannot fully explain our data. It is likely that changes in both strategy and the business environment lead product firms to place more emphasis on services."
749,"The Effect of Payment Schemes on Inventory Decisions: The Role of Mental Accounting","Chen, Li and Koek, A. Guerhan and Tong, Jordan D.","MANAGEMENT SCIENCE","59","2","436-451","2013","FEB","Behavioral Operations;Newsvendor;Mental Accounting;Decision Under Uncertainty","","Does the payment scheme have an effect on inventory decisions in the newsvendor problem? Keeping the net profit structure constant, we examine three payment schemes that can be interpreted as the newsvendor's order being financed by the newsvendor herself (scheme 0), by the supplier through delayed order payment (scheme S), and by the customer through advanced revenue (scheme C). In a laboratory study, we find that inventory quantities exhibit a consistent decreasing pattern in the order of schemes 0, S. and C, with the order quantities of scheme S being close to the expected-profit-maximizing solution. These observations are inconsistent with the expected-profit-maximizing model, contradict what a regular or hyperbolic time-discounting model would predict, and cannot be explained by the loss aversion model. Instead, they are consistent with a model that underweights the order-time payments, which can be explained by the prospective accounting theory in the mental accounting literature. A second study shows that the results hold even. if all physical payments are conducted at the same time, suggesting that the framing of the payment scheme is sufficient to induce the prospective accounting behavior. We further validate the robustness of our model under different profit conditions. Our findings contribute to the understanding of the psychological processes involved in newsvendor decisions and have implications for supply chain financing and contract design."
750,"A Dynamic Level-k Model in Sequential Games","Ho, Teck-Hua and Su, Xuanming","MANAGEMENT SCIENCE","59","2","452-469","2013","FEB","Level-K Models;Learning;Sequential Games;Backward Induction;Behavioral Game Theory","","Backward induction is a widely accepted principle for predicting behavior in sequential games. In the classic example of the centipede game, however, players frequently violate this principle. An alternative is a dynamic level-k model, where players choose a rule from a rule hierarchy. The rule hierarchy is iteratively defined such that the level-k rule is a best response to the level-(k - 1) rule, and the level-infinity rule corresponds to backward induction. Players choose rules based on their best guesses of others' rules and use historical plays to improve their guesses. The model captures two systematic violations of backward induction in centipede games, limited induction and repetition unraveling. Because the dynamic level-k model always converges to backward induction over repetition, the former can be considered to be a tracing procedure for the latter. We also examine the generalizability of the dynamic level-k model by applying it to explain systematic violations of backward induction in sequential bargaining games. We show that the same model is capable of capturing these violations in two separate bargaining experiments."
751,"Individual vs. Aggregate Preferences: The Case of a Small Fish in a Big Pond","Blackburn, Douglas W. and Ukhov, Andrey D.","MANAGEMENT SCIENCE","59","2","470-484","2013","FEB","Risk Aversion;Risk Seeking;Investor Sentiment;Risk Premium","","We study the relationship between the risk preferences of individuals and the risk preferences of the aggregate economy. To emphasize the vast differences that can occur between individual and market preferences brought about through aggregation, we assume an economy consisting entirely of risk seekers. We show that such individuals can lead to an aggregate economy that is risk averse. The converse is also true. An aggregate economy that exhibits risk aversion does not imply an economy of individual risk averters. An economy demanding a risk premium can be formed from individuals who do not demand such compensation. Understanding the relationship between the preferences of individuals and the preferences of the aggregate economy is crucial for understanding the connection between the behavioral finance literature, which focuses on individual preferences, and the asset-pricing literature, which focuses on aggregate prices. We discuss empirical implications of these results."
752,"Solving Constrained Consumption-Investment Problems by Simulation of Artificial Market Strategies","Bick, Bjoern and Kraft, Holger and Munk, Claus","MANAGEMENT SCIENCE","59","2","485-503","2013","FEB","Optimal Consumption And Investment;Numerical Solution;Labor Income;Incomplete Markets;Artificially Unconstrained Markets;Welfare Loss","","Utility-maximizing consumption and investment strategies in closed form are unknown for realistic settings involving portfolio constraints, incomplete markets, and potentially a high number of state variables. Standard numerical methods are hard to implement in such cases. We propose a numerical procedure that combines the abstract idea of artificial, unconstrained complete markets, well-known closed-form solutions in affine or quadratic return models, straightforward Monte Carlo simulation, and a standard iterative optimization routine. Our method provides an upper bound on the wealth-equivalent loss compared to the unknown optimal strategy, and it facilitates our understanding of the economic forces at play by building on closed-form expressions for the strategies considered. We illustrate and test our method on the life-cycle problem of an individual who receives unspanned labor income and cannot borrow or short sell. The upper loss bound is small, and our method performs well in comparison with two existing methods."
753,"Lens or Prism? Patent Citations as a Measure of Knowledge Flows from Public Research","Roach, Michael and Cohen, Wesley M.","MANAGEMENT SCIENCE","59","2","504-525","2013","FEB","Patent Citations;Knowledge Flows;Academic Research;Innovation;Measurement","","This paper assesses the validity and accuracy of firms' backward patent citations as a measure of knowledge flows from public research by employing a newly constructed data set that matches patents to survey data at the level of the research and development lab. Using survey-based measures of the dimensions of knowledge flows, we identify sources of systematic measurement error associated with backward citations to both patent and nonpatent references. We find that patent citations reflect the codified knowledge flows from public research, but they appear to miss knowledge flows that are more private and contract based in nature, as well as those used in firm basic research. We also find that firms' patenting and citing strategies affect patent citations, making citations less indicative of knowledge flows. In addition, an illustrative analysis examining the magnitude and direction of measurement error bias suggests that measuring knowledge flows with patent citations can lead to substantial underestimation of the effect of public research on firms' innovative performance. Throughout our analyses we find that nonpatent references (e.g., journals, conferences, etc.), not the more commonly used patent references, are a better measure of knowledge originating from public research."
754,"How Costly Is Diversity? Affirmative Action in Light of Gender Differences in Competitiveness","Niederle, Muriel and Segal, Carmit and Vesterlund, Lise","MANAGEMENT SCIENCE","59","1","1-16","2013","JAN","Gender Differences;Competitiveness;Affirmative Action","","Affirmative action is often criticized for causing reverse discrimination and lowering the qualifications of those hired under the policy. However, the magnitude of such adverse effects depends on whether the best suited candidate is hired absent the policy. Indeed affirmative action may compensate for the distortion discrimination imposes on the selection of candidates. This paper asks whether affirmative action can have a similar corrective impact when qualified individuals fail to apply for a job. We evaluate the effect of introducing a gender quota in an environment where high-performing women fail to enter competitions they can win. We show that guaranteeing women equal representation among winners increases their entry. The response exceeds that predicted by the change in probability of winning and is in part driven by women being more willing to compete against other women. The consequences are substantial as the boost in supply essentially eliminates the anticipated costs of the policy."
755,"Judging Borrowers by the Company They Keep: Friendship Networks and Information Asymmetry in Online Peer-to-Peer Lending","Lin, Mingfeng and Prabhala, Nagpurnanand R. and Viswanathan, Siva","MANAGEMENT SCIENCE","59","1","17-35","2013","JAN","Peer-To-Peer (P2P) Lending;Value Of Social Networks;Signaling;Information Asymmetry;Credit Markets","","We study the online market for peer-to-peer (P2P) lending, in which individuals bid on unsecured microloans sought by other individual borrowers. Using a large sample of consummated and failed listings from the largest online P2P lending marketplace, Prosper.com, we find that the online friendships of borrowers act as signals of credit quality. Friendships increase the probability of successful funding, lower interest rates on funded loans, and are associated with lower ex post default rates. The economic effects of friendships show a striking gradation based on the roles and identities of the friends. We discuss the implications of our findings for the disintermediation of financial markets and the design of decentralized electronic markets."
756,"Buying Beauty: On Prices and Returns in the Art Market","Renneboog, Luc and Spaenjers, Christophe","MANAGEMENT SCIENCE","59","1","36-53","2013","JAN","Art;Auctions;Hedonic Regressions;Investments;Repeat-Sales Regressions;Sentiment","","This paper investigates the price determinants and investment performance of art. We apply a hedonic regression analysis to a new data set of more than one million auction transactions of paintings and works on paper. Based on the resulting price index, we conclude that art has appreciated in value by a moderate 3.97% per year, in real U. S. dollar terms, between 1957 and 2007. This is a performance similar to that of corporate bonds-at much higher risk. A repeat-sales regression on a subset of the data demonstrates the robustness of our index. Next, quantile regressions document larger average price appreciations (and higher volatilities) in more expensive price brackets. We also find variation in historical returns across mediums and movements. Finally, we show that measures of high-income consumer confidence and art market sentiment predict art price trends."
757,"Performance Appraisals and the Impact of Forced Distribution-An Experimental Investigation","Berger, Johannes and Harbring, Christine and Sliwka, Dirk","MANAGEMENT SCIENCE","59","1","54-68","2013","JAN","Performance Measurement;Forced Distribution;Forced Ranking;Motivation;Experiment","","A real-effort experiment is investigated in which supervisors have to rate the performance of individual workers who in turn receive a bonus payment based on these ratings. We compare a baseline treatment in which supervisors are not restricted in their rating behavior to a forced distribution system in which they have to assign differentiated grades. We find that productivity is significantly higher under a forced distribution by about 6% to 12%. However, the productivity effects are less clear cut when participants have prior experience with the baseline condition. Moreover, a forced distribution becomes detrimental when workers have access to a simple option to sabotage each other."
758,"The Advertising Mix for a Search Good","Anderson, Simon P. and Renault, Regis","MANAGEMENT SCIENCE","59","1","69-83","2013","JAN","Persuasion Game;Advertising;Search;Content Analysis;Information","","We extend the persuasion game to bring it squarely into the economics of advertising. We model advertising as exciting consumer interest into learning more about the product, and determine a firm's equilibrium choice of advertising content over quality information, price information, and horizontal match information. Equilibrium is unique whenever advertising is necessary. The outcome is a separating equilibrium with quality unravelling. Lower-quality firms need to provide more information. For a given quality level, as a function of consumer visit costs, first quality information is disclosed, then price information and then horizontal product information are added to the advertising mix. Some suggestive evidence is provided from airline ads in newspapers."
759,"Dynamic Pricing Competition with Strategic Customers Under Vertical Product Differentiation","Liu, Qian and Zhang, Dan","MANAGEMENT SCIENCE","59","1","84-101","2013","JAN","Dynamic Pricing;Pricing Competition;Strategic Customers;Vertical Differentiation","","We consider dynamic pricing competition between two firms offering vertically differentiated products to strategic customers who are intertemporal utility maximizers. We show that price skimming arises as the unique pure-strategy Markov perfect equilibrium in the game under a simple condition. Our results highlight the asymmetric effect of strategic customer behavior on quality-differentiated firms. Even though the profit of either firm decreases as customers become more strategic, the low-quality firm suffers substantially more than the high-quality firm. Furthermore, we show that unilateral commitment to static pricing by either firm generally improves profits of both firms. Interestingly, both firms enjoy higher profit lifts when the high-quality firm commits rather than when the low-quality firm commits."
760,"Appropriability Mechanisms and the Platform Partnership Decision: Evidence from Enterprise Software","Huang, Peng and Ceccagnoli, Marco and Forman, Chris and Wu, D. J.","MANAGEMENT SCIENCE","59","1","102-121","2013","JAN","Platform;Partnership;Intellectual Property Rights;Downstream Capabilities;Software Industry","","We examine whether ownership of intellectual property rights (IPR) or downstream capabilities is effective in encouraging entry into markets complementary to a proprietary platform by preventing the platform owner from expropriating rents from start-ups. We study this question in the context of the software industry, an environment where evidence of the efficacy of IPR as a mechanism to appropriate the returns from innovation has been mixed. Entry, in our context, is measured by an independent software vendor's (ISV's) decision to become certified by a platform owner and produce applications compatible with the platform. We find that ISVs with a greater stock of formal IPR (such as patents and copyrights), and those with stronger downstream capabilities (as measured by trademarks and consulting services) are more likely to join the platform, suggesting that these mechanisms are effective in protecting ISVs from the threat of expropriation. We also find that the effects of IPR on the likelihood of partnership are greater when an ISV has weak downstream capabilities or when the threat of imitation is greater, such as when the markets served by the ISV are growing quickly."
761,"Intertemporal CAPM with Conditioning Variables","Maio, Paulo","MANAGEMENT SCIENCE","59","1","122-141","2013","JAN","Asset Pricing Models;Conditional Capm;Icapm;Linear Multifactor Models;Predictability Of Returns;Cross-Section Of Stock Returns;Time-Varying Risk Aversion;Momentum;Value Premium","","This paper derives and tests an intertemporal capital asset pricing model (ICAPM) based on a conditional version of the Campbell-Vuolteenaho two-beta ICAPM (bad beta, good beta (BBGB)). The novel factor is a scaled cash-flow factor that results from the interaction between cash-flow news and a lagged state variable (market dividend yield or consumer price index inflation). The cross-sectional tests over 10 portfolios sorted on size, 10 portfolios sorted on book-to-market, and 10 portfolios sorted on momentum show that the scaled ICAPM explains relatively well the dispersion in excess returns on the 30 portfolios. The results for an alternative set of equity portfolios (25 portfolios sorted on size and momentum) show that the scaled ICAPM prices particularly well the momentum portfolios. Moreover, the scaled ICAPM compares favorably with alternative asset pricing models in pricing both sets of equity portfolios. The scaled factor is decisive to account for the dispersion in average excess returns between past winner and past loser stocks. More specifically, past winners are riskier than past losers in times of high price of risk. Therefore, a time-varying cash-flow beta/price of risk provides a rational explanation for momentum."
762,"GUB Covers and Power-Indexed Formulations for Wireless Network Design","D'Andreagiovanni, Fabio and Mannino, Carlo and Sassano, Antonio","MANAGEMENT SCIENCE","59","1","142-156","2013","JAN","Wireless Network Design;Power Discretization;0-1 Linear Programming;Gub Cover Inequalities;Strong Formulation","","W e propose a pure 0-1 formulation for the wireless network design problem, i.e., the problem of configuring a set of transmitters to provide service coverage to a set of receivers. In contrast with classical mixed-integer formulations, where power emissions are represented by continuous variables, we consider only a finite set of power values. This has two major advantages: it better fits the usual practice and eliminates the sources of numerical problems that heavily affect continuous models. A crucial ingredient of our approach is an effective basic formulation for the single knapsack problem representing the coverage condition of a receiver. This formulation is based on the generalized upper bound (GUB) cover inequalities introduced by Wolsey [Wolsey L (1990) Valid inequalities for 0-1 knapsacks and mips with generalised upper bound constraints. Discrete Appl. Math. 29(2-3):251-261]; and its core is an extension of the exact formulation of the GUB knapsack polytope with two GUB constraints. This special case corresponds to the very common practical situation where only one major interferer is present. We assess the effectiveness of our formulation by comprehensive computational results over realistic instances of two typical technologies, namely, WiMAX and DVB-T."
763,"Diagnostic Accuracy Under Congestion","Alizamir, Saed and de Vericourt, Francis and Sun, Peng","MANAGEMENT SCIENCE","59","1","157-171","2013","JAN","Service Operations;Queueing Theory;Dynamic Programming;Decision Making;Information Search;Bayes' Rule","","In diagnostic services, agents typically need to weigh the benefit of running an additional test and improving the accuracy of diagnosis against the cost of delaying the provision of services to others. Our paper analyzes how to dynamically manage this accuracy/congestion trade-off. To that end, we study an elementary congested system facing an arriving stream of customers. The diagnostic process consists of a search problem in which the service provider conducts a sequence of imperfect tests to determine the customer's type. We find that the agent should continue to perform the diagnosis as long as her current belief that the customer is of a given type falls into an interval that depends on the congestion level as well as the number of performed tests thus far. This search interval should shrink as congestion intensifies and as the number of performed tests increases if additional conditions hold. Our study reveals that, contrary to diagnostic services without congestion, the base rate (i.e., the prior probability of the customer type) has an effect on the agent's search strategy. In particular, the optimal search interval shrinks when customer types are more ambiguous a priori, i.e., as the base rate approaches the value at which the agent is indifferent between types. Finally, because of congestion effects, the agent should sometimes diagnose the customer as being of a given type, even if test results indicate otherwise. All these insights disappear in the absence of congestion."
764,"Worst-Case Value at Risk of Nonlinear Portfolios","Zymler, Steve and Kuhn, Daniel and Rustem, Berc","MANAGEMENT SCIENCE","59","1","172-188","2013","JAN","Value At Risk;Derivatives;Robust Optimization;Second-Order Cone Programming;Semidefinite Programming","","Portfolio optimization problems involving value at risk (VaR) are often computationally intractable and require complete information about the return distribution of the portfolio constituents, which is rarely available in practice. These difficulties are compounded when the portfolio contains derivatives. We develop two tractable conservative approximations for the VaR of a derivative portfolio by evaluating the worst-case VaR over all return distributions of the derivative underliers with given first-and second-order moments. The derivative returns are modelled as convex piecewise linear or-by using a delta-gamma approximation-as (possibly nonconvex) quadratic functions of the returns of the derivative underliers. These models lead to new worst-case polyhedral VaR (WPVaR) and worst-case quadratic VaR (WQVaR) approximations, respectively. WPVaR serves as a VaR approximation for portfolios containing long positions in European options expiring at the end of the investment horizon, whereas WQVaR is suitable for portfolios containing long and/or short positions in European and/or exotic options expiring beyond the investment horizon. We prove that-unlike VaR that may discourage diversification-WPVaR and WQVaR are in fact coherent risk measures. We also reveal connections to robust portfolio optimization."
765,"Collaborative Cost Reduction and Component Procurement Under Information Asymmetry","Kim, Sang-Hyun and Netessine, Serguei","MANAGEMENT SCIENCE","59","1","189-206","2013","JAN","Procurement;Contracting;Product Development;Asymmetric Information;Collaboration","","During development of an innovative product there is often considerable uncertainty about component production cost, and it is of interest for both the manufacturer and the supplier to engage in a collaborative effort to reduce this uncertainty and lower the expected cost. Despite the obvious benefits this brings, the supplier may be reluctant to collaborate as he fears revealing his proprietary cost information. We investigate how information asymmetry and procurement contracting strategies interact to influence the supply chain parties' incentives to collaborate. We consider a number of procurement contracting strategies, and identify a simple strategy, expected margin commitment (EMC), that effectively promotes collaboration. The manufacturer prefers EMC if collaboration leads to a large reduction in unit cost and/or demand variability is low. Otherwise, a screening contract based on price and quantity is preferred. We also find that, paradoxically, ex post efforts to enhance supply chain efficiency may hinder ex ante collaboration that precedes production."
766,"The Effect of Information Technology-Enabled Flexibility on Formation and Market Value of Alliances","Tafti, Ali and Mithas, Sunil and Krishnan, M. S.","MANAGEMENT SCIENCE","59","1","207-225","2013","JAN","Information Technology;Service-Oriented Architecture;Alliances;Tobin'S Q;Business Value Of It","","This study investigates the effect of information technology (IT) architecture flexibility on strategic alliance formation and firm value. We first examine the effect of three dimensions of IT architecture flexibility (open communication standards, cross-functional transparency, and modularity) on formation of three types of alliances (arm's-length, collaborative, and joint-venture alliances, respectively). Then, we examine how capabilities in IT flexibility can enhance the value derived from alliances. Our sample includes data from 169 firms that are publicly listed in the United States and that span multiple industries. We find that adoption of open communication standards is associated with the formation of arm's-length alliances, and modularity of IT architecture is associated with the formation of joint ventures. We also find that IT architecture flexibility enhances the value of arm's-length, collaborative, and joint-venture alliances. The contribution of IT flexibility to value is greater in the case of collaborative alliances than in arm's-length alliances. Taken together, these findings suggest that appropriate investments in IT can help to facilitate reconfiguration of resources and modification of processes in collaboration-intensive alliances."
767,"Crowdsourcing New Product Ideas over Time: An Analysis of the Dell IdeaStorm Community","Bayus, Barry L.","MANAGEMENT SCIENCE","59","1","226-244","2013","JAN","Innovation;Marketing;Ideation;Creativity;Fixation","","Several organizations have developed ongoing crowdsourcing communities that repeatedly collect ideas for new products and services from a large, dispersed crowd of nonexperts (consumers) over time. Despite its promises, little is known about the nature of an individual's ideation efforts in such an online community. Studying Dell's IdeaStorm community, serial ideators are found to be more likely than consumers with only one idea to generate an idea the organization finds valuable enough to implement, but they are unlikely to repeat their early success once their ideas are implemented. As ideators with past success attempt to again come up with ideas that will excite the organization, they instead end up proposing ideas similar to their ideas that were already implemented (i.e., they generate less diverse ideas). The negative effects of past success are somewhat mitigated for ideators with diverse commenting activity on others' ideas. These findings highlight some of the challenges in maintaining an ongoing supply of quality ideas from the crowd over time."
768,"Effects of Piracy on Quality of Information Goods","Lahiri, Atanu and Dey, Debabrata","MANAGEMENT SCIENCE","59","1","245-264","2013","JAN","Piracy;Quality;Pricing;Information Good;Versioning","","It is commonly believed that piracy of information goods leads to lower profits, which translate to lower incentives to invest in innovation and eventually to lower-quality products. Manufacturers, policy makers, and researchers all claim that inadequate piracy enforcement efforts translate to lower investments in product development. However, we find many practical examples that contradict this claim. Therefore, to examine this claim more carefully, we develop a rigorous economic model of the manufacturer's quality decision problem in the presence of piracy. We consider a monopolist who does not have any marginal costs but has a product development cost quadratic in the quality level produced. The monopolist faces a consumer market heterogeneous in its preference for quality and offers a quality level that maximizes its profit. We also allow for the possibility that the manufacturer may use versioning to counter piracy. We unexpectedly find that in certain situations, lower piracy enforcement increases the monopolist's incentive to invest in quality. We explain the reasons and welfare implications of our findings."
769,"The Behavioralist Visits the Factory: Increasing Productivity Using Simple Framing Manipulations","Hossain, Tanjim and List, John A.","MANAGEMENT SCIENCE","58","12","2151-2167","2012","DEC","Framing Effect;Natural Field Experiment;Worker Productivity;Loss Aversion","","Recent discoveries in behavioral economics have led to important new insights concerning what can happen in markets. Such gains in knowledge have come primarily via laboratory experiments a missing piece of the puzzle in many cases is parallel evidence drawn from naturally occurring field counterparts. We provide a small movement in this direction by taking advantage of a unique opportunity to work with a Chinese high-tech manufacturing facility. Our study revolves around using insights gained from one of the most influential lines of behavioral research framing manipulations in an attempt to increase worker productivity in the facility. Using a natural field experiment, we report several insights. For example, conditional incentives framed as both losses and gains increase productivity for both individuals and teams. In addition, teams more acutely respond to bonuses posed as losses than as comparable bonuses posed as gains. The magnitude of this framing effect is roughly 1%: that is, total team productivity is enhanced by 1% purely due to the framing manipulation. Importantly, we find that neither the framing nor the incentive effect lose their significance over time; rather, the effects are observed over the entire sample period. Moreover, we learn that repeated interaction with workers and conditionality of the bonus contract are substitutes for sustenance of incentive effects in the long run."
770,"Selling to Conspicuous Consumers: Pricing, Production, and Sourcing Decisions","Tereyagoglu, Necati and Veeraraghavan, Senthil","MANAGEMENT SCIENCE","58","12","2168-2189","2012","DEC","Strategic Customer Behavior;Game Theory;Conspicuous Consumption;Pricing;Scarcity;Sourcing","","Consumers often purchase goods that are hard to find to conspicuously display their exclusivity and social status. Firms that produce such conspicuously consumed goods such as designer apparel, fashion goods, jewelry, etc., often face challenges in making optimal pricing and production decisions. Such firms are confronted with precipitous trade-off between high sales volume and high margins, because of the highly uncertain market demand, strategic consumer behavior, and the display of conspicuous consumption. In this paper, we propose a model that addresses pricing and production decisions for a firm, using the rational expectations framework. We show that, in equilibrium, firms may offer high availability of goods despite the presence of conspicuous consumption. We show that scarcity strategies are harder to adopt as demand variability increases, and we provide conditions under which scarcity strategies could be successfully adopted to improve profits. Finally, to credibly commit to scarcity strategy, we show that firms can adopt sourcing strategies, such as sourcing from an expensive production location/supplier or using expensive raw materials."
771,"Robust Simulation of Global Warming Policies Using the DICE Model","Hu, Zhaolin and Cao, Jing and Hong, L. Jeff","MANAGEMENT SCIENCE","58","12","2190-2206","2012","DEC","Environment;Global Warming;Programming;Semidefinite;Simulation;Applications","","Integrated assessment models that combine geophysics and economics features are often used to evaluate compare global warming,policies. Because there are typically profound uncertainties in these models, a simulation approach is often used. This approach requires the distribution of the uncertain parameters clearly specified. However, this is typically impossible because there is often a significant amount of ambiguity (e.g., estimation error) in specifying the distribution. In this paper, we adopt the widely used multivariate normal distribution to model the uncertain parameters. However, we assume that the mean vector and covariance matrix of the distribution are within some ambiguity sets. We then show how to find the worst-case performance of a given policy for all distributions constrained by the ambiguity sets. This worst-case performance provides a robust evaluation of the policy. We test our algorithm on a famous integrated model of climate change, known as the Dynamic Integrated Model of Climate and the Economy (DICE model). We find that the DICE model is sensitive to the means and covariance of the parameters. Furthermore, we find that, based on the DICE model, moderately tight environmental policies robustly outperform the no controls policy and the famous aggressive policies proposed by Stern and Gore."
772,"Reflected Knowledge and Trust in Global Collaboration","Mortensen, Mark and Neeley, Tsedal B.","MANAGEMENT SCIENCE","58","12","2207-2224","2012","DEC","Global Work;Organizational Studies;Behavior;Trust","","Scholars argue that direct knowledge about distant colleagues is crucial for fostering trust in global collaboration. However, their arguments focus mainly on how trust accrues from knowledge about distant collaborators' personal characteristics, relationships, and behavioral norms. We suggest that an equally important trust mechanism is reflected knowledge, knowledge that workers gain about the personal characteristics, relationships, and behavioral norms of their own site through the lens of their distant collaborators. Based on surveys gathered from 140 employees in a division of a global chemical company, we found that direct knowledge and reflected knowledge enhanced trust in distinct ways. Although both enhanced feelings of closeness with others, results indicate that direct knowledge increased focal actors' understanding of their distant colleagues, whereas reflected knowledge promoted feelings of being understood. We discuss implications of reflected knowledge to theories of trust and interpersonal dynamics in globally distributed collaboration."
773,"Managers and Students as Newsvendors","Bolton, Gary E. and Ockenfels, Axel and Thonemann, Ulrich W.","MANAGEMENT SCIENCE","58","12","2225-2233","2012","DEC","Newsvendor Game;Laboratory Experiment;Manager Behavior;Information Usage","","We compare how experienced procurement managers and students solve the newsvendor problem. We find that managers broadly exhibit the same kind of pull-to-center bias as students do. Also, managers use information and task training no better than students. The performance of managers is positively affected by the level of their education and their level in the organizational hierarchy. We discuss implications for theory and for how ordering might be improved in practice."
774,"On the Efficiency-Fairness Trade-off","Bertsimas, Dimitris and Farias, Vivek F. and Trichakis, Nikolaos","MANAGEMENT SCIENCE","58","12","2234-2250","2012","DEC","Programming;Nonlinear;Theory;Decision Analysis;Multiple Criteria;Games-Group Decisions;Bargaining;Fairness","","This paper deals with a basic issue: How does one approach the problem of designing the right objective for a given resource allocation problem? The notion of what is right can be fairly nebulous; we consider two issues that we see as key: efficiency and fairness. We approach the problem of designing objectives that account for the natural tension between efficiency and fairness in the context of a framework that captures a number of resource allocation problems of interest to managers. More precisely, we consider a rich family of objectives that have been well studied in the literature for their fairness properties. We deal with the problem of selecting the appropriate objective from this family. We characterize the trade-off achieved between efficiency and fairness as one selects different objectives and develop several concrete managerial prescriptions for the selection problem based on this trade-off. Finally, we demonstrate the value of our framework in a case study that considers air traffic management."
775,"The Impact of Royalty Contract Revision in a Multistage Strategic R&D Alliance","Xiao, Wenqiang and Xu, Yi","MANAGEMENT SCIENCE","58","12","2251-2271","2012","DEC","Research And Development;Royalty Contract;Renegotiation;Incentives;R&D Alliance","","This paper investigates the impact of royalty revision on incentives and profits in a two-stage (research and development (R&D) stage and marketing stage) alliance with a marketer and an innovator. The marketer offers royalty contracts to the innovator. We find that the potential for royalty revision leads to more severe distortions in the optimal initial royalty contracts offered by the marketer. We show that if the innovator plays a significant role in the marketing stage, the marketer should offer a low royalty rate initially and then revise the royalty rate up later. Otherwise, she should do the opposite. We identify two major effects of royalty revision. First, royalty revision provides the marketer with a flexibility to dynamically adjust royalty rates across the two stages of the alliance to better align the innovator's incentives. This incentive-realigning effect improves the marketer's profit. Second, royalty revision makes it harder for the marketer to obtain private information from the innovator, because the innovator worries that the marketer Will take advantage of the information to revise the initial contract to a more favorable one to herself later. This information-revealing effect hurts the marketer's profit. We characterize in what kind of alliances marketers would benefit the most from royalty revision so that managers should clearly establish the expectation for royalty revision, and in what kind of alliances markerters would not benefit from royalty revision so that managers should commit not to revise the initial royalty contract. With royalty contracts that are contingent on the R&D outcome of the R&D stage, we find that contingent contract structure could be either substitutable (by fully capturing the incentive re-aligning effect) or complementary (by weakening the information revealing effect) to royalty revision, depending on whether the innovator plays a significant role in the marketing stage. Managers may need to use a contingent contract (if possible) either to replace or with royalty revision accordingly to improve profits."
776,"Do Investment Banks' Relationships with Investors Impact Pricing? The Case of Convertible Bond Issues","Henderson, Brian J. and Tookes, Heather","MANAGEMENT SCIENCE","58","12","2272-2291","2012","DEC","Corporate Finance;Securities Issuance;Convertible Bonds;Underpricing","","This study examines the role of repeat interactions between placement agents (investment banks) and investors in the initial pricing of convertible bonds. Under the assumption that attracting repeat investors can reduce search frictions in primary issue markets, we test the hypothesis that banks' relationships with investors actually allow more favorable pricing for issuing firms (in contrast to the favoritism hypothesis, under which banks use underpricing to reward favored clients). In the empirical analysis we also allow for a potentially important alternative channel through which search frictions might impact initial pricing: expected after-market liquidity. Using a sample of 601 Rule 144A issues for the years 1997-2007, we document robust negative relationships between at-issue discounts and both types of frictions. Our findings suggest that search frictions play a meaningful role in initial convertible bond pricing and, specifically, that intermediaries can add substantial value through repeated interactions with investors."
777,"Pathwise Optimization for Optimal Stopping Problems","Desai, Vijay V. and Farias, Vivek F. and Moallemi, Ciamac C.","MANAGEMENT SCIENCE","58","12","2292-2308","2012","DEC","Dynamic Programming;Optimal Control;Optimal Stopping;American Options;Bermudian Options","","We introduce the pathwise optimization (PO) method, a new convex optimization procedure to produce upper and lower bounds on the optimal value (the price) of a high-dimensional optimal stopping problem. The PO method builds on a dual characterization of optimal stopping problems as optimization problems over the space of martingales, which we dub the martingale duality approach. We demonstrate via numerical experiments that the PO method produces upper bounds of a quality comparable with state-of-the-art approaches, but in a fraction of the time required for those approaches. As a by-product, it yields lower bounds (and suboptimal exercise policies) that are substantially superior to those produced by state-of-the-art methods. The PO method thus constitutes a practical and desirable approach to high-dimensional pricing problems. Furthermore, we develop an approximation theory relevant to martingale duality approaches in general and the PO method in particular. Our analysis provides a guarantee on the quality of upper bounds resulting from these approaches and identifies three key determinants of their performance: the quality of an input value function approximation, the square root of the effective time horizon of the problem, and a certain spectral measure of predictability of the underlying Markov chain. As a corollary to this analysis we develop approximation guarantees specific to the PO method. Finally, we view the PO method and several approximate dynamic programming methods for high-dimensional pricing problems through a common lens and in doing so show that the PO method dominates those alternatives."
778,"The Visible Hand? Demand Effects of Recommendation Networks in Electronic Markets","Oestreicher-Singer, Gal and Sundararajan, Arun","MANAGEMENT SCIENCE","58","11","1963-1981","2012","NOV","Social Network;Social Media;Peer Effects;Homophily;Slotting;Selection;Electronic Markets;Electronic Commerce;Product Networks","","Online commercial interactions have increased dramatically over the last decade, leading to the emergence of networks that link the electronic commerce landing pages of related products to one another. Our paper conjectures that the explicit visibility of such product networks can alter demand spillovers across their constituent items. We test this conjecture empirically using data about the copurchase networks and demand levels associated with more than 250,000 interconnected books offered on Amazon.com over the period of one year while controlling for alternative explanations of demand correlation using a variety of approaches. Our findings suggest that on average the explicit visibility of a copurchase relationship can lead to up to an average threefold amplification of the influence that complementary products have on each others' demand levels. We also find that newer and more popular products use the attention they garner from their network position more efficiently and that diversity in the sources of spillover further amplifies the demand effects of the recommendation network. Our paper presents new evidence quantifying the role of network position in electronic markets and highlights the power of basing (virtual) shelf position on consumer preferences that are explicitly revealed through shared purchasing patterns."
779,"Men Too Sometimes Shy Away from Competition: The Case of Team Competition","Dargnies, Marie-Pierre","MANAGEMENT SCIENCE","58","11","1982-2000","2012","NOV","Teams;Gender Gap;Tournament","","Recent results in experimental and personnel economics indicate that women do not like competitive environments as much as men. This paper presents an experimental design that gives participants the opportunity to enter a tournament as part of a team rather than alone. Although a large and significant gender gap in entry in the individual tournament is found, in line with the literature, no gender gap is found in entry in the team tournament. Women do not enter the tournament significantly more often when it is team based, but men enter significantly less when they are part of a team than when alone. The main reason for men's disaffection with team competition appears to be linked to the uncertainty of their teammate's performance in a team tournament. More precisely, high-performing men fear being the victims of the free-riding behavior of their teammate. Women, especially low-performing women, tend to enter the team tournament more often than the individual one when they know they will be matched to a teammate of the same level as their own."
780,"Empirical Investigation of Retail Expansion and Cannibalization in a Dynamic Environment","Pancras, Joseph and Sriram, S. and Kumar, V.","MANAGEMENT SCIENCE","58","11","2001-2018","2012","NOV","Marketing;Retailing And Wholesaling;Advertising And Media;Economics;Econometrics","","Managers of retail chains who seek to add new stores or close existing ones need to know the net impact of a store's opening/closure on the overall chain performance. This requires inferring the extent to which each store generates incremental sales as opposed to competing with other stores belonging to the chain for the same set of customers. However, when the chain is experiencing a growth or a decline in sales, not accounting for these dynamics in goodwill is likely to yield misleading estimates of incremental sales versus cannibalization. Moreover, firms might have been strategic in opening outlets in locations with favorable characteristics. We need to control for this location endogeneity while inferring the marginal effect of store opening/closure. In this paper, we develop a demand model that accounts for dynamics in goodwill, location endogeneity, and spatial competition between geographically proximate retail outlets. We calibrate the model parameters on both attitudinal and behavioral data for a fast food chain in a large U. S. city. The results imply that consumers perceive a travel cost of $0.60 per mile. As regards the composition of sales at individual stores, on average, 86.7% of sales constitute incremental purchases with the rest derived from cannibalized sales from nearby stores belonging to the chain. We also find significant decay in cannibalization with distance such that when the distance between stores increases by one mile, the sales lost due to cannibalization decreases by 28.1%; there is virtually no cannibalization at a distance of 10 miles. In terms of managerial applications, we discuss how managers can use the model presented in this paper to make two key decisions: (a) isolating locations that can be closed by identifying stores that yield the lowest marginal benefit to the chain and (b) dealing with franchisees' potential concerns about cannibalization."
781,"Product Market Efficiency: The Bright Side of Myopic, Uninformed, and Passive External Finance","Noe, Thomas H. and Rebello, Michael J. and Rietz, Thomas A.","MANAGEMENT SCIENCE","58","11","2019-2036","2012","NOV","Adverse Selection;Financing;Reputation","","We model the effect of external financing on a firm's ability to maintain a reputation for high-quality production. Producing high quality is first best. Defecting to low quality is tempting because it lowers current costs while revenue remains unchanged because consumers and outside investors cannot immediately observe the defection. However, defection to low quality impairs the firm's reputation, which lowers cash flows and inhibits production over the long term. Financing via short-term claims discourages defection to low quality because the gains from defection are mostly captured by outside investors through an increase in the value of their claims. Therefore, if the firm relies on short-term external financing, it is more likely to produce over the long run, produce high-quality goods, and enjoy high profitability. The aggregate results from a laboratory experiment generally accord with these predictions."
782,"Optimal Search for Product Information","Branco, Fernando and Sun, Monic and Villas-Boas, J. Miguel","MANAGEMENT SCIENCE","58","11","2037-2056","2012","NOV","Marketing;Pricing;Search Costs;Information;Learning","","Consumers often need to search for product information before making purchase decisions. We consider a tractable (continuous-time) model of gradual learning, in which consumers incur search costs to learn further product information, and update their expected utility of the product at each search occasion. We characterize the optimal stopping rules for either purchase, or no purchase, as a function of search costs and of the importance/informativeness of each attribute. This paper also characterizes how the likelihood of purchase changes with the ex ante expected utility, search costs, and the importance/informativeness of each attribute. We discuss optimal pricing, the impact of consumer search on profits and social welfare, and how the seller chooses its price to strategically affect the extent of the consumers' search behavior. We show that lower search costs can hurt the consumer because the seller may then choose to charge higher prices. Discounting creates asymmetry in the purchase and no-purchase search thresholds, and may lead to lower prices if search occurs in equilibrium, or higher prices if there is no search in equilibrium. This paper also considers searching for signals of the value of the product, heterogeneous importance of attributes, endogenous intensity of search, and social learning."
783,"When Does It Pay to Delay Supplier Qualification? Theory and Experiments","Wan, Zhixi and Beil, Damian R. and Katok, Elena","MANAGEMENT SCIENCE","58","11","2057-2075","2012","NOV","Procurement Auctions;Supplier Qualification;Experiments","","We study a procurement setting in which the buyer seeks a low price but will not allocate the contract to a supplier who has not passed qualification screening. Qualification screening is costly for the buyer, involving product tests, site visits, and interviews. In addition to a qualified incumbent supplier, the buyer has an entrant of unknown qualification. The buyer wishes to run a price-only, open-descending reverse auction between the incumbent and the entrant, and faces a strategic choice about whether to perform qualification screening on the entrant before or after the auction. We analytically study the buyer's optimal strategy, accounting for the fact that under postauction qualification, the incumbent knows he could lose the auction but still win the contract. In our analysis, we derive the incumbent's optimal bidding strategy under postauction qualification and find that he follows a threshold structure in which high-cost incumbents hold back on bidding-or even boycott the auction-to preserve their profit margin, and only lower-cost incumbents bid to win. These results are strikingly different from the usual open-descending auction analysis where all bidders are fully qualified and bidding to win is always a dominant strategy. We test our analytical results in the laboratory, with human subjects. We find that qualitatively our theoretical predictions hold up quite well, although incumbent suppliers bid somewhat more aggressively than the theory predicts, making buyers more inclined to use postauction qualification."
784,"Coordination of Price Promotions in Complementary Categories","Sinitsyn, Maxim","MANAGEMENT SCIENCE","58","11","2076-2094","2012","NOV","Price Promotions;Complementary Products;Heterogeneous Consumers","","In this paper, I investigate the outcome of a price competition between two firms, each producing two complementary products. Specifically, I study each firm's decision to coordinate price promotions of its products. Consumers are divided into loyals, who purchase both products from their preferred firm, and heterogeneous switchers, who choose between four possible bundles or buy a product in a single category. The switchers are willing to pay some price premium in order to purchase two complementary products that share the same brand name and are produced by the same firm, because they believe that these products are a better match than two complementary products with different brand names. I find that each firm predominantly promotes its complementary products together. This finding is correlationally supported by data in the shampoo and conditioner and in the cake mix and cake frosting categories."
785,"Aspirational Preferences and Their Representation by Risk Measures","Brown, David B. and De Giorgi, Enrico and Sim, Melvyn","MANAGEMENT SCIENCE","58","11","2095-2113","2012","NOV","Representation Of Choice;Risk Measures;Aspiration Levels;Decision Theory Paradoxes","","We consider choice over uncertain, monetary payoffs and study a general class of preferences. These preferences favor diversification, except perhaps on a subset of sufficiently disliked acts over which concentration is instead preferred. This structure encompasses a number of known models (e.g., expected utility and several variants under a concave utility function). We show that such preferences share a representation in terms of a family of measures of risk and targets. Specifically, the choice function is equivalent to selection of a maximum index level such that the risk of beating the target at that level is acceptable. This representation may help to uncover new models of choice. One that we explore in detail is the special case when the targets are bounded. This case corresponds to a type of satisficing and has descriptive relevance. Moreover, the model is amenable to large-scale optimization."
786,"Robust Storage Assignment in Unit-Load Warehouses","Ang, Marcus and Lim, Yun Fong and Sim, Melvyn","MANAGEMENT SCIENCE","58","11","2114-2130","2012","NOV","Inventory;Production;Uncertainty;Programming;Linear;Large Scale Systems;Transportation;Materials Handling","","Assigning products to and retrieving them from proper storage locations are crucial decisions in minimizing the operating cost of a unit-load warehouse. The problem becomes intractable when the warehouse faces variable supply and uncertain demand in a multiperiod setting. We assume a factor-based demand model in which demand for each product in each period is affinely dependent on some uncertain factors. The distributions of these factors are only partially characterized. We introduce a robust optimization model that minimizes the worst-case expected total travel in the warehouse with distributional ambiguity of demand. Under a linear decision rule, we obtain a storage and retrieval policy by solving a moderate-size linear optimization problem. Surprisingly, despite imprecise specification of demand distributions, our computational studies suggest that the linear policy achieves close to the expected value given perfect information and significantly outperforms existing heuristics in the literature."
787,"Execution Risk in High-Frequency Arbitrage","Kozhan, Roman and Tham, Wing Wah","MANAGEMENT SCIENCE","58","11","2131-2149","2012","NOV","Execution Risk;Limit To Arbitrage;Liquidity;High-Frequency Trading Strategies","","In this paper, we investigate the role of execution risk in high-frequency trading through arbitrage strategies. We show that if rational agents face uncertainty about completing their arbitrage portfolios, then arbitrage is limited even in markets with perfect substitutes and convertibility. Using a simple model, we demonstrate that this risk arises from the crowding effect of competing arbitrageurs entering the same trade and inflicting negative externalities on each other. Our empirical results provide evidence that support the relevance of execution risk in high-frequency arbitrage."
788,"Local Religious Beliefs and Mutual Fund Risk-Taking Behaviors","Shu, Tao and Sulaeman, Johan and Yeung, P. Eric","MANAGEMENT SCIENCE","58","10","1779-1796","2012","OCT","Risk-Taking;Mutual Funds;Geographic Location;Religion","","We study the effects of local religious beliefs on mutual fund risk-taking behaviors. Funds located in low-Protestant or high-Catholic areas exhibit significantly higher fund return volatilities. Similar differences persist when we use the religiosity ratios at fund managers' college locations. Risk-taking associated with local religious beliefs manifests in higher portfolio concentrations, higher,portfolio turnover, more aggressive interim trading, and more tournament risk-shifting behaviors, but not over-weighting risky individual stocks. Overall, our results suggest that local religious beliefs have significant influences on mutual fund behaviors."
789,"Corporate Strategy, Analyst Coverage, and the Uniqueness Paradox","Litov, Lubomir P. and Moreton, Patrick and Zenger, Todd R.","MANAGEMENT SCIENCE","58","10","1797-1815","2012","OCT","Corporate Strategy;Analyst Coverage;Strategic Uniqueness;Diversification","","In this paper, we argue that managers confront a paradox in selecting strategy. On one hand, capital markets systematically discount uniqueness in the strategy choices of firms. Uniqueness in strategy heightens the cost of collecting and analyzing information to evaluate a firm's future value. These greater costs in strategy evaluation discourage the collection and analysis of information regarding the firm, and result in a valuation discount. On the other hand, uniqueness in strategy is a necessary condition for creating economic ::ents and should, except for this information cost, be positively associated with firm value. We find empirical support for both propositions using a novel measure of strategy uniqueness in a firm panel data set between 1985 and 2007."
790,"Contingent Capital with a Capital-Ratio Trigger","Glasserman, Paul and Nouri, Behzad","MANAGEMENT SCIENCE","58","10","1816-1833","2012","OCT","Probability;Diffusion;Stochastic Model Applications;Finance;Asset Pricing","","Contingent capital in the form of debt that converts to equity when a bank faces financial distress has been proposed as a mechanism to enhance financial stability and avoid costly government rescues. Specific proposals vary in their choice of conversion trigger and conversion mechanism. We analyze the case of contingent capital with a capital-ratio trigger and partial and ongoing conversion. The capital ratio we use is based on accounting or book values to approximate the regulatory ratios that determine capital requirements for banks. The conversion process is partial and ongoing in the sense that each time a bank's capital ratio reaches the minimum threshold, just enough debt is converted to equity to meet the capital requirement, so long as the contingent capital has not been depleted. We derive closed-form expressions for the market value of such securities when the firm's asset value is modeled as geometric Brownian motion, and from these we get formulas for the fair yield spread on the convertible debt. A key step in the analysis is an explicit expression for the fraction of equity held by the original shareholders and the fraction held by converted investors in the contingent capital."
791,"Dividend Smoothing and Predictability","Chen, Long and Da, Zhi and Priestley, Richard","MANAGEMENT SCIENCE","58","10","1834-1853","2012","OCT","Dividend-Price Ratio;Earning-Price Ratio;Dividend Growth;Earnings Growth;Return;Predictability;Dividend Smoothing","","The relative predictability of returns and dividends is a central issue because it forms the paradigm to interpret asset price variation. A little studied question is how dividend smoothing, as a choice of corporate policy, affects predictability. We show that even if dividends are supposed to be predictable without smoothing, dividend smoothing can bury this predictability. Because aggregate dividends are dramatically more smoothed in the postwar period than before, the lack of dividend growth predictability in the postwar period does not necessarily mean that there is no cash flow news in stock price variations; rather, a more plausible interpretation is that dividends are smoothed. Using two alternative measures that are less subject to dividend smoothing-net payout and earnings-we reach the consistent conclusion that cash flow news plays a more important role than discount rate news in price variations in the postwar period."
792,"Large-Scale Service Marketplaces: The Role of the Moderating Firm","Allon, Gad and Bassamboo, Achal and Cil, Eren B.","MANAGEMENT SCIENCE","58","10","1854-1872","2012","OCT","Service Operations;Fluid Models;Asymptotic Analysis;Large Games;Noncooperative Game Theory","","Recently, large-scale, Web-based service marketplaces, where many small service providers compete among themselves in catering to customers with diverse needs, have emerged. Customers who frequent these marketplaces seek quick resolutions and thus are usually willing to trade prices with waiting times. The main goal of this paper is to discuss the role of the moderating firm in facilitating information gathering, operational efficiency, and communication among agents in service marketplaces. Surprisingly, we show that operational efficiency may be detrimental to the overall efficiency of the marketplace. Furthermore, we establish that to reap the expected gains of operational efficiency, the moderating firm may need to complement the operational efficiency by enabling communication among its agents. The study emphasizes the scale of such marketplaces and the impact it has on the outcomes."
793,"Hierarchies and the Survival of Prisoners of War During World War II","Holderness, Clifford G. and Pontiff, Jeffrey","MANAGEMENT SCIENCE","58","10","1873-1886","2012","OCT","Hierarchy;Markets;Centralization;Decentralization;Organizational Structure","","Using a comprehensive database of American prisoners of war during World War IT, we find that survival from captivity generally declines as the hierarchy of a prisoner's group becomes steeper or more closely matches the military's established hierarchy. There is no evidence that survival is enhanced by being held in more hierarchical groups. One interpretation of these findings that is consistent with survivors' accounts is that the military's hierarchy was too inflexible to adapt from the battlefield to captivity and this inflexibility impeded trading among the prisoners."
794,"A Generalized Norton-Bass Model for Multigeneration Diffusion.","Jiang, Zhengrui and Jain, Dipak C.","MANAGEMENT SCIENCE","58","10","1887-1897","2012","OCT","Norton-Bass Model;Multigeneration Diffusion;Leapfrogging;Switching","","The Norton-Bass (NB) model is often credited as the pioneering multigeneration diffusion model in marketing. However, as acknowledged by the authors, when counting the number of adopters who substitute an old product generation with a new generation, the NB model does not differentiate those who have already adopted the old generation from those who have not. In this study, we develop a generalized Norton-Bass (GNB) model that separates the two different types of substitutions. The GNB model provides closed-form expressions for both the number of units in use and the adoption rate, and offers greater flexibility in parameter estimation, forecasting, and revenue projection. An appealing aspect of the GNB model is that it us,uses exactly the same set of parameters as the NB model and is mathematically consistent with the later. Empirical results show that the GNB model delivers better overall performance than previous models both in terms of model fit and forecasting performance. The analyses also show that differentiating leapfrogging and switching adoptions based on the GNB model can help gain additional insights into the process of multigeneration diffusion. Furthermore, we demonstrate that the GNB model can incorporate the effect of marketing mix variables on the speed of diffusion for all product generations."
795,"Managing Disruption Risk: The Interplay Between Operations and Insurance","Dong, Lingxiu and Tomlin, Brian","MANAGEMENT SCIENCE","58","10","1898-1915","2012","OCT","Disruptions;Inventory;Insurance","","s Disruptive events that halt production can have severe business consequences if not appropriately managed. Business interruption (BI) insurance offers firms a financial mechanism for managing their exposure to disruption risk. Firms can also avail of operational measures to manage the risk. In this paper, we explore the relationship between BI insurance and operational measures. We model a manufacturing firm that can purchase BI insurance, invest in inventory, and avail of emergency sourcing. Allowing the insurance premium to depend on the firm's insurance and operational decisions, we characterize the optimal insurance deductible and coverage limit as well as the optimal inventory level. We prove that insurance and operational measures Are not always substitutes, and we establish conditions under which they can be complements; that is, insurance can increase the marginal value of inventory and can increase the overall value of emergency sourcing. We also find that the value of insurance is higher for those firms less able to absorb financially significant disruptions. As disruptions become longer but rarer, the value of emergency sourcing increases, and the value of inventory and the value of insurance increase before eventually decreasing."
796,"Asset Pricing Restrictions on Predictability: Frictions Matter","de Roon, Frans and Szymanowska, Marta","MANAGEMENT SCIENCE","58","10","1916-1932","2012","OCT","Time-Series Predictability;Cross-Sectional Predictability;Asset Pricing Tests;Market Frictions","","U.S. stock portfolios sorted on size; momentum; transaction costs; market-to-book, investment-to-assets, and return-on-assets (ROA) ratios; and industry classification show considerable levels and variation of return predictability, inconsistent with asset pricing models. This means that a predictable risk premium is not equal to compensation for systematic risk as implied by asset pricing theory. We show that introducing market frictions relaxes these asset pricing moments from a strict equality to a range. Empirically, it is not short sales constraints but transaction costs (below 35 basis points) that help to reconcile the observed predictability with linear portfolio return-based factor models, and partly with the durable consumption model. Across the sorts, predictability in industry returns can be reconciled with all models considered with only a 25 basis point transaction cost, whereas for momentum and ROA portfolios, up to 115 basis points are needed."
797,"Supply Chain Performance Under Market Valuation: An Operational Approach to Restore Efficiency","Lai, Guoming and Xiao, Wenqiang and Yang, Jun","MANAGEMENT SCIENCE","58","10","1933-1951","2012","OCT","Supply Chain;Newsvendor;Capital Market Valuation","","Based on a supply chain framework, we study the stocking decision of a downstream buyer who receives private demand information and has the incentive to influence her capital market valuation. We first characterize a market equilibrium under a general, single buyback contract. We show that the buyer's stocking decision can be distorted in equilibrium. Such a downstream stocking distortion hurts the buyer firm's own performance, and it also influences the performances of the supplier and the supply chain. We further reveal scenarios where full supply chain efficiency cannot be reached under any single buyback contract. Then, focusing on contract design, we characterize conditions under which a menu of buyback contracts can prevent downstream stocking distortion and restore full efficiency in the supply chain. Our study demonstrates that in a supply chain context, a firm's incentive to undertake real economic activities to influence capital market valuation can potentially be resolved through operational means."
798,"Modeling Bounded Rationality in Capacity Allocation Games with the Quantal Response Equilibrium","Chen, Yefen and Su, Xuanming and Zhao, Xiaobo","MANAGEMENT SCIENCE","58","10","1952-1962","2012","OCT","Bounded Rationality;Capacity Allocation;Supply Chain;Quantal Response Equilibrium;Nash Equilibrium","","We consider a supply chain with a single supplier and two retailers. The retailers choose their orders strategically, and if their orders exceed the supplier's capacity, quantities are allocated proportionally to the orders. We experimentally study the capacity allocation game using subjects motivated by financial incentives. We find that the Nash equilibrium, which assumes that players are perfectly rational, substantially exaggerates retailers' tendency to strategically order more than they need. We propose a model of bounded rationality based on the quantal response equilibrium, in which players are not perfect optimizers and they face uncertainty in their opponents' actions. We structurally estimate model parameters using the maximum-likelihood method. Our results confirm that retailers exhibit bounded rationality, become more rational through repeated game play, but may not converge to perfect rationality as assumed by the Nash equilibrium. Finally, we consider several alternative behavioral theories and show that they do not explain our experimental data as well as our bounded rationality model."
799,"How Near-Miss Events Amplify or Attenuate Risky Decision Making","Tinsley, Catherine H. and Dillon, Robin L. and Cronin, Matthew A.","MANAGEMENT SCIENCE","58","9","1596-1613","2012","SEP","Near Miss;Risk;Decision Making;Natural Disasters;Organizational Hazards;Hurricanes;Oil Spills","","In the aftermath of many natural and man-made disasters, people often wonder why those affected were underprepared, especially when the disaster was the result of known or regularly occurring hazards (e.g., hurricanes). We study one contributing factor: prior near-miss experiences. Near misses are events that have some nontrivial expectation of ending in disaster but, by chance, do not. We demonstrate that when near misses are interpreted as disasters that did not occur, people illegitimately underestimate the danger of subsequent hazardous situations and make riskier decisions (e.g., choosing not to engage in mitigation activities for the potential hazard). On the other hand, if near misses can be recognized and interpreted as disasters that almost happened, this will counter the basic near-miss effect and encourage more mitigation. We illustrate the robustness of this pattern across populations with varying levels of real expertise with hazards and different hazard contexts (household evacuation for a hurricane, Caribbean cruises during hurricane season, and deep-water oil drilling). We conclude with ideas to help people manage and communicate about risk."
800,"The Relational Advantages of Intermediation","Belavina, Elena and Girotra, Karan","MANAGEMENT SCIENCE","58","9","1614-1631","2012","SEP","Global Sourcing;Intermediaries;Supply Chain Relationships;Relational Contracts;Flexibility;Li & Fung;Repeated Games","","This paper provides a novel explanation for the use of supply chain intermediaries. We find that even in the absence of the well-known transactional and informational advantages of mediation, intermediaries improve supply chain performance. In particular, intermediaries facilitate responsive adaptation of the buyers' supplier base to their changing needs while simultaneously ensuring that suppliers behave as if they had long-term sourcing commitments from buying firms. In the face of changing buyer needs, an intermediary that sources on behalf of multiple buyers can responsively change the composition of future business committed to a supplier such that a sufficient level of business comes from the buyer(s) that most prefer this supplier. On the other hand, direct buyers that source only for themselves must provide all their committed business to a supplier from their own sourcing needs, even if they no longer prefer this supplier. Unlike existing theories of intermediation, our theory better explains the observed phenomenon that although transactional barriers and information asymmetries have steadily decreased, the use of intermediaries has soared, even among large companies such as Walmart."
801,"Firm Survival and Industry Evolution in Vertically Related Populations","de Figueiredo, John M. and Silverman, Brian S.","MANAGEMENT SCIENCE","58","9","1632-1650","2012","SEP","Organizational Ecology;Strategy;Vertical Integration;Computer-Electronic Industries","","This paper examines how the density and governance of vertically related populations affect the life chances of organizations. We integrate the literatures on organizational ecology and vertical integration to develop a theory of how (1) specialized upstream industries affect downstream survival rates, (2) the prevalence of different governance forms among upstream and downstream organizations moderates this relationship, and (3) different forms of governance exert differential competitive pressures on focal organizations. We find evidence supporting our hypotheses in an empirical examination of the downstream laser printer industry and upstream laser engine industry."
802,"Link to Success: How Blogs Build an Audience by Promoting Rivals","Mayzlin, Dina and Yoganarasimhan, Hema","MANAGEMENT SCIENCE","58","9","1651-1668","2012","SEP","Game Theory;Social Media;Linking;Signaling;Blogs","","Empirically, we find that Web logs (or blogs) often link to other blogs in the same category. We present an analytical model that explains why a rational blogger may choose to link to another blog. We allow bloggers to differ along two dimensions: (1) the ability to post news-breaking content, and (2) the ability to find news in other blogs. By linking, a blog signals to the reader that it will be able to direct her to news in other blogs in the future. The downside of a link is that it is a positive signal on the rival's news-breaking ability. We show that linking will be in equilibrium when the heterogeneity on the ability to break news is low relative to the heterogeneity on the ability to find news in other blogs. One implication of the linking mechanism is that blogs that are high on the news-breaking ability are more likely to gain readers. Hence, despite the fact that bloggers link for purely selfish reasons, the macro effects of this activity is that readers' learning is enhanced."
803,"Comparing Business and Household Sector Innovation in Consumer Products: Findings from a Representative Study in the United Kingdom","von Hippel, Eric and de Jong, Jeroen P. J. and Flowers, Stephen","MANAGEMENT SCIENCE","58","9","1669-1681","2012","SEP","User Innovation;Consumer Innovation;Measurement;Research And Development","","In a first survey of its type, we measure development and modification of consumer products by product users in a representative sample of 1,173 UK consumers age 18 and older. We estimate this previously unmeasured type of household sector innovation to be quite large: 6.1% of UK consumers-nearly 2.9 million individuals-have engaged in consumer product innovation during the prior three years. In aggregate, consumers' annual product development expenditures are more than 1.4 times larger than the annual consumer product R&D expenditures of all firms in the United Kingdom combined. Consumers engage in many small projects that seem complementary to the innovation efforts of incumbent producers. Consumer innovators very seldom protect their innovations via intellectual property, and 17% diffuse to others. These results imply that, at the country level, productivity studies yield inflated effect sizes for producer innovation in consumer goods. They also imply that existing companies should reconfigure their product development systems to find and build on prototypes developed by consumers."
804,"Combining Equity and Utilitarianism in a Mathematical Programming Model","Hooker, J. N. and Williams, H. P.","MANAGEMENT SCIENCE","58","9","1682-1693","2012","SEP","Healthcare;Integer Programming;Applications;Mixed-Integer Modeling","","We discuss the problem of combining the conflicting objectives of equity and utilitarianism, for social policy making, in a single mathematical programming model. The definition of equity we use is the Rawlsian one of maximizing the minimum utility over individuals or classes of individuals. However, when the disparity of utility becomes too great, the objective becomes progressively utilitarian. Such a model is particularly applicable not only to health provision but to other areas as well. Building a mixed-integer/linear programming (MILP) formulation of the problem raises technical issues, because the objective function is nonconvex and the hypograph is not MILP representable in its initial form. We present a succinct formulation and show that it is sharp in the sense that its linear programming relaxation describes the convex hull of the feasible set (before extra resource allocation or policy constraints are added). We apply the formulation to a healthcare planning problem and show that instances of realistic size are easily solved by standard MILP software."
805,"Supply-Side Story: Risks, Guarantees, Competition, and Information Asymmetry","Gumus, Mehmet and Ray, Saibal and Gurnani, Haresh","MANAGEMENT SCIENCE","58","9","1694-1714","2012","SEP","Supply-Risk Management;Asymmetric Information;Signaling;Guarantees;Stochastic Spot Market","","The risk of supply disruption increases as firms seek to procure from cheaper, but unproven, suppliers. We model a supply chain consisting of a single buyer and two suppliers, both of which compete for the buyer's order and face risk of supply disruption. One supplier is comparatively more reliable but also more expensive, whereas the other one is less reliable but cheaper and faces higher risk of disruption. Moreover, the risk level of the unreliable supplier may be private information, and this lack of visibility increases the buyer's purchasing risk. In such settings, the unreliable supplier often provides a price and quantity (P&Q) guarantee to the buyer. Our objective is to study the underlying motivation for the guarantee offer and its effects on the competitive intensity and the performance of the chain partners. Our model also includes a spot market that can be utilized by any party to buy or to sell. The spot market price is random, partially depends on the available capacity of the two suppliers, and has a positive spread between buying and selling prices. We analytically characterize the equilibrium contracts for the two suppliers and the buyer's optimal procurement strategy. First, our analysis shows that P&Q guarantee allows the unreliable supplier to better compete against the more reliable one by providing supply assurance to the buyer. More importantly, when information asymmetry risk is high, use of a guarantee may enable the unreliable supplier to credibly signal her true risk, thereby improving visibility into the chain. This signal can also be used by the buyer to infer the expected spot market price. In spite of these benefits, a guarantee offer in an asymmetric setting may not always be desirable for the buyer. Rather, it can reduce competition between the suppliers, resulting in higher costs for the buyer."
806,"Dynamic Pricing with Financial Milestones: Feedback-Form Policies","Besbes, Omar and Maglaras, Costis","MANAGEMENT SCIENCE","58","9","1715-1731","2012","SEP","Revenue Management;Dynamic Pricing;Market Uncertainty;Estimation;Feedback;Real Estate;Asymptotic Analysis","","We study a seller that starts with an initial inventory of goods, has a target horizon over which to sell the goods, and is subject to a set of financial milestone constraints on the revenues and sales that need to be achieved at different time points along the sales horizon. We characterize the revenue maximizing dynamic pricing policy for the seller and highlight the effect of revenue and sales milestones on its structure. The optimal policy can be written in feedback form, where the price at each point in time is selected so as to track the most stringent among all future milestones. Building on that observation, we propose a discrete-review policy that aims to dynamically track the appropriate milestone constraint and show that this simple and practical policy is near optimal in settings with large initial capacity and long sales horizons even in settings with no advance demand model information. One motivating application comes from the sales of new multiunit, residential real estate developments, where intermediate milestone constraints play an important role in their financing and construction."
807,"Robust Portfolio Choice with Learning in the Framework of Regret: Single-Period Case","Lim, Andrew E. B. and Shanthikumar, J. George and Vahn, Gah-Yi","MANAGEMENT SCIENCE","58","9","1732-1746","2012","SEP","Parameter Uncertainty;Ambiguity;Model Uncertainty;Learning;Regret;Relative Regret;Competitive Analysis;Portfolio Selection;Bayesian Methods;Objective-Based Loss Functions;Convex Duality","","In this paper, we formulate a single-period portfolio choice problem with parameter uncertainty in the framework of relative regret. Relative regret evaluates a portfolio by comparing its return to a family of benchmarks, where the benchmarks are the wealths of fictitious investors who invest optimally given knowledge of the model parameters, and is a natural objective when there is concern about parameter uncertainty or model ambiguity. The optimal relative regret portfolio is the one that performs well in relation to all the benchmarks over the family of possible parameter values. We analyze this problem using convex duality and show that it is equivalent to a Bayesian problem, where the Lagrange multipliers play the role of the prior distribution, and the learning model involves Bayesian updating of these Lagrange multipliers/prior. This Bayesian problem is unusual in that the prior distribution is endogenously chosen by solving the dual optimization problem for the Lagrange multipliers, and the objective function involves the family of benchmarks from the relative regret problem. These results show that regret is a natural means by which robust decision making and learning can be combined."
808,"Intermediated Blind Portfolio Auctions","Padilla, Michael and Van Roy, Benjamin","MANAGEMENT SCIENCE","58","9","1747-1760","2012","SEP","Finance;Games-Group Decisions;Bidding-Auctions;Information Systems;It Policy And Management;Electronic Commerce","","As much as 12% of the daily volume on the New York Stock Exchange, and similar volumes on other major world exchanges, involves sales by institutional investors to brokers through blind portfolio auctions. Such transactions typically take the form of a first-price sealed-bid auction in which the seller engages a few potential brokers and provides limited information about the portfolio being sold. Uncertainty about the portfolio contents reduces bids, effectively increasing the transaction cost paid by the seller. We consider the use of a trusted intermediary or equivalent cryptographic protocol to reduce transaction costs. In particular, we propose a mechanism through which each party provides relevant private information to an intermediary who ultimately reveals only the portfolio contents and price paid, and only to the seller and winning broker. Through analysis of a game-theoretic model, we demonstrate substantial potential benefits to sellers."
809,"Consumer Valuation of Modularly Upgradeable Products","Uelkue, Sezer and Dimofte, Claudiu V. and Schmidt, Glen M.","MANAGEMENT SCIENCE","58","9","1761-1776","2012","SEP","Product Architecture;Modularity;Product Upgrades;Product Replacement;Pricing;Temporal Construal;Hyperbolic Discounting;Resource Slack","","Although product modularity is often advocated as a design strategy in the operations management literature, little is known about how consumers respond to modular products. In this research we undertake several experiments to explore consumer response to modularly upgradeable products in settings featuring technological change. We consider both the initial product choice (between a modularly upgradeable product and an integral one) and the subsequent upgrade decision (replacement of a module versus full product replacement). First, we show that consumers tend to discount the cost savings associated with modular upgrades excessively (insufficiently) when the time between the initial purchase and the upgrade is short (long). This suggests that modular upgradability as a product feature has higher profit potential for slowly rather than rapidly improving products. Second, we observe a preference reversal between the initial purchase and the point of upgrade: At the point of initial purchase, people foresee making a full product replacement in the future, yet, when faced with the actual upgrade decision, they are more likely to revert to modular upgrades. Finally, we discuss and test several pricing and product design strategies that the firm can use to respond to these cognitive biases."
810,"A Market-Based Measure of Credit Portfolio Quality and Banks' Performance During the Subprime Crisis","Knaup, Martin and Wagner, Wolf","MANAGEMENT SCIENCE","58","8","1423-1437","2012","AUG","Credit Portfolio Risk;Asset Quality;Banks;Subprime Crisis","","We propose a new method for measuring the quality of banks' credit portfolios. This method makes use of information embedded in bank share prices by exploiting differences in their sensitivity to credit default swap spreads of borrowers of varying quality. The method allows us to derive a credit risk indicator (CRI). This indicator represents the perceived share of high-risk exposures in a bank's portfolio and can be used as a risk weight for computing regulatory capital requirements. We estimate CRIs for the 150 largest U.S. bank holding companies. We find that their CRIs are able to forecast bank failures and share price performances during the crisis of 2007-2009, even after controlling for a variety of traditional asset quality and general risk proxies."
811,"Working When No One Is Watching: Motivation, Test Scores, and Economic Success","Segal, Carmit","MANAGEMENT SCIENCE","58","8","1438-1457","2012","AUG","Organizational Studies;Motivation-Incentives;Behavior;Labor;Economics;Utility Preference;Applications","","This paper provides evidence that scores on simple, low-stakes tests are associated with future economic 1 success because the scores also reflect test takers' personality traits associated with their level of intrinsic motivation. To establish this, I use the coding speed test that was administered without incentives to participants in the National Longitudinal Survey of Youth (NLSY). I show that, controlling for cognitive ability, the coding speed scores are correlated with future earnings of male NLSY participants. I provide evidence that the coding speed scores relate to intrinsic motivation. I show that the scores of the highly motivated, though less educated, group (potential recruits to the U.S. military), are higher than the NLSY participants' scores. I use controlled experiments to show directly that intrinsic motivation is an important component of the unincentivized coding speed scores and that it relates to test takers' personality traits."
812,"Combinatorial Auctions for Procurement: An Empirical Study of the Chilean School Meals Auction","Olivares, Marcelo and Weintraub, Gabriel Y. and Epstein, Rafael and Yung, Daniel","MANAGEMENT SCIENCE","58","8","1458-1481","2012","AUG","Combinatorial Auctions;Procurement;Auction Design;Empirical;Public Sector Applications","","In this paper we conduct an empirical investigation of a large-scale combinatorial auction (CA)-the Chilean auction for school meals in which the government procures half a billion dollars worth of meal services every year. Our empirical study is motivated by two fundamental aspects in the design of CAs: (1) which packages should bidders be allowed to bid on and (2) diversifying the supplier base to promote competition. We use bidding data to uncover important aspects of the firms' cost structure and their strategic behavior, both of which are not directly observed by the auctioneer; these estimates inform the auction design. Our results indicate that package bidding that allows firms to express their cost synergies due to economies of scale and density seems appropriate. However, we also found evidence that firms can take advantage of this flexibility by discounting package bids for strategic reasons and not driven by cost synergies. Because this behavior can lead to inefficiencies, it may be worth evaluating whether to prohibit certain specific combinations in the bidding process. Our results also suggest that market share restrictions and running sequential auctions seem to promote competition in the long run, without significantly increasing the short-run cost for the government due to unrealized cost synergies. Our results highlight that the simultaneous consideration of the firms' operational cost structure and their strategic behavior is key to the successful design of a CA. More broadly, our paper is the first to provide an econometric study of a large-scale CA, providing novel and substantive insights regarding bidding behavior in this type of auction."
813,"An Examination of the Efficiency, Foreclosure, and Collusion Rationales for Vertical Takeovers","Shenoy, Jaideep","MANAGEMENT SCIENCE","58","8","1482-1501","2012","AUG","Finance;Corporate Finance;Vertical Integration;Antitrust;Efficiency;Market Power;Mergers;Acquisitions;Product Markets;Firm Boundaries;Corporate Restructuring;Foreclosure;Collusion","","We investigate the efficiency, foreclosure, and collusion rationales for vertical integration in a large sample of vertically related takeovers. The efficiency rationale, as discussed under the transaction cost economics and property rights theories, posits that vertical integration mitigates contractual inefficiencies between suppliers and customers (termed as holdup) and provides incentives to undertake relationship-specific investments. In contrast, the foreclosure and collusion rationales suggest that vertical integration is anticompetitive in nature. Specifically, the foreclosure argument suggests that vertical integration is used to raise costs of rival firms, and the collusion argument suggests that vertical integration facilitates coordination between the integrated firm and its rivals. To distinguish between the three hypotheses, we examine (1) the announcement period wealth effects to the merging firms, rival firms, and customer firms; and (2) the operating performance changes to the merging firms in vertical takeovers. We find that firms expand their vertical boundaries consistent with an efficiency enhancing rationale."
814,"On the Conditional Risk and Performance of Financially Distressed Stocks","O'Doherty, Michael S.","MANAGEMENT SCIENCE","58","8","1502-1520","2012","AUG","Conditional Capm;Asset-Pricing Anomalies;Distress Risk;Default Risk;Information Risk","","Several recent articles find that stocks with high probabilities of bankruptcy or default earn anomalously low returns and negative unconditional capital asset pricing model (CAPM) alphas in the post-1980 period. I show that the conditional CAPM resolves the performance difference between high- and low-distress stocks. In particular, financially distressed stocks have relatively low exposure to market risk during bad economic times. I help to explain these findings through a theoretical model in which a levered firm's equity beta is negatively related to uncertainty about the unobserved value of its underlying assets."
815,"Money-Back Guarantees: Helping the Low-Quality Retailer","McWilliams, Bruce","MANAGEMENT SCIENCE","58","8","1521-1524","2012","AUG","Marketing;Retailing And Wholesaling;Competitive Strategy;Product Policy","","Existing literature, based on signaling theory, suggests that money-back guarantees (MBGs) will be utilized by high-quality firms, where high quality is defined as a low likelihood of product return. However, in today's world, MBGs are ubiquitous among major retailers, even when the likelihood of product return varies greatly between them. To understand this phenomenon, we explore a competitive environment between high- and low-quality retailers where consumers are fully informed and risk neutral, and retailers realize a salvage value for returned products. When MBGs are profitable, under continuous demand it is Nash equilibrium for both retailers to offer MBGs, and the low-quality retailer gains while the high-quality retailer loses relative to when MBGs are not offered. In contrast, if demand is lumpy, retailers can act monopolistically over their respective market segments, allowing both retailers to gain from MBGs, although the low-quality retailer still gains more."
816,"Social Learning Through Endogenous Information Acquisition: An Experiment","Celen, Bogachan and Hyndman, Kyle","MANAGEMENT SCIENCE","58","8","1525-1548","2012","AUG","Social Learning;Information Acquisition;Link Formation;Herd Behavior","","This paper provides a test of a theory of social learning through endogenous information acquisition. A group of subjects face a decision problem under uncertainty. Subjects are endowed with private information about the fundamentals of the problem and make decisions sequentially. The key feature of the experiment is that subjects can observe the decisions of predecessors by forming links at a cost. The model predicts that the average welfare is enhanced in the presence of a small cost. Our experimental results support this prediction. When the informativeness of signals changes across treatments, behavior changes in accordance with the theory. However, within treatments, there are important deviations from rationality such as a tendency to conform and excessive link formation. Given these biases, our results indicate that subjects would, except when faced with a small cost, have been better off not forming any links."
817,"From Wires to Partners: How the Internet Has Fostered R&D Collaborations Within Firms","Forman, Chris and van Zeebroeck, Nicolas","MANAGEMENT SCIENCE","58","8","1549-1568","2012","AUG","R&D Organization;Geography Of Innovation;Internet Adoption;It Investments;Collaborative Work","","How did the diffusion of the Internet influence research collaborations within firms? We examine the relationship between business use of basic Internet technology and the size and geographic composition of industrial research teams between 1992 and 1998. We find robust empirical evidence that basic Internet adoption is associated with an increased likelihood of collaborative patents from geographically dispersed teams. On the contrary, we find no evidence of such a link between Internet adoption and within-location collaborative patents, nor do we find any evidence of a relationship between basic Internet and single-inventor patents. We interpret these results as evidence that adoption of basic Internet significantly reduced the coordination costs of research teams, but find little evidence that a drop in the costs of shared resource access significantly improved research productivity."
818,"Outsourcing a Two-Level Service Process","Lee, Hsiao-Hui and Pinker, Edieal J. and Shumsky, Robert A.","MANAGEMENT SCIENCE","58","8","1569-1584","2012","AUG","Queues;Applications;Industries;Business Services;Information Systems;It Policy And Management;Outsourcing","","This paper studies outsourcing decisions for a two-level service process in which the first level serves as a 1 gatekeeper for a second level of experts. The objective of the system operator (the client) is to minimize the sum of staffing costs, customer waiting costs, and mistreatment costs due to unsuccessful attempts by a gatekeeper to solve the customer's problem. The client may outsource all or part of the process to a vendor, and first-best contracts exist when the client outsources only gatekeepers or experts. When the client outsources the entire system as a two-level process, a client-optimal contract may not exist unless the exogenous system parameters satisfy a particular (and unlikely) coordination condition. In addition, optimal incentive-compatible contracts exist when the vendor's structure choice (one level or two levels) can deviate from the client's preference. Finally, we numerically examine how vendor structure choice and labor cost advantages influence the client's optimal outsourcing option."
819,"Psychological Pressure in Competitive Environments: New Evidence from Randomized Natural Experiments","Kocher, Martin G. and Lenz, Marc V. and Sutter, Matthias","MANAGEMENT SCIENCE","58","8","1585-1591","2012","AUG","Tournament;First-Mover Advantage;Psychological Pressure;Field Experiment;Soccer;Penalty Shootouts","","Dynamic competitive settings may create psychological pressure when feedback about the performance of competitors is provided before the end of the competition. Such psychological pressure could produce a first-mover advantage, despite a priori equal winning probabilities. Using data from a randomized natural experiment-penalty shootouts in soccer-we reexamine evidence by Apesteguia and Palacios-Huerta [Apesteguia J, Palacios-Huerta 1 (2010) Psychological pressure in competitive environments: Evidence from a randomized natural experiment. Amer. Econom. Rev. 100(5):2548-2564]. They report a 21-percentage-point advantage for first movers over second movers in terms of winning probabilities. Extending their sample of 129 shootouts to 540, we fail to detect any significant first-mover advantage. Our results are fully consistent with recent evidence from other sports contests."
820,"Quantifying Managerial Ability: A New Measure and Validity Tests","Demerjian, Peter and Lev, Baruch and McVay, Sarah","MANAGEMENT SCIENCE","58","7","1229-1248","2012","JUL","Managerial Ability;Managerial Talent;Managerial Efficiency","","We propose a measure of managerial ability, based on managers' efficiency in generating revenues, which is available for a large sample of firms and outperforms existing ability measures. We find that our measure is strongly associated with manager fixed effects and that the stock price reactions to chief executive officer (CEO) turnovers are positive (negative) when we assess the outgoing CEO as low (high) ability. We also find that replacing CEOs with more (less) able CEOs is associated with improvements (declines) in subsequent firm performance. We conclude with a demonstration of the potential of the measure. We find that the negative relation between equity financing and future abnormal returns documented in prior research is mitigated by managerial ability. Specifically, more able managers appear to utilize equity issuance proceeds more effectively, illustrating that our more precise measure of managerial ability will allow researchers to pursue studies that were previously difficult to conduct."
821,"Public Opinion and Executive Compensation","Kuhnen, Camelia M. and Niessen, Alexandra","MANAGEMENT SCIENCE","58","7","1249-1272","2012","JUL","Executive Compensation;Public Opinion;Media Coverage","","We investigate whether public opinion influences the level and structure of executive compensation. During 1992-2008, the negativity of press coverage of chief executive officer (CEO) pay varied significantly, with stock options being the most criticized pay component. We find that after more negative press coverage of CEO pay, firms reduce option grants and increase less contentious types of pay such as salary, although overall compensation does not change. The reduction in option pay after increased press negativity is more pronounced when firms, CEOs, and boards have stronger reputation concerns. Our within-firm, within-year identification shows the results cannot be explained by annual changes in accounting rules regarding executive compensation, stock market conditions, or pay mean reversion."
822,"On Fair Routing from Emergency Departments to Hospital Wards: QED Queues with Heterogeneous Servers","Mandelbaum, Avishai and Momcilovic, Petar and Tseytlin, Yulia","MANAGEMENT SCIENCE","58","7","1273-1291","2012","JUL","Queueing Systems;Heterogeneous Servers;Healthcare;Hospital Routing Policies;Fairness;Quality- And Efficiency-Driven Regime;Asymptotic Analysis","","The interface between an emergency department and internal wards is often a hospital's bottleneck. Motivated by this interaction in an anonymous hospital, we analyze queueing systems with heterogeneous server pools, where the pools represent the wards, and the servers are beds. Our queueing system, with a single centralized queue and several server pools, forms an inverted-V model. We introduce the randomized most-idle (RMI) routing policy and analyze it in the quality- and efficiency-driven regime, which is natural in our setting. The RMI policy results in the same server fairness (measured by idleness ratios) as the longest-idle-server-first (LISF) policy, which is commonly used in call centers and considered fair. However, the RMI policy utilizes only the information on the number of idle servers in different pools, whereas the LISF policy requires information that is unavailable in hospitals on a real-time basis."
823,"Network Progeny? Prefounding Social Ties and the Success of New Entrants","Roberts, Peter W. and Sterling, Adina D.","MANAGEMENT SCIENCE","58","7","1292-1304","2012","JUL","Organizational Studies;Economic Sociology;Entrepreneurship;Networks","","Entrepreneurs that were employed by successful industry incumbents prior to founding tend to confer advantages on their new organizations. We propose and then demonstrate a similar network progeny effect rooted in the social relationships that form among entrepreneurs. Our analysis of new entrants into the Ontario wine industry shows that prefounding friendship ties of the founders of one especially prominent entrepreneurial firm led to significantly higher ice wine prices. This attests to the promise of a network progeny extension of the parent-progeny account of new firm success. Follow-on analysis indicates that this effect is not attributable to an entrant's ability to make ice wines of superior quality or to it having access to better distribution knowledge. We therefore conclude that having a social tie to this prominent entrepreneurial firm generated reflected prominence that enhanced the valuations and therefore prices of wines made by connected market entrants."
824,"Streaks in Earnings Surprises and the Cross-Section of Stock Returns","Loh, Roger K. and Warachka, Mitch","MANAGEMENT SCIENCE","58","7","1305-1321","2012","JUL","Trends;Streaks;Gambler'S Fallacy;Post-Earnings-Announcement Drift","","The gambler's fallacy [Rabin, M. 2002. Inference by believers in the law of small numbers. Quart. J. Econom. 117(3) 775-816] predicts that trends bias investor expectations. Consistent with this prediction, we find that investors underreact to streaks of consecutive earnings surprises with the same sign. When the most recent earnings surprise extends a streak, post-earnings-announcement drift is strong and significant. In contrast, the drift is negligible following the termination of a streak. Indeed, streaks explain about half of the post-earnings-announcement drift in our sample. Our results are robust to more general definitions of trends than streaks and a battery of control variables including the magnitude of earnings surprises and their autocorrelation. Overall, post-earnings-announcement drift has a significant time-series component that is consistent with the gambler's fallacy."
825,"Information Environment and Equity Risk Premium Volatility Around the World","Lau, Sie Ting and Ng, Lilian and Zhang, Bohui","MANAGEMENT SCIENCE","58","7","1322-1340","2012","JUL","Market Risk Premium Volatility;Information Environments;Implied Cost Of Capital;Var","","This paper examines whether and how differences in investors' information environments (measured by a country's information disclosure, accounting standards, and financial transparency) are related to cross-country differences in the market risk premium volatility. We use the vector-autoregressive and implied cost of capital methods to extract time variation in risk premiums for 41 developed and emerging markets worldwide. Consistent with theoretical predictions, countries with better information environments tend to experience a lower risk premium volatility, even after controlling for various country variables that are potentially associated with variation in risk premiums. Our analysis of two exogenous events, specifically the 1997 Asian financial crisis and 2008 global financial crisis, further corroborates our key finding that information environments play an important role in explaining market risk premium variability."
826,"Efficient Cost Allocation","Ray, Korok and Goldmanis, Maris","MANAGEMENT SCIENCE","58","7","1341-1356","2012","JUL","Cost Allocation;Cost Sharing;Mechanism Design;Teams;Efficiency","","Firms routinely allocate the costs of common corporate resources down to divisions. The main insight of this paper is that any efficient allocation rule must reflect the firm's underlying cost structure. We propose a new allocation rule (the polynomial rule), which achieves efficiency and approximate budget balance. Welfare losses due to linear allocation rules increase with firm size, so polynomial allocation rules dominate linear rules for larger firms."
827,"Product and Price Competition with Satiation Effects","Caro, Felipe and Martinez-de-Albeniz, Victor","MANAGEMENT SCIENCE","58","7","1357-1373","2012","JUL","Utility Preference;Dynamic Programming: Deterministic;Discrete Time;Marketing: Product Policy","","Consumers become satiated with a product when purchasing too much too quickly. How much is too much and how quickly is too quickly depends on the characteristics of the product relative to the time interval between consumption periods. Knowing that, consumers allocate their budget to products that generate less satiation effects. Retailers should then choose to sell products that induce minimal satiation, but usually this is operationally more costly. To study this trade-off, we provide an analytical model based on utility theory that relates customer consumption to price and satiation, in the context of multiple competing retailers. We determine the purchasing pattern over time and provide an explicit expression to determine the consumption level in steady state. We derive market shares and show that they take the form of an attraction model in which the attractiveness depends on price and product satiation. We use this to analyze the competition between firms that maximize long-term average profit. We characterize the equilibrium under three scenarios: (i) price-only competition, (ii) product-only competition, and (iii) price and product competition. The results reveal the interplay between a key marketing lever (price) and the firm's ability to offer products that generate less satiation. In particular, we show that when a firm becomes more efficient at reducing satiation, its competitor may benefit if competition is on product only, but not if it is on price and product. We also find that when satiation effects are not managed, a firm's profit may be significantly reduced while a strategic competitor can largely benefit."
828,"Measuring the Informative and Persuasive Roles of Detailing on Prescribing Decisions","Ching, Andrew T. and Ishihara, Masakazu","MANAGEMENT SCIENCE","58","7","1374-1387","2012","JUL","Detailing;Informative Role;Persuasive Role;Prescription Drugs;Decisions Under Uncertainty;Diffusion","","In the pharmaceutical industry, measuring the importance of informative and persuasive roles of detailing is crucial for both drug manufacturers and policy makers. However, little progress has been made in disentangling these two roles of detailing in empirical research. In this paper, we provide a new identification strategy to address this problem. Our key identification assumptions are that the informative component of detailing is chemical specific and the persuasive component is brand specific. Our strategy is to focus on markets where some drug manufacturers engage in a comarketing agreement, under which two or more companies market the same chemical using their own brand names. With our identification assumptions, the variation in the relative market shares of these two brands, together with their brand specific detailing efforts, would allow us to measure the persuasive component of detailing. The variation in the market shares of chemicals, and the detailing efforts summed across brands made of the same chemical, would allow us to measure the informative component of detailing. Using the data for angiotensin-converting enzyme inhibitor with diuretic in Canada, we find evidence that our identification strategy can help disentangle these two effects. Although both effects are statistically significant, we find that the persuasive function of detailing plays a very minor role in determining the demand at the chemical level-the informative role of detailing is mainly responsible for the diffusion patterns of chemicals. In contrast, the persuasive role of detailing plays a crucial role in determining the demand for brands that comarket the same chemical."
829,"Contractual Flexibility, Rent Seeking, and Renegotiation Design: An Empirical Analysis of Information Technology Outsourcing Contracts","Susarla, Anjana","MANAGEMENT SCIENCE","58","7","1388-1407","2012","JUL","Contractual Flexibility;Rent Seeking;It Outsourcing;Incomplete Contracts;Renegotiation Design","","This paper examines renegotiation design in contracts for outsourced information technology (IT) services. Whereas prior literature in information systems has highlighted the likelihood of ex post rent seeking engendered by renegotiation, we build upon literature on incomplete contracts to posit that renegotiation can be Pareto improving by incorporating contingencies revealed ex post. Research on contract renegotiation has been hampered by two sets of challenges: the lack of appropriate data and empirical challenges in identification. We circumvent this problem both by appropriate data collection and by employing an identification strategy to address alternate causal explanations. We propose a measure, Pareto improving amendments, to assess renegotiation outcomes that enhance the value from outsourcing by hazard equilibration and by incorporating learning. Using a unique sample of 141 IT outsourcing contracts, we examine the role of decision rights delineated ex ante in enabling Pareto improving amendments and in resolving the trade-off between adaptation and rent seeking. We find that flexibility provisions, termination for convenience rights, and contractual rights whereby vendors are granted rights to reuse know-how are associated with Pareto improving amendments. The results are robust to potential endogeneity of contractual provisions when parties have feasible foresight and to the possibility of adverse selection in the sample. We also examine alternate explanations from the literature on contractual breach. Implications for practitioners and researchers are discussed."
830,"The Power of Diversity over Large Solution Spaces","LiCalzi, Marco and Surucu, Oktay","MANAGEMENT SCIENCE","58","7","1408-1421","2012","JUL","Problem Solving;Bounded Rationality;Theory Of Teams;Groupthink","","We consider a team of agents with limited problem-solving ability facing a disjunctive task over a large solution space. We provide sufficient conditions for the following four statements. First, two heads are better than one: a team of two agents will solve the problem even if neither agent alone would be able to. Second, teaming up does not guarantee success: if the agents are not sufficiently creative, even a team of arbitrary size may fail to solve the problem. Third, defendit numerus: when the agent's problem-solving ability is adversely affected by the complexity of the solution space, the solution of the problem requires only a mild increase in the size of the team. Fourth, groupthink impairs the power of diversity: if agents' abilities are positively correlated, a larger team is necessary to solve the problem."
831,"Hiring Cheerleaders: Board Appointments of Independent Directors","Cohen, Lauren and Frazzini, Andrea and Malloy, Christopher J.","MANAGEMENT SCIENCE","58","6","1039-1058","2012","JUN","Independent Directors;Appointments;Analysts;Board Members","","We provide evidence that firms appoint independent directors who are overly sympathetic to management, while still technically independent according to regulatory definitions. We explore a subset of independent directors for whom we have detailed, microlevel data on their views regarding the firm prior to being appointed to the board: sell-side analysts who are subsequently appointed to the boards of companies they previously covered. We find that boards appoint overly optimistic analysts who are also poor relative performers. The magnitude of the optimistic bias is large: 82.0% of appointed recommendations are strong buy/buy recommendations, compared with 56.9% for all other analyst recommendations. We also show that appointed analysts' optimism is stronger at precisely those times when firms' benefits are larger. Last, we find that appointing firms are more likely to have management on the board nominating committee, appear to be poorly governed, and increase earnings management and chief executive officer compensation following these board appointments."
832,"Home Sweet Home: Entrepreneurs' Location Choices and the Performance of Their Ventures","Dahl, Michael S. and Sorenson, Olav","MANAGEMENT SCIENCE","58","6","1059-1071","2012","JUN","Organizational Studies;Effectiveness-Performance;Behavior;Economics;Econometrics","","Entrepreneurs, even more than employees, tend to locate in regions in which they have deep roots (home regions). Here, we examine the performance implications of these choices. Whereas one might expect entrepreneurs to perform better in these regions because of their richer endowments of regionally embedded social capital, they might also perform worse if their location choices rather reflect a preference for spending time with family and friends. We examine this question using comprehensive data on Danish start-ups. Ventures perform better-survive longer and generate greater annual profits and cash flows-when located in regions in which their founders have lived longer. This effect appears substantial, similar in size to the value of prior experience in the industry (i.e., to being a spin-off)."
833,"Consumption Externality and Yield Uncertainty in the Influenza Vaccine Supply Chain: Interventions in Demand and Supply Sides","Arifoglu, Kenan and Deo, Sarang and Iravani, Seyed M. R.","MANAGEMENT SCIENCE","58","6","1072-1091","2012","JUN","Influenza Vaccine;Supply Chain Inefficiency;Strategic Consumer Behavior;Externality;Yield Uncertainty","","We study the impact of yield uncertainty (supply side) and self-interested consumers (demand side) on the inefficiency in the influenza vaccine supply chain. Previous economic studies, focusing on demand side, find that the equilibrium demand is always less than the socially optimal demand because self-interested individuals do not internalize the social benefit of protecting others via reduced infectiousness (positive externality). In contrast, we show that the equilibrium demand can be greater than the socially optimal demand after accounting for the limited supply due to yield uncertainty and manufacturer's incentives. The main driver for this result is a second (negative) externality: Self-interested individuals ignore that vaccinating people with high infection costs is more beneficial for the society when supply is limited. We show that the extent of the negative externality can be reduced through more efficient and less uncertain allocation mechanisms. To investigate the relative effectiveness of government interventions on supply and demand sides under various demand and supply characteristics, we construct two partially centralized scenarios where the social planner (i.e., government) intervenes either on the demand side or the supply side, but not both. We conduct an extensive numerical analysis."
834,"An Evidence-Based Incentive System for Medicare's End-Stage Renal Disease Program","Lee, Donald K. K. and Zenios, Stefanos A.","MANAGEMENT SCIENCE","58","6","1092-1105","2012","JUN","Healthcare Pay-For-Performance;Dialysis;Evidence-Based Mechanism Design;Structural Estimation","","Recent legislations directed Medicare to revamp its decades-old system for reimbursing dialysis treatments, with focus on the risk adjustment of payments and on the transition toward a pay-for-compliance system. To design an optimal payment system that incorporates these features, we develop an empirical method to estimate the structural parameters of the principal-agent model underlying Medicare's dialysis payment system. We use the model and parameter estimates to answer the following questions: Can a pay-for-compliance system based only on the intermediate performance measures currently identified by Medicare achieve first-best? How should patient outcomes be risk adjusted, and what welfare gains can be achieved by doing so? Our main findings are as follows: (1) the current set of intermediate measures identified by Medicare are not comprehensive enough for use alone in a pay-for-compliance system; (2) paying for risk-adjusted downstream outcomes instead of raw downstream outcomes can lengthen the hospital-free life of admitted patients by two weeks per patient per year without increasing Medicare expenditures."
835,"Organizational Structure and the Limits of Knowledge Sharing: Incentive Conflict and Agency in Car Leasing","Pierce, Lamar","MANAGEMENT SCIENCE","58","6","1106-1121","2012","JUN","Knowledge-Based View;Vertical Integration;Leasing;Agency Theory;Automotive Industry","","This paper argues that conflicting incentives among managers may impede potential knowledge-sharing benefits from vertical integration. I study knowledge-based agency costs from vertical integration in car leasing, where manufacturer-owned captive lessors compete with independent lessors. Both organizational forms must acquire and integrate diffuse knowledge to accurately predict vehicle depreciation-a condition critical for profitability. Using a data set of 180,000 leases, I compare contracts of independent and captive lessors across car models, market conditions, and product life cycles. I find that managers in vertically integrated firms have conflicting incentives on whether to accurately and completely share proprietary knowledge, and show that these incentives appear to generate agency costs inconsistent with corporate profitability as managers selectively use and share knowledge for personal gain. The findings suggest that most knowledge benefits of vertical integration will be nullified when managerial interests are incompatible with the profit concerns of the firm."
836,"Reconceptualizing Stars: Scientist Helpfulness and Peer Performance","Oettl, Alexander","MANAGEMENT SCIENCE","58","6","1122-1140","2012","JUN","Star Scientists;Human Capital;Helpfulness;Productivity","","It is surprising that the prevailing performance taxonomy for scientists (star versus nonstar) focuses only on individual output and ignores social behavior, because innovation is often characterized as a communal process. To develop a deeper understanding of the mechanisms by which scientists influence the productivity of others, I expand the traditional taxonomy of scientists that focuses solely on productivity and add a second, social dimension: helpfulness to others. Using a combination of academic paper publications and citations to capture scientist productivity and the receipt of academic paper acknowledgments to measure helpfulness, I examine the change in publishing output of the coauthors of 149 scientists that die. Coauthors of highly helpful scientists that die experience a decrease in output quality but not output quantity. Meanwhile, the deaths of high productivity scientists that are not highly helpful do not influence their coauthors' output. In addition, scientists who are helpful with conceptual feedback (critique and advice) have a larger impact on the performance of their coauthors than scientists who provide help with material access, scientific tools, or technical work. Within the context of evaluating scientific productivity, it may be time to update our conceptualization of a star."
837,"Specialization and Variety in Repetitive Tasks: Evidence from a Japanese Bank","Staats, Bradley R. and Gino, Francesca","MANAGEMENT SCIENCE","58","6","1141-1159","2012","JUN","Learning;Motivation;Productivity;Specialization;Variety;Work Fragmentation","","Sustaining operational productivity in the completion of repetitive tasks is critical to many organizations' success. Yet research points to two different work-design-related strategies for accomplishing this goal: specialization to capture the benefits of repetition and variety (i.e., working on different tasks) to keep workers motivated and provide them opportunities to learn. In this paper, we investigate how these two strategies may bring different productivity benefits over time. For our empirical analyses, we use two and a half years of transaction data from a Japanese bank's home loan application-processing line. We find that over the course of a single day, specialization, as compared to variety, is related to improved worker productivity. However, when we examine workers' experience across a number of days, we find that variety helps improve worker productivity. Additionally, we show that part of this benefit results from workers' cumulative experience with changeovers. Our results highlight the need for organizations to transform specialization and variety into mutually reinforcing strategies rather than treating them as mutually exclusive. Overall, our paper identifies new ways to improve operational performance through the effective allocation of work."
838,"Advance Selling When Consumers Regret","Nasiry, Jayad and Popescu, Ioana","MANAGEMENT SCIENCE","58","6","1160-1177","2012","JUN","Advance Selling;Behavioral Pricing;Consumer Regret;Refunds;Consumer Options","","We characterize the effect of anticipated regret on consumer decisions and on firm profits and policies in an advance selling context where buyers have uncertain valuations. Advance purchases trigger action regret if valuations turn out to be lower than the price paid, whereas delaying purchase may cause inaction regret from missing a discount or facing a stockout. Consumers whom we describe as emotionally rational act strategically in response to the firm's policies and in anticipation of regret. In this context, regret explains two types of behavioral patterns: inertia (delayed purchase) and frenzies (buying early at negative surplus). We show how firms should optimally respond to consumer regret and also characterize a normative regret threshold above which they should not advance sell. Action regret reduces profits as well as the value of advance selling and booking limit policies for price-setting firms; inaction regret has the opposite effects. These effects are diminished by capacity constraints and are reversed for firms facing price pressure in the advance period (owing, e.g., to competition or market heterogeneity). Regret heterogeneity explains premium advance selling for the capacity-constrained firm, which may benefit from larger shares of regretful buyers. Finally, we show how the negative effects of regret on profits can be mitigated by regret-priming marketing campaigns and by offering refunds or options or allowing resales. Our results highlight the importance of assessing the relative strength of regret within and across market segments and of accounting for these factors in pricing and marketing policies."
839,"Double Marginalization in Performance-Based Advertising: Implications and Solutions","Dellarocas, Chrysanthos","MANAGEMENT SCIENCE","58","6","1178-1195","2012","JUN","Information Systems;Digital Marketing;Advertising;Electronic Markets And Auctions;Electronic Commerce;Sponsored Search;Keyword Auctions","","An important current trend in advertising is the replacement of traditional pay-per-exposure (pay-per-impression) pricing models with performance-based mechanisms in which advertisers pay only for measurable actions by consumers. Such pay-per-action (PPA) mechanisms are becoming the predominant method of selling advertising on the Internet. Well-known examples include pay-per-click, pay-per-call, and pay-per-sale. This work highlights an important, and hitherto unrecognized, side effect of PPA advertising. I find that, if the prices of advertised goods are endogenously determined by advertisers to maximize profits net of advertising expenses, PPA mechanisms induce firms to distort the prices of their goods (usually upward) relative to prices that would maximize profits in settings where advertising is sold under pay-per-exposure methods. Upward price distortions reduce both consumer surplus and the joint publisher advertiser profit, leading to a net reduction in social welfare. They persist in current auction-based PPA mechanisms, such as the ones used by Google, Yahoo!, and Microsoft. In the latter settings they also reduce publisher revenues relative to pay-per-exposure methods. I show that these phenomena constitute a form of double marginalization and discuss a number of enhancements to today's PPA mechanisms that restore equilibrium pricing of advertised goods to efficient levels, improving both consumer surplus as well as the publisher's expected profits."
840,"The Strategic Perils of Low Cost Outsourcing","Feng, Qi and Lu, Lauren Xiaoyuan","MANAGEMENT SCIENCE","58","6","1196-1210","2012","JUN","Outsourcing;Multiunit Bilateral Bargaining;Competition;Supplier Cost Advantage","","The existing outsourcing literature has generally overlooked the cost differential and contract negotiations between manufacturers and suppliers (by assuming identical cost structures and adopting the Stackelberg framework). One fundamental question yet to be addressed is whether upstream suppliers' cost efficiency is always beneficial to downstream manufacturers in the presence of competition and negotiations. In other words, does low cost outsourcing always lead to a win-win outcome? To answer this question, we adopt a multiunit bilateral bargaining framework to investigate competing manufacturers' sourcing decisions. We analyze two supply chain structures: one-to-one channels, in which each manufacturer may outsource to an exclusive supplier; and one-to-two channels, in which each manufacturer may outsource to a common supplier. We show that, under both structures, low cost outsourcing may lead to a win-lose outcome in which the suppliers gain and the manufacturers lose. This happens because suppliers' cost advantage may backfire on competing manufacturers through two negative effects. First, a decrease of upstream cost weakens a manufacturer's bargaining position by reducing her disagreement payoff (i.e., her insourcing profit) because the competing manufacturer can obtain a low cost position through outsourcing. Second, in one-to-two channels, the common supplier's bargaining position is strengthened with a lower cost because his disagreement payoff increases (i.e., his profit from serving only one manufacturer increases). The endogeneity of disagreement payoffs in our model highlights the importance of modeling firm negotiations under competition. Moreover, we identify an interesting bargaining externality between competing manufacturers when they outsource to a common supplier. Because the supplier engages in two negotiations, his share of profit from the trade with one manufacturer affects the total surplus of the trade with the other manufacturer. Because of this externality, surprisingly, as a manufacturer's bargaining power decreases, her profit under outsourcing may increase and it may be more likely for her to outsource."
841,"Information Technology and Trademarks: Implications for Product Variety","Gao, Guodong (Gordon) and Hitt, Lorin M.","MANAGEMENT SCIENCE","58","6","1211-1226","2012","JUN","Business Value Of It;Trademark;Competitive Advantage;Product Variety","","This paper examines the relationship between information technology (IT) and trademarks. Using an 11-year panel data set (1987-1997) of IT capital Stock, trademark holdings, and other measures for 116 Fortune 1000 manufacturing firms, we find that IT contributes to higher trademark holdings. Further, we find evidence suggesting that firms with more IT capital tend to apply for more new trademarks and retire existing trademarks more quickly, leading to a shorter trademark life cycle. Because trademarks are mainly used by firms to communicate differences among similar products to the marketplace, these results suggest that the business value of IT can be realized in greater product variety."
842,"The Extroverted Firm: How External Information Practices Affect Innovation and Productivity","Tambe, Prasanna and Hitt, Lorin M. and Brynjolfsson, Erik","MANAGEMENT SCIENCE","58","5","843-859","2012","MAY","Information Technology;Productivity;Organizational Practices;External Focus;Complementarities;High-Performance Work Practices;Product Development;High-Tech Clusters","","We gather detailed data on organizational practices and information technology (IT) use at 253 firms to examine the hypothesis that external focus-the ability of a firm to detect and therefore respond to changes in its external operating environment-increases returns to IT, especially when combined with decentralized decision making. First, using survey-based measures, we find that external focus is correlated with both organizational decentralization, and IT investment. Second, we find that a cluster of practices including external focus, decentralization, and IT is associated with improved product innovation capabilities. Third, we develop and test a three-way complementarities model that indicates that the combination of external focus, decentralization, and IT is associated with significantly higher productivity in our sample. We also introduce a new set of instrumental variables representing barriers to IT-related organizational change and find that our results are robust when we account for the potential endogeneity of organizational investments. Our results may help explain why firms that operate in information-rich environments such as high-technology clusters or areas with high worker mobility have experienced especially high returns to IT investment and suggest a set of practices that some managers may be able to use to increase their returns from IT investments."
843,"Information Transmission and the Bullwhip Effect: An Empirical Investigation","Bray, Robert L. and Mendelson, Haim","MANAGEMENT SCIENCE","58","5","860-875","2012","MAY","Bullwhip Effect;Martingale Model Of Forecast Evolution;Production Smoothing;Bullwhip Decomposition;Demand Uncertainty","","The bullwhip effect is the amplification of demand variability along a supply chain: a company bullwhips if it purchases from suppliers more variably than it sells to customers. Such bullwhips (amplifications of demand variability) can lead to mismatches between demand and production and hence to lower supply chain efficiency. We investigate the bullwhip effect in a sample of 4,689 public U. S. companies over 1974-2008. Overall, about two-thirds of firms bullwhip. The sample's mean and median bullwhips, both significantly positive, respectively measure 15.8% and 6.7% of total demand variability. Put another way, the mean quarterly standard deviation of upstream orders exceeds that of demand by $20 million. We decompose the bullwhip by information transmission lead time. Estimating the bullwhip's information-lead-time components with a two-stage estimator, we find that demand signals firms observe with more than three-quarters' notice drive 30% of the bullwhip, and those firms observe with less than one-quarter's notice drive 51%. From 1974-1994 to 1995-2008, our sample's mean bullwhip dropped by a third."
844,"Signaling Quality via Queues","Debo, Laurens G. and Parlour, Christine and Rajan, Uday","MANAGEMENT SCIENCE","58","5","876-891","2012","MAY","Games-Group Decisions;Stochastic;Probability;Stochastic Model Applications;Queues;Birth-Death","","We consider an M/M/1 queueing system with impatient consumers who observe the length of the queue before deciding whether to buy the product. The product may have high or low quality, and consumers are heterogeneously informed. The firm chooses a slow or (at a cost) a fast service rate. In equilibrium, informed consumers join the queue if it is below a threshold. The threshold varies with the quality of the good, so an uninformed consumer updates her belief about quality on observing the length of the queue. The strategy of an uninformed consumer has a hole: she joins the queue at lengths both below and above the hole, but not at the hole itself. We show that if the prior probability the product has high quality and the proportion of informed consumers are both low, a high-quality firm may select a slower service rate than a low-quality firm. The queue can therefore be a valuable signaling device for a high-quality firm. Strikingly, in some scenarios, the high-quality firm may choose the slow service rate even if the technological cost of speeding up is zero."
845,"Rational Herding in Microloan Markets","Zhang, Juanjuan and Liu, Peng","MANAGEMENT SCIENCE","58","5","892-912","2012","MAY","Rational Herding;Observational Learning;Bayesian Inference;Microloan Markets;Peer-To-Peer Lending;Prosper.Com","","Microloan markets allow individual borrowers to raise funding from multiple individual lenders. We use a unique panel data set that tracks the funding dynamics of borrower listings on Prosper.com, the largest microloan market in the United States. We find evidence of rational herding among lenders. Well-funded borrower listings tend to attract more funding after we control for unobserved listing heterogeneity and payoff externalities. Moreover, instead of passively mimicking their peers (irrational herding), lenders engage in active observational learning (rational herding); they infer the creditworthiness of borrowers by observing peer lending decisions and use publicly observable borrower characteristics to moderate their inferences. Counterintuitively, obvious defects (e.g., poor credit grades) amplify a listing's herding momentum, as lenders infer superior creditworthiness to justify the herd. Similarly, favorable borrower characteristics (e.g., friend endorsements) weaken the herding effect, as lenders attribute herding to these observable merits. Follow-up analysis shows that rational herding beats irrational herding in predicting loan performance."
846,"Three-Way Complementarities: Performance Pay, Human Resource Analytics, and Information Technology","Aral, Sinan and Brynjolfsson, Erik and Wu, Lynn","MANAGEMENT SCIENCE","58","5","913-931","2012","MAY","Incentive Systems;Information Technology;Performance Pay;Human Resource Analytics;Complementarity;Enterprise Systems;Erp;Productivity;Production Function;Principal-Agent Model","","We test for three-way complementarities among information technology (IT), performance pay, and human resource (HR) analytics practices. We develop a principal-agent model examining how these practices work together as an incentive system that produces a larger productivity premium when the practices are implemented in concert rather than separately. We assess our model by combining fine-grained data on human capital management (HCM) software adoption over 11 years with detailed survey data on incentive systems and HR analytics practices for 189 firms. We find that the adoption of HCM software is greatest in firms that have also adopted performance pay and HR analytics practices. Furthermore, HCM adoption is associated with a large productivity premium when it is implemented as a system of organizational incentives, but has less benefit when adopted in isolation. The system of three-way complements produces disproportionately greater benefits than pairwise interactions, highlighting the importance of including all three complements. Productivity increases significantly when the HCM systems go live but not when they are purchased, which can be years earlier. This helps rule out reverse causality as an explanation for our findings."
847,"When to Fire Customers: Customer Cost-Based Pricing","Shin, Jiwoong and Sudhir, K. and Yoon, Dae-Hee","MANAGEMENT SCIENCE","58","5","932-947","2012","MAY","Customer Cost Information;Activity-Based Costing;Behavior-Based Price Discrimination;Forward-Looking Customers;Customer Relationship Management","","The widespread adoption of activity-based costing enables firms to allocate common service costs to each customer, allowing for precise measurement of both the cost to serve a particular customer and the customer's profitability. In this paper, we investigate how pricing strategies based on customer cost information affects a firm's customer acquisition and retention dynamics, and ultimately its profit, using a two-period monopoly model with high-and low-cost customer segments. Although past purchase and cost information helps firms to increase profits through differential prices for good and bad customers in the second period (price discrimination effect), it can hurt firms because strategic forward-looking consumers may delay purchases to avoid higher future prices (ratchet effect). We find that when the customer cost heterogeneity is sufficiently large, it is optimal for firms to fire some of its high-cost customers, and customer cost-based pricing is profitable. Surprisingly, it is optimal to fire even some profitable customers. This result is robust even when the cost to serve is endogenous and determined by the consumer's choice of service level. We also shed insight on acquisition-retention dynamics, on when firms can improve their profitability by selectively firing known old bad customers, and on replacing the old bad customers with a mix of new good and bad customers."
848,"Competition Between Organizational Groups: Its Impact on Altruistic and Antisocial Motivations","Goette, Lorenz and Huffman, David and Meier, Stephan and Sutter, Matthias","MANAGEMENT SCIENCE","58","5","948-960","2012","MAY","Group Decisions, Cooperation;Punishment;Experiment, Army","","Firms are often organized into groups. Group membership has been shown empirically to have positive effects, in the form of increased prosocial behavior toward in-group members. This includes an enhanced willingness to engage in altruistic punishment of inefficient defection. Our paper provides evidence of a dark side of group membership. In the presence of cues of competition between groups, a taste for harming the out-group emerges: punishment ceases to serve a norm enforcement function, and instead, out-group members are punished harder and regardless of whether they cooperate or defect. Our results point to a mechanism that might help explain previous mixed results on the social value of punishment, and they contribute to understanding the sources of conflict between groups. They also point to an important trade-off for firms: introducing competition enhances within-group efficiency but also generates costly between-group conflict."
849,"Impact of Performance-Based Contracting on Product Reliability: An Empirical Analysis","Guajardo, Jose A. and Cohen, Morris A. and Kim, Sang-Hyun and Netessine, Serguei","MANAGEMENT SCIENCE","58","5","961-979","2012","MAY","Reliability;Maintenance Repairs;Empirical Operations Management;Supply Chain Contracting;Aerospace Industry","","Using a proprietary data set provided by a major manufacturer of aircraft engines, we empirically investigate how product reliability is impacted by the use of two different types of after-sales maintenance support contracts: time and material contracts (T&MC) and performance-based contracts (PBC). We offer a number of competing arguments based on the theory of incentives that establish why product reliability may increase or decrease under PBC. We build a two-stage econometric model that explicitly accounts for the endogeneity of contract choices, and find evidence of a positive and significant effect of PBC on product reliability. The estimation of our model indicates that product reliability is higher by 25%-40% under PBC compared to under T&MC, once the endogeneity of contract choice is taken into account. Our results are consistent with two mechanisms for reliability improvement under PBC: more frequent scheduled maintenance and better care performed in each maintenance event."
850,"Dynamics of Rate-of-Return Regulation","Nezlobin, Alexander and Rajan, Madhav V. and Reichelstein, Stefan","MANAGEMENT SCIENCE","58","5","980-995","2012","MAY","Accounting;Marginal Cost;Rate-Of-Return Regulation;Depreciation","","Under rate-of-return regulation, a firm's product prices are constrained by the requirement that investors not earn more than an allowable return on the firm's assets. This paper examines the dynamic properties of the rate-of-return regulation process when the regulated firm periodically undertakes new capacity investments. Our analysis identifies prices that correspond to stationary values of the regulation process. It is shown that the underlying depreciation rules for property, plant, and equipment determine whether these stationary prices will be above, equal to, or below the long-run marginal cost of providing the regulated service. We provide conditions under which the rate-of-return regulation process is dynamically stable so that prices indeed converge to their stationary values. The overall efficiency of this regulation method is shown to depend on how well the applicable depreciation schedule matches the productivity pattern of the assets in use."
851,"Consistency Judgments, Embeddedness, and Relationship Outcomes in Interorganizational Networks","Vinhas, Alberto Sa and Heide, Jan B. and Jap, Sandy D.","MANAGEMENT SCIENCE","58","5","996-1011","2012","MAY","Organizational Studies;Design;Effectiveness-Performance;Strategy;Information","","Past research has shown how outcomes in interorganizational relationships are influenced by the characteristics of the individual relationship in question. Focusing on relationships between suppliers and their organizational buyers, we augment this perspective by positing that relationship outcomes are also influenced by social comparison processes involving perceptions of a supplier's practices across comparable buyer relationships. Based on past research on embedded ties and institutional theory, we propose that the effect of these comparison processes depends on the nature of a buyer's existing interorganizational ties and on the norms that are brought to bear on the relationship in question. We test our propositions based on 788 observations of organizational buyers who have relationships with the same supplier. Our findings paint a complex, multilevel picture of the process by which relationship outcomes come about in interorganizational networks."
852,"Modeling Purchasing Behavior with Sudden Death: A Flexible Customer Lifetime Model","Bemmaor, Albert C. and Glady, Nicolas","MANAGEMENT SCIENCE","58","5","1012-1021","2012","MAY","Buyer Behavior;Mixture Models;Catalog Retailing;Gompertz Distribution","","T his study proposes a new customer lifetime model: the gamma/Gompertz distribution (G/G). The advantage of this model relative to the well-known Pareto distribution is twofold: (i) its probability density function can exhibit a mode at zero or an interior mode, and (ii) it can be skewed to the right or to the left. We combine the G/G with a negative binomial distribution (NBD) and obtain the moments of the distribution of the number of transactions over (0, T] and (T, T + T{*}]. Out of six data sets, the G/G/NBD model provides a notable improvement in the log-likelihood over the Pareto/NBD model in four data sets. It can indicate substantial differences in expected residual lifetimes compared to the Pareto/NBD and induce a retention rather than acquisition policy. On the average, the G/G/NBD exhibits slightly better forecasts of the mean number of transactions than the Pareto/NBD."
853,"Relicensing as a Secondary Market Strategy","Oraiopoulos, Nektarios and Ferguson, Mark E. and Toktay, L. Beril","MANAGEMENT SCIENCE","58","5","1022-1037","2012","MAY","Durable Goods;Secondary Market;Relicensing Fee;Remanufacturing;Closed-Loop Supply Chain","","Secondary markets in the information technology industry, where used or refurbished equipment is traded, have been growing steadily. For original equipment manufacturers (OEMs) in this industry, the importance of secondary markets has grown in parallel, not only as a source of revenue, but also because of their impact on these firms' competitive advantage and market strategy. Recent articles in the press have severely criticized some OEMs who are perceived to be actively trying to eliminate the secondary market for their products. Other OEMs have policies that enhance their secondary markets. The goal of this paper is to understand how an OEM's incentives and optimal strategies vis-a-vis the secondary market are shaped contingent on her relative competitive advantage, product characteristics, and consumer preferences. The critical trade-off that we examine is whether the indirect benefit from maintaining an active secondary market (the resale value effect) can outweigh the potentially negative effect of the sales of used products at the expense of new product sales (the cannibalization effect). To that end, we develop a durable good model where the OEM can directly affect the resale value of her product through a relicensing fee charged to the buyer of the refurbished equipment. We analyze the OEM's strategy in both the monopoly and the duopoly cases, characterize the optimal relicensing fee set by the OEM, and draw conclusions on the conditions that favor stimulating or deterring the secondary market."
854,"Bias in White: A Longitudinal Natural Experiment Measuring Changes in Discrimination","Rubineau, Brian and Kang, Yoon","MANAGEMENT SCIENCE","58","4","660-677","2012","APR","Healthcare;Treatment;Professional;Education Systems;Organizational Studies;Effectiveness-Performance;Behavior","","Many professions are plagued by disparities in service delivery. Racial disparities in policing, mortgage lending, and healthcare are some notable examples. Because disparities can result from a myriad of mechanisms, crafting effective disparity mitigation policies requires knowing which mechanisms are active and which are not. In this study we can distinguish whether one mechanism-statistical discrimination-is a primary explanation for racial disparities in physicians' treatment of patients. In a longitudinal natural experiment using repeated quasi-audit studies of medical students, we test for within-cohort changes in disparities from medical student behaviors as they interact with white and black patient actors. We find significant increases in medical students' disparate behaviors by patient race between their first and second years of medical school. This finding is inconsistent with statistical discrimination predictions and challenges the idea that statistical discrimination is primarily responsible for racial disparities in patient care."
855,"Now IT's Personal: Offshoring and the Shifting Skill Composition of the US Information Technology Workforce","Tambe, Prasanna and Hitt, Lorin M.","MANAGEMENT SCIENCE","58","4","678-695","2012","APR","Information Systems;It Policy And Management;Management Of It Human Resources;Organizational Change;Outsourcing;Offshoring","","We combine new information technology (IT) offshoring and IT workforce microdata to investigate how the use of IT offshore captive centers is affecting the skill composition of the U. S. onshore IT workforce. The analysis is based on the theory that occupations involving tasks that are tradable, such as tasks that require little personal communication or hands-on interaction with U. S.-based objects, are vulnerable to being moved offshore. Consistent with this theory, we find that firms that have offshore IT captive centers have 8% less of their onshore IT workforce involved in tradable occupations; those without offshore captive centers have increased the proportion of onshore employment in these same occupations by 3%. In addition, we find that hourly IT workers (e. g., IT contractors) are disproportionately employed in tradable jobs, and their onshore employment is 2%-3% lower in firms with offshore captive centers. These findings persist after considering different measures of employment composition, including controls for human capital, firm performance, domestic outsourcing, and whether firms choose to build or buy software. Instrumental variables and corroborating regressions suggest that our estimates are conservative-the magnitude of the effect generally rises after accounting for reverse causality and measurement error."
856,"How Does the Variance of Product Ratings Matter?","Sun, Monic","MANAGEMENT SCIENCE","58","4","696-707","2012","APR","Information Transmission;Product Ratings;Social Media;User-Generated Content","","This paper examines the informational role of product ratings. We build a theoretical model in which ratings can help consumers figure out how much they would enjoy the product. In our model, a high average rating indicates a high product quality, whereas a high variance of ratings is associated with a niche product, one that some consumers love and others hate. Based on its informational role, a higher variance would correspond to a higher subsequent demand if and only if the average rating is low. We find empirical evidence that is consistent with the theoretical predictions with book data from Amazon.com and BN.com. A higher standard deviation of ratings on Amazon improves a book's relative sales rank when the average rating is lower than 4.1 stars, which is true for 35% of all the books in our sample."
857,"Broadening Focus: Spillovers, Complementarities, and Specialization in the Hospital Industry","Clark, Jonathan R. and Huckman, Robert S.","MANAGEMENT SCIENCE","58","4","708-722","2012","APR","Operational Focus;Spillovers;Complementarities;Healthcare;Organizational Studies;Effectiveness-Performance;Productivity;Hospitals","","The long-standing argument that focused operations outperform others stands in contrast to claims about the benefits of broader operational scope. The performance benefits of focus are typically attributed to reduced complexity, lower uncertainty, and the development of specialized expertise; the benefits of greater breadth are linked to the economies of scope achieved by sharing common resources, such as advertising or production capacity, across activities. Within the literature on corporate strategy, this tension between focus and breadth is reconciled by the concept of related diversification (i.e., a firm with multiple operating units, each specializing in distinct but related activities). We consider whether there are similar benefits to related diversification within an operating unit and examine the mechanism that generates these benefits. Using the empirical context of cardiovascular care within hospitals, we first examine the relationship between a hospital's level of specialization in cardiovascular care and the quality of its clinical performance on cardiovascular patients. We find that, on average, focus has a positive effect on quality performance. We then distinguish between positive spillovers and complementarities to examine (1) the extent to which a hospital's specialization in areas related to cardiovascular care directly impacts performance on cardiovascular patients (positive spillovers) and (2) whether the marginal benefit of a hospital's focus in cardiovascular care depends on the degree to which the hospital cospecializes in related areas (complementarities). In our setting, we find evidence of such complementarities in specialization."
858,"White Lies","Erat, Sanjiv and Gneezy, Uri","MANAGEMENT SCIENCE","58","4","723-733","2012","APR","Deception;Lies;Cheap Talk;Experiments","","In this paper we distinguish between two types of white lies: those that help others at the expense of the person telling the lie, which we term altruistic white lies, and those that help both others and the liar, which we term Pareto white lies. We find that a large fraction of participants are reluctant to tell even a Pareto white lie, demonstrating a pure lie aversion independent of any social preferences for outcomes. In contrast, a non-negligible fraction of participants are willing to tell an altruistic white lie that hurts them a bit but significantly helps others. Comparing white lies to those where lying increases the liar's payoff at the expense of another reveals important insights into the interaction of incentives, lying aversion, and preferences for payoff distributions. Finally, in line with previous findings, women are less likely to lie when it is costly to the other side. Interestingly though, we find that women are more likely to tell an altruistic lie."
859,"Local R&D Strategies and Multilocation Firms: The Role of Internal Linkages","Alcacer, Juan and Zhao, Minyuan","MANAGEMENT SCIENCE","58","4","734-753","2012","APR","Technology Clusters;Knowledge Spillover;Internalization;Appropriability","","This study looks at the role of internal linkages in highly competitive clusters. We argue that, in addition to serving as a mechanism for sourcing knowledge, strong internal linkages help firms increase internalization and create higher levels of technological interdependence across firm locations. Firms with strong networks of internal linkages are able to maintain tighter control over local innovation and reduce the risk that knowledge outflows will advantage competitors in clusters. Our empirical analysis of the global semiconductor industry shows that industry leaders intensify internal linkages across locations when they collocate with direct market competitors, but not when they collocate with innovators in the same technological field. We also find that internal linkages are associated with more knowledge flow within firms and less knowledge expropriation by collocated competitors. Our results suggest that future research in cluster innovation should consider the critical role of multilocation firms, their internal organization across clusters, and their responses to technological and market competition in clusters."
860,"Traditional and IS-Enabled Customer Acquisition on the Internet","Choi, Jeonghye and Bell, David R. and Lodish, Leonard M.","MANAGEMENT SCIENCE","58","4","754-769","2012","APR","Count Model;Internet Retailing;Search;Spatial Analysis;Word-Of-Mouth","","Geographic variation in consumer use of Internet retailers is partly explained by variation in offline shopping costs. Explanations for geographic variation in the efficacy of different customer acquisition methods including traditional methods of offline word-of-mouth (WOM) and magazine advertising and information systems (IS)-enabled methods of online WOM and online search remain unexplored. We estimate a multivariate negative binomial distribution (NBD) model on zip code-level customer counts from a leading Internet retailer and provide new insights into factors explaining geographic variation in the success of these methods. First, we show that target customer density explains geographic variation over and above the impact due to the number of potential customers. Moreover, the effect of density is greatest for offline and online WOM acquisitions; this suggests that density contributes to contagion, connectivity, and a hypothesized social multiplier. Second, when senders and recipients of WOM share consumption benefits, WOM is more powerful and compelling. We find that location-based convenience benefits have stronger effects on location-dependent offline WOM acquisitions than on location-independent online WOM acquisitions. Third, acquisition channels contribute differently to the total customer pool-offline WOM acquisitions are clustered, whereas magazine acquisitions are dispersed. Finally, separate click-to-conversion data from Coremetrics.com indicates that using the model-based predictions to target specific markets delivers a twofold improvement in actual click-to-order rates."
861,"Managing an Available-to-Promise Assembly System with Dynamic Short-Term Pseudo-Order Forecast","Gao, Long and Xu, Susan H. and Ball, Michael O.","MANAGEMENT SCIENCE","58","4","770-790","2012","APR","Available-To-Promise;Pseudo Orders;Markov;Stochastic Dynamic Programming;Prioritization;Resource And Demand Matching;Resource-Imbalance-Based Rationing;Short-Term And Long-Term Forecasts;Robustness","","We study an order promising problem in a multiclass, available-to-promise (ATP) assembly system in the presence of pseudo orders. A pseudo order refers to a tentative customer order whose attributes, such as the likelihood of an actual order, order quantity, and confirmation timing, can change dynamically over time. A unit demand from any class is assembled from one manufactured unit and one inventory unit, where the manufactured unit takes one unit of capacity and needs a single period to produce. An accepted order must be filled before a positive delivery lead time. The underlying order acceptance decisions involve trade-offs between committing resources (production capacity and component inventory) to low-reward firm orders and reserving resources for high-reward orders. We develop a Markov chain model that captures the key characteristics of pseudo orders, including demand lumpiness, nonstationarity, and volatility. We then formulate a stochastic dynamic program for the ATP assembly system that embeds the Markov chain model as a short-term forecast for pseudo orders. We show that the optimal order acceptance policy is characterized by class prioritization, resource-imbalance-based rationing, and capacity-inventory-demand matching. In particular, the rationing level for each class is determined by a critical value that depends on the resource imbalance level, defined as the net difference between the production capacity and component inventory levels. Extensive numerical tests underscore the importance of the key properties of the optimal policy and provide operational and managerial insights on the value of the short-term demand forecast and the robustness of the optimal policy."
862,"On Evaluation Costs in Strategic Factor Markets: The Implications for Competition and Organizational Design","Ross, David Gaddis","MANAGEMENT SCIENCE","58","4","791-804","2012","APR","Strategy;Organizational Studies;Design;Motivation-Incentives","","This paper uses a formal model to study how evaluation costs affect competition for resources in strategic factor markets. It finds that relative scarcity may not always benefit resource sellers. Rather, when competition among resource investors passes a certain threshold intensity, miscoordination among investors increases to the point that sellers' expected profits decline. This paper extends the model to consider how investors organize to overcome managerial agency in resource evaluation. Two organizational designs are considered: (a) incentivization, wherein a lower-level manager is motivated by an incentive contract to evaluate resources for an investor, and (b) supervision, wherein evaluation is either handled directly or closely monitored by headquarters. The model suggests that competition among investors will be associated with a greater use of supervision and that investors using supervision will tend to make lower offers. This paper also finds that supervision will be more common when valuable resources are rare."
863,"Optimal Forecasting Groups","Lamberson, P. J. and Page, Scott E.","MANAGEMENT SCIENCE","58","4","805-810","2012","APR","Combining Forecasts;Optimal Groups;Information Aggregation","","This paper characterizes the optimal composition of a group for making a combined forecast. In the model, individual forecasters have types defined according to a statistical criterion we call type coherence. Members of the same type have identical expected accuracy, and forecasters within a type have higher covariance than forecasters of different types. We derive the optimal group composition as a function of predictive accuracy, between- and within-type covariance, and group size. Group size plays a critical role in determining the optimal group: in small groups the most accurate type should be in the majority, whereas in large groups the type with the least within-type covariance should dominate."
864,"Effect of Information Feedback on Bidder Behavior in Continuous Combinatorial Auctions","Adomavicius, Gediminas and Curley, Shawn P. and Gupta, Alok and Sanyal, Pallab","MANAGEMENT SCIENCE","58","4","811-830","2012","APR","Auctions;Combinatorial Auctions;Information Feedback;Bidder Behavior;Experimental Economics","","Combinatorial auctions-in which bidders can bid on combinations of goods-can increase the economic efficiency of a trade when goods have complementarities. Recent theoretical developments have lessened the computational complexity of these auctions, but the issue of cognitive complexity remains an unexplored barrier for the online marketplace. This study uses a data-driven approach to explore how bidders react to the complexity in such auctions using three experimental feedback treatments. Using cluster analyses of the bids and the clicks generated by bidders, we find three stable bidder strategies across the three treatments. Further, these strategies are robust for separate experiments using a different setup. We also benchmark the continuous auctions against an iterative form of combinatorial auction-the combinatorial clock auction. The enumeration of the bidding strategies across different types of feedback, along with the analysis of their economic implications, is offered to help practitioners design better combinatorial auction environments."
865,"Probability and Time Trade-Off","Baucells, Manel and Heukamp, Franz H.","MANAGEMENT SCIENCE","58","4","831-842","2012","APR","Risk Preferences;Time Preferences;Probability Discount Rate;Subendurance;Magnitude Effect;Psychological Distance","","Probability and time are integral dimensions of virtually any decision. To treat them together, we consider the prospect of receiving outcome x with a probability p at time t. We define risk and time distance, and show that if these two distances are traded off linearly, then preferences are characterized by three functions: a value function, a probability discount rate function, and a psychological distance function. The concavity of the psychological distance function explains the common ratio and common difference effects. A decreasing probability discount rate accounts for the magnitude effect. The discount rate and the risk premium depend on the shape of these three functions."
866,"Fighting City Hall: Entry Deterrence and Technology Upgrades in Cable TV Markets","Seamans, Robert C.","MANAGEMENT SCIENCE","58","3","461-475","2012","MAR","Entry;Entry Deterrence;Technology;Public-Private Interaction","","This article investigates how private firms respond to potential entry from public firms. This paper uses a data set of over 3,000 U.S. cable TV systems to present evidence consistent with entry deterrence. incumbent cable TV firms upgrade faster when located in markets with a potential municipal entrant. However, the same systems are then slower to offer new products enabled by the upgrade, suggesting upgrades in these markets occur for strategic reasons. Incumbent cable systems also upgrade faster in response to municipal entry threats than to private entry threats. Understanding how private firms respond to potential entry from public firms is especially important in light of recent U.S. government entry into several industries."
867,"Constant Proportion Debt Obligations: A Postmortem Analysis of Rating Models","Gordy, Michael B. and Willemann, Soren","MANAGEMENT SCIENCE","58","3","476-492","2012","MAR","Credit Risk;Securitization;Structured Credit;Rating Agencies;Stochastic Volatility","","In its complexity and its vulnerability to market volatility, the constant proportion debt obligation (CPDO) might be viewed as the poster child for the excesses of financial engineering in the credit market. This paper examines the CPDO as a case study in model risk in the rating of complex structured products. We demonstrate that the models used by Standard and Poor's (S&P) and Moody's fail in-sample specification tests even during the precrisis period and in particular understate the kurtosis of spread changes. Because stochastic volatility is the most natural explanation for the excess kurtosis, we estimate an extended version of the S&P model with stochastic volatility and find that the volatility-of-volatility is large and significant. An implication is that agency model-implied probabilities of attaining high spread levels were biased downward, which in turn biased the rating upward. We conclude with larger lessons for the rating of complex products and for modeling credit risk in general."
868,"Cutting in Line: Social Norms in Queues","Allon, Gad and Hanany, Eran","MANAGEMENT SCIENCE","58","3","493-506","2012","MAR","Queues;Games;Group Decisions;Social Norms","","Although the norm in many retail banks is to serve customers on a first-come, first-served basis, some customers try to cut the line, usually by providing an excuse for their urgency. In other queues, however, this behavior is considered unacceptable and is aggressively banned. In all of these cases, customer exhibit strategies that have not yet been explored in the operations literature: they choose whether or not to cut the line and must also decide whether to accept or reject such intrusions by others. This paper derives conditions for the emergence of such behavior in equilibrium among the customers themselves, i.e., when the queue manager is not involved in granting priorities and the customers have to use community enforcement to sustain such equilibria."
869,"Calendar Cycles, Infrequent Decisions, and the Cross Section of Stock Returns","Jagannathan, Ravi and Marakani, Srikant and Takehara, Hitoshi and Wang, Yong","MANAGEMENT SCIENCE","58","3","507-522","2012","MAR","Ccapm;Japanese Stock Market;Uk Stock Market;Cross Section Of Stock Returns;Infrequent Decisions;Deterministic Cycles;Calendar Cycles","","We show that when investors review their consumption and investment plans infrequently at different points in time with interim information flows, the standard consumption-based capital asset pricing model (CCAPM) will continue to hold only at those points in time when all investors review their plans. Stylized facts suggest that the end of the tax year is a candidate for one such points in time. Therefore, we should expect more support for the CCAPM during the period surrounding the end of the tax year, i.e., the fourth and first quarters in Japan where the tax year ends in December, and the first and second quarters in the United Kingdom where the tax year ends in April. Our empirical findings are consistent with these expectations."
870,"Is Leasing Greener Than Selling?","Agrawal, Vishal V. and Ferguson, Mark and Toktay, L. Beril and Thomas, Valerie M.","MANAGEMENT SCIENCE","58","3","523-533","2012","MAR","Durable Goods;Sustainable Operations;Green Marketing;Environment;Servicizing","","Based on the proposition that leasing is environmentally superior to selling, some firms have adopted a leasing strategy and others promote their existing leasing programs as environmentally superior to green their image. The argument is that because a leasing firm retains ownership of the off-lease units, it has an incentive to remarket them or invest in designing a more durable product, resulting in a lower volume of new production and disposal. However, leasing might be environmentally inferior because of the direct control the firm has over the off-lease products, which may prompt the firm to remove them from the market to avoid cannibalizing the demand for new products. Motivated by these issues, we adopt a life-cycle environmental impact perspective and analytically investigate if leasing can be both more profitable and have a lower total environmental impact. We find that leasing can be environmentally worse despite remarketing all off-lease products and greener than selling despite the mid-life removal of off-lease products. Our analysis also provides insights for environmental groups and entities that use different approaches to improve the environmental performance of business practices. We show that imposing disposal fees or encouraging remanufacturing, under some conditions, can actually lead to higher environmental impact. We also identify when educating consumers to be more environmentally conscious can improve the relative environmental performance of leasing."
871,"Density Forecasting of Intraday Call Center Arrivals Using Models Based on Exponential Smoothing","Taylor, James W.","MANAGEMENT SCIENCE","58","3","534-549","2012","MAR","Call Centers;Arrival Rate;Density Forecasting;Exponential Smoothing;Seasonality","","A key input to the call center staffing process is a forecast for the number of calls arriving. Density forecasts of arrival rates are needed for analytical call center models, which assume Poisson arrivals with a stochastic arrival rate. Density forecasts of call volumes can be used in simulation models and are also important for the analysis of outsourcing contracts. A forecasting method, which has previously shown strong potential, is Holt-Winters exponential smoothing adapted for modeling the intraday and intraweek cycles in intraday data. To enable density forecasting of the arrival volume and rate, we develop a Poisson count model, with gamma distributed arrival rate, which captures the essential features of this exponential smoothing method. The apparent stationary level in our data leads us to develop versions of the new model for series with stationary levels. We evaluate forecast accuracy up to two weeks ahead using data from three organizations. We find that the stationary level models improve prediction beyond approximately two days ahead, and that these models perform well in comparison with sophisticated benchmarks. This is confirmed by the results of a call center simulation model, which demonstrates the use of arrival rate density forecasting to support staffing decisions."
872,"Sequential Sampling with Economics of Selection Procedures","Chick, Stephen E. and Frazier, Peter","MANAGEMENT SCIENCE","58","3","550-569","2012","MAR","Simulation;Statistical Analysis;Probability;Diffusion;Decision Analysis;Dynamic Programming;Bayesian","","Sequential sampling problems arise in stochastic simulation and many other applications. Sampling is used to infer the unknown performance of several alternatives before one alternative is selected as best. This paper presents new economically motivated fully sequential sampling procedures to solve such problems, called economics of selection procedures. The optimal procedure is derived for comparing a known standard with one alternative whose unknown reward is inferred with sampling. That result motivates heuristics when multiple alternatives have unknown rewards. The resulting procedures are more effective in numerical experiments than any previously proposed procedure of which we are aware and are easily implemented. The key driver of the improvement is the use of dynamic programming to model sequential sampling as an option to learn before selecting an alternative. It accounts for the expected benefit of adaptive stopping policies for sampling, rather than of one-stage policies, as is common in the literature."
873,"Bayesian Dynamic Pricing Policies: Learning and Earning Under a Binary Prior Distribution","Harrison, J. Michael and Keskin, N. Bora and Zeevi, Assaf","MANAGEMENT SCIENCE","58","3","570-586","2012","MAR","Revenue Management;Pricing;Estimation;Bayesian Learning;Exploration-Exploitation","","Motivated by applications in financial services, we consider a seller who offers prices sequentially to a stream of potential customers, observing either success or failure in each sales attempt. The parameters of the underlying demand model are initially unknown, so each price decision involves a trade-off between learning and earning. Attention is restricted to the simplest kind of model uncertainty, where one of two demand models is known to apply, and we focus initially on performance of the myopic Bayesian policy (MBP), variants of which are commonly used in practice. Because learning is passive under the MBP (that is, learning only takes place as a by-product of actions that have a different purpose), it can lead to incomplete learning and poor profit performance. However, under one additional assumption, a constrained variant of the myopic policy is shown to have the following strong theoretical virtue: the expected performance gap relative to a clairvoyant who knows the underlying demand model is bounded by a constant as the number of sales attempts becomes large."
874,"Chasing a Moving Target: Exploitation and Exploration in Dynamic Environments","Posen, Hart E. and Levinthal, Daniel A.","MANAGEMENT SCIENCE","58","3","587-601","2012","MAR","Adaptation;Learning;Exploration;Exploitation;Turbulence","","A common justification for organizational change is that the circumstances in which the organization finds itself have changed, thereby eroding the value of utilizing existing knowledge. On the surface, the claim that organizations should adapt by generating new knowledge seems obvious and compelling. However, this standard wisdom overlooks the possibility that the reward to generating new knowledge may itself be eroded if change is an ongoing property of the environment. This observation in turn suggests that environmental change is not a self-evident call for strategies of greater exploration. Indeed, under some conditions the appropriate response to environmental change is a renewed focus on exploiting existing knowledge and opportunities. We develop a computational model based on the canonical multiarmed bandit formulation of exploration and exploitation. We endeavor to understand the mechanisms by which environmental change acts to make purposeful efforts at organizational adaptation less (or more) valuable."
875,"Multiattribute One-Switch Utility","Tsetlin, Ilia and Winkler, Robert L.","MANAGEMENT SCIENCE","58","3","602-605","2012","MAR","Decision Analysis;Multiattribute Utility;One-Switch Property;Utility Assessment;Sumex Utility","","The one-switch property states that the preference between any two lotteries switches at most once as wealth increases. Working within the expected utility framework, we extend the one-switch notion to the multiattribute case and identify the families of multiattribute utility functions that are one-switch. We then show that all multiattribute one-switch utility functions can be approximated by a sum of two multiattribute exponential utilities (sumex utility). Finally, we discuss how the one-switch property, when appropriate, can simplify the assessment of multiattribute utility."
876,"Managing Delegated Search Over Design Spaces","Erat, Sanjiv and Krishnan, Vish","MANAGEMENT SCIENCE","58","3","606-623","2012","MAR","Research And Development;Open Innovation;Product Design;Clustering;Search","","Organizations increasingly seek solutions to their open-ended design problems by employing a contest approach in which search over a solution space is delegated to outside agents. We study this new class of problems, which are costly to specify, pose credibility issues for the focal firm, and require finely tuned awards for meeting the firm's needs. Through an analytical model, we examine the relationship between problem specification, award structure, and breadth of solution space searched by outside agents toward characterizing how a firm should effectively manage such open-ended design contests. Our results independently establish and offer a causal explanation for an interesting phenomenon observed in design contests-clustering of searchers in specific regions of the solution space. The analysis also yields a cautionary finding-although the breadth of search increases with number of searchers, the relationship is strongly sublinear (logarithmic). Finally, from the practical perspective of managing the delegated search process, our results offer rules of thumb on how many and what size awards should be offered, as well as the extent to which firms should undertake problem specification, contingent on the nature (open-endedness and uncertainty) of the design problem solution being delegated to outside agents."
877,"Pricing Kernels with Stochastic Skewness and Volatility Risk","Chabi-Yo, Fousseni","MANAGEMENT SCIENCE","58","3","624-640","2012","MAR","Pricing Kernels;Risk Aversion;Skewness Preference;Volatility Risk","","I derive pricing kernels in which the market volatility is endogenously determined. Using the Taylor expansion series of the representative investor's marginal utility, I show that the price of market volatility risk is restricted by the investor's risk aversion and skewness preference. The risk aversion is estimated to be between two and five and is significant. The price of the market volatility is negative. Consistent with economic theory, I find that the pricing kernel decreases in the market index return and increases in market volatility. The projection of the estimated pricing kernel onto a polynomial function of the market return produces puzzling behaviors, which can be observed in the pricing kernel and absolute risk aversion functions. The inclusion of additional terms in the Taylor expansion series of the investor's marginal utility produces a pricing kernel function of market stochastic volatility, stochastic skewness, and stochastic kurtosis. The prices of risk of these moments are restricted by the investor's risk aversion, skewness preference, and kurtosis preference. The prices of risk of these moments should not be confused with the price of risk of powers of the market return, such as coskewness and cokurtosis."
878,"Optimal Compensation and Pay-Performance Sensitivity in a Continuous-Time Principal-Agent Model","Ju, Nengjiu and Wan, Xuhu","MANAGEMENT SCIENCE","58","3","641-657","2012","MAR","Continuous-Time Principal-Agent Models;Optimal Concave Contract;Stochastic Optimal Effort;Pay-Performance Sensitivity","","This paper studies the optimal contract between risk-neutral shareholders and a constant relative risk-aversion manager in a continuous-time model. Several interesting results are obtained. First, the optimal compensation is increasing but concave in output value if the manager is more risk averse than a log-utility manager. Second, when the manager has a log utility, a linear contract is optimal when there is no explicit lower bound on the compensation, and an option contract is optimal when there is an explicit lower bound. Third, optimal effort is stochastic (state dependent). Fourth, consistent with empirical findings and contrary to standard agency theory predictions, the relationship between pay-performance sensitivity and firm performance and that between pay-performance sensitivity and firm risk can be nonmonotonic."
879,"Beyond the Glass Ceiling: Does Gender Matter?","Adams, Renee B. and Funk, Patricia","MANAGEMENT SCIENCE","58","2, SI","219-235","2012","FEB","Directors;Gender;Boards;Values;Risk","","A large literature documents that women are different from men in their choices and preferences, but little is known about gender differences in the boardroom. If women must be like men to break the glass ceiling, we might expect gender differences to disappear among directors. Using a large survey of directors, we show that female and male directors differ systematically in their core values and risk attitudes, but in ways that differ from gender differences in the general population. These results are robust to controlling for differences in observable characteristics. Consistent with findings for the population, female directors are more benevolent and universally concerned but less power oriented than male directors. However, in contrast to findings for the population, they are less tradition and security oriented than their male counterparts. They are also more risk loving than male directors. Thus, having a woman on the board need not lead to more risk-averse decision making."
880,"Does the Rolodex Matter? Corporate Elite's Small World and the Effectiveness of Boards of Directors","Bang Dang Nguyen","MANAGEMENT SCIENCE","58","2, SI","236-252","2012","FEB","Social Networks;Ceo Turnover;Board Of Directors;Firm Performance;Corporate Governance","","This paper investigates the impact of social ties on the effectiveness of boards of directors. When the chief executive officer (CEO) and a number of directors belong to the same social networks, the CEO is less likely to be dismissed for poor performance. The results are robust to different measures of performance and networks, and consistent after controlling for CEO ability and connected boards' superior information. Although being ousted is costly for all CEOs-who must then devote time to finding new employment and only succeed in 62% of cases-socially connected CEOs are more likely to find new and better employment after a forced departure. Evidence from this paper suggests that close social ties between board members and CEOs impact the workings of the board of directors."
881,"Keynes Meets Markowitz: The Trade-Off Between Familiarity and Diversification","Boyle, Phelim and Garlappi, Lorenzo and Uppal, Raman and Wang, Tan","MANAGEMENT SCIENCE","58","2, SI","253-272","2012","FEB","Investment;Portfolio Choice;Ambiguity;Robust Control;Underdiversification","","We develop a model of portfolio choice to nest the views of Keynes, who advocates concentration in a few familiar assets, and Markowitz, who advocates diversification. We use the concepts of ambiguity and ambiguity aversion to formalize the idea of an investor's familiarity toward assets. The model shows that for any given level of expected returns, the optimal portfolio depends on two quantities: relative ambiguity across assets and the standard deviation of the expected return estimate for each asset. If both quantities are low, then the optimal portfolio consists of a mix of familiar and unfamiliar assets; moreover, an increase in correlation between assets causes an investor to increase concentration in familiar assets (flight to familiarity). Alternatively, if both quantities are high, then the optimal portfolio contains only the familiar asset(s), as Keynes would have advocated. In the extreme case in which both quantities are very high, no risky asset is held (nonparticipation)."
882,"A Global Equilibrium Asset Pricing Model with Home Preference","Solnik, Bruno and Zuo, Luo","MANAGEMENT SCIENCE","58","2, SI","273-292","2012","FEB","International Asset Pricing;Home Bias;Familiarity;Regret","","We develop a global equilibrium asset pricing model assuming that investors suffer from foreign aversion, a preference for home assets based on familiarity. Using a utility formulation inspired by regret theory, we derive closed-form solutions. When the degree of foreign aversion is high in a given country, investors place a high valuation on domestic equity, which results in a low expected return. Thus, the model generates the simple prediction that a country's degree of home bias and the expected return of its domestic assets should be inversely related. Our predicted relation between the degree of home bias and a country's expected return has the opposite sign predicted by models that assume some form of market segmentation. Using International Monetary Fund portfolio data, we find that expected returns are negatively related to home bias."
883,"Investor Sentiment and Analysts' Earnings Forecast Errors","Hribar, Paul and McInnis, John","MANAGEMENT SCIENCE","58","2, SI","293-307","2012","FEB","Accounting;Finance;Asset Pricing","","We correlate analysts' forecast errors with temporal variation in investor sentiment. We find that when sentiment is high, analysts' forecasts of one-year-ahead earnings and long-term earnings growth are relatively more optimistic for uncertain or difficult-to-value firms. Adding these forecast errors to a regression of stock returns on sentiment absorbs a sizable fraction of the explanatory power of sentiment for the cross section of future returns. This finding provides direct support for the notion that investor sentiment affects the earnings expectations of hard-to-value firms. Additional tests suggest that this bias in expectations is unlikely to be strategic in nature. Our results provide new insight into the mechanism through which investor sentiment affects returns."
884,"The Party's Over: The Role of Earnings Guidance in Resolving Sentiment-Driven Overvaluation","Seybert, Nicholas and Yang, Holly I.","MANAGEMENT SCIENCE","58","2, SI","308-319","2012","FEB","Finance;Asset Pricing;Management;Earnings Guidance;Investor Sentiment;Market Efficiency","","This paper shows that an important link between investor sentiment and firm. overvaluation is optimistic earnings expectations, and that management earnings guidance helps resolve sentiment-driven overvaluation. Using previously identified firm characteristics, we find that most of the negative returns to uncertain firms in months following high-sentiment periods fall within the three-day window around the issuance of management earnings guidance. Comparisons of guidance months to nonguidance months show that guidance issuance affects the magnitude and not just the daily distribution of negative returns. There is also some evidence of negative returns around earnings announcements for firms that previously issued guidance, suggesting that guidance does not entirely correct optimistic earnings expectations. To provide additional insight into the strength of the guidance effect, we show that the market reacts more strongly to surprises, particularly negative surprises, following high-sentiment periods. Finally, firms with higher transient institutional ownership are less likely to guide, and their guidance is less likely to contain bad news following high-sentiment periods, indicating that managers with a short-term focus are hesitant to correct optimistic market expectations."
885,"The Accrual Anomaly: Risk or Mispricing?","Hirshleifer, David and Hou, Kewei and Teoh, Siew Hong","MANAGEMENT SCIENCE","58","2, SI","320-335","2012","FEB","Capital Markets;Accruals;Market Efficiency;Behavioral Finance;Limited Attention","","We document considerable return comovement associated with accruals after controlling for other common factors. An accrual-based factor-mimicking portfolio has a Sharpe ratio of 0.16, higher than that of the market factor or the SMB and HML factors of Fama and French. According to rational frictionless asset pricing models, the ability of accruals to predict returns should come from the loadings on this accrual factor-mimicking portfolio. However, our tests indicate that it is the accrual characteristic rather than the accrual factor loading that predicts returns. These findings suggest that investors misvalue the accrual characteristic and cast doubt on the rational risk explanation."
886,"Investor Inattention and the Market Impact of Summary Statistics","Gilbert, Thomas and Kogan, Shimon and Lochstoer, Lars and Ozyildirim, Ataman","MANAGEMENT SCIENCE","58","2, SI","336-350","2012","FEB","Capital Markets;Stale Macroeconomic Information;Investor Inattention","","We show that U.S. stock and Treasury futures prices respond sharply to recurring stale information releases: In particular, we identify a unique macroeconomic series-the U.S. Leading Economic Index (R) (LET)-which is released monthly and constructed as a summary statistic of previously released inputs. We show that a front-running strategy that trades S&P 500 futures in the direction of the announcement a day before its release and then trades in the opposite direction of the announcement following its release generates an average annual return of close to 8%. These patterns are more pronounced for high beta stocks, for stocks that are more difficult to arbitrage, and during times when investors' sensitivity to firm-specific stale information is high. Treasury futures exhibit similar, albeit less pronounced, price patterns. Other measures of information arrival, such as price volatility and volume, spike following the release. These empirical findings suggest that some investors are inattentive to the stale nature of the information included in the LEI releases, instead interpreting it as new information, and thereby causing temporary yet significant mispricing."
887,"Market Madness? The Case of Mad Money","Engelberg, Joseph and Sasseville, Caroline and Williams, Jared","MANAGEMENT SCIENCE","58","2, SI","351-364","2012","FEB","Finance;Asset Pricing;Investment Criteria;Media;Attention","","We use the popular television show Mad Money, hosted by Jim Cramer, to test theories of attention and limits to arbitrage. Stock recommendations on Mad Money constitute attention shocks to a large audience of individual traders. We find that stock recommendations lead to large overnight returns that subsequently reverse over the next few months. The spike-reversal pattern is strongest among small, illiquid stocks that are hard to arbitrage. Using daily Nielsen ratings as a direct measure of attention, we find that the overnight return is strongest when high-income viewership is high. We also find weak price effects among sell, recommendations. Taken together, the evidence supports the retail attention hypothesis of Barber and Odean (Barber, B., T. Odean. 2008. All that glitters: The effect of attention and news on the buying behavior of individual and institutional investors. Rev. Financial Stud. 21(2) 785-818) and illustrates the potential role of media in generating mispricing."
888,"Do Cultural Differences Between Contracting Parties Matter? Evidence from Syndicated Bank Loans","Giannetti, Mariassunta and Yafeh, Yishay","MANAGEMENT SCIENCE","58","2, SI","365-383","2012","FEB","Financial Contracts;Risk Sharing;Behavioral Bias;Culture","","We investigate whether cultural differences between professional decision makers affect financial contracts in a large data set of international syndicated bank loans. We find that more culturally distant lead banks offer borrowers smaller loans at a higher interest rate and are more likely to require third-party guarantees. These effects do not disappear following repeated interaction between borrower and lender and are economically sizable: A one-standard-deviation increase in cultural distance, approximately the distance between Canada and the United States or between Japan and South Korea, is associated with a 6.5 basis point higher loan spread; the loan spread increases by about 23 basis points if the bank-firm match involves culturally more distant parties, for example, from Japan and the United States. We also find that cultural differences not only affect the relation between borrower and lender, but also hamper risk sharing between participant banks and culturally distant lead banks."
889,"Bubbles and Information: An Experiment","Sutter, Matthias and Huber, Juergen and Kirchler, Michael","MANAGEMENT SCIENCE","58","2, SI","384-393","2012","FEB","Finance;Experiment;Bubbles","","Asymmetric distribution of information, although omnipresent in real markets, is rarely considered in experimental economics. We study whether information about imminent future dividends can abate bubbles in experimental asset markets. We find that markets with asymmetrically informed traders have significantly smaller bubbles than markets with symmetrically informed or uninformed traders. Hence, fundamental values are better reflected in market prices-implying higher market efficiency-when some traders know more than others about future dividends. This suggests that bubbles are abated when traders know that a subset of them have an edge (in information) over others."
890,"A Transaction-Level Analysis of Spatial Arbitrage: The Role of Habit, Attention, and Electronic Trading","Overby, Eric and Clarke, Jonathan","MANAGEMENT SCIENCE","58","2, SI","394-412","2012","FEB","Spatial Arbitrage;Seller Distribution;Decision Making;Habit;Attention Allocation;Market Efficiency;Electronic Trading;Information Technology;Automotive","","Despite the central role of arbitrage in finance and economic theory, there is limited evidence of the factors that create and eliminate arbitrage opportunities, how often arbitrage occurs, and how profitable it is. We address these gaps via a transaction-level analysis of spatial arbitrage in the wholesale automotive market. We investigate why arbitrage opportunities are created by analyzing how sellers choose where to sell vehicles. We find that the attention sellers pay to the distribution of a vehicle is negatively related to the probability that it is arbitraged. Arbitrage occurs in approximately 1% of transactions, although electronic trading is making arbitrage less prevalent by improving buyer/seller matching across locations. Arbitrage yields a 5.6% return on average, although arbitrageurs take a loss 14% of the time. Our results contribute to the literature on arbitrage, the effect of attention allocation on market outcomes, and the effect of information technology on market efficiency."
891,"Penny Wise, Dollar Foolish: Buy-Sell Imbalances On and Around Round Numbers","Bhattacharya, Utpal and Holden, Craig W. and Jacobsen, Stacey","MANAGEMENT SCIENCE","58","2, SI","413-431","2012","FEB","Cognitive Reference Points;Round Numbers;Left-Digit Effect;Nine-Ending Prices;Trading Strategies","","This paper provides evidence that stock traders focus on round numbers as cognitive reference points for value. Using a random sample of more than 100 million stock transactions, we find excess buying (selling) by liquidity demanders at all price points one penny below (above) round numbers. Further, the size of the buy-sell imbalance is monotonic in the roundness of the adjacent round number (i.e., largest adjacent to integers, second-largest adjacent to half-dollars, etc.). Conditioning on the price path, we find much stronger excess buying (selling) by liquidity demanders when the ask falls (bid rises) to reach the integer than when it crosses the integer. We discuss and test three explanations for these results. Finally, 24-hour returns also vary by price point, and buy-sell imbalances are a major determinant of that variation across price points. Buying (selling) by liquidity demanders below (above) round numbers yield losses approaching $1 billion per year."
892,"Initial Public Offerings as Lotteries: Skewness Preference and First-Day Returns","Green, T. Clifton and Hwang, Byoung-Hyoun","MANAGEMENT SCIENCE","58","2, SI","432-444","2012","FEB","Lotteries;Skewness Preference;Ipo Underpricing","","We find that initial public offerings (IPOs) with high expected skewness experience significantly greater first-day returns. The skewness effect is stronger during periods of high investor sentiment and is related to differences in skewness across industries as well as to time-series variation in the level of skewness in the market. IPOs with high expected skewness earn more negative abnormal returns in the following one to five years. High expected skewness is also associated with a higher fraction of small-sized trades on the first day of trading, which is consistent with a greater shift in holdings from institutions to individuals. The results suggest that first-day IPO returns are related to a preference for skewness."
893,"Prospect Theory, Liquidation, and the Disposition Effect","Henderson, Vicky","MANAGEMENT SCIENCE","58","2, SI","445-460","2012","FEB","Prospect Theory;Behavioral Finance;Disposition Effect;Liquidation;Optimal Stopping","","There is a well-known intuition linking prospect theory with the disposition effect, the tendency of investors to sell assets that have risen in value rather than fallen. Recently, several authors have studied rigorous models in an attempt to formalize the intuition. However, some have found it difficult to predict a disposition effect while others produce a more extreme prediction where investors never voluntarily sell at a loss. We solve a model of asset liquidation where investors realize utility over gains and losses, and utility is concave over gains and convex over losses. Under the preferences of Tversky and Kahneman (Tversky, A., D. Kahneman. 1992. Advances in prospect theory: Cumulative representation of uncertainty. J. Risk Uncertainty 5(4) 297-323) and lognormal asset prices, investors exhibit a disposition effect as gains are realized at a greater rate than losses. Nonetheless, in contrast to the extant literature, we find that the investor will give up and sell at a loss when the asset has a sufficiently low Sharpe ratio."
894,"Split or Steal? Cooperative Behavior When the Stakes Are Large","van den Assem, Martijn J. and van Dolder, Dennie and Thaler, Richard H.","MANAGEMENT SCIENCE","58","1, 1, SI","2-20","2012","JAN","Natural Experiment;Game Show;Prisoner'S Dilemma;Cooperation;Cooperative Behavior;Social Behavior;Social Preferences;Reciprocity;Reciprocal Behavior;Context Effects;Anchoring","","We examine cooperative behavior when large sums of money are at stake, using data from the television game show Golden Balls. At the end of each episode, contestants play a variant on the classic prisoner's dilemma for large and widely ranging stakes averaging over $20,000. Cooperation is surprisingly high for amounts that would normally be considered consequential but look tiny in their current context, what we call a big peanuts phenomenon. Utilizing the prior interaction among contestants, we find evidence that people have reciprocal preferences. Surprisingly, there is little support for conditional cooperation in our sample. That is, players do not seem to be more likely to cooperate if their opponent might be expected to cooperate. Further, we replicate earlier findings that males are less cooperative than females, but this gender effect reverses for older contestants because men become increasingly cooperative as their age increases."
895,"The Behavioral Genetics of Behavioral Anomalies","Cesarini, David and Johannesson, Magnus and Magnusson, Patrik K. E. and Wallace, Bjorn","MANAGEMENT SCIENCE","58","1, 1, SI","21-34","2012","JAN","Behavioral Anomalies;Behavior Genetics;Heuristics And Biases","","A number of recent papers have examined the environmental and genetic sources of individual differences in economic and financial decision making. Here we contribute to this burgeoning literature by extending it to a number of key behavioral anomalies that are thought to be of importance for consumption, savings, and portfolio selection decisions. Using survey-based evidence from more than 11,000 Swedish twins, we demonstrate that a number of anomalies such as, for instance, the conjunction fallacy, default bias, and loss aversion are moderately heritable, in contrast, our estimates imply that variation in common environment explains only a small share of individual differences. We also report suggestive evidence in favor of a shared genetic architecture between cognitive reflection and a subset of the studied anomalies. These results offer some support for the proposition that the heritable variation in behavioral anomalies is partly mediated by genetic variance in cognitive ability. Taken together with previous findings, our results underline the importance of genetic differences as a source of heterogeneity in economic and financial decision making."
896,"A Model of Casino Gambling","Barberis, Nicholas","MANAGEMENT SCIENCE","58","1, 1, SI","35-51","2012","JAN","Gambling;Prospect Theory;Time Inconsistency;Probability Weighting","","We show that prospect theory offers a rich theory of casino gambling, one that captures several features of actual gambling behavior. First, we demonstrate that for a wide range of preference parameter values, a prospect theory agent would be willing to gamble in a casino even if the casino offers only bets with no skewness and with zero or negative expected value. Second, we show that the probability weighting embedded in prospect theory leads to a plausible time inconsistency: at the moment he enters a casino, the agent plans to follow one particular gambling strategy; but after he starts playing, he wants to switch to a different strategy. The model therefore predicts heterogeneity in gambling behavior: how a gambler behaves depends on whether he is aware of the time inconsistency; and, if he is aware of it, on whether he can commit in advance to his initial plan of action."
897,"The Impact of Personal Experience on Behavior: Evidence from Video-Rental Fines","Haselhuhn, Michael P. and Pope, Devin G. and Schweitzer, Maurice E. and Fishman, Peter","MANAGEMENT SCIENCE","58","1, 1, SI","52-61","2012","JAN","Behavioral Economics;Decision Making;Backward-Looking Behavior;Decisions Following Descriptions Versus Experience;Learning","","Personal experience matters. In a field setting with longitudinal data, we disentangle the effects of learning new information from the effects of personal experience. We demonstrate that experience with a fine, controlling for the effect of learning new information, significantly boosts future compliance. We also show that experience with a large fine boosts compliance more than experience with a small fine, but that the influence of experience with both large and small fines decays sharply over time."
898,"Norms and Contracting","Kessler, Judd B. and Leider, Stephen","MANAGEMENT SCIENCE","58","1, 1, SI","62-77","2012","JAN","Experiment;Norms;Incomplete Contracts","","We argue that contracts establish the norms of a relationship and that individuals incur disutility when deviating from these norms. In a laboratory experiment, we allow agents to make simple contracts before they play one of four games, and the most effective contract always includes an unenforceable handshake agreement to take the first-best action. In three games, a contract with only this handshake agreement is (at least weakly) optimal. The handshake is particularly effective in games with strategic complements. Our results highlight an explanation for contractual incompleteness: establishing a norm can effectively substitute for weak enforceable restrictions."
899,"The Impact of Gender Composition on Team Performance and Decision Making: Evidence from the Field","Apesteguia, Jose and Azmat, Ghazala and Iriberri, Nagore","MANAGEMENT SCIENCE","58","1, 1, SI","78-93","2012","JAN","Gender;Teams;Performance;Decision Making","","We investigate whether the gender composition of teams affects their economic performance. We study a large business game, played in groups of three, in which each group takes the role of a general manager. There are two parallel competitions, one involving undergraduates and the other involving MBA students. Our analysis shows that teams formed by three women are significantly outperformed by all other gender combinations, both at the undergraduate and MBA levels. Looking across the performance distribution, we find that for undergraduates, three-women teams are outperformed throughout, but by as much as 0.47 of a standard deviation of the mean at the bottom and by only 0.09 at the top. For MBA students, at the top, the best performing group is two men and one woman. The differences in performance are explained by differences in decision making. We observe that three-women teams are less aggressive in their pricing strategies, invest less in research and development, and invest more in social sustainability initiatives than does any other gender combination."
900,"Feedback, Self-Esteem, and Performance in Organizations","Kuhnen, Camelia M. and Tymula, Agnieszka","MANAGEMENT SCIENCE","58","1, 1, SI","94-113","2012","JAN","Organizational Studies;Personnel;Motivation-Incentives;Productivity","","We examine whether private feedback about relative performance can mitigate moral hazard in competitive environments by modifying the agents' self-esteem. In our experimental setting, people work harder and expect to rank better when told that they may learn their ranking, relative to cases when feedback will not be provided. Individuals who ranked better than expected decrease output but expect a better rank in the future, whereas those who ranked worse than expected increase output but lower their future rank expectations. Feedback helps create a ratcheting effect in productivity, mainly because of the fight for dominance at the top of the rank hierarchy. Our findings suggest that organizations can improve employee productivity by changing the likelihood of feedback, the reference group used to calculate relative performance, and the informativeness of the feedback message."
901,"Gender, Competition, and Managerial Decisions","Price, Curtis R.","MANAGEMENT SCIENCE","58","1, 1, SI","114-122","2012","JAN","Decision Analysis;Labor Market;Discrimination;Gender Differences;Experiment","","The purpose of this study is to investigate the use of competitive compensation between a manager and a worker in the laboratory. To this end, we impose a simple agency relationship between two groups of subjects termed managers and workers. The manager chooses a compensation scheme for the worker from either a piece rate or a tournament payment scheme and is paid based on the workers performance in the task. The results indicate that when given information about worker ability, male managers choose the tournament significantly less often for a female worker. On the other hand, when no information about worker ability is given to the manager, there is no difference in compensation choice for the worker, although male and female managers differ significantly in their own preferences for compensation scheme. We conjecture that these results are tied to the fact that there is a measurable stereotype that females are worse at the task relative to males, although further research is needed in this regard."
902,"Aggregation and Manipulation in Prediction Markets: Effects of Trading Mechanism and Information Distribution","Jian, Lian and Sami, Rahul","MANAGEMENT SCIENCE","58","1, 1, SI","123-140","2012","JAN","Prediction Markets;Experiments;Market Scoring Rule","","We conduct laboratory experiments on variants of market scoring rule prediction markets, under different information distribution patterns, to evaluate the efficiency and speed of information aggregation, as well as test recent theoretical results on manipulative behavior by traders. We find that markets structured to have a fixed sequence of trades exhibit greater accuracy of information aggregation than the typical form that has unstructured trade. In comparing two commonly used mechanisms, we find no significant difference between the performance of the direct probability-report form and the indirect security-trading form of the market scoring rule. In the case of the markets with a structured order, we find evidence supporting the theoretical prediction that information aggregation is slower when information is complementary. In structured markets, the theoretical prediction that there will be more delayed trading in complementary markets is supported, but we find no support for the prediction that there will be more bluffing in complementary markets. However, the theoretical predictions are not borne out in the unstructured markets."
903,"Apologies as Signals: With Evidence from a Trust Game","Ho, Benjamin","MANAGEMENT SCIENCE","58","1, 1, SI","141-158","2012","JAN","Apologies;Remorse;Signaling;Trust Game;Attribution Theory","","Apologies are part of a social institution designed to restore frayed relationships not only in daily life but also in the domains of corporate governance, medical malpractice litigation, political reputation, organizational culture, etc. The theory shows that in a general class of moral hazard games with imperfect information about agents with two-dimensional type, apologies exhibit regular properties-e.g., apologies are more frequent in long relationships, early in relationships, and between better-matched partners. A variant of the trust game demonstrates that communication matters in a manner consistent with economic theory; specifically, the words I am sorry appear to select equilibrium behavior consistent with the theory's main predictions."
904,"A Case-Based Model of Probability and Pricing Judgments: Biases in Buying and Selling Uncertainty","Brenner, Lyle A. and Griffin, Dale W. and Koehler, Derek J.","MANAGEMENT SCIENCE","58","1, 1, SI","159-178","2012","JAN","Probability;Finance;Asset Pricing;Decision Analysis;Prospect Theory;Value Function;Forecasting","","We integrate a case-based model of probability judgment with prospect theory to explore asset pricing under uncertainty. Research within the heuristics and biases tradition suggests that probability judgments respond primarily to case-specific evidence and disregard aggregate characteristics of the class to which the case belongs, resulting in predictable biases. The dual-system framework presented here distinguishes heuristic assessments of value and evidence strength from deliberative assessments that incorporate prior odds and likelihood ratios following Bayes' rule. Hypotheses are derived regarding the relative sensitivity of judged probabilities, buying prices, and selling prices to case- versus class-based evidence. We test these hypotheses using a simulated stock market in which participants can learn from experience and have incentives for accuracy. Valuation of uncertain assets is found to be largely case based even in this economic setting; however, consistent with the framework's predictions, distinct patterns of miscalibration are found for buying prices, selling prices, and probability judgments."
905,"Paying to Be Nice: Consistency and Costly Prosocial Behavior","Gneezy, Ayelet and Imas, Alex and Brown, Amber and Nelson, Leif D. and Norton, Michael I.","MANAGEMENT SCIENCE","58","1, 1, SI","179-187","2012","JAN","Charitable Giving;Moral Consistency;Licensing;Field Experiment","","Building on previous research in economics and psychology, we propose that the costliness of initial prosocial behavior positively influences whether that behavior leads to consistent future behaviors. We suggest that costly prosocial behaviors serve as a signal of prosocial identity and that people subsequently behave in line with that self-perception. In contrast, costless prosocial acts do not signal much about one's prosocial identity, so subsequent behavior is less likely to be consistent and may even show the reductions in prosocial behavior associated with licensing. The results of a laboratory experiment and a large field experiment converge to support our account."
906,"Imprecise Data Sets as a Source of Ambiguity: A Model and Experimental Evidence","Arad, Ayala and Gayer, Gabrielle","MANAGEMENT SCIENCE","58","1, 1, SI","188-202","2012","JAN","Decision Analysis;Theory;Inference;Uncertainty","","In many circumstances, evaluations are based on empirical data. However, some observations may be imprecise, meaning that it is not entirely clear what occurred in them. We address the question of how beliefs are formed in these situations. The individual in our model is essentially a frequentist. He first makes a subjective judgment about the occurrence of the event for each imprecise observation. This may be any number between zero and one. He then evaluates the event by its subjective frequency of occurrence. Our model connects the method of processing imprecise observations with the individual's attitude toward ambiguity. An individual who in imprecise observations puts low (high) weight on the possibility that an event occurred is ambiguity averse (loving). An experiment supports the main assertions of the model: with precise data, subjects behave as if there were no ambiguity, whereas with imprecise data subjects turn out to be ambiguity averse."
907,"A Multimethod Approach to Identifying Norms and Normative Expectations Within a Corporate Hierarchy: Evidence from the Financial Services Industry","Burks, Stephen V. and Krupka, Erin L.","MANAGEMENT SCIENCE","58","1, 1, SI","203-217","2012","JAN","Ethics;Norms;Vignette;Survey;Coordination Game;Incentive Compatible;Financial Services;Financial Adviser;Whistle-Blowing;Fiduciary Responsibility;Organizational Fit","","We use an incentive-compatible economic experiment and surveys in the field at a large financial services firm to identify the norms for on-the-job behavior among financial advisers and their leaders, and the normative expectations each group has of the other. We examine whistle-blowing on a peer, an incentive clash between serving the client and earning commissions, and a dilemma about fiduciary responsibility to a client. We find patterns of agreement among advisers, among leaders, and between the two groups, that are consistent with company guidelines identified ex ante. However, we also find measurable differences between what leaders expect and the actual norms of advisers. When there is such a mismatch we are able to distinguish mis-communication from ethical disagreement between leaders and advisers. Finally, we show that when advisers' personal ethical opinions do not match group norms, this mismatch is correlated with job dissatisfaction and lying for money in a second experiment."
908,"Corporate Governance, Debt, and Investment Policy During the Great Depression","Graham, John R. and Hazarika, Sonali and Narasimhan, Krishnamoorthy","MANAGEMENT SCIENCE","57","12","2083-2100","2011","DEC","Corporate Governance;Capital Structure;Investment Policy;Great Depression;Stock Market Value","","We study a period of severe disequilibrium to investigate whether board characteristics are related to corporate investment, debt usage, and firm value. During the 1930-1938 Depression era, when the corporate sector was shocked by an unprecedented downturn, we document a relation between board characteristics and firm performance that varies in economically sensible ways: Complex firms (that would benefit more from board advice) exhibit a positive relation between board size and firm value, and simple firms exhibit a negative relation between board size and firm value. Moreover, simple firms with large boards do not downsize adequately in response to the severe economic contraction: they invest more (or shrink less) and use more debt during the 1930s. We document similar effects for the number of outside directors on the board. Finally, we also find that companies with properly aligned governance structures are more likely to replace the company president following poor performance."
909,"How Do Acquirers Retain Successful Target CEOs? The Role of Governance","Wulf, Julie and Singh, Harbir","MANAGEMENT SCIENCE","57","12","2101-2114","2011","DEC","Organizational Studies;Strategy;Motivation-Incentives;Finance;Corporate Finance","","The resource-based view argues that acquisitions can build competitive advantage partially through retention of valuable human capital of the target firm. However, making commitments to retain and motivate successful top managers is a challenge when contracts are not enforceable. Investigating the conditions under which target chief executive officers (CEOs) are retained in a sample of mergers in the 1990s, we find greater retention of better-performing and higher-paid CEOs-both measures of valuable human capital. We also show that the performance-retention link is stronger when the acquirer's governance provisions support managers and when the acquirer's CEO owns more equity. Although it is not common for acquirers to retain target CEOs, we argue that they are more likely to do so when their governance environment maintains managerial discretion. Based on a joint analysis of retention and governance, our findings are largely consistent with a managerial human capital explanation of retention."
910,"Monte Carlo Algorithms for Default Timing Problems","Giesecke, Kay and Kim, Baeho and Zhu, Shilin","MANAGEMENT SCIENCE","57","12","2115-2129","2011","DEC","Simulation;Probability;Stochastic Model Applications;Financial Institutions;Banks","","Dynamic, intensity-based point process models are widely used to measure and price the correlated default risk in portfolios of credit-sensitive assets such as loans and corporate bonds. Monte Carlo simulation is an important tool for performing computations in these models. This paper develops, analyzes, and evaluates two simulation algorithms for intensity-based point process models. The algorithms extend the conventional thinning scheme to the case where the event intensity is unbounded, a feature common to many standard model formulations. Numerical results illustrate the performance of the algorithms for a familiar top-down model and a novel bottom-up model of correlated default risk."
911,"Efficient Two-Dimensional Packing Algorithms for Mobile WiMAX","Lodi, Andrea and Martello, Silvano and Monaci, Michele and Cicconetti, Claudio and Lenzini, Luciano and Mingozzi, Enzo and Eklund, Carl and Moilanen, Jani","MANAGEMENT SCIENCE","57","12","2130-2144","2011","DEC","Mobile Wimax;Two-Dimensional Packing;Computational Complexity;Experimental Analysis","","We present the result of research, developed within Nokia Siemens Networks, to solve the downlink subframe allocation problem in Mobile WiMAX (IEEE 802.16) technology in its full complexity, while simultaneously fulfilling real-life constraints on processing power and delay. We describe the IEEE 802.16 standard, and introduce two system models. A theoretical analysis of the two-dimensional packing problems originated by such models shows that they are both NP-hard in the strong sense. From a practical point of view, the processing budget for scheduling in the base station was estimated to be 1 ms on a state-of-the-art PC. Thus, we introduce two highly efficient heuristics that were developed to handle the system practically. A thorough computational analysis of their optimization characteristics and a system-level evaluation in realistic scenarios proved that the algorithms offer significant capacity gain in Mobile WiMAX systems that translate to increased operator revenues."
912,"A Multiechelon Inventory Problem with Secondary Market Sales","Angelus, Alexandar","MANAGEMENT SCIENCE","57","12","2145-2162","2011","DEC","Inventory Theory;Multiechelon;Stock Disposals;Secondary Markets;Dynamic Programming;Optimal Policy;Heuristics;Echelon Base-Stock Policy","","We consider a finite-horizon, multiechelon inventory system in which the surplus of stock can be sold (i.e., disposed) in the secondary markets at each stage in the system. What are called nested echelon order-up-to policies are shown to be optimal for jointly managing inventory replenishments and secondary market sales. Under a general restriction on model parameters, we establish that it is optimal not to both sell off excess stock and replenish inventory. Secondary market sales complicate the structure of the system, so that the classical Clark and Scarf echelon reformulation no longer allows for the decomposition of the objective function under the optimal policy. We introduce a novel class of policies, referred to as the disposal saturation policies, and show that there exists a disposal saturation policy, determined recursively by a single base-stock level at each echelon, that achieves the decomposition of this problem. The resulting optimal replenishment policy is shown to be the echelon base-stock policy. We demonstrate the heuristic performance of this disposal saturation policy through a series of numerical studies: except at extreme ranges of model parameters, the policy provides a very good approximation to the optimal policy while avoiding the curse of dimensionality. We also conduct numerical studies to determine the value of the secondary markets for multistage supply chains and assess its sensitivity to model parameters. The results provide potentially useful insights for companies seeking to enter or develop secondary markets for supply chains."
913,"Stochastic Capacity Investment and Flexible vs. Dedicated Technology Choice in Imperfect Capital Markets","Boyabatli, Onur and Toktay, L. Beril","MANAGEMENT SCIENCE","57","12","2163-2179","2011","DEC","Capacity;Flexibility;Financing;Newsvendor;Limited Liability;Market Imperfection","","This paper analyzes the impact of endogenous credit terms under capital market imperfections in a capacity investment setting. We model a monopolist firm that decides on its technology choice (flexible versus dedicated) and capacity level under demand uncertainty. Differing from the majority of the stochastic capacity investment literature, we assume that the firm is budget constrained and can relax its budget constraint by borrowing from a creditor. The creditor offers technology-specific loan contracts to the firm, after which the firm makes its technology choice and subsequent decisions. Capital market imperfections impose financing frictions on the firm. Our analysis contributes to the capacity investment literature by extending the theory of stochastic capacity investment and flexible versus dedicated technology choice to understand the impact of capital market imperfections, and by analyzing the impact of demand uncertainty (variability and correlation) on the operational decisions and the performance of the firm under different capital market conditions. We demonstrate that the endogenous nature of credit terms in imperfect capital markets may modify or reverse conclusions concerning capacity investment and technology choice obtained under the perfect market assumption and we explain why. The theory developed in this paper suggests some rules of thumb for the strategic management of the capacity and technology choice in imperfect capital markets."
914,"Securitization and Real Investment in Incomplete Markets","Gaur, Vishal and Seshadri, Sridhar and Subrahmanyam, Marti G.","MANAGEMENT SCIENCE","57","12","2180-2196","2011","DEC","Incomplete Markets;Securitization;Financial Innovation;Real Options;Project Financing","","We study the impact of financial innovations on real investment decisions within the framework of an incomplete market economy comprised of firms, investors, and an intermediary. The firms face unique investment opportunities that arise in their business operations and can be undertaken at given reservation prices. The cash flows thus generated are not spanned by the securities traded in the financial market and cannot be valued uniquely. The intermediary purchases claims against these cash flows, pools them together, and sells tranches of primary or secondary securities to the investors. We derive necessary and sufficient conditions under which projects are undertaken due to the intermediary's actions, and firms are amenable to the pool proposed by the intermediary, compared to the no-investment option or the option of forming alternative pools. We also determine the structure of the new securities created by the intermediary and identify how it exploits the arbitrage opportunities available in the market. Our results have implications for valuation of real investments, synergies among them, and their financing mechanisms. We illustrate these implications using an example of inventory decisions under random demand."
915,"How Do Financial Firms Manage Risk? Unraveling the Interaction of Financial and Operational Hedging","Hankins, Kristine Watson","MANAGEMENT SCIENCE","57","12","2197-2212","2011","DEC","Finance;Corporater Finance;Financial Institutions;Banks;Risk Management","","This paper investigates how firms manage risk by examining the relationship between financial and operational hedging using a sample of bank holding companies. Risk management theory holds that capital market imperfections make cash flow volatility costly. I investigate whether financial firms consider this cost or focus exclusively on managing tradable exposures. After documenting that acquisitions provide operational hedging by reducing potentially costly volatility, I find that postacquisition financial hedging declines even after controlling for the specific underlying risks. In addition, the decrease in financial hedging is related to the acquisition's level of operational hedging. Larger increases in operational hedging are followed by larger declines in financial hedging. These results indicate that firms in this sample manage aggregate risk, not just tradable exposures, and that operational hedging can substitute for financial hedging."
916,"Evaluating Value-at-Risk Models with Desk-Level Data","Berkowitz, Jeremy and Christoffersen, Peter and Pelletier, Denis","MANAGEMENT SCIENCE","57","12","2213-2227","2011","DEC","Risk Management;Backtesting;Volatility;Disclosure","","We present new evidence on disaggregated profit and loss (P/L) and value-at-risk (VaR) forecasts obtained from a large international commercial bank. Our data set includes the actual daily P/L generated by four separate business lines within the bank. All four business lines are involved in securities trading and each is observed daily for a period of at least two years. Given this unique data set, we provide an integrated, unifying framework for assessing the accuracy of VaR forecasts. We use a comprehensive Monte Carlo study to assess which of these many tests have the best finite-sample size and power properties. Our desk-level data set provides importance guidance for choosing realistic P/L-generating processes in the Monte Carlo comparison of the various tests. The conditional autoregressive value-at-risk test of Engle and Manganelli (2004) performs best overall, but duration-based tests also perform well in many cases."
917,"Multiechelon Procurement and Distribution Policies for Traded Commodities","Goel, Ankur and Gutierrez, Genaro J.","MANAGEMENT SCIENCE","57","12","2228-2244","2011","DEC","Commodity Procurement;Commodity Markets;Marginal Convenience Yield;Multiechelon Inventory Management","","We consider a firm that procures and distributes a commodity from spot and forward markets under randomly fluctuating prices; the commodity is distributed downstream to a set of nonhomogeneous retailers to satisfy random demand. We formulate a model that allows one to compute approximate, but near optimal, procurement and distribution policies for this system, and we explore the value of the commodity's market in providing managers with (a) additional flexibility in procurement and (b) information on price dynamics generated through the trading of futures contracts. Our results indicate that the presence of the commodity market and the information that it conveys may lead to significant reductions in inventory-related costs; however, to obtain these benefits, both the spot procurement flexibility and the term structure of prices generated by the commodity market must be incorporated in the formulation of the operating policy. Managerial insights on the procurement strategy as a function of variability in prices and demand are also discussed."
918,"The Effects of Focus on Performance: Evidence from California Hospitals","Singh, Diwas K. C. and Terwiesch, Christian","MANAGEMENT SCIENCE","57","11","1897-1912","2011","NOV","Productivity;Quality;Health-Care Operations;Service Operations","","We use hospital-level discharge data from cardiac patients in California to estimate the effects of focus on operational performance. We examine focus at three distinct levels of the organization-at the firm level, at the operating unit level, and at the process flow level. We find that focus at each of these levels is associated with improved outcomes, namely, faster services at higher levels of quality, as indicated by lower lengths of stay (LOS) and reduced mortality rates. We then analyze the extent to which the superior operational outcome is driven by focused hospitals truly excelling in their operations or by focused hospitals simply cherry-picking easy-to-treat patients. To do this, we use an instrumental variables estimation strategy that effectively randomizes the assignment of patients to hospitals. After controlling for selective patient admissions, the previously observed benefits of firm level focus disappear; focused hospitals no longer demonstrate a statistically significant reduction in LOS or mortality rate. However, at more granular measures of focus within the hospital (e.g., operating unit level), we find that more focus leads to a shorter LOS, even after controlling for selective admission effects."
919,"Competing Matchmakers: An Experimental Analysis","Hossain, Tanjim and Minor, Dylan and Morgan, John","MANAGEMENT SCIENCE","57","11","1913-1925","2011","NOV","Platform Competition;Two-Sided Markets;Monopoly;E-Commerce","","Platform competition is ubiquitous, yet platform market structure is little understood. Theory models typically suffer from equilibrium multiplicity-platforms might coexist or the market might tip to either platform. We use laboratory experiments to study the outcomes of platform competition. When platforms are primarily vertically differentiated, we find that even when platform coexistence is theoretically possible, markets inevitably tip to the more efficient platform. When platforms are primarily horizontally differentiated, so there is no single efficient platform, we find strong evidence of equilibrium coexistence."
920,"Covenants in Venture Capital Contracts","Bengtsson, Ola","MANAGEMENT SCIENCE","57","11","1926-1943","2011","NOV","Financial Contracting;Venture Capital;Entrepreneurship","","This paper studies how covenants are included in contracts between venture capitalists (VCs) and entrepreneurs. I show that VCs hold covenanted veto rights even though they are shareholders who have access to other powerful governance solutions. Unlike bank loans and bonds, venture capital (VC) contracts exhibit considerable variation in their contractual designs. I exploit this variation to confirm the argument that covenants are in place to overcome a conflict of interest that arises from debt-like contractual features of a venture capitalist's preferred stock. In particular, I find that contracts with higher fixed payoffs include 1.6 more covenants than do contracts with lower fixed payoffs. Similarly, VC contracts with no VC board majority requirement include 0.6 more covenants than do contracts that require a VC board majority. Covenants are also more common with older companies and when fewer VCs invest in a round. My findings contribute to both the debt covenant literature and the entrepreneurial finance literature."
921,"Cooperation Without Enforcement? A Comparative Analysis of Litigation and Online Reputation as Quality Assurance Mechanisms","Bakos, Yannis and Dellarocas, Chrysanthos","MANAGEMENT SCIENCE","57","11","1944-1962","2011","NOV","Reputation;Litigation;Reputation And Litigation Trade-Off;Reputation In Markets;Private Ordering;Reputation And Adverse Selection;Litigation And Moral Hazard","","Commerce depends on buyers and sellers fulfilling their contractual obligations; mechanisms inducing such performance are essential to well-functioning markets. Internet-enabled reputation mechanisms that collect and disseminate consumer feedback have emerged as prominent means for inducing seller performance in online and offline markets. This paper compares the ability of reputation and more traditional litigation-like mechanisms for dispute resolution to induce efficient economic outcomes. We use a game-theoretic formulation and derive results for their relative efficiency and effectiveness individually or as complements. We find that the popular view of reputation as an efficient and relatively costless way to induce seller effort under all circumstances is incorrect; reputation is less efficient than litigation in inducing any given level of effort. Thus, reputation improves efficiency only in settings where the high cost of litigation, insufficient damage levels, or low court accuracy induce suboptimal effort or cause market failure. When adverse selection is important, reputation helps reveal the true types of market participants, which may offset its higher cost of inducing effort. Finally, adding reputation to existing litigation mechanisms increases seller effort and may require adjusting damage awards to avoid inducing excessive effort that reduces economic efficiency."
922,"Skill, Luck, and the Multiproduct Firm: Evidence from Hedge Funds","de Figueiredo, Jr., Rui J. P. and Rawley, Evan","MANAGEMENT SCIENCE","57","11","1963-1978","2011","NOV","Organizational Studies;Strategy;Financial Institutions;Investment;Economics;Econometric Dynamics","","We formalize the idea that when managers require external investment to expand, higher-skilled firms will be more likely to diversify in equilibrium, even though managers can exploit asymmetric information about their ability to raise capital from investors. We exploit the timing of new fund launches in the hedge fund industry to distinguish between agency and capability effects in firm product diversification decisions, using a large survivor-bias-free panel data set on the hedge fund industry from 1994 to 2006. Empirically we show that diversifying firms' excess returns are high relative to those of other firms prior to diversification and fall within firm following diversification, but are six basis points higher per month per unit of risk ex post compared to a matched sample of focused firms. The evidence suggests that managers exploit asymmetric information about their own ability to time diversification decisions; yet, the discipline of markets ensures that better firms diversify, on average. The results provide large-sample empirical evidence that agency effects and firm capabilities jointly influence diversification decisions."
923,"Modeling Security-Check Queues","Zhang, Zhe George and Luh, Hsing Paul and Wang, Chia-Hung","MANAGEMENT SCIENCE","57","11","1979-1995","2011","NOV","Security Inspection Level;Service Capacity;Two-Stage Queue;Renewal Process Approximation;Coxian Distribution;Quasi-Birth-And-Death Process","","Motivated by the waiting lines between the U.S.-Canadian border crossings, we investigate a security-check system with both security and customer service goals. In such a system, every customer has to be inspected by the first-stage inspector, but only a proportion of customers need to go through the second stage for further inspection. This further inspection proportion, affecting both security screening and the system congestion, becomes a key decision variable for the security-check system. Using a stylized two-stage queueing model, we established the convexity of the expected waiting cost function. With such a property, the optimal further inspection proportion can be determined to achieve the balance of the two goals and the service capacities can be classified into security-favorable, security-unfavorable, or security-infeasible categories. A specific capacity category implies if the security and customer service goals are consistent or in conflict. In addition, we have verified that the properties discovered in the stylized model also hold approximately in a more general multiserver setting. Numerical results are presented to demonstrate the accuracy and robustness of the approximations and the practical value of the model."
924,"Simple Economics of the Price-Setting Newsvendor Problem","Salinger, Michael and Ampudia, Miguel","MANAGEMENT SCIENCE","57","11","1996-1998","2011","NOV","Cost Analysis;Inventory/Production;Perishable/Aging Items;Uncertainty;Marketing;Pricing","","The Lerner relationship linking the profit-maximizing price to marginal cost and the elasticity of demand generalizes to the price-setting newsvendor, and the result resolves the puzzle over the different effects of additive and multiplicative uncertainty on the solution. Multiplicative uncertainty increases the optimal price because it increases the marginal cost of a unit sold and does not affect the markup factor. Additive uncertainty has no effect on the marginal cost of a unit sold and lowers the markup factor because it increases the elasticity of the average quantity sold with respect to price."
925,"Stars and Misfits: Self-Employment and Labor Market Frictions","Astebro, Thomas and Chen, Jing and Thompson, Peter","MANAGEMENT SCIENCE","57","11","1999-2017","2011","NOV","Entrepreneurship;Self-Employment;Jack-Of-All-Trades;Skill Complementarity","","Recent evidence has shown that entrants into self-employment are disproportionately drawn from the tails of the earnings and ability distributions. This observation is explained by a multitask model of occupational choice in which frictions in the labor market induce mismatches between firms and workers, and misassignment of workers to tasks. The model also yields distinctive predictions relating prior work histories to earnings and to the probability of entry into self-employment. These predictions are tested with the Korean Labor and Income Panel Study, from which we find considerable support for the model."
926,"Extracting Business Value from IT: A Sensemaking Perspective of Post-Adoptive Use","Hsieh, J. J. Po-An and Rai, Arun and Xu, Sean Xin","MANAGEMENT SCIENCE","57","11","2018-2039","2011","NOV","Business Value;Information Technology;Post-Adoptive Behavior;Extended Use;Sensemaking;Feedback Mechanisms;Customer Relationship Management;Crm Technology","","How can firms extract value from already-implemented information technologies (IT) that support the work processes of employees? One approach is to stimulate employees to engage in post-adoptive extended use, i.e., to learn and apply more of the available functions of the implemented technologies to support their work. Such learning behavior of extending functions in use is ingrained in a process by which users make sense of the technologies in the context of their work system. This study draws on sensemaking theory to develop a model to understand the antecedents, contingencies, and consequences of customer service employees' extended use of customer relationship management (CRM) technologies. The model is tested using multisource longitudinal data collected through a field study of one of the world's largest telecommunications service providers. Our results suggest that employees engage in post-adoptive sensemaking at two levels: technology and work system. We found that sensemaking at both of these levels impacts the extended use of CRM technologies. Employees' sensemaking at the technology level is influenced by employees' assessment of technology quality, whereas employees' sensemaking at the work system level is influenced by customers' assessment of service quality. Moreover, in the case of low technology quality and low service quality, specific mechanisms for employee feedback should be conceptualized and aligned at two levels: through employee participation at the technology level and through work system coordination at the work system level. Such alignment can mitigate the undesirable effect of low technology quality and low service quality, thereby facilitating extended use. Importantly, we found that extended use amplifies employees' service capacity, leading to better objective performance. Put together, our findings highlight the critical role of employees' sensemaking about the implemented technologies in promoting their extended use of IT and improving their work performance."
927,"Integrated Product Architecture and Pricing for Managing Sequential Innovation","Krishnan, Vish and Ramachandran, Karthik","MANAGEMENT SCIENCE","57","11","2040-2053","2011","NOV","Product Design And Pricing;Modular Upgradability;Sequential Innovation","","Science and technology advances drive firms to continually enhance their product's performance and launch sequentially improving offerings. Firms face challenges in marketing such improving products to well-informed, forward-looking consumers who anticipate product improvements and seek to delay their purchase timing. Product design, specifically a modular upgradable architecture in which improving and stable subsystems of a product are separated and selectively upgraded, can be a valuable approach for marketers to alleviate consumer concerns about product obsolescence. However, such an architecture-based approach can present new challenges as well, and dealing with them requires carefully coordinated cross-functional decision making by the firm. In this paper, we identify and formalize the notion of design inconsistency, which refers to the monopolist firm's inability to commit to future product design architectures. We find that firms experience design inconsistency even when they are able to commit to future prices, and design inconsistency lowers firm profits as well as consumer surplus. We then derive a joint product architecture and pricing approach to solve this problem; this enables an innovating firm to optimally and in a time-consistent manner launch modular upgradable products. The modeling and analysis in the paper lends insight into types of markets and products for which modular upgradability is most appropriate and offers guidelines on making pricing and product design decisions jointly for managing sequential innovation."
928,"Preference Reversals Under Ambiguity","Maafi, Hela","MANAGEMENT SCIENCE","57","11","2054-2066","2011","NOV","Ambiguity;Classical Preference Reversal;Choice Versus Valuation;Prospect Theory;Decision Weights","","Preference reversals have been widely studied using risky or riskless gambles. However, little is known about preference reversals under ambiguity (unknown probabilities). Subjects were asked to make a binary choice between ambiguous P-bets (big likelihood of giving small prize) and ambiguous $-bets (small likelihood of giving large prize) and their willingness to accept was elicited. Subjects then performed the same two tasks with risky bets, where the probability of winning for a given risky bet is the center of the probability interval of the corresponding ambiguous bet. Preference reversals are not only replicated under ambiguity but are even stronger than are those under risk. This is due to higher elicited prices for the $-bet and lower elicited prices for the P-bet under ambiguity than under risk. This result can be explained by the shape of the weighting function for different levels of uncertainty and for different elicitation modes."
929,"Option Pricing Under a Mixed-Exponential Jump Diffusion Model","Cai, Ning and Kou, S. G.","MANAGEMENT SCIENCE","57","11","2067-2081","2011","NOV","Jump Diffusion;Mixed-Exponential Distributions;Lookback Options;Barrier Options;Merton'S Normal Jump Diffusion Model;First Passage Times","","This paper aims to extend the analytical tractability of the Black-Scholes model to alternative models with arbitrary jump size distributions. More precisely, we propose a jump diffusion model for asset prices whose jump sizes have a mixed-exponential distribution, which is a weighted average of exponential distributions but with possibly negative weights. The new model extends existing models, such as hyperexponential and double-exponential jump diffusion models, because the mixed-exponential distribution can approximate any distribution as closely as possible, including the normal distribution and various heavy-tailed distributions. The mixed-exponential jump diffusion model can lead to analytical solutions for Laplace transforms of prices and sensitivity parameters for path-dependent options such as lookback and barrier options. The Laplace transforms can be inverted via the Euler inversion algorithm. Numerical experiments indicate that the formulae are easy to implement and accurate. The analytical solutions are made possible mainly because we solve a high-order integro-differential equation explicitly. A calibration example for SPY options shows that the model can provide a reasonable fit even for options with very short maturity, such as one day."
930,"Tournaments Without Prizes: Evidence from Personnel Records","Blanes i Vidal, Jordi and Nossol, Mareike","MANAGEMENT SCIENCE","57","10","1721-1736","2011","OCT","Tournaments;Relative Concerns;Status Concerns;Relative Performance Feedback;Relative Performance Evaluation","","W e use a quasi-experimental research design to study the effect of giving workers feedback on their relative performance. The setting is a firm in which workers are paid piece rates and where, for exogenous reasons, management begins to reveal to workers their relative position in the distribution of pay and productivity. We find that merely providing this information leads to a large and long-lasting increase in productivity that is costless to the firm. Our findings are consistent with the interpretation that workers' incipient concerns about their relative standing are activated by information about how they are performing relative to others."
931,"Selling to Strategic Consumers When Product Value Is Uncertain: The Value of Matching Supply and Demand","Swinney, Robert","MANAGEMENT SCIENCE","57","10","1737-1751","2011","OCT","Strategic Consumer Behavior, Quick Response;Consumer Learning;Pricing;Demand Uncertainty","","W e address the value of quick response production practices when selling to a forward-looking consumer population with uncertain, heterogeneous valuations for a product. Consumers have the option of purchasing the product early, before its value has been learned, or delaying the purchase decision until a time at which valuation uncertainty has been resolved. Whereas individual consumer valuations are uncertain ex ante, the market size is uncertain to the firm. The firm may either commit to a single production run at a low unit cost prior to learning demand, or commit to a quick response strategy that allows additional production after learning additional demand information. We find that the value of quick response is generally lower with strategic (forward-looking) customers than with nonstrategic (myopic) customers in this setting. Indeed, it is possible for a quick response strategy to decrease the profit of the firm, though whether this occurs depends on various characteristics of the market; specifically, we identify conditions under which quick response increases profit (when prices are increasing, when dissatisfied consumers can return the product at a cost to the firm) and conditions under which quick response may decrease profit (when prices are constant or when consumer returns are not allowed)."
932,"Dynamic Portfolio Optimization with Transaction Costs: Heuristics and Dual Bounds","Brown, David B. and Smith, James E.","MANAGEMENT SCIENCE","57","10","1752-1770","2011","OCT","Dynamic Programming;Portfolio Optimization","","W e consider the problem of dynamic portfolio optimization in a discrete-time, finite-horizon setting. Our general model considers risk aversion, portfolio constraints (e. g., no short positions), return predictability, and transaction costs. This problem is naturally formulated as a stochastic dynamic program. Unfortunately, with nonzero transaction costs, the dimension of the state space is at least as large as the number of assets, and the problem is very difficult to solve with more than one or two assets. In this paper, we consider several easy-to-compute heuristic trading strategies that are based on optimizing simpler models. We complement these heuristics with upper bounds on the performance with an optimal trading strategy. These bounds are based on the dual approach developed in Brown et al. (Brown, D. B., J. E. Smith, P. Sun. 2009. Information relaxations and duality in stochastic dynamic programs. Oper. Res. 58(4) 785-801). In this context, these bounds are given by considering an investor who has access to perfect information about future returns but is penalized for using this advance information. These heuristic strategies and bounds can be evaluated using Monte Carlo simulation. We evaluate these heuristics and bounds in numerical experiments with a risk-free asset and 3 or 10 risky assets. In many cases, the performance of the heuristic strategy is very close to the upper bound, indicating that the heuristic strategies are very nearly optimal."
933,"Integrating Long-Term and Short-Term Contracting in Beef Supply Chains","Boyabatli, Onur and Kleindorfer, Paul R. and Koontz, Stephen R.","MANAGEMENT SCIENCE","57","10","1771-1787","2011","OCT","Contracting;Beef Supply Chain;Commodity Risk Management;Multiproduct Newsvendor;Window Contracts","","T his paper analyzes the optimal procurement, processing, and production decisions of a meat-processing company (hereafter, a packer) in a beef supply chain. The packer processes fed cattle to produce two beef products, program (premium) boxed beef and commodity boxed beef, in fixed proportions, but with downward substitution of the premium product for the commodity product. The packer can source input (fed cattle) from a contract market, where long-term contracts are signed in advance of the required delivery time, and from a spot market on the spot day. Contract prices are taken to be of a general window form, linear in the spot price but capped by upper and lower limits on realized contract price. Our analysis provides managerial insights on the interaction of window contract terms with processing options. We show that the packer benefits from a low correlation between the spot price and product market uncertainties, and this is independent of the form of the window contract. Although the expected revenues from processing increase in spot price variability, the overall impact on profitability depends on the parameters of the window contract. Using a calibration based on the report by the GIPSA (Grain Inspection, Packers and Stockyards Administration. 2007. GIPSA livestock and meat marketing study, vol. 3: Fed cattle and beef industries. Report, U. S. Department of Agriculture, Washington, DC), this paper elucidates for the first time the value of long-term contracting as a complement to spot sourcing in the beef supply chain. Our comparative statics results provide some rules of thumb for the packer for the strategic management of the procurement portfolio. In particular, we show that higher variability (higher spot price variability, product market variability, and correlation) increases the profits of the packer, but decreases the reliance on the contract market relative to the spot market."
934,"Exogenous Learning, Seller-Induced Learning, and Marketing of Durable Goods","Jing, Bing","MANAGEMENT SCIENCE","57","10","1788-1801","2011","OCT","Durable Goods;Experience Goods;Customer Learning;Dynamic Pricing","","W hen learning of product characteristics takes some time, a firm introducing a new durable faces the trade-off between releasing early to an uninformed market and deferring release to a better-informed market. In a two-period monopoly, we examine the strategic interaction between exogenous learning (EL) and seller-induced learning (SIL) and the firm's product release and pricing strategies. The familiar, direct effect of strong learning is to facilitate a higher price for informed customers. We point out its indirect effect of inducing a higher period 1 price for uninformed customers (by lowering their expected utility from learning). These two effects underlie three major results. First, a strong learning intensity does not always imply deferred release. Surprisingly, for medium unit costs, the firm releases late (early) when learning intensity is weak (strong). Second, SIL facilitates different product release strategies, depending on the unit cost level. Potential SIL investment facilitates early release for low or medium unit costs, but may facilitate deferred release for high unit costs. Lastly, when customers have heterogeneous prior valuation, the high-end customers may buy early at a lower price and the low-end customers may buy later at a higher price, contrary to the usual skim pricing with informed customers."
935,"New Product Diffusion Decisions Under Supply Constraints","Shen, Wenjing and Duenyas, Izak and Kapuscinski, Roman","MANAGEMENT SCIENCE","57","10","1802-1810","2011","OCT","Inventory Production;Policies;Pricing;Production Smoothing;Capacity;Bass Model;Diffusion","","Two recent papers on managing new product diffusion decisions under production constraints reach somewhat contradictory conclusions. Ho et al. (Ho, T.-H., S. Savin, C. Terwiesch. 2002. Managing demand and sales dynamics in new product diffusion under supply constraint. Management Sci. 48(2) 187-206) show that it is never optimal to refuse to satisfy any customers when the firm has inventory of the product. On the other hand, in a very similar model, Kumar and Swaminathan (Kumar, S., J. M. Swaminathan. 2003. Diffusion of innovations under supply constraints. Oper. Res. 51(6) 866-879) show that production constraints may in fact lead a firm to reject customers' orders even when the firm has the inventory to satisfy them (to slow down new product diffusion). We provide a counterexample to the results of Ho et al. (2002) and show that in their and Kumar and Swaminathan's (2003) models, it may be optimal to deny customers a product in inventory. We provide a generalization of both models that includes the ability to dynamically price the product (and also allows capacity and production costs to vary over time). We show that the unintuitive but optimal behavior of denying customers products that are in inventory disappears when the firm can dynamically set prices."
936,"Note: A Reply to New Product Diffusion Decisions Under Supply Constraints","Ho, Teck-Hua and Savin, Sergei and Terwiesch, Christian","MANAGEMENT SCIENCE","57","10","1811-1812","2011","OCT","Marketing-Operation Interface;Bass Diffusion Model;Capacity Planning","","In our prior work on product diffusions in presence of a capacity constraint, we postulated that a firm operating in such an environment should always attempt to fulfill as much of the present demand as is possible with the capacity constraint. In other words, the firm would never have demand backlogged while accumulating inventory. In this note, we derive a sufficient condition for the optimality of such fulfillment policy."
937,"The Circulation of Ideas in Firms and Markets","Hellmann, Thomas and Perotti, Enrico","MANAGEMENT SCIENCE","57","10","1813-1826","2011","OCT","Innovation;Market For Ideas;Start-Ups;Spin-Offs","","This paper models the generation, circulation, and completion of new ideas, showing how markets and innovative firms complement each other in a symbiotic relationship. Novel ideas are initially incomplete and require further insight before yielding a valuable innovation. Finding the complementary piece requires ideas to circulate, which creates appropriation risks. Circulation of ideas in markets ensures efficient completion, but because ideas can be appropriated, market entrepreneurs underinvest in idea generation. Firms can establish boundaries that guarantee safe circulation of internal ideas, but because firms need to limit idea circulation, they may fail to achieve completion. Spin-offs allow firms to benefit from the market's strength at idea completion, whereas markets benefit from firms' strength at generating new ideas. The model predicts diverse organizational forms (internal ventures, spin-offs, and start-ups) coexisting and mutually reinforcing each other. The analysis provides new insights into the structure of innovation-driven clusters such as Silicon Valley."
938,"Demand Forecasting Behavior: System Neglect and Change Detection","Kremer, Mirko and Moritz, Brent and Siemsen, Enno","MANAGEMENT SCIENCE","57","10","1827-1843","2011","OCT","Forecasting;Behavioral Operations;System Neglect;Exponential Smoothing","","We analyze how individuals make forecasts based on time-series data. Using a controlled laboratory experiment, we find that forecasting behavior systematically deviates from normative predictions: Forecasters overreact to forecast errors in relatively stable environments, but underreact to errors in relatively unstable environments. The performance loss that is due to such systematic judgment biases is larger in stable than in unstable environments."
939,"Cash-Out or Flameout! Opportunity Cost and Entrepreneurial Strategy: Theory, and Evidence from the Information Security Industry","Arora, Ashish and Nandkumar, Anand","MANAGEMENT SCIENCE","57","10","1844-1860","2011","OCT","Entrepreneurship;Opportunity Costs;Performance","","We analyze how entrepreneurial opportunity cost conditions performance. Departing from the common practice of using survival as a measure of entrepreneurial performance, we model both failure and cashout (liquidity event) as conditioned by the same underlying process. High-opportunity-cost entrepreneurs prefer a shorter time to success, even if this also implies failing more quickly, whereas entrepreneurs with fewer outside alternatives will choose less aggressive strategies and, consequently, linger on longer. We formalize this intuition with a simple model. Using a novel data set of information security start-ups, we find that entrepreneurs with high opportunity costs are not only more likely to cash out more quickly but are also more likely to fail faster. Not only is survival a poor indicator of performance, but its use as one obscures the relationship between entrepreneurial characteristics, entrepreneurial strategies, and outcomes."
940,"Intellectual Capital and Financing Decisions: Evidence from the US Patent Data","Liu, Qiao and Wong, Kit Pong","MANAGEMENT SCIENCE","57","10","1861-1878","2011","OCT","Capital Structure;Default;Intellectual Capital;Patent-Based Metrics;R&D-Based Metrics","","This paper develops a real options model to understand two distinct roles played by intellectual capital in corporate financing decisions. Whereas limiting a firm's debt capacity because of its low liquidation value, intellectual capital enhances a firm's debt capacity through its positive impact on earnings. Our model shows that the former dominates or is dominated by the latter, depending on whether the rate of dissipation of intellectual capital upon default is larger or smaller than a critical level, respectively. Using patent-based and research-and-development-based variables as proxies for intellectual capital, we find robust evidence that the relation between intellectual capital and leverage is positive. Specifically, a one-standard-deviation increase in the level of a firm's intellectual capital is associated with an increase of 6.6% to 21.1% in its market leverage. We further find this positive relation to be stronger for biotechnology firms."
941,"Experienced vs. Described Uncertainty: Do We Need Two Prospect Theory Specifications?","Abdellaoui, Mohammed and L'Haridon, Olivier and Paraschiv, Corina","MANAGEMENT SCIENCE","57","10","1879-1895","2011","OCT","Experience-Based Decisions;Description-Based Decisions;Rare Events;Risk;Uncertainty;Prospect Theory;Utility;Loss Aversion;Decision Weights;Probability Weighting;Source Of Uncertainty;Ambiguity","","This paper reports on the results of an experimental elicitation at the individual level of all prospect theory components (i.e., utility, loss aversion, and weighting functions) in two decision contexts: situations where alternatives are described as probability distributions and situations where the decision maker must experience unknown probability distributions through sampling before choice. For description-based decisions, our results are fully consistent with prospect theory's empirical findings under risk. Furthermore, no significant differences are detected across contexts as regards utility and loss aversion. Whereas decision weights exhibit similar qualitative properties across contexts typically found under prospect theory, our data suggest that, for gains at least, the subjective treatment of uncertainty in experience-based and description-based decisions is significantly different. More specifically, we observe a less pronounced overweighting of small probabilities and a more pronounced underweighting of moderate and high probabilities for experience-based decisions. On the contrary, for losses, no significant differences were observed in the evaluation of prospects across contexts."
942,"Label Confusion: The Groucho Effect of Uncertain Standards","Harbaugh, Rick and Maxwell, John W. and Roussillon, Beatrice","MANAGEMENT SCIENCE","57","9","1512-1527","2011","SEP","Marketing;Communications;Information Theory;Environment","","abels certify that a product meets some standard for quality, but often consumers are unsure of the exact standard that the label represents. Focusing on the case of ecolabels for environmental quality, we show how even small amounts of uncertainty can create consumer confusion that reduces or eliminates the value to firms of adopting voluntary labels. First, consumers are most suspicious of a label when a product with a bad reputation has it, so labels are often unpersuasive at showing that a seemingly bad product is actually good. Second, label proliferation aggravates the effect of uncertainty, causing the informativeness of labels to decrease rather than increase. Third, uncertainty makes labeling and nonlabeling equilibria more likely to coexist as the number of labels increases, so consumers face greater strategic uncertainty over how to interpret the presence or absence of a label. Finally, a label can be legitimitized or spoiled for other products when a product with a good or bad reputation displays it, so firms may adopt labels strategically to manipulate such information spillovers, which further exacerbates label confusion. Managers can reduce label confusion by supporting mandatory labeling or by undertaking investments to make certain labels focal."
943,"Corporate Social Responsibility and Competitive Advantage: Overcoming the Trust Barrier","Du, Shuili and Bhattacharya, C. B. and Sen, Sankar","MANAGEMENT SCIENCE","57","9","1528-1545","2011","SEP","Corporate Social Responsibility;Competitive Strategy;Challenger Brand;Affective Trust","","This research builds on the complementary corporate social responsibility (CSR) literatures in strategy and marketing to provide insight into the efficacy of CSR as a challenger's competitive weapon against a market leader. Through an investigation of a real-world CSR initiative, we show that the challenger can reap superior business returns (i. e., more positive attitudinal and behavioral outcomes) among consumers who had participated in its CSR initiative, relative to those who were merely aware of the initiative. Specifically, participant consumers demonstrate the desired attitudinal and behavioral changes in favor of the challenger, regardless of their affective trust in the leader, whereas aware consumers' reactions become less favorable as their affective trust in the leader increases. Furthermore, participant consumers, but not aware ones, form a communal, trust-based bond with the challenger."
944,"Optimal and Competitive Assortments with Endogenous Pricing Under Hierarchical Consumer Choice Models","Koek, A. Guerhan and Xu, Yi","MANAGEMENT SCIENCE","57","9","1546-1563","2011","SEP","Assortment Planning;Product Variety;Category Management;Pricing;Inventory Costs;Nested Multinomial Logit Model","","This paper studies assortment planning and pricing for a product category with heterogeneous product types from two brands. We model consumer choice using the nested multinomial logit framework with two different hierarchical structures: a brand-primary model in which consumers choose a brand first, then a product type in the chosen brand, and a type-primary model in which consumers choose a product type first, then a brand within that product type. We consider a centralized regime that finds the optimal solution for the whole category and a decentralized regime that finds a competitive equilibrium between two brands. We find that optimal and competitive assortments and prices have quite distinctive properties across different models. Specifically, with the brand-primary model, both the optimal and the competitive assortments for each brand consist of the most popular product types from the brand. With the type-primary choice model, the optimal and the competitive assortments for each brand may not always consist of the most popular product types of the brand. Instead, the overall assortment in the category consists of a set of most popular product types. The price of a product under the centralized regime can be characterized by a sum of a markup that is constant across all products and brands, its procurement cost, and its marginal operational cost, implying a lower price for more popular products. The markup may be different for each brand and product type under the decentralized regime, implying a higher price for brands with a larger market share. These properties of the assortments and prices can be used as effective guidelines for managers to identify and price the best assortments and to rule out nonoptimal assortments. Our results suggest that to offer the right set of products and prices, category and/or brand managers should create an assortment planning process that is aligned with the hierarchical choice process consumers commonly follow to make purchasing decisions."
945,"The Labor Illusion: How Operational Transparency Increases Perceived Value","Buell, Ryan W. and Norton, Michael I.","MANAGEMENT SCIENCE","57","9","1564-1579","2011","SEP","Marketing;Channels Of Distribution;Queues;Industries;Business Services;Inventory-Production;Operating Characteristics;Service Operations;Service Design","","A ubiquitous feature of even the fastest self-service technology transactions is the wait. Conventional wisdom and operations theory suggest that the longer people wait, the less satisfied they become; we demonstrate that because of what we term the labor illusion, when websites engage in operational transparency by signaling that they are exerting effort, people can actually prefer websites with longer waits to those that return instantaneous results-even when those results are identical. In five experiments that simulate service experiences in the domains of online travel and online dating, we demonstrate the impact of the labor illusion on service value perceptions, demonstrate that perceptions of service provider effort induce feelings of reciprocity that together mediate the link between operational transparency and increased valuation, and explore boundary conditions and alternative explanations."
946,"The Threat from Within: Account Managers' Concern About Opportunism by Their Own Team Members","Murtha, Brian R. and Challagalla, Goutam and Kohli, Ajay K.","MANAGEMENT SCIENCE","57","9","1580-1593","2011","SEP","Transaction-Specific Investments;Internal Opportunism;Continuity;Internal Blocking;Sales Teams","","It is well known that transaction-specific investments (TSIs) made in customers by account managers makes them vulnerable to opportunism by customers (i.e., the targets of the investments). The present research shows that TSIs made in customers by account managers can also lead them to be concerned about internal opportunism by nontargets of the investments (e.g., information technology or finance specialists in their own teams). Furthermore, it shows that concern about internal opportunism leads account managers to engage in internal blocking of their own team members (i.e., restricting their access to customers and to customer information) 1 which results in lower performance with customers. This phenomenon is a conundrum in that account managers interested in stronger performance with customers appear to block the very functional specialists who can help them attain better performance. This research also identifies two types of continuities (account manager-customer continuity and specialist-customer continuity) that moderate the relationship between TSIs and concern about internal opportunism. Building on the literature in economics and organization theory, our research suggests that cross-functional teams that are designed to bring different functional areas together are more complex to manage than previously believed."
947,"The Stock Market in the Driver's Seat! Implications for R&D and Marketing","Chakravarty, Anindita and Grewal, Rajdeep","MANAGEMENT SCIENCE","57","9","1594-1609","2011","SEP","Finance;Marketing;Research And Development","","The budgets for research and development (R&D) and marketing should be determined by managers to attain product market advantages. However, in response to investor expectations for short-term stock returns, managers may modify these budgets myopically to avoid unexpected short-term earnings shortfalls, at the cost of long-term profitability. We propose that the past behavior of firm stock returns and volatility may create investor expectations of short-term financial performance, which drives managers to modify either R&D or marketing budgets or both. In the context of high-technology firms, a Bayesian vector autoregression model, supported by content analysis, shows that few firms exhibit high levels of managerial myopia by simultaneously cutting both R&D and marketing budgets; instead, firms display moderate myopic reactions, in the form of unanticipated decreases in R&D budgets but increased budgets for marketing functions. The tendency to manage myopically in response to past stock returns and volatility increases as firm size or industry concentration decrease."
948,"The Dark Side of Rapport: Agent Misbehavior Face-to-Face and Online","Jap, Sandy and Robertson, Diana C. and Hamilton, Ryan","MANAGEMENT SCIENCE","57","9","1610-1622","2011","SEP","Buyer-Seller Interactions;Misbehavior;Unethical Behavior;Rapport;Emotion;Online Media;Lying;Misleading;Overpromising","","A considerable body of research has extolled the virtues of establishing rapport in negotiations. Negotiators who are high in rapport tend to be more likely to reach an agreement and more satisfied with the outcome. Although rapport generally has been found to have positive effects in standard negotiation settings, we investigate the effects of rapport in impasse settings, where conflict between negotiators' core needs means that a successful deal can only be reached when one or both parties acts unethically or misbehaves, for example, by lying to the negotiation partner. In a series of three experiments, we find that negotiators who have a high level of rapport are more likely to behave unethically than are negotiators who have a low level of rapport. We find this effect holds both when high rapport results from the way in which negotiations are conducted (face-to-face versus computer mediated) and also when rapport is established through a brief rapport-building exercise before negotiations begin. Finally, we find that the negative effects (unethical behavior)-but not the positive effects (satisfaction with the negotiation, trust, and willingness to work in the future with the negotiation partner)-of high rapport are reduced when negotiators are given a simple reminder before negotiations begin that one's actions can have long-term repercussions for one's reputation. Taken together, this research supports the idea that, despite its several advantages, in certain situations rapport has a dark side, of which negotiators must be wary."
949,"Creating Social Contagion Through Viral Product Design: A Randomized Trial of Peer Influence in Networks","Aral, Sinan and Walker, Dylan","MANAGEMENT SCIENCE","57","9","1623-1639","2011","SEP","Peer Influence;Social Contagion;Social Networks;Viral Marketing;Viral Product Design;Information Systems;Randomized Experiment","","We examine how firms can create word-of-mouth peer influence and social contagion by designing viral features into their products and marketing campaigns. To econometrically identify the effectiveness of different viral features in creating social contagion, we designed and conducted a randomized field experiment involving the 1.4 million friends of 9,687 experimental users on Facebook.com. We find that viral features generate econometrically identifiable peer influence and social contagion effects. More surprisingly, we find that passive-broadcast viral features generate a 246% increase in peer influence and social contagion, whereas adding active-personalized viral features generate only an additional 98% increase. Although active-personalized viral messages are more effective in encouraging adoption per message and are correlated with more user engagement and sustained product use, passive-broadcast messaging is used more often, generating more total peer adoption in the network. Our work provides a model for how randomized trials can identify peer influence in social networks."
950,"Newspaper Reports and Consumer Choice: Evidence from the Do Not Call Registry","Goh, Khim-Yong and Hui, Kai-Lung and Png, Ivan P. L.","MANAGEMENT SCIENCE","57","9","1640-1654","2011","SEP","Advertising;Journalism;Information;Persuasion;Policy;Publicity","","Despite annual expenditures on public relations exceeding $19.42 billion, U.S. businesses lack practical guidance about the effectiveness of publicity in mass media. Here, we assemble a rich and novel data set to gauge the impact of news reports on consumer sign-ups with the U.S. Do Not Call (DNC) Registry. Using multiple identification strategies, we found robust evidence that news reports increased consumer registrations. Specifically, a 1% increase in the number of news reports increased DNC registrations by 0.018%. The impact increased with mention of the toll-free telephone number and URL, but decreased with the length of the headline and main text. Furthermore, we found evidence that reports affect behavior through persuasion as well as information-the impact on registration was higher for reports that mentioned the number of other people registering. Finally, the impact of news reports on consumer registration was stronger in national than local newspapers and in politically neutral and Democrat than Republican newspapers."
951,"Durable Products, Time Inconsistency, and Lock-in","Gilbert, Stephen M. and Jonnalagedda, Sreelata","MANAGEMENT SCIENCE","57","9","1655-1670","2011","SEP","Marketing;Product Policy;New Products;Decision Analysis;Strategic Consumers","","Many durable products cannot be used without a contingent consumable product, e. g., printers require ink, iPods require songs, razors require blades, etc. For such products, manufacturers may be able to lock in consumers by making their products incompatible with consumables that are produced by other firms. We examine the effectiveness of such a strategy in the presence of strategic consumers who anticipate the future prices of both the durable product and the contingent consumable. Under a lock-in strategy, the manufacturer has pricing power over the contingent consumable, which she can use to extract additional rents from higher valuation consumers, but such pricing power may also reduce consumers' willingness to pay for the durable because it subjects them to being held up with higher consumables prices in the future. Restricting our attention to linear pricing policies, we find that if the manufacturer can commit to shutting down production of her durable after an initial one-time sale, then competition from another consumable of an appropriately degraded level of quality can benefit the manufacturer by mitigating consumers' fears of being held up. On the other hand, when the manufacturer cannot commit to shutting down production of her durable, then her own output of additional durables gives her an incentive to keep consumables prices low, and competition in the consumables market is less beneficial."
952,"An Empirical Analysis of User Content Generation and Usage Behavior on the Mobile Internet","Ghose, Anindya and Han, Sang Pil","MANAGEMENT SCIENCE","57","9","1671-1691","2011","SEP","Mobile Internet;Social Networks;Content Generation;Content Usage;Interdependence;Geographical Mobility;Identification","","We quantify how user mobile Internet usage relates to unique characteristics of the mobile Internet. In particular, we focus on examining how the mobile-phone-based content generation behavior of users relates to content usage behavior. The key objective is to analyze whether there is a positive or negative interdependence between the two activities. We use a unique panel data set that consists of individual-level mobile Internet usage data that encompass individual multimedia content generation and usage behavior. We combine this knowledge with data on user calling patterns, such as duration, frequency, and locations from where calls are placed, to construct their social network and to compute their geographical mobility. We build an individual-level simultaneous equation panel data model that controls for the different sources of endogeneity of the social network. We find that there is a negative and statistically significant temporal interdependence between content generation and usage. This finding implies that an increase in content usage in the previous period has a negative impact on content generation in the current period and vice versa. The marginal effect of this interdependence is stronger on content usage (up to 8.7%) than on content generation (up to 4.3%). The extent of geographical mobility of users has a positive effect on their mobile Internet activities. Users more frequently engage in content usage compared to content generation when they are traveling. In addition, the variance of user mobility has a stronger impact on their mobile Internet activities than does the mean. We also find that the social network has a strong positive effect on user behavior in the mobile Internet. These analyses unpack the mechanisms that stimulate user behavior on the mobile Internet. Implications for shaping user mobile Internet usage behavior are discussed."
953,"Pooling, Access, and Countervailing Power in Channel Governance","Hendrikse, George","MANAGEMENT SCIENCE","57","9","1692-1702","2011","SEP","Channel Governance;Cooperatives;Pooling;Foreclosure;Market Power;Incomplete Contracts","","Fruit and vegetable marketing organization the Greenery has experienced various governance structure changes, like horizontal merger, forward integration, and the emergence of grower associations. A multilateral incomplete contracting model is presented to account for these changes by analysing the interactions between pooling, access, and countervailing power. This model does not only explain the changes at the Greenery, but it contributes also to the design of efficient channel governance."
954,"Cyclical Bid Adjustments in Search-Engine Advertising","Zhang, Xiaoquan (Michael) and Feng, Juan","MANAGEMENT SCIENCE","57","9","1703-1719","2011","SEP","Bid Adjustment;Edgeworth Cycle;Keyword Auction","","Keyword advertising, or sponsored search, is one of the most successful advertising models on the Internet. One distinctive feature of keyword auctions is that they enable advertisers to adjust their bids and rankings dynamically, and the payoffs are realized in real time. We capture this unique feature with a dynamic model and identify an equilibrium bidding strategy. We find that under certain conditions, advertisers may engage in cyclical bid adjustments, and equilibrium bidding prices may follow a cyclical pattern: price-escalating phases interrupted by price-collapsing phases, similar to an Edgeworth cycle in the context of dynamic price competitions. Such cyclical bidding patterns can take place in both first-and second-price auctions. We obtain two data sets containing detailed bidding records of all advertisers for a sample of keywords in two leading search engines. Our empirical framework, based on a Markov switching regression model, suggests the existence of such cyclical bidding strategies. The cyclical bid-updating behavior we find cannot be easily explained with static models. This paper emphasizes the importance of adopting a dynamic perspective in studying equilibrium outcomes of keyword auctions."
955,"Group Buying: A New Mechanism for Selling Through Social Interactions","Jing, Xiaoqing and Xie, Jinhong","MANAGEMENT SCIENCE","57","8","1354-1372","2011","AUG","Group Buying;Word Of Mouth;Interpersonal Information Sharing;Referral Rewards Programs;Pricing;Social Interaction;Marketing;Internet","","This paper examines a unique selling strategy, Group Buying, under which consumers enjoy a discounted group price if they are willing and able to achieve a required group size and coordinate their transaction time. We argue that Group Buying allows a seller to gain from facilitating consumer social interaction, i.e., using a group discount to motivate informed customers to work as sales agents to acquire less-informed customers through interpersonal information/knowledge sharing. We formally model such an information-sharing effect and examine if and when Group Buying is more profitable than (1) traditional individual-selling strategies, and (2) another popular social interaction scheme, Referral Rewards programs. We show that Group Buying dominates traditional individual-selling strategies when the information/knowledge gap between expert and novice consumers is neither too high nor too low (e.g., for products in the midstage of their life cycle) and when interpersonal information sharing is very efficient (e.g., in cultures that emphasize trust and group conformity, or when implemented through existing online social networks). We also show that, unlike Referral Rewards programs, Group Buying requires information sharing before any transaction takes place, thereby increasing the scale of social interaction but also incurring a higher cost. As a result, Group Buying is optimal when interpersonal communication is very efficient or when the product valuation of the less-informed consumer segment is high."
956,"Goodbye Pareto Principle, Hello Long Tail: The Effect of Search Costs on the Concentration of Product Sales","Brynjolfsson, Erik and Hu, Yu (Jeffrey) and Simester, Duncan","MANAGEMENT SCIENCE","57","8","1373-1386","2011","AUG","Long Tail;Search Cost;Product Variety;Concentration;Product Sales;Internet;Electronic Commerce","","Many markets have historically been dominated by a small number of best-selling products. The Pareto principle, also known as the 80/20 rule, describes this common pattern of sales concentration. However, information technology in general and Internet markets in particular have the potential to substantially increase the collective share of niche products, thereby creating a longer tail in the distribution of sales. This paper investigates the Internet's long tail phenomenon. By analyzing data collected from a multichannel retailer, it provides empirical evidence that the Internet channel exhibits a significantly less concentrated sales distribution when compared with traditional channels. Previous explanations for this result have focused on differences in product availability between channels. However, we demonstrate that the result survives even when the Internet and traditional channels share exactly the same product availability and prices. Instead, we find that consumers' usage of Internet search and discovery tools, such as recommendation engines, are associated with an increase the share of niche products. We conclude that the Internet's long tail is not solely due to the increase in product selection but may also partly reflect lower search costs on the Internet. If the relationships we uncover persist, the underlying trends in technology portend an ongoing shift in the distribution of product sales."
957,"Systemic Risk: What Defaults Are Telling Us","Giesecke, Kay and Kim, Baeho","MANAGEMENT SCIENCE","57","8","1387-1405","2011","AUG","Banks;Financial System;Correlated Failure;Systemic Risk","","This paper develops dynamic measures of the systemic risk of the financial sector as a whole. It defines systemic risk as the conditional probability of failure of a sufficiently large fraction of the total population of financial institutions. This definition recognizes that the cause of systemic distress is the correlated failure of institutions to meet obligations to creditors, customers, and trading partners. The likelihood estimators of the failure probability are based on a dynamic hazard model of correlated failure timing that captures the influence on failure timing of time-varying macroeconomic and sector-specific risk factors, and of spillover effects. Tests indicate that our measures provide accurate out-of-sample forecasts of the term structure of systemic risk in the United States for the period from 1998 to 2009."
958,"A Generalized Measure of Riskiness","Bali, Turan G. and Cakici, Nusret and Chabi-Yo, Fousseni","MANAGEMENT SCIENCE","57","8","1406-1423","2011","AUG","Riskiness;Economic Index Of Riskiness;Operational Measure Of Riskiness;Risk-Neutral Measures;Stock Returns","","This paper proposes a generalized measure of riskiness that nests the original measures pioneered by Aumann and Serrano (Aumann, R. J., R. Serrano. 2008. An economic index of riskiness. J. Political Econom. 116(5) 810-836) and Foster and Hart (Foster, D. P., S. Hart. 2009. An operational measure of riskiness. J. Political Econom. 117(5) 785-814). The paper introduces the generalized options' implied measure of riskiness based on the risk-neutral return distribution of financial securities. It also provides asset allocation implications and shows that the forward-looking measures of riskiness successfully predict the cross section of 1-, 3-, 6-, and 12-month-ahead risk-adjusted returns of individual stocks. The empirical results indicate that the generalized measure of riskiness is able to rank equity portfolios based on their expected returns per unit of risk and hence yields a more efficient strategy for maximizing expected return of the portfolio while minimizing its risk."
959,"The Benefits of Aggregate Performance Metrics in the Presence of Career Concerns","Arya, Anil and Mittendorf, Brian","MANAGEMENT SCIENCE","57","8","1424-1437","2011","AUG","Aggregation;Career Concerns;Group Performance Measures","","This paper considers the desirability of aggregate performance measures in light of the fact that many individuals' performance incentives are driven by a desire to shape external perceptions (and thus future pay). In contrast to the case of explicit incentive contracts, we find that when individuals' actions are driven by career incentives, an aggregate measure (e.g., group or team output) can sometimes alleviate moral hazard concerns and improve efficiency. Aggregation intermingles performance measures that may be differentially affected by skill and effort of many agents. When such entanglement increases the prospect that the external market will attribute an employee's effort-driven contribution to transferable skills, the employee exerts higher effort as a means of posturing to the market. The incentive benefit of aggregation is weighed against the incentive cost because of information loss. Information loss from aggregation can reduce the market's reliance on the measure and thus diminish agents' desire to undertake effort to influence the measure."
960,"Hedging and Vertical Integration in Electricity Markets","Aid, Rene and Chemla, Gilles and Porchet, Arnaud and Touzi, Nizar","MANAGEMENT SCIENCE","57","8","1438-1452","2011","AUG","Corporate Finance;Industries;Electric-Electronic;Financial Institutions;Markets;Asset Pricing","","This paper analyzes the interactions between competitive (wholesale) spot, retail, and forward markets and vertical integration in electricity markets. We develop an equilibrium model with producers, retailers, and traders to study and quantify the impact of forward markets and vertical integration on prices, risk premia, and retail market shares. We point out that forward hedging and vertical integration are two separate mechanisms for demand and spot price risk diversification that both reduce the retail price and increase retail market shares. We show that they differ in their impact on prices and firms' utility because of the asymmetry between production and retail segments. Vertical integration restores the symmetry between producers' and retailers' exposure to demand risk, whereas linear forward contracts do not. Vertical integration is superior to forward hedging when retailers are highly risk averse. We illustrate our analysis with data from the French electricity market."
961,"Risk-Neutral Models for Emission Allowance Prices and Option Valuation","Carmona, Rene and Hinz, Juri","MANAGEMENT SCIENCE","57","8","1453-1468","2011","AUG","Emission Derivatives;Emissions Markets;Cap-And-Trade Schemes;Environmental Finance","","The existence of mandatory emission trading schemes in Europe and the United States, and the increased liquidity of trading on futures contracts on CO(2) emissions allowances, led naturally to the next step in the development of these markets: These futures contracts are now used as underliers for a vibrant derivative market. In this paper, we give a rigorous analysis of a simple risk-neutral reduced-form model for allowance futures prices, demonstrate its calibration to historical data, and show how to price European call options written on these contracts."
962,"CEO Overconfidence and Innovation","Galasso, Alberto and Simcoe, Timothy S.","MANAGEMENT SCIENCE","57","8","1469-1484","2011","AUG","Innovation;R&D;Ceo Overconfidence;Managerial Biases","","Are the attitudes and beliefs of chief executive officers (CEOs) linked to their firms' innovative performance? This paper uses a measure of overconfidence, based on CEO stock-option exercise, to study the relationship between a CEO's revealed beliefs about future performance and standard measures of corporate innovation. We begin by developing a career concern model where CEOs innovate to provide evidence of their ability. The model predicts that overconfident CEOs, who underestimate the probability of failure, are more likely to pursue innovation, and that this effect is larger in more competitive industries. We test these predictions on a panel of large publicly traded firms for the years from 1980 to 1994. We find a robust positive association between overconfidence and citation-weighted patent counts in both cross-sectional and fixed-effect models. This effect is larger in more competitive industries. Our results suggest that overconfident CEOs are more likely to take their firms in a new technological direction."
963,"Valuing the Treasury's Capital Assistance Program","Glasserman, Paul and Wang, Zhenyu","MANAGEMENT SCIENCE","57","7","1195-1211","2011","JUL","Finance;Securities;Financial Institutions;Banks;Dynamic Programming;Applications","","T he Capital Assistance Program (CAP) was created by the U. S. government in February 2009 to provide backup capital to large financial institutions unable to raise sufficient capital from private investors. Under the terms of the CAP, a participating bank receives contingent capital by issuing preferred shares to the Treasury combined with embedded options for both parties: The bank gets the option to redeem the shares or convert them to common equity, with conversion mandatory after seven years; the Treasury earns dividends on the preferred shares and gets warrants on the bank's common equity. We develop a contingent claims framework in which to estimate market values of these CAP securities. The interaction between the competing options held by the buyer and issuer of these securities creates a game between the two parties, and our approach captures this strategic element of the joint valuation problem and clarifies the incentives it creates. We apply our method to the 18 publicly held bank holding companies that participated in the Supervisory Capital Assessment Program (the stress test) launched together with the CAP. On average, we estimate that compared to a market transaction, the CAP securities carry a net value of approximately 30% of the capital invested for a bank participating to the maximum extent allowed under the terms of the program. We also find that the net value varies widely across banks. We compare our estimates with abnormal stock price returns for the stress test banks at the time the terms of the CAP were announced; we find correlations between 0.78 and 0.85, depending on the precise choice of period and set of banks included. These results suggest that our valuation aligns with shareholder perception of the value of the program, prompting questions about industry reactions and the overall impact of the program."
964,"Mixed Source","Casadesus-Masanell, Ramon and Llanes, Gaston","MANAGEMENT SCIENCE","57","7","1212-1230","2011","JUL","Open Source;User Innovation;Business Models;Complementarity;Compatibility;Value Creation;Value Capture","","W e study competitive interaction between a profit-maximizing firm that sells software and complementary services, and a free open-source competitor. We examine the firm's choice of business model between the proprietary model (where all software modules are proprietary), the open-source model (where all-modules are open source), and the mixed-source model (where some-but not all-modules are open). When a module is opened, users can access and improve the code, which increases quality and value creation. Opened modules, however, are available for others to use free of charge. We derive the set of possibly optimal business models when the modules of the firm and the open-source competitor are compatible (and thus can be combined) and incompatible, and show that (i) when the firm's modules are of high (low) quality, the firm is more open under incompatibility (compatibility) than under compatibility (incompatibility); (ii) firms are more likely to open substitute, rather than complementary, modules to existing open-source projects; and (iii) there may be no trade-off between value creation and value capture when comparing business models with different degrees of openness."
965,"Market Timing with Option-Implied Distributions: A Forward-Looking Approach","Kostakis, Alexandros and Panigirtzoglou, Nikolaos and Skiadopoulos, George","MANAGEMENT SCIENCE","57","7","1231-1249","2011","JUL","Asset Allocation;Option-Implied Distributions;Market Timing;Performance Evaluation;Portfolio Choice;Risk Aversion","","We address the empirical implementation of the static asset allocation problem by developing a forward-looking approach that uses information from market option prices. To this end, we extract constant maturity S&P 500 implied distributions and transform them to the corresponding risk-adjusted ones. Then we form optimal portfolios consisting of a risky and a risk-free asset and evaluate their out-of-sample performance. We find that the use of risk-adjusted implied distributions times the market and makes the investor better off than if she uses historical returns' distributions to calculate her optimal strategy. The results hold under a number of evaluation metrics and utility functions and carry through even when transaction costs are taken into account. Not surprisingly, the reported market timing ability deteriorated during the recent subprime crisis. An extension of the approach to a dynamic asset allocation setting is also presented."
966,"Exclusive Territories and Manufacturers' Collusion","Piccolo, Salvatore and Reisinger, Markus","MANAGEMENT SCIENCE","57","7","1250-1266","2011","JUL","Exclusive Territories;Supply Chains;Tacit Collusion;Information Sharing;Vertical Restraints","","This paper highlights the rationale for exclusive territories in a model of repeated interaction between competing supply chains. We show that with observable contracts exclusive territories have two countervailing effects on manufacturers' incentives to sustain tacit collusion. First, granting local monopolies to retailers softens competition in a one-shot game. Hence, punishment profits are larger, thereby rendering deviation more profitable. Second, exclusive territories stifle deviation profits because retailers of competing brands adjust their prices to the wholesale contract offered by a deviant manufacturer, whereas intrabrand competition prevents such instantaneous reaction. We show that the latter effect tends to dominate, thereby making exclusive territories a more suitable organizational mode to cooperate. These insights are robust to endogenous communication between manufacturers. We also consider retailers' service investments. Here, a novel effect emerges that softens the procollusive value of exclusive territories: Retailers of a deviant manufacturer increase investments, which renders deviation more profitable."
967,"Modeling the Loss Distribution","Chava, Sudheer and Stefanescu, Catalina and Turnbull, Stuart","MANAGEMENT SCIENCE","57","7","1267-1287","2011","JUL","Loss Distribution;Default Prediction;Recovery Rates;Basel Ii","","In this paper, we focus on modeling and predicting the loss distribution for credit risky assets such as bonds and loans. We model the probability of default and the recovery rate given default based on shared covariates. We develop a new class of default models that explicitly accounts for sector specific and regime dependent unobservable heterogeneity in firm characteristics. Based on the analysis of a large default and recovery data set over the horizon 1980-2008, we document that the specification of the default model has a major impact on the predicted loss distribution, whereas the specification of the recovery model is less important. In particular, we find evidence that industry factors and regime dynamics affect the performance of default models, implying that the appropriate choice of default models for loss prediction will depend on the credit cycle and on portfolio characteristics. Finally, we show that default probabilities and recovery rates predicted out of sample are negatively correlated and that the magnitude of the correlation varies with seniority class, industry, and credit cycle."
968,"When Acquisition Spoils Retention: Direct Selling vs. Delegation Under CRM","Dong, Yan and Yao, Yuliang and Cui, Tony Haitao","MANAGEMENT SCIENCE","57","7","1288-1299","2011","JUL","Customer Acquisition;Customer Retention;Customer Value;Customer Relationship Management;Incentive Mechanism","","The widespread implementation of customer relationship management technologies in business has allowed companies to increasingly focus on both acquiring and retaining customers. The challenge of designing incentive mechanisms that simultaneously focus on customer acquisition and customer retention comes from the fact that customer acquisition and customer retention are usually separate but intertwined tasks that make providing proper incentives more difficult. The present study develops incentive mechanisms that simultaneously address acquisition and retention of customers with an emphasis on the interactions between them. The main focus of this study is to examine the impact of the negative effect of acquisition on retention, i.e., the spoiling effect, on firm performance under direct selling and delegation of customer acquisition. Our main finding is that the negative effect of acquisition on retention has a significant impact on acquisition and retention efforts and firm profit. In particular, when the customer acquisition and retention are independent, the firm's profit is higher under direct selling than under delegation; however, when acquisition spoils retention, interestingly, the firm's profit may be higher under delegation. Our analysis also finds that the spoiling effect not only reduces the optimal acquisition effort but may also reduce retention effort under both direct selling and delegation. Comparing the optimal efforts under direct selling and delegation, the acquisition effort is always lower under delegation regardless of the spoiling effect, but the retention effort may be higher under delegation with the spoiling effect. Furthermore, when the customer antagonism effect from price promotions is considered, our main results hold regarding the firm's preferences between direct selling and delegation, which demonstrates the robustness of our model."
969,"Centralized vs. Decentralized Ambulance Diversion: A Network Perspective","Deo, Sarang and Gurvich, Itai","MANAGEMENT SCIENCE","57","7","1300-1319","2011","JUL","Emergency Department;Ambulance Diversion;Game Theory;Queueing Networks","","One of the most important operational challenges faced by emergency departments (EDs) in the United States is patient overcrowding. In periods of overcrowding, an ED can request the emergency medical services (EMS) agency to divert incoming ambulances to neighboring hospitals, a phenomenon known as ambulance diversion. The EMS agency may accept this request provided that at least one of the neighboring EDs is not on diversion. From an operations perspective, properly executed ambulance diversion should result in resource pooling and reduce the overcrowding and delays in a network of EDs. Recent evidence indicates, however, that this potential benefit is not always realized. In this paper, we provide one potential explanation for this discrepancy and suggest potential remedies. Using a queueing game between two EDs that aim to minimize their own waiting time, we find that decentralized decisions regarding diversion explain the lack of pooling benefits. Specifically, we find the existence of a defensive equilibrium, wherein each ED does not accept diverted ambulances from the other ED. This defensiveness results in a depooling of the network and, subsequently, in delays that are significantly higher than when a social planner coordinates diversion. The social optimum is itself difficult to characterize analytically and has limited practical appeal because it depends on problem parameters such as arrival rates and length of stay. Instead, we identify an alternative solution that does not require the exact knowledge of the parameters and may be used by the EMS agencies to coordinate diversion decisions when defensive diversion is present. We show that this solution is approximately optimal for the social planner's problem. Moreover, it is Pareto improving over the defensive equilibrium whereas the social optimum, in general, might not be."
970,"Preference Reversals for Ambiguity Aversion","Trautmann, Stefan T. and Vieider, Ferdinand M. and Wakker, Peter P.","MANAGEMENT SCIENCE","57","7","1320-1333","2011","JUL","Ambiguity Aversion;Preference Reversal;Loss Aversion;Choice Versus Valuation","","T his paper finds preference reversals in measurements of ambiguity aversion, even if psychological and informational circumstances are kept constant. The reversals are of a fundamentally different nature than the reversals found before because they cannot be explained by context-dependent weightings of attributes. We offer an explanation based on Sugden's random-reference theory, with different elicitation methods generating different random reference points. Then measurements of ambiguity aversion that use willingness to pay are confounded by loss aversion and hence overestimate ambiguity aversion."
971,"Testing for Prudence and Skewness Seeking","Ebert, Sebastian and Wiesen, Daniel","MANAGEMENT SCIENCE","57","7","1334-1349","2011","JUL","Decision Making Under Risk;Precautionary Savings;Prudence;Downside Risk;Skewness Seeking;Laboratory Experiment","","Numerous theoretical predictions such as precautionary saving or preventive behavior have been derived for prudent decision makers. Further, prudence can be characterized as downside risk aversion and plays a key role in preference for skewness. We use a simple experimental method to test for prudence and skewness preference in the laboratory and compare the two. To this end, we introduce a novel graphical representation of compound lotteries that is easily accessible to subjects and test it for robustness, using a factorial design. Prudence is observed on the aggregate and individual level. We find that prudence does not boil down to skewness seeking. We further provide some theoretical explanations for this result."
972,"Anticipatory Sorting and Gender Segregation in Temporary Employment","Fernandez-Mateo, Isabel and King, Zella","MANAGEMENT SCIENCE","57","6","989-1008","2011","JUN","Organizational Studies;Personnel;Hiring;Gender Stratification","","We examine the roots of gender segregation in the screening process by using a longitudinal data set of candidates considered for temporary projects at a staffing firm and following their progress through the hiring pipeline. Theories invoked to explain gender segregation across jobs traditionally rely on firm-specific human capital and expectations of future commitment to explain this phenomenon. These do not apply in this setting. Yet we find that the staffing firm is more likely to shortlist women for low-paid projects and less likely to do so for high-paid ones. These effects are due to women being considered for different projects than men, and associated at least partially to the level of competition within vacancies. Although client companies also exhibit some gender-sorting behavior in the later steps of the hiring process, they are more likely to prefer women and less likely to sort them into lower-paid projects. Our findings are consistent with anticipatory gender-sorting mechanisms, by which first screeners generate segregation when narrowing down the pool of candidates for later decision makers. We discuss the implications of this case for theories of gender stratification and workplace inequality, especially in mediated labor markets."
973,"Managing Product Variety and Collocation in a Competitive Environment: An Empirical Investigation of Consumer Electronics Retailing","Ren, Charlotte R. and Hu, Ye and Hu, Yu (Jeffrey) and Hausman, Jerry","MANAGEMENT SCIENCE","57","6","1009-1024","2011","JUN","Product Variety;Competition;Collocation;Differentiation","","Product variety is an important strategic tool that firms can use to attract customers and respond to competition. This study focuses on the retail industry and investigates how stores manage their product variety, contingent on the presence of competition and their actual distance from rivals. Using a unique data set that contains all Best Buy and Circuit City stores in the United States, the authors find that a store's product variety (i.e., number of stock-keeping units) increases if a rival store exists in its market but, in the presence of such competition, decreases when the rival store is collocated (within one mile of the focal store). Moreover, collocated rival stores tend to differentiate themselves by overlapping less in product range than do noncollocated rivals. This smaller and more differentiated product variety may be because of coordinated interactions between collocated stores. In summary, this paper presents evidence of both coordination and competition in retailers' use of product variety."
974,"Optimal Housing, Consumption, and Investment Decisions over the Life Cycle","Kraft, Holger and Munk, Claus","MANAGEMENT SCIENCE","57","6","1025-1041","2011","JUN","Housing;Labor Income;Portfolio Choice;Life-Cycle Decisions;Reits","","W e derive explicit solutions to life-cycle utility maximization problems involving stock and bond investment, perishable consumption, and the rental and ownership of residential real estate. Prices of houses, stocks and bonds, and labor income are correlated. Because of a positive correlation between house prices and labor income, young individuals want little exposure to house price risk and tend to rent their home. Later in life the desired housing investment increases and will eventually reach and exceed the desired consumption, suggesting that the individual should buy his home-and either additional housing units (for renting out) or house price-linked financial assets. In the final years, preferences shift back to home rental. The derived strategies are still useful if housing positions are only reset infrequently. Our results suggest that markets for real estate investment trusts or other house price-linked contracts lead to nonnegligible welfare gains."
975,"Why Genius Leads to Adversity: Experimental Evidence on the Reputational Effects of Task Difficulty Choices","Katok, Elena and Siemsen, Enno","MANAGEMENT SCIENCE","57","6","1042-1054","2011","JUN","Incentives In R&D;Behavioral Operations;Career Concerns;Decentralization","","We use a behavioral laboratory experiment to study how agents with reputation concerns select the difficulty of their tasks. Drawing upon existing theory, we subjected participants in our study to a context in which they had to convince a principal of their capability to reap financial benefits. Our results show that participants tended to increase the difficulty of their task to enhance their reputation. In addition, we provide evidence that performance rewards reduce a less capable agent's tendency to choose a more difficult task, whereas a highly capable agent's pattern of choices is unaffected by performance rewards. Although the productivity of agents in our experiment therefore decreased if they had to convince a principal of their capability, we show that these detrimental performance implications can to some degree be overcome for less capable agents through performance rewards or by ensuring that the principal can interpret the agent's choice."
976,"Optimal Preorder Strategy with Endogenous Information Control","Chu, Leon Yang and Zhang, Hao","MANAGEMENT SCIENCE","57","6","1055-1077","2011","JUN","Preorder;Advance Selling;Information Release;Consumer Valuation Control","","In this paper, we investigate the integrated information and pricing strategy for a seller who can take customer preorders before the release of a product. The preorder option enables the seller to sell a product at an early stage when consumers are less certain about their valuations. We find that the optimal pricing strategy may be highly dependent on the amount of information available at preorder and that a small change in the latter may cause a dramatic change in the proportion of consumers who preorder under optimal pricing. Furthermore, the seller's optimal information strategy depends on a key measure, the normalized margin, which is the ratio between the expected profit margin and the standard deviation of consumer valuation. Although the seller may want to release some information or none, she should never release all information. Finally, under the optimal information and pricing strategy, the benefit of preorder is most pronounced when the normalized margin is in a medium range."
977,"Dynamic Price Competition with Fixed Capacities","Martinez-de-Albeniz, Victor and Talluri, Kalyan","MANAGEMENT SCIENCE","57","6","1078-1093","2011","JUN","Revenue Management;Bid Prices;Subgame-Perfect Equilibrium","","In this paper, we study price competition for an oligopoly in a dynamic setting, where each of the sellers has a fixed number of units available for sale over a fixed number of periods. Demand is stochastic, and depending on how it evolves, sellers may change their prices at any time. This reflects the fact that firms constantly, and almost costlessly, change their prices, reacting to updates in their estimates of market demand, competitor prices, or inventory levels. In a setting with demand uncertainty, we show that there is a unique subgame-perfect equilibrium for a duopoly, in which all states sellers engage in Bertrand competition and the seller with the lower equilibrium reservation value sells a unit at a price equal to the competitor's equilibrium reservation value. This structure therefore extends the marginal-value concept of bid-price control, used in many revenue management implementations, to a competitive model. We give a closed-form solution to the equilibrium price paths for a duopoly and extend all the results to an n-firm oligopoly. We then study extensions to multiple customer types, uncertain valuations, and differentiated products."
978,"Loss Aversion with a State-Dependent Reference Point","De Giorgi, Enrico G. and Post, Thierry","MANAGEMENT SCIENCE","57","6","1094-1110","2011","JUN","Behavioral Finance;Asset Pricing;Equity Premium Puzzle;Reference-Dependent Preferences","","This study investigates reference-dependent choice with a stochastic, state-dependent reference point. The optimal reference-dependent solution equals the optimal consumption solution ( no loss aversion) if the reference point is selected fully endogenously. Given that loss aversion is widespread, we conclude that the reference point generally includes an important exogenously fixed component. We develop a choice model in which adjustment costs can cause stickiness relative to an initial, exogenous reference point. Using historical U. S. investment benchmark data, we show that this model is consistent with diversification across bonds and stocks for a wide range of evaluation horizons, despite the historically high-risk premium of stocks compared to bonds."
979,"Trust in Forecast Information Sharing","Oezer, Oezalp and Zheng, Yanchong and Chen, Kay-Yut","MANAGEMENT SCIENCE","57","6","1111-1137","2011","JUN","Trust;Trustworthiness;Cheap Talk;Asymmetric Forecast Information;Wholesale Price Contract;Behavioral Economics;Experimental Economics","","This paper investigates the capacity investment decision of a supplier who solicits private forecast information from a manufacturer. To ensure abundant supply, the manufacturer has an incentive to inflate her forecast in a costless, nonbinding, and nonverifiable type of communication known as cheap talk. According to standard game theory, parties do not cooperate and the only equilibrium is uninformative-the manufacturer's report is independent of her forecast and the supplier does not use the report to determine capacity. However, we observe in controlled laboratory experiments that parties cooperate even in the absence of reputation-building mechanisms and complex contracts. We argue that the underlying reason for cooperation is trust and trustworthiness. The extant literature on forecast sharing and supply chain coordination implicitly assumes that supply chain members either absolutely trust each other and cooperate when sharing forecast information, or do not trust each other at all. Contrary to this all-or-nothing view, we determine that a continuum exists between these two extremes. In addition, we determine (i) when trust is important in forecast information sharing, (ii) how trust is affected by changes in the supply chain environment, and (iii) how trust affects related operational decisions. To explain and better understand the observed behavioral regularities, we also develop an analytical model of trust to incorporate both pecuniary and nonpecuniary incentives in the game-theoretic analysis of cheap-talk forecast communication. The model identifies and quantifies how trust and trustworthiness induce effective cheap-talk forecast sharing under the wholesale price contract. We also determine the impact of repeated interactions and information feedback on trust and cooperation in forecast sharing. We conclude with a discussion on the implications of our results for developing effective forecast management policies."
980,"Mandatory Fair Value Accounting and Information Asymmetry: Evidence from the European Real Estate Industry","Muller, III, Karl A. and Riedl, Edward J. and Sellhorn, Thorsten","MANAGEMENT SCIENCE","57","6","1138-1153","2011","JUN","Fair Value;Disclosure;Ifrs;Information Asymmetry;Investment Property","","We examine the effects of mandating the provision of fair value information for long-lived tangible assets on firms' information asymmetry. Specifically, we investigate whether European real estate firms' compulsory adoption of International Accounting Standard 40 (IAS 40; Investment Property), which mandated the provision of investment property fair values in 2005, resulted in reduced information asymmetry across market participants. Using as a control group firms that voluntarily provided these fair values prior to the mandatory adoption of IAS 40, we find that mandatory adoption firms exhibit a larger decline in information asymmetry, as reflected in lower bid-ask spreads. However, we also find that mandatory adoption firms continue to have higher information asymmetry than voluntary adoption firms, which appears partially attributable to the lower reliability of fair values reported by the mandatory adoption firms. Together, this evidence adds to the debate on fair value accounting by demonstrating that common adoption of fair value, even for long-lived tangible assets, under a mandatory reporting regime can reduce, but not necessarily eliminate, information asymmetry differences across firms."
981,"The Impact of Demand Aggregation Through Delayed Component Allocation in an Assemble-to-Order System","Bernstein, Fernando and DeCroix, Gregory A. and Wang, Yulan","MANAGEMENT SCIENCE","57","6","1154-1171","2011","JUN","Assemble-To-Order;Inventory Production;Policies;Capacity;Stochastic;Multi-Item","","We consider an assemble-to-order system in which multiple products are assembled from a common component and a set of product-dedicated components. Component capacities are chosen prior to a finite-horizon selling season, and the common component is allocated to the products based on observed demands. We propose a collection of allocation mechanisms involving varying degrees of demand aggregation, ranging from a scheme under which all demands are observed prior to making the allocation decision to allocations made for each arriving demand. In this context, we explore the impact of the allocation scheme on sales, profits, and capacity decisions, including the degree of capacity imbalance. We find that the benefit from increased demand aggregation is closely linked to the degree of capacity imbalance: profit gains from delayed allocation tend to be higher in systems in which the optimal capacity portfolio is highly unbalanced when the allocation decision is made after observing all demands. We develop insights into what detailed system parameters lead to the largest gains from demand aggregation and also explore the trade-offs associated with the choice of an allocation scheme when customers exhibit impatience if the allocation scheme forces them to wait to be served."
982,"Efficient Risk Estimation via Nested Sequential Simulation","Broadie, Mark and Du, Yiping and Moallemi, Ciamac C.","MANAGEMENT SCIENCE","57","6","1172-1194","2011","JUN","Simulation;Decision Analysis;Risk;Risk Management;Sequential Analysis","","We analyze the computational problem of estimating financial risk in a nested simulation. In this approach, an outer simulation is used to generate financial scenarios, and an inner simulation is used to estimate future portfolio values in each scenario. We focus on one risk measure, the probability of a large loss, and we propose a new algorithm to estimate this risk. Our algorithm sequentially allocates computational effort in the inner simulation based on marginal changes in the risk estimator in each scenario. Theoretical results are given to show that the risk estimator has a faster convergence order compared to the conventional uniform inner sampling approach. Numerical results consistent with the theory are presented."
983,"Going, Going, Gone? The Apparent Demise of the Accruals Anomaly","Green, Jeremiah and Hand, John R. M. and Soliman, Mark T.","MANAGEMENT SCIENCE","57","5","797-816","2011","MAY","Accruals Anomaly;Market Efficiency;Hedge Funds","","Consistent with public statements made by sophisticated practitioners, we document that the hedge returns to Sloan's (Sloan, R. G. 1996. Do stock prices fully reflect information in accruals and cash flows about future earnings? Accounting Rev. 71(3) 289-315) accruals anomaly appear to have decayed in U. S. stock markets to the point that they are, on average, no longer reliably positive. We explore some potential reasons why this has happened. Our empirical analyses suggest that the anomaly's demise stems in part from an increase in the amount of capital invested by hedge funds into exploiting it, as measured by hedge fund assets under management and trading volume in extreme accrual firms. A decline in the size of the accrual mispricing signal, as measured by the magnitude of extreme decile accruals and the relative persistence of cash flows and accruals, may also play a (weaker) role."
984,"Can Losing Lead to Winning?","Berger, Jonah and Pope, Devin","MANAGEMENT SCIENCE","57","5","817-827","2011","MAY","Competition;Motivation;Performance;Prospect Theory","","Individuals, groups, and teams who are behind their opponents in competition tend to be more likely to lose. In contrast, we show that through increasing motivation, being slightly behind can actually increase success. Analysis of more than 18,000 professional basketball games illustrates that being slightly behind at halftime leads to a discontinuous increase in winning percentage. Teams behind by a point at halftime, for example, actually win more often than teams ahead by one, or approximately six percentage points more often than expected. This psychological effect is roughly half the size of the proverbial home-team advantage. Analysis of more than 45,000 collegiate basketball games finds consistent, though smaller, results. Experiments corroborate the field data and generalize their findings, providing direct causal evidence that being slightly behind increases effort and casting doubt on alternative explanations for the results. Taken together, these findings illustrate that losing can sometimes lead to winning."
985,"How Does Popularity Information Affect Choices? A Field Experiment","Tucker, Catherine Elizabeth and Zhang, Juanjuan","MANAGEMENT SCIENCE","57","5","828-842","2011","MAY","Popularity Information;Observational Learning;Field Experiment;Internet Marketing","","Popularity information is usually thought to reinforce existing sales trends by encouraging customers to flock to mainstream products with broad appeal. We suggest a countervailing market force: popularity information may benefit niche products with narrow appeal disproportionately, because the same level of popularity implies higher quality for narrow-appeal products than for broad-appeal products. We examine this hypothesis empirically using field experiment data from a website that lists wedding service vendors. Our findings are consistent with this hypothesis: narrow-appeal vendors receive more visits than equally popular broad-appeal vendors after the introduction of popularity information."
986,"Incentives and Problem Uncertainty in Innovation Contests: An Empirical Analysis","Boudreau, Kevin J. and Lacetera, Nicola and Lakhani, Karim R.","MANAGEMENT SCIENCE","57","5","843-863","2011","MAY","Innovation Contests;Uncertainty;Innovation;Problem Solving;Tournaments","","Contests are a historically important and increasingly popular mechanism for encouraging innovation. A central concern in designing innovation contests is how many competitors to admit. Using a unique data set of 9,661 software contests, we provide evidence of two coexisting and opposing forces that operate when the number of competitors increases. Greater rivalry reduces the incentives of all competitors in a contest to exert effort and make investments. At the same time, adding competitors increases the likelihood that at least one competitor will find an extreme-value solution. We show that the effort-reducing effect of greater rivalry dominates for less uncertain problems, whereas the effect on the extreme value prevails for more uncertain problems. Adding competitors thus systematically increases overall contest performance for high-uncertainty problems. We also find that higher uncertainty reduces the negative effect of added competitors on incentives. Thus, uncertainty and the nature of the problem should be explicitly considered in the design of innovation tournaments. We explore the implications of our findings for the theory and practice of innovation contests."
987,"Designing Multiperson Tournaments with Asymmetric Contestants: An Experimental Study","Chen, Hua and Ham, Sung H. and Lim, Noah","MANAGEMENT SCIENCE","57","5","864-883","2011","MAY","Tournaments;Compensation;Sales Management;Experimental Economics;Behavioral Economics","","Is the right amount of effort exerted in multiperson tournaments where contestants have two different levels of initial endowments (termed favorites and underdogs)? We develop theoretical predictions for the level of effort and the effect of varying the prize structure. We test these predictions for three-person tournaments using an economic experiment in a social environment where contest outcomes are publicly announced. We find that both favorites and underdogs overexert effort relative to the theoretical point predictions. Moreover, in the treatment with two favorites and one underdog, favorites increase their effort when the number of prizes is increased from one to two, contrary to the theory prediction. We show that a generalized model that allows for psychological losses from losing for favorites and psychological gains from winning for underdogs because of social comparisons tracks the experimental results better than the standard theoretical model."
988,"Overconfidence by Bayesian-Rational Agents","Van den Steen, Eric","MANAGEMENT SCIENCE","57","5","884-896","2011","MAY","Overconfidence;Decision Analysis;Risk;Bayesian Updating;Differing Priors;Heterogeneous Priors","","This paper derives two mechanisms through which Bayesian-rational individuals with differing priors will tend to be relatively overconfident about their estimates and predictions, in the sense of overestimating the precision of these estimates. The intuition behind one mechanism is slightly ironic: In trying to update optimally, Bayesian agents overweight information of which they overestimate the precision and underweight in the opposite case. This causes overall an overestimation of the precision of the final estimate, which tends to increase as agents get more data."
989,"Retail Channel Structure Impact on Strategic Engineering Product Design","Williams, Nathan and Kannan, P. K. and Azarm, Shapour","MANAGEMENT SCIENCE","57","5","897-914","2011","MAY","New Product Design;Engineering Design;Research And Development;Retail Channels;Marketing;Game Theory;Genetic Algorithms;Latent Class Models;Structural Models","","We examine, in a strategic setting, the broad issue of how retail channel structures-retail monopoly versus retail duopoly-impact a manufacturer's optimal new product design, both in terms of engineering design specifications as well as manufacturer and retailer profits. Our strategic framework enables manufacturers in specific contexts to anticipate the reactions of the retailers and competitive manufacturers to new designs in terms of the retail and wholesale pricing and to understand how different channel structures and channel strategies (such as an exclusive channel strategy) impact the engineering design of the new product, conditional on consumer preference distributions and competitor product attributes. Based on a simple numerical and a power tool design example, we illustrate how the insight from the framework translates to design guidelines; specifically, understanding which designs are optimal under differing channel structure conditions, and which design variables need precise targeting given their profit sensitivity."
990,"Entry and Patenting in the Software Industry","Cockburn, Iain M. and MacGarvie, Megan J.","MANAGEMENT SCIENCE","57","5","915-933","2011","MAY","Innovation;Intellectual Property Rights;Software Patents;Entry","","To what extent are firms kept out of a market by patents covering related technologies? Do patents held by potential entrants make it easier to enter markets? We estimate the empirical relationship between market entry and patents for 27 narrowly defined categories of software products during the period 1990-2004. Controlling for demand, market structure, average patent quality, and other factors, we find that a 10% increase in the number of patents relevant to market reduces the rate of entry by 3%-8%, and this relationship intensified following expansions in the patentability of software in the mid-1990s. However, potential entrants with patent applications relevant to a market are more likely to enter it. Finally, patents appear to substitute for complementary assets in the entry process, because patents have both greater entry-deterring and entry-promoting effects for firms without prior experience in other markets."
991,"Who Should Be Responsible for Software Security? A Comparative Analysis of Liability Policies in Network Environments","August, Terrence and Tunca, Tunay I.","MANAGEMENT SCIENCE","57","5","934-959","2011","MAY","It Policy And Management;Economics Of Is;Network Economics;Enabling Technologies;Software;Liability;Zero-Day","","In recent years, vendor liability for software security vulnerabilities has been the center of an important debate in the software community and a topic gaining government attention in legislative committees and hearings. The importance of this question surrounding vendor security liability is amplified when one considers the increasing emergence of zero-day attacks where hackers take advantage of vulnerabilities before the software vendor has a chance to release protective patches. In this paper, we compare the effectiveness of three software liability policies: vendor liability for damages, vendor liability for patching costs, and government imposed security standards. We find that vendor liability for losses is not effective in improving social welfare in the short run, while liability for patching costs can be effective if either patching costs are large and the likelihood of a zero-day attack is low, or patching costs are small and zero-day likelihood is high. In the long run, when the vendor can invest in reducing the likelihood of security vulnerabilities, loss liability is still ineffective when the zero-day attack probability is high but can increase both vendor investment in security and social welfare when zero-day attack likelihood is sufficiently low. When the zero-day attack probability is high, patch liability is ineffective if user patching costs are large, but partial patch liability can boost vendor investment and improve welfare when patching costs are small. In contrast, in an environment with low zero-day attack probability, full vendor patch liability can be optimal. Finally, comparing the effectiveness of the three liability policies under study, we find that government imposed standards on software security investment can be preferable to both patching and loss liability on the vendor, if zero-day attack likelihood is sufficiently low. However, if zero-day attacks are a common occurrence and patching costs are not too high, partial patch liability is the most effective policy."
992,"Monte Carlo Bounds for Game Options Including Convertible Bonds","Beveridge, Christopher and Joshi, Mark","MANAGEMENT SCIENCE","57","5","960-974","2011","MAY","Finance;Asset Pricing;Games-Group Decisions;Stochastic;Probability;Stochastic Model Applications;Monte Carlo Simulation;Bermudan Optionality","","We introduce two new methods to calculate bounds for zero-sum game options using Monte Carlo simulation. These extend and generalize upper-bound duality results to the case where both parties of a contract have Bermudan optionality. It is shown that the primal-dual simulation method can still be used as a generic way to obtain bounds in the extended framework, and we apply the new results to the pricing of convertible bonds by simulation."
993,"Risk Preferences at Different Time Periods: An Experimental Investigation","Abdellaoui, Mohammed and Diecidue, Enrico and Oencueler, Ayse","MANAGEMENT SCIENCE","57","5","975-987","2011","MAY","Time Preferences;Risk Preferences;Delayed Lotteries;Attitude Toward Risk;Utility;Decision Weights;Optimism;Sensitivity To Probabilities","","Intertemporal decision making under risk involves two dimensions: time preferences and risk preferences. This paper focuses on the impact of time on risk preferences, independent of the intertemporal trade-off of outcomes, i.e., time preferences. It reports the results of an experimental study that examines how delayed resolution and payment of risky options influence individual choice. We used a simple experimental design based on the comparison of two-outcome monetary lotteries with the same delay. Raw data clearly reveal that subjects become more risk tolerant for delayed lotteries. Assuming a prospect theory-like model under risk, we analyze the impact of time on utility and decision weights, independent of time preferences. We show that the subjective treatment of outcomes (i.e., utility) is not significantly affected by time. In fact, the impact of time is completely absorbed by the probability weighting function. The effect of time on risk preferences was found to generate probabilistic optimism resulting in a higher risk tolerance for delayed lotteries."
994,"Sabotage in Tournaments: Evidence from a Laboratory Experiment","Harbring, Christine and Irlenbusch, Bernd","MANAGEMENT SCIENCE","57","4","611-627","2011","APR","Decision Analysis;Applications;Organizational Studies;Decision Making;Motivation;Incentives","","Although relative performance schemes are pervasive in organizations, reliable empirical data on induced sabotage behavior are almost nonexistent. We study sabotage in repeated tournaments in a controlled laboratory experiment and observe that effort and sabotage are higher for higher wage spreads. Additionally, we find that also in the presence of tournament incentives, agents react reciprocally to higher wages by exerting higher effort. Destructive activities are reduced by explicitly calling them by their name sabotage. Communication among principal and agents can curb sabotage when they agree on flat prize structures and increased output. If sabotage is not possible, the principals choose tournament incentives more often."
995,"Fund Flows, Performance, Managerial Career Concerns, and Risk Taking","Hu, Ping and Kale, Jayant R. and Pagani, Marco and Subramanian, Ajay","MANAGEMENT SCIENCE","57","4","628-646","2011","APR","Mutual Funds;Asset Flows;Relative Risk;Ability;Career Concerns;Employment Risk","","We develop a unified model of the interactions among investors, fund companies, and fund managers. We show that the interplay between a manager's incentives from her compensation structure and career concerns leads to a nonmonotonic (approximately U-shaped) relation between her risk choices and prior performance relative to her peers. Significantly outperforming (underperforming) managers are less (more) likely to be fired in the future and are also more likely to increase relative risk. Ceteris paribus, relative risk declines with the level of employment risk faced by a manager. Using a large sample of mutual fund managers, we find strong support for the hypothesized U-shaped relation between relative risk and prior performance. Our findings also highlight the importance of employment risk as the underlying driver of risk shifting by fund managers. Our theoretical model also generates additional hypotheses that link determinants of the fund flow-performance relation and managers' employment risk to their risk-taking behavior. In support, our empirical analysis shows that funds with higher expense ratios have less convex fund flow-performance relations and less convex U-shaped relations between relative risk and prior performance; funds with younger managers, who face greater employment risk, have more convex U-shaped relative risk-prior performance relations; and managers in larger fund families have lower incentives to engage in risk shifting, thereby leading to a less convex U-shaped relation."
996,"Integrated Sequencing and Scheduling in Coil Coating","Hoehn, Wiebke and Koenig, Felix G. and Moehring, Rolf H. and Luebbecke, Marco E.","MANAGEMENT SCIENCE","57","4","647-666","2011","APR","Sequencing;Scheduling;Integrated Steel Production;Coil Coating;2-Union Graphs;Independent Set;Branch-And-Price","","We consider a complex planning problem in integrated steel production. A sequence of coils of sheet metal needs to be color coated in consecutive stages. Different coil geometries and changes of colors necessitate time-consuming setup work. In most coating stages one can choose between two parallel color tanks. This can either reduce the number of setups needed or enable setups concurrent with production. A production plan comprises the sequencing of coils and the scheduling of color tanks and setup work. The aim is to minimize the makespan for a given set of coils. We present an optimization model for this integrated sequencing and scheduling problem. A core component is a graph theoretical model for concurrent setup scheduling. It is instrumental for building a fast heuristic that is embedded into a genetic algorithm to solve the sequencing problem. The quality of our solutions is evaluated via an integer program based on a combinatorial relaxation, showing that our solutions are within 10% of the optimum. Our algorithm is implemented at Salzgitter Flachstahl GmbH, a major German steel producer. This has led to an average reduction in makespan by over 13% and has greatly exceeded expectations."
997,"An Experimental Study of Information Revelation Policies in Sequential Auctions","Cason, Timothy N. and Kannan, Karthik N. and Siebert, Ralph","MANAGEMENT SCIENCE","57","4","667-688","2011","APR","Complete And Incomplete Information Revelation Policies;Laboratory Study;Procurement Auction;Multistage Game","","Theoretical models of information asymmetry have identified a trade-off between the desire to learn and the desire to prevent an opponent from learning private information. This paper reports a laboratory experiment that investigates if actual bidders account for this trade-off, using a sequential procurement auction with private cost information and varying information revelation policies. Specifically, the Complete Information Revelation Policy, where all submitted bids are revealed between auctions, is compared to the Incomplete Information Revelation Policy, where only the winning bid is revealed. The experimental results are largely consistent with the theoretical predictions. For example, bidders pool with other types to prevent an opponent from learning significantly more often under a Complete Information Revelation Policy. Also as predicted, the procurer pays less when employing an Incomplete Information Revelation Policy only when the market is highly competitive. Bids are usually more aggressive than the risk-neutral quantitative prediction, which is broadly consistent with risk aversion."
998,"Contract Complexity and Performance Under Asymmetric Demand Information: An Experimental Evaluation","Kalkanci, Basak and Chen, Kay-Yut and Erhun, Feryal","MANAGEMENT SCIENCE","57","4","689-704","2011","APR","Behavioral Operations Management;All-Unit Quantity Discount Contracts;Price-Only Contracts;Complex Contracts;Contract Performance;Supply Chain Efficiency;Asymmetric Demand Information;Experience-Weighted Attraction Learning Model","","Exploring the tension between theory and practice regarding complexity and performance in contract design is especially relevant. The goal of this paper is to understand why simpler contracts may commonly be preferred in practice despite being theoretically suboptimal. We study a two-tier supply chain with a single supplier and a single buyer to characterize the impact of contract complexity and asymmetric information on performance and to compare theoretical predictions to actual behavior in human subject experiments. In the experiments, the computerized buyer faces a newsvendor setting and has better information on end-consumer demand than the human supplier. The supplier offers either a quantity discount contract (with two or three price blocks) or a price-only contract, contracts that are commonplace in practice, yet different in complexity. Results show that, contrary to theoretical predictions, quantity discounts do not necessarily increase the supplier's profits. We also observe a more equitable distribution of profits between the supplier and the buyer than what theory predicts. These observations can be described with three decision biases (the probabilistic choice bias, the reinforcement bias, and the memory bias) and can be modeled using the experience-weighted attraction learning model. Our results demonstrate that simpler contracts, such as a price-only contract or a quantity discount contract with a low number of price blocks, are sufficient for a supplier designing contracts under asymmetric demand information."
999,"Generating Ambiguity in the Laboratory","Stecher, Jack and Shields, Timothy and Dickhaut, John","MANAGEMENT SCIENCE","57","4","705-712","2011","APR","Ambiguity;Ellsberg;Knightian Uncertainty;Laboratory Experiments;Decision Analysis;Theory","","This article develops a method for drawing samples from a distribution with no finite quantiles or moments. The method provides researchers with a way to give subjects the experience of ambiguity. In any experiment, learning the distribution from experience is impossible for the subjects, essentially because it is impossible for the experimenter. We characterize our method, illustrate it in simulations, and then test it in a laboratory experiment. Our method does not withhold sampling information, does not assume that the subject is incapable of making statistical inferences, is replicable across experiments, and requires no special apparatus. We compare our method to the techniques used in related experiments that attempt to produce an ambiguous experience for the subjects."
1000,"Buying from the Babbling Retailer? The Impact of Availability Information on Customer Behavior","Allon, Gad and Bassamboo, Achal","MANAGEMENT SCIENCE","57","4","713-726","2011","APR","Inventory;Cheap Talk;Revenue Management","","Provision of real-time information by a firm to its customers has become prevalent in recent years in both the service and retail sectors. In this paper, we study a retail operations model where customers are strategic in both their actions and in the way they interpret information, whereas the retailer is strategic in the way it provides information. This paper focuses on the ability (or the lack thereof) to communicate unverifiable information and influence customers' actions. We develop a game-theoretic framework to study this type of communication and discuss the equilibrium language emerging between the retailer and its customers. We show that for a single retailer and homogeneous customer population setting, the equilibrium language that emerges carries no information. In this sense, a single retailer providing information on its own cannot create any credibility with the customers. We study how the results are impacted due to the heterogeneity of the customers. We provide conditions under which the firm may be able to influence the customer behavior. In particular, we show that the customers' willingness to pay and willingness to wait cannot be ranked in an opposite manner. However, even when the firm can influence each customer class separately, the effective demand is not impacted."
1001,"How Does a Retailer's Service Plan Affect a Manufacturer's Warranty?","Jiang, Bo and Zhang, Xubing","MANAGEMENT SCIENCE","57","4","727-740","2011","APR","Service Plans;Warranty;Signaling;Distribution Channels;Game Theory","","A service plan is a type of optional warranty beyond manufacturers' base warranties that retailers offer to consumers. In this paper, we examine how a service plan affects the role played by a manufacturer's base warranty. Analysis shows that when consumers can assess product quality (i.e., the probability of product failure), the manufacturer's warranty is negatively affected by the presence of a service plan. In the presence of such a plan, a base warranty is offered only when the manufacturer is very cost-efficient in providing a warranty relative to the retailer. In this case, although the double-marginalization problem is aggravated, offering a (limited) base warranty reduces the total warranty cost in the channel and provokes the retailer into enlarging the service plan coverage. When consumers cannot assess product quality, a high-quality manufacturer is motivated to offer a base warranty to signal its quality. In the presence of a service plan, however, a very cost-efficient manufacturer is discouraged from doing so."
1002,"The Benefits of Competitive Upward Channel Decentralization","Liu, Yunchuan and Tyagi, Rajeev K.","MANAGEMENT SCIENCE","57","4","741-751","2011","APR","Upward Channel Decentralization;Production Outsourcing;Product Positioning;Distribution Channel;Game Theory","","Upward channel decentralization occurs when firms choose to not manufacture products by themselves and procure products from upstream suppliers. Current voices from marketing scholars and practitioners have predominantly focused on the cost benefits when production is outsourced to lower-cost upstream suppliers. In this paper, we study the effects of upward channel decentralization where competing firms can outsource their production to upstream suppliers who do not have any advantages on production costs. We show how downstream firms can still benefit from upward channel decentralization provided their product positioning is endogenous. Thus, we provide a new theory on the strategic benefits of upward channel decentralization. We also use this framework to show a new benefit to manufacturers selling through downstream retailers rather than directly. We examine the implications of our theory for consumer and social welfare, and also draw managerial implications."
1003,"Comarketing Alliances: Should You Contract on Actions or Outcomes?","Chennamaneni, Pavan Rao and Desiraju, Ramarao","MANAGEMENT SCIENCE","57","4","752-762","2011","APR","Comarketing Alliances;Marketing Externality;Information Asymmetry;Input Versus Output Monitoring","","Comarketing alliances often involve multiple partners, and a given partner's marketing efforts on behalf of the alliance can indirectly affect the demand of the other partners. Individual partners, however, can ignore the effects of such an externality and invest suboptimally to the detriment of the alliance. This paper examines the relative effectiveness of outcome-and action-based contracts in providing the alliance partners with the incentives to invest appropriately. We develop a mathematical model in which a focal firm (e. g., Sony) contracts with two partners (e. g., McDonald's and Old Navy) when each of these partners is privately informed about the impact of the alliance on its demand. Our analysis evaluates the strengths and weaknesses of outcome- (or output-) and action-based (or input-based) contracts in settings with varying levels of the demand externality. We find that when there is either no externality or a relatively weak positive externality, there is a strict preference for output-based contracts; that preference, however, is reversed with a sufficiently strong positive externality. This paper explains the underlying rationale for these findings."
1004,"Capacity Investment Timing by Start-ups and Established Firms in New Markets","Swinney, Robert and Cachon, Gerard P. and Netessine, Serguei","MANAGEMENT SCIENCE","57","4","763-777","2011","APR","Capacity;Competition;Uncertainty;Investment Timing;Game Theory","","We analyze the competitive capacity investment timing decisions of both established firms and start-ups entering new markets, which have a high degree of demand uncertainty. Firms may invest in capacity early (when uncertainty is high) or late (when uncertainty has been resolved), possibly at different costs. Established firms choose an investment timing and capacity level to maximize expected profits, whereas start-ups make those choices to maximize the probability of survival. When a start-up competes against an established firm, we find that when demand uncertainty is high and costs do not decline too severely over time, the start-up takes a leadership role and invests first in capacity, whereas the established firm follows; by contrast, when two established firms compete in an otherwise identical game, both firms invest late. We conclude that the threat of firm failure significantly impacts the dynamics of competition involving start-ups."
1005,"The Value of Fast Fashion: Quick Response, Enhanced Design, and Strategic Consumer Behavior","Cachon, Gerard P. and Swinney, Robert","MANAGEMENT SCIENCE","57","4","778-795","2011","APR","Strategic Consumer Behavior;Quick Response;Fast Fashion;Game Theory","","A fast fashion system combines quick response production capabilities with enhanced product design capabilities to both design hot products that capture the latest consumer trends and exploit minimal production lead times to match supply with uncertain demand. We develop a model of such a system and compare its performance to three alternative systems: quick-response-only systems, enhanced-design-only systems, and traditional systems (which lack both enhanced design and quick response capabilities). In particular, we focus on the impact of each of the four systems on strategic or forward-looking consumer purchasing behavior, i.e., the intentional delay in purchasing an item at the full price to obtain it during an end-of-season clearance. We find that enhanced design helps to mitigate strategic behavior by offering consumers a product they value more, making them less willing to risk waiting for a clearance sale and possibly experiencing a stockout. Quick response mitigates strategic behavior through a different mechanism: by better matching supply to demand, it reduces the chance of a clearance sale. Most importantly, we find that although it is possible for quick response and enhanced design to be either complements or substitutes, the complementarity effect tends to dominate. Hence, when both quick response and enhanced design are combined in a fast fashion system, the firm typically enjoys a greater incremental increase in profit than the sum of the increases resulting from employing either system in isolation. Furthermore, complementarity is strongest when customers are very strategic. We conclude that fast fashion systems can be of significant value, particularly when consumers exhibit strategic behavior."
1006,"Noncompete Covenants: Incentives to Innovate or Impediments to Growth","Samila, Sampsa and Sorenson, Olav","MANAGEMENT SCIENCE","57","3","425-438","2011","MAR","Venture Capital;Financial Intermediaries;Legal Institutions;Entrepreneurship;Employment;Innovation;Wages","","We find that the enforcement of noncompete clauses significantly impedes entrepreneurship and employment growth. Based on a panel of metropolitan areas in the United States from 1993 to 2002, our results indicate that, relative to states that enforce noncompete covenants, an increase in the local supply of venture capital in states that restrict the scope of these agreements has significantly stronger positive effects on (i) the number of patents, (ii) the number of firm starts, and (iii) employment. We address potential endogeneity in the supply of venture capital by using endowment returns as an instrumental variable. Our results point to a strong interaction between financial intermediation and the legal regime in promoting entrepreneurship and economic growth."
1007,"Organizing Contests for Status: The Matthew Effect vs. the Mark Effect","Bothner, Matthew S. and Podolny, Joel M. and Smith, Edward Bishop","MANAGEMENT SCIENCE","57","3","439-457","2011","MAR","Networks;Graphs;Theory;Organizational Studies;Design;Effectiveness;Performance;Status;Leadership","","What is the best way to design tournaments for status, in which individuals labor primarily for the esteem of their peers? What process, in other words, should organizers of status-based contests impose upon those who covet peer recognition? We propose a formal model of status-based competition that contrasts two competing alternatives. The first, following Merton, is the Matthew Effect, according to which a tournament's architect directs slack resources to elite actors and thus widens the distribution of rewards by favoring cumulative advantage. The second is the  Mark Effect, under which a tournament's designer instead pushes slack resources to marginal actors and thus tightens the distribution of rewards. Our results suggest that although the Mark Effect is better for the social welfare of most tournaments, the Matthew Effect is preferable in two distinct contexts: in small tournaments where variation in underlying ability translates into acute advantages for the most capable contestants; and in large tournaments whose contestants face constant, rather than rising, marginal costs-a condition we relate to contestants' perception of their work as intrinsically valuable. Our contributions are twofold: We find, counter to the thrust of Merton's work, that cumulative advantage is not invariably optimal for the functioning of status contests; and we identify circumstances in which the production of superstars is likely to make contests for status better off in aggregate. Implications for future research on status and management are discussed."
1008,"Search Engine Advertising: Channel Substitution When Pricing Ads to Context","Goldfarb, Avi and Tucker, Catherine E.","MANAGEMENT SCIENCE","57","3","458-470","2011","MAR","Advertising And Media;Information Systems;It Policy And Management;Electronic Commerce;Search Engine Advertising","","We explore substitution patterns across advertising platforms. Using data on the advertising prices paid by lawyers for 139 Google search terms in 195 locations, we exploit a natural experiment in ambulance-chaser regulations across states. When lawyers cannot contact clients by mail, advertising prices per click for search engine advertisements are 5%-7% higher. Therefore, online advertising substitutes for offline advertising. This substitution toward online advertising is strongest in markets with fewer customers, suggesting that the relationship between the online and offline media is mediated by the marketers' need to target their communications."
1009,"Portfolio Dynamics for Customers of a Multiservice Provider","Schweidel, David A. and Bradlow, Eric T. and Fader, Peter S.","MANAGEMENT SCIENCE","57","3","471-486","2011","MAR","Customer Relationship Management;Dynamic Hidden Markov Model;Customer Value","","Multiservice providers, such as telecommunication and financial service companies, can benefit from understanding how customers' service portfolios evolve over the course of their relationships. This can provide guidance for managerial issues such as customer valuation and predicting customers' future behavior, whether it is acquiring additional services, selectively dropping current services, or ending the relationship entirely. In this research, we develop a dynamic hidden Markov model to identify latent states that govern customers' affinity for the available services through which customers evolve. In addition, we incorporate and demonstrate the importance of separating two other sources of dynamics: portfolio inertia and service stickiness. We then examine the relationship between state membership and managerially relevant metrics, including customers' propensities for acquiring additional services or terminating the relationship, and customer lifetime value. Through a series of illustrative vignettes, we show that customers who have discarded a particular service may have an increased risk of canceling all services in the near future (as intuition would suggest) but also may be more prone to acquire more services, a provocative finding of interest to service providers. Our findings also emphasize the need to look beyond the previous period, as in much current research, and consider how customers have evolved over their entire relationship in order to predict their future actions."
1010,"A New Goodness-of-Fit Test for Event Forecasting and Its Application to Credit Defaults","Bloechlinger, Andreas and Leippold, Markus","MANAGEMENT SCIENCE","57","3","487-505","2011","MAR","Out-Of-Sample Validation;Probability Calibration;Hosmer-Lemeshow Statistic;Bernoulli Mixture Models;Credit Risk","","We develop a new goodness-of-fit test for validating the performance of probability forecasts. Our test statistic is particularly powerful under sparseness and dependence in the observed data. To build our test statistic, we start from a formal definition of calibrated forecasts, which we operationalize by introducing two components. The first component tests the level of the estimated probabilities; the second validates the shape, measuring the differentiation between high and low probability events. After constructing test statistics for both level and shape, we provide a global goodness-of-fit statistic, which is asymptotically chi(2) distributed. In a simulation exercise, we find that our approach is correctly sized and more powerful than alternative statistics. In particular, our shape statistic is significantly more powerful than the Kolmogorov-Smirnov test. Under independence, our global test has significantly greater power than the popular Hosmer-Lemeshow's chi(2) test. Moreover, even under dependence, our global test remains correctly sized and consistent. As a timely and important empirical application of our method, we study the validation of a forecasting model for credit default events."
1011,"Reference-Point Formation and Updating","Baucells, Manel and Weber, Martin and Welfens, Frank","MANAGEMENT SCIENCE","57","3","506-519","2011","MAR","Reference-Point Formation;Reference-Dependent Preferences;Disposition Effect;Probability Weighting","","Reference-dependent preferences have been well accepted in decision sciences, experimental economics, behavioral finance, and marketing. However, we still know very little about how decision makers form and update their reference points given a sequence of information. Our paper provides some novel experiments in a financial context to advance the understanding of reference-point formation over time. Our subjects' reference price is best described as a combination of the first and the last price of the time series, with intermediate prices receiving smaller and nondecaying weights. Hence, reference prices are not recursive. We provide a parsimonious formula to predict the reference points, which we test out-of-sample. The fit of the model is reasonably good."
1012,"Evaluating Heuristics Used When Designing Product Costing Systems","Balakrishnan, Ramji and Hansen, Stephen and Labro, Eva","MANAGEMENT SCIENCE","57","3","520-541","2011","MAR","Costing;Estimation;Activity-Based Costing;Cost Drivers;Cost Pools","","The academic and practitioner literature justifies firms' use of product costs in product pricing and capacity planning decisions as heuristics to address an otherwise intractable problem. However, product costs are the output of a cost reporting system, which itself is the outcome of heuristic design choices. In particular, because of informational limitations, when designing cost systems firms use simple rules of thumb to group resources into cost pools and to select drivers used to allocate the pooled costs to products. Using simulations, we examine how popular choices in costing system design influence the error in reported costs. Taking information needs into account, we offer alternative ways to translate the vague guidance in the literature to implementable methods. Specifically, we compare size-based rules for forming cost pools with more informationally demanding correlation-based rules and develop a blended method that performs well in terms of accuracy. In addition, our analysis suggests that significant gains can be made from using a composite driver rather than selecting a driver based on the consumption pattern for the largest resource only, especially when combined with correlation-based rules to group resources. We vary properties of the underlying cost structure (such as the skewness in resource costs, the traceability of resources to products, the sharing of resources across products, and the variance in resource consumption patterns) to address the generalizability of our findings and to show when different heuristics might be preferred."
1013,"A Model of Probabilistic Choice Satisfying First-Order Stochastic Dominance","Blavatskyy, Pavlo R.","MANAGEMENT SCIENCE","57","3","542-548","2011","MAR","Probabilistic Choice;First-Order Stochastic Dominance;Random Utility;Strong Utility","","This paper presents a new model of probabilistic binary choice under risk. In this model, a decision maker always satisfies first-order stochastic dominance. If neither lottery stochastically dominates the other alternative, a decision maker chooses in a probabilistic manner. The proposed model is derived from four standard axioms (completeness, weak stochastic transitivity, continuity, and common consequence independence) and two relatively new axioms. The proposed model provides a better fit to experimental data than do existing models. The baseline model can be extended to other domains such as modeling variable consumer demand."
1014,"New Plant Venture Performance Differences Among Incumbent, Diversifying, and Entrepreneurial Firms: The Impact of Industry Learning Intensity","Balasubramanian, Natarajan","MANAGEMENT SCIENCE","57","3","549-565","2011","MAR","Entrepreneurs;Learning Environment;Pre-Start-Up Experience;Dynamic Capabilities","","Prior firm experience, firm capabilities, and the industry environment are known to be important determinants of new-venture performance. We hypothesize that firm experience prior to setting up a new venture influences the ability to learn from experience after start-up (which is a key capability), and that this relationship is moderated by the importance of learning by doing within the new venture's industry (which is a critical aspect of the industry environment). We argue that together, these relationships influence performance differences among new plant ventures of incumbents, diversifying entrants, and entrepreneurial (de novo) entrants. Using data on 47,915 new plant ventures in U.S. manufacturing, we find that incumbents and diversifying entrants establish significantly more productive new plants than de novo entrants, and that this advantage significantly increases with the importance of learning by doing in an industry (industry learning intensity). These productivity differences appear to be driven more by learning subsequent to plant start-up than by initial disparities in productivity. Together, these findings strongly suggest that pre-start-up experience adds to the process of post-start-up learning, and that the industry learning environment plays an important role in whether entrepreneurial firms can achieve a competitive advantage over existing firms."
1015,"Sharing Demand Information in Competing Supply Chains with Production Diseconomies","Ha, Albert Y. and Tong, Shilu and Zhang, Hongtao","MANAGEMENT SCIENCE","57","3","566-581","2011","MAR","Supply Chain Management;Supply Chain Competition;Information Sharing","","This paper studies the incentive for vertical information sharing in competing supply chains with production technologies that exhibit diseconomies of scale. We consider a model of two supply chains each consisting of one manufacturer selling to one retailer, with the retailers engaging in Cournot or Bertrand competition. For Cournot retail competition, we show that information sharing benefits a supply chain when (1) the production diseconomy is large and (2) either competition is less intense or at least one retailer's information is less accurate. A supply chain may become worse off when making its information more accurate or production diseconomy smaller, if such an improvement induces the firms in the rival supply chain to cease sharing information. For Bertrand retail competition, we show that information sharing benefits a supply chain when (1) the production diseconomy is large and (2) either competition is less intense or information is more accurate. Under Bertrand competition a manufacturer may be worse off by receiving information, which is never the case under Cournot competition. Information sharing in one supply chain triggers a competitive reaction from the other supply chain and this reaction is damaging to the first supply chain under Cournot competition but may be beneficial under Bertrand competition."
1016,"The Midweight Method to Measure Attitudes Toward Risk and Ambiguity","van de Kuilen, Gijs and Wakker, Peter P.","MANAGEMENT SCIENCE","57","3","582-598","2011","MAR","Prospect Theory;Ambiguity;Probability Weighting;Pessimism","","This paper introduces a parameter-free method for measuring the weighting functions of prospect theory and rank-dependent utility. These weighting functions capture risk attitudes, subjective beliefs, and ambiguity attitudes. Our method, called the midweight method, is based on a convenient way to obtain midpoints in the weighting function scale. It can be used both for risk (known probabilities) and for uncertainty (unknown probabilities). The resulting integrated treatment of risk and uncertainty is particularly useful for measuring ambiguity, i.e., the difference between uncertainty and risk. Compared to existing methods to measure weighting functions and attitudes toward uncertainty and ambiguity, our method is more efficient and can accommodate violations of expected utility under risk. An experiment demonstrates the tractability of our method, yielding plausible results such as ambiguity aversion for moderate and high likelihoods but ambiguity seeking for low likelihoods, as predicted by Ellsberg."
1017,"Promised Delivery Time and Capacity Games in Time-Based Competition","Shang, Weixin and Liu, Liming","MANAGEMENT SCIENCE","57","3","599-610","2011","MAR","Time-Based Competition;Consumer Choice Model;Nash Equilibrium;Switching Surface;Quality Differentiation;Capacity Competition;Marketing-Operations Interface","","We investigate firms' competitive behaviors in industries where customers are sensitive to both promised delivery time (PDT) and quality of service (QoS) measured by the on-time delivery rate. To study the competition in PDT at the marketing level, we construct an oligopoly game with an external QoS requirement. We show that there exists a unique Nash equilibrium, and the equilibrium QoS exhibits a switching surface structure with respect to capacities. To study the competition in capacity at the strategic level, we construct a two-stage game in which the firms compete in terms of their capacities in stage 1 and in terms of PDT in stage 2. We show the existence of two different types of pure strategy equilibria and characterize them. This study provides the following insights: an index of time-based competitive advantage (ITCA) and the first-mover advantage determine the positions of the firms in time-based competition; either the well-known prisoner's dilemma or off-equilibrium behaviors due to different preferences for equilibria (when multiple equilibria exist) may lead the firms to overinvest in capacity, but no one may gain a competitive advantage; a uniform improvement in internal efficiency (i.e., a uniform capacity cost reduction) may harm everyone; quality differentiation (i.e., going beyond the QoS benchmark) plays a dual role in time-based competition, either helping a firm with a larger ITCA to compete more effectively, or helping a firm possibly with a smaller ITCA to preempt competitors and protect its market advantage."
1018,"Accelerated Learning of User Profiles","Atahan, Pelin and Sarkar, Sumit","MANAGEMENT SCIENCE","57","2","215-239","2011","FEB","Personalization;Bayesian Learning;Information Theory;Recommendation Systems","","Websites typically provide several links on each page visited by a user. Whereas some of these links help users easily navigate the site, others are typically used to provide targeted recommendations based on the available user profile. When the user profile is not available ( or is inadequate), the site cannot effectively target products, promotions, and advertisements. In those situations, the site can learn the profile of a user as the user traverses the site. Naturally, the faster the site can learn a user's profile, the sooner the site can benefit from personalization. We develop a technique that sites can use to learn the profile as quickly as possible. The technique identifies links for sites to make available that will lead to a more informative profile when the user chooses one of the offered links. Experiments conducted using our approach demonstrate that it enables learning the profiles markedly better after very few user interactions as compared to benchmark approaches. The approach effectively learns multiple attributes simultaneously, can learn well classes that have highly skewed priors, and remains quite effective even when the distribution of link profiles at a site is relatively homogeneous. The approach works particularly well when a user's traversal is influenced by the most recently visited pages on a site. Finally, we show that the approach is robust to noise in the estimates for the probability parameters needed for its implementation."
1019,"Organizational Change and Employee Stress","Dahl, Michael S.","MANAGEMENT SCIENCE","57","2","240-256","2011","FEB","Organizational Studies;Personnel;Behavior;Strategy","","This article analyzes the relationship between organizational change and employee health. It illuminates the potentially negative outcomes of change at the level of the employee. In addition, it relates to the ongoing debate over how employees react to and respond to organizational change. I hypothesize that change increases the risk of negative stress, and I test this hypothesis using a comprehensive panel data set of all stress-related medicine prescriptions for 92,860 employees working in 1,517 of the largest Danish organizations. The findings suggest that the risk of receiving stress-related medication increases significantly for employees at organizations that change, especially those that undergo broad simultaneous changes along several dimensions. Thus, organizational changes are associated with significant risks of employee health problems. These effects are further explored with respect to employees at different hierarchical levels as well as at firms of different sizes and from different sectors."
1020,"The Impact of Founders' Professional-Education Background on the Adoption of Open Science by For-Profit Biotechnology Firms","Ding, Waverly W.","MANAGEMENT SCIENCE","57","2","257-273","2011","FEB","Entrepreneurship;Founder Background;Professional Education;Open Science;Diffusion Of Innovation;Tmt","","This paper investigates the effect of founders' professional-education background on the adoption of an open-science technology strategy, using a sample of 512 young biotechnology firms. After controlling for founders' prior work experience and other organizational and environmental factors, I find that firms with proportionally more Ph.D.-holding entrepreneurs on the founding team have a higher probability of adopting open science. In addition, founders' educational background can mitigate the constraint of organizational environments on strategy. A crowded technological niche provides a more challenging environment for firms to implement open science, due to higher scooping risks. The deterrent effect, however, of such a high-risk environment is smaller among firms founded by proportionally more Ph.D.-holding entrepreneurs. There is also some evidence of a stronger effect of founders' educational background on open science in an institutional environment in which open science has yet to become the industry norm. This finding is consistent with and complements the growing body of research that emphasizes the importance of entrepreneurial background in developing knowledge about new-venture strategy and structure."
1021,"Status, Quality, and Attention: What's in a (Missing) Name?","Simcoe, Timothy S. and Waguespack, Dave M.","MANAGEMENT SCIENCE","57","2","274-290","2011","FEB","Status;Technology;Sociology Of Science","","How much are we influenced by an author's identity when evaluating his or her work? This paper exploits a natural experiment to measure the impact of status signals in the context of open standards development. For a period of time, e-mails announcing new submissions to the Internet Engineering Task Force would replace individual author names with et al. if submission volumes were unusually high. We measure the impact of status signals by comparing the effect of obscuring high-versus low-status author names. Our results show that name-based signals can explain up to three-quarters of the difference in publication rates between high- and low-status authors. The signaling effect disappears for a set of prescreened proposals that receive more scrutiny than a typical submission, suggesting that status signals are more important when attention is scarce (or search costs high). We also show that submissions from high-status authors receive more attention on electronic discussion boards, which may help high-status authors to develop their ideas and bring them forward to publication."
1022,"Determinants and Outcomes of Internet Banking Adoption","Xue, Mei and Hitt, Lorin M. and Chen, Pei-yu","MANAGEMENT SCIENCE","57","2","291-307","2011","FEB","Internet Banking Adoption;Customer Efficiency;Network Effects","","This paper examines the drivers of adoption of Internet banking and the linkages among adoption drivers and outcomes (product acquisition, service activity, profitability, loyalty). We relate Internet banking adoption to customer demand for banking services, the availability of alternative channels, customers' efficiency in service coproduction (customer efficiency), and local Internet banking penetration. We find that customers who have greater transaction demand and higher efficiency, and reside in areas with a greater density of online banking adopters, are faster to adopt online banking after controlling for time, regional, and individual characteristics. Consistent with prior work, we find that customers significantly increase their banking activity, acquire more products, and perform more transactions. These changes in behavior are not associated with short-run increases in customer profitability, but customers who adopt online banking have a lower propensity to leave the bank. Building on these observations we also find that the adoption drivers are linked to the postadoption changes in behavior or profitability. Customers who live in areas with a high branch density or high Internet banking penetration increase their product acquisition and transaction activity more than Internet banking adopters in other regions. Efficient customers and those with high service demand show greater postadoption profitability."
1023,"Portfolio Choice Under Cumulative Prospect Theory: An Analytical Treatment","He, Xue Dong and Zhou, Xun Yu","MANAGEMENT SCIENCE","57","2","315-331","2011","FEB","Portfolio Choice;Single Period;Cumulative Prospect Theory;Reference Point;Loss Aversion;S-Shaped Utility Function;Probability Weighting;Well-Posedness","","We formulate and carry out an analytical treatment of a single-period portfolio choice model featuring a reference point in wealth, S-shaped utility (value) functions with loss aversion, and probability weighting under Kahneman and Tversky's cumulative prospect theory (CPT). We introduce a new measure of loss aversion for large payoffs, called the large-loss aversion degree (LLAD), and show that it is a critical determinant of the well-posedness of the model. The sensitivity of the CPT value function with respect to the stock allocation is then investigated, which, as a by-product, demonstrates that this function is neither concave nor convex. We finally derive optimal solutions explicitly for the cases in which the reference point is the risk-free return and those in which it is not (while the utility function is piecewise linear), and we employ these results to investigate comparative statics of optimal risky exposures with respect to the reference point, the LLAD, and the curvature of the probability weighting."
1024,"Channel Stuffing with Short-Term Interest in Market Value","Lai, Guoming and Debo, Laurens and Nan, Lin","MANAGEMENT SCIENCE","57","2","332-346","2011","FEB","Channel Stuffing;Inventory Management;Market Value","","We study how a manager's short-term interest in the firm's market value may motivate channel stuffing: shipping excess inventory to the downstream channel. Channel stuffing allows a manager to report sales in excess of demand in order to influence investors' valuation of the firm. We apply an inventory model that highlights the potential role of inventory in the manager's channel stuffing and the investors' valuation strategies. Sales in our model are constrained by available inventory. Our model yields a semiseparating and semipooling equilibrium contingent on the initial inventory level: When the demand is lower than a threshold that depends on and is below the initial inventory level, the manager pads sales by a part of the excess inventory and releases the inflated sales report. The investors correct the reported sales and are able to infer perfectly the firm's value. When the demand reaches or exceeds this threshold, the manager pads any excess inventory to the sales and reports the initial inventory is sold out, which censors large demand realizations. Then the investors only infer the real demand is no less than the threshold and value the firm accordingly by expectation. Channel stuffing can influence the inventory decision, too. We find both over- and underinvestment in the initial inventory can arise in our model. We discuss empirical and managerial implications of our findings."
1025,"Managing Consumer Returns in a Competitive Environment","Shulman, Jeffrey D. and Coughlan, Anne T. and Savaskan, R. Canan","MANAGEMENT SCIENCE","57","2","347-362","2011","FEB","Marketing;Channels Of Distribution;Competitive Strategy;Pricing","","This paper investigates the pricing and restocking fee decisions of two competing firms selling horizontally differentiated products. We model a duopoly facing consumers who have heterogeneous tastes for the products and who must experience a product before knowing how well it matches with their preferences. The analysis yields several key insights. Restocking fees not only can be sustained in a competitive environment, but also are more severe when consumers are less informed about product fit and when consumers place a greater importance on how well products' attributes fit with their preferences. We compare the competitive equilibrium prices to a scenario in which consumers are certain about their preferences and find conditions defining when consumer uncertainty results in higher equilibrium prices. Comparison to a monopoly setting yields a surprising result: Equilibrium restocking fees in a competitive environment can be higher than those charged by a monopolist."
1026,"Cooperation in Games with Forgetfulness","Thomadsen, Raphael and Bhardwaj, Pradeep","MANAGEMENT SCIENCE","57","2","363-375","2011","FEB","Marketing;Competitive Strategy;Games-Group Decisions;Information Systems;It Policy And Management","","Companies and managers are apt to forget information, yet classic game theory analysis assumes that all players have perfect recall. This paper expands the literature by examining how introducing forgetfulness into a multiplayer game-theoretic framework can help or hinder cooperative behavior. We find that forgetfulness impacts the ability of firms to cooperate in countervailing directions. On one hand, forgetfulness can diminish the ability to punish deviators, making cooperation more difficult. On the other hand, under some conditions forgetfulness can make meting out severe punishments-even below-(stage) minimax punishments-credible and decrease the ability for players to effectively deviate, facilitating cooperation even in circumstances where cooperation cannot be sustained under perfect recall. We apply our model to a number of strategic games that commonly appear in the literature."
1027,"Product Recalls in the Medical Device Industry: An Empirical Exploration of the Sources and Financial Consequences","Thirumalai, Sriram and Sinha, Kingshuk K.","MANAGEMENT SCIENCE","57","2","376-392","2011","FEB","Medical Device;Recalls;Quality;Econometric Analyses;Performance;Learning","","Medical devices play an increasingly significant role in the delivery of health care today. However, persistent quality problems with medical devices and the associated recalls present potential health risks to patients and personnel using these devices. This study addresses three key issues in this regard. First, it empirically assesses the financial implications of medical device recalls to understand if these consequences are severe enough to deter firms from introducing potentially hazardous medical devices into the market, as can be inferred from the literature. Second, the study considers a cross section of medical device manufacturers to examine the effect of firm characteristics on the costs of poor quality. Third, in an attempt to explore the sources of recalls, this study investigates firm characteristics that are likely to be associated with device recalls. The econometric analyses in the study are based on data from manufacturers in the medical device industry over a four-year period (2002-2005). Contrary to our expectations, the findings of the study indicate that at an aggregate level, the market penalties for medical device recalls are not significant, i.e., at the aggregate level, the costs of poor quality are not severe. Furthermore, we find that the magnitude of financial consequences of device recalls is affected by the product scope, sales, growth prospects, and the capital structure of a firm. In our analyses exploring the sources of device recalls, we find that firms with a research and development focus, developing broader product portfolios, have a higher likelihood of device recalls. Also, we find that the likelihood of recalls decreases with prior recall experience, indicating the presence of learning. Implications of the study findings, limitations, and directions for future research are identified."
1028,"Economic Interpretation of Probabilities Estimated by Maximum Likelihood or Score","Johnstone, D. J.","MANAGEMENT SCIENCE","57","2","308-314","2011","FEB","Probability Forecast;Scoring Rule;Maximum Likelihood;Maximum Score Estimation","","The conventional method of estimating a probability prediction model by maximum likelihood (MLE) is a form of maximum score estimation with economic meaning. Of all the probabilities that a given model might have produced, those obtained by MLE yield maximum in-sample betting return to a log utility investor. Recognition of this affinity between MLE and log utility begs the wider methodological question of whether different decision makers benefit in different degrees from different probabilities. Probabilities produced by MLE can be either too conservative or too bold relative to those found by maximizing utility under more risk-tolerant or risk-averse score functions. A very (not very) risk-averse user, who bets characteristically small (large) fractions of wealth based on a conservative forecast, is bound to make a rapidly (slowly) increasing bet as the forecast probability becomes progressively bolder or more distant from the market probability. The effect of this interaction between risk aversion and forecast is that a highly risk-averse user may need a much bolder forecast to obtain the same certainty equivalent as a more risk-tolerant investor. It follows more broadly that professional forecasters should anticipate how a client with given risk aversion expects to gain from any given forecast, or forecast revision, before committing resources toward making a better informed (but still honest) forecast."
1029,"I Think You Think I Think You're Lying: The Interactive Epistemology of Trust in Social Networks","Moldoveanu, Mihnea C. and Baum, Joel A. C.","MANAGEMENT SCIENCE","57","2","393-412","2011","FEB","Organizational Studies;Strategy;Networks Graphs;Theory;Design;Information;Philosophy Of Modeling","","We investigate the epistemology of trust in social networks. We posit trust as a special epistemic state that depends on actors' beliefs about each others' beliefs as well as about states of the world. It offers new ideas and tools for representing the core elements of trust both within dyads and larger groups and presents an approach that makes trust measurable in a noncircular and predictive, rather than merely postdictive, fashion. After advancing arguments for the importance of interactive belief systems to the successful coordination of behavior, we tune our investigation of trust by focusing on beliefs that are important to mobilization and coordination and show how trust functions to influence social capital arising from network structure. We present empirical evidence corroborating the importance of higher-order beliefs to understanding trust and the interactive analysis of trust to the likelihood of successful coordination."
1030,"Estimating the Operational Impact of Container Inspections at International Ports","Bakshi, Nitin and Flynn, Stephen E. and Gans, Noah","MANAGEMENT SCIENCE","57","1","1-20","2011","JAN","Homeland Security;Container Inspections;Queueing Simulation","","A U.S. law mandating nonintrusive imaging and radiation detection for 100% of U. S.-bound containers at international ports has provoked widespread concern that the resulting congestion would hinder trade significantly. Using detailed data on container movements, gathered from two large international terminals, we simulate the impact of the two most important inspection policies that are being considered. We find that the current inspection regime being advanced by the U. S. Department of Homeland Security can only handle a small percentage of the total load. An alternate inspection protocol that emphasizes screening-a rapid primary scan of all containers, followed by a more careful secondary scan of only a few containers that fail the primary test-holds promise as a feasible solution for meeting the 100% scanning requirement."
1031,"Carbon Capture by Fossil Fuel Power Plants: An Economic Analysis","Islegen, Oezge and Reichelstein, Stefan","MANAGEMENT SCIENCE","57","1","21-39","2011","JAN","Cost-Benefit Analysis;Environment;Pollution;Government;Energy Policies;Accounting;Natural Resources;Energy","","For fossil fuel power plants to be built in the future, carbon capture and storage (CCS) technologies offer the potential for significant reductions in carbon dioxide (CO(2)) emissions. We examine the break-even value for CCS adoptions, that is, the critical value in the charge for CO(2) emissions that would justify investment in CCS capabilities. Our analysis takes explicitly into account that the supply of electricity at the wholesale level (generation) is organized competitively in some U. S. jurisdictions, whereas in others a regulated utility provides integrated generation and distribution services. For either market structure, we find that emissions charges near $30 per tonne of CO(2) would be the break-even value for adopting CCS capabilities at new coal-fired power plants. The corresponding break-even values for natural gas plants are substantially higher, near $60 per tonne. Our break-even estimates serve as a basis for projecting the change in electricity prices once carbon emissions become costly. CCS capabilities effectively put an upper bound on the increase in electricity prices resulting from carbon regulations, and we estimate this bound to be near 30% at the retail level for both coal and natural gas plants. In contrast to the competitive power supply scenario, however, these price increases materialize only gradually for a regulated utility. The delay in price adjustments reflects that for regulated firms the basis for setting product prices is historical cost, rather than current cost."
1032,"An Investigation of Earnings Management Through Marketing Actions","Chapman, Craig J. and Steenburgh, Thomas J.","MANAGEMENT SCIENCE","57","1","72-92","2011","JAN","Accounting;Marketing;Pricing;Promotion;Real Earnings Management","","Prior research hypothesizes managers use real actions, including the reduction of discretionary expenditures, to manage earnings to meet or beat key benchmarks. This paper examines this hypothesis by testing how different types of marketing expenditures are used to boost earnings for a durable commodity consumer product that can be easily stockpiled by end consumers. Combining supermarket scanner data with firm-level financial data, we find evidence that differs from prior literature. Instead of reducing expenditures to boost earnings, soup manufacturers roughly double the frequency and change the mix of marketing promotions (price discounts, feature advertisements, and aisle displays) at the fiscal quarter-end when they have greater incentive to boost earnings. Our results confirm managers' stated willingness to sacrifice long-term value in order to smooth earnings and their stated preference to use real actions to boost earnings to meet different types of earnings benchmarks. We estimate that marketing actions can be used to boost quarterly net income by up to 5% depending on the depth and duration of promotion. However, there is a price to pay, with the cost in the following period being approximately 7.5% of quarterly net income. Finally, a unique aspect of the research setting allows tests of who is responsible for the earnings management. Although firms appear unable to increase the frequency of aisle display promotions in the short run, they can reallocate these promotions within their portfolio of brands. Results show firms shifting display promotions away from smaller revenue brands toward larger ones following periods of poor financial performance. This indicates the behavior is determined by parties above brand managers in the firm. These findings are consistent with firms engaging in real earnings management and suggest that effects on subsequent reporting periods and competitor behavior are greater than previously documented."
1033,"Competing to Be Certain (But Wrong): Market Dynamics and Excessive Confidence in Judgment","Radzevick, Joseph R. and Moore, Don A.","MANAGEMENT SCIENCE","57","1","93-106","2011","JAN","Overconfidence;Advice;Competition;Markets;Judgment","","In this paper, we investigate how market competition contributes to the expression of overconfidence among those competing for influence. We find evidence that market competition exacerbates the tendency to express excessive confidence. This evidence comes from experiments in which advisors attempt to sell their advice. In the first, advisors must compete with other advice sellers. In the second, advisors and their customers are paired. Advisors are overconfident in both studies and it helps advisors sell their advice. However, competition between advisors in the market further exacerbates overconfidence. In a third study, we demonstrate that the market competition drives overconfidence even when advisors vary in quality. We also investigate the strategic expressions and interpretations of confidence by both sides in the exchange."
1034,"Opportunity Spaces in Innovation: Empirical Analysis of Large Samples of Ideas","Kornish, Laura J. and Ulrich, Karl T.","MANAGEMENT SCIENCE","57","1","107-128","2011","JAN","Search;Opportunity;Opportunities;Idea;Ideation;Idea Generation;Innovation;Creativity;Innovation Process;Opportunity Identification;Concept Development;Product Development;Product Design;Entrepreneurship","","A common approach to innovation, parallel search, is to identify a large number of opportunities and then to select a subset for further development, with just a few coming to fruition. One potential weakness with parallel search is that it permits repetition. The same, or a similar, idea might be generated multiple times, because parallel exploration processes typically operate without information about the ideas that have already been identified. In this paper we analyze repetition in five data sets comprising 1,368 opportunities and use that analysis to address three questions: (1) When a large number of efforts to generate ideas are conducted in parallel, how likely are the resulting ideas to be redundant? (2) How large are the opportunity spaces? (3) Are the unique ideas more valuable than those similar to many others? The answer to the first question is that although there is clearly some redundancy in the ideas generated by aggregating parallel efforts, this redundancy is quite small in absolute terms in our data, even for a narrowly defined domain. For the second question, we propose a method to extrapolate how many unique ideas would result from an unbounded effort by an unlimited number of comparable idea generators. Applying that method, and for the settings we study, the estimated total number of unique ideas is about one thousand for the most narrowly defined domain and greater than two thousand for the more broadly defined domains. On the third question, we find a positive relationship between the number of similar ideas and idea value: the ideas that are least similar to others are not generally the most valuable ones."
1035,"Grammar-Based Integer Programming Models for Multiactivity Shift Scheduling","Cote, Marie-Claude and Gendron, Bernard and Rousseau, Louis-Martin","MANAGEMENT SCIENCE","57","1","151-163","2011","JAN","Shift Scheduling;Implicit Models;Mixed Integer Programming;Context-Free Grammars","","This paper presents a new implicit formulation for shift scheduling problems, using context-free grammars to model the rules for the composition of shifts. From the grammar, we generate an integer programming (IP) model having a linear programming relaxation equivalent to that of the classical set covering model. When solved by a state-of-the-art IP solver on problem instances with a small number of shifts, our model, the set covering formulation, and a typical implicit model from the literature yield comparable solution times. On instances with a large number of shifts, our formulation shows superior performance and can model a wider variety of constraints. In particular, multiactivity cases, which cannot be modeled by existing implicit formulations, can easily be handled with grammars. We present comparative experimental results on a large set of instances involving one work activity, as well as on problems dealing with up to 10 work activities."
1036,"Information Goods vs. Industrial Goods: Cost Structure and Competition","Jones, Roy and Mendelson, Haim","MANAGEMENT SCIENCE","57","1","164-176","2011","JAN","Information Goods;Convex Development Cost;Product And Price Competition","","We study markets for information goods and find that they differ significantly from markets for traditional industrial goods. Markets for information goods in which products are vertically differentiated lack the segmentation inherent in markets for industrial goods. As a result, a monopoly will offer only a single product. Competition leads to highly concentrated information-good markets, with the leading firm behaving almost like a monopoly even with free entry and without network effects. We study how the structure of the firms' cost functions drives our results."
1037,"Do Auctioneers Pick Optimal Reserve Prices?","Davis, Andrew M. and Katok, Elena and Kwasnica, Anthony M.","MANAGEMENT SCIENCE","57","1","177-192","2011","JAN","Reserve Prices;Procurement Auctions;Behavioral Operations","","We investigate how auctioneers set reserve prices in auctions. A well-established theoretical result, assuming risk neutrality of the seller, is that the optimal reserve price should not depend on the number of participating bidders. In a set of controlled laboratory experiments, we find that seller behavior often deviates from the theoretical benchmarks. We extend the existing theory to explore three alternative explanations for our results: risk aversion, anticipated regret, and probability weighting. After fitting our data to each of these models through parameter estimation techniques on both an aggregate and individual level, we find that all three models are consistent with some of the characteristics of our data, but that the regret model provides a slightly more favorable fit overall."
1038,"Understanding the Two Components of Risk Attitudes: An Experimental Analysis","Qiu, Jianying and Steiger, Eva-Maria","MANAGEMENT SCIENCE","57","1","193-199","2011","JAN","Risk Attitude;Cumulative Prospect Theory;Experimental Study","","Cumulative prospect theory introduced the weighting of probabilities as an additional component to capture risk attitudes. However, this addition would be a less significant challenge to expected utility theory (EU) if utility curvature and probability weighting showed strong positive correlation. In that case the utility curvature in EU alone, although not properly describing risky behavior in general, would still capture most of the variance of individual risk aversion. This study provides experimental evidence that such a strong and positive correlation does not exist. Although most individuals exhibit concave utility and convex probability weighting, the two components show no strong positive correlation."
1039,"Ranking Intervals and Dominance Relations for Ratio-Based Efficiency Analysis","Salo, Ahti and Punkka, Antti","MANAGEMENT SCIENCE","57","1","200-214","2011","JAN","Efficiency Analysis;Data Envelopment Analysis;Preference Modeling","","We develop comparative results for ratio-based efficiency analysis (REA) based on the decision-making units' (DMUs') relative efficiencies over sets of feasible weights that characterize preferences for input and output variables. Specifically, we determine (i) ranking intervals, which indicate the best and worst efficiency rankings that a DMU can attain relative to other DMUs; (ii) dominance relations, which show what other DMUs a given DMU dominates in pairwise efficiency comparisons; and (iii) efficiency bounds, which show how much more efficient a given DMU can be relative to some other DMU or a subset of other DMUs. Unlike conventional efficiency scores, these results are insensitive to outlier DMUs. They also show how the DMUs' efficiency ratios relate to each other for all feasible weights, rather than for those weights only for which the data envelopment analysis (DEA) efficiency score of some DMU is maximized. We illustrate the usefulness of these results by revisiting reported DEA studies and by describing a recent case study on the efficiency comparison of university departments."
1040,"Quality-Speed Conundrum: Trade-offs in Customer-Intensive Services","Anand, Krishnan S. and Pac, M. Fazil and Veeraraghavan, Senthil","MANAGEMENT SCIENCE","57","1","40-56","2011","JAN","Strategic Customers;Queueing Games;Service Operations;Cost Disease","","In many services, the quality or value provided by the service increases with the time the service provider spends with the customer. However, longer service times also result in longer waits for customers. We term such services, in which the interaction between quality and speed is critical, as customer-intensive services. In a queueing framework, we parameterize the degree of customer intensity of the service. The service speed chosen by the service provider affects the quality of the service through its customer intensity. Customers queue for the service based on service quality, delay costs, and price. We study how a service provider facing such customers makes the optimal quality-speed trade-off. Our results demonstrate that the customer intensity of the service is a critical driver of equilibrium price, service speed, demand, congestion in queues, and service provider revenues. Customer intensity leads to outcomes very different from those of traditional models of service rate competition. For instance, as the number of competing servers increases, the price increases, and the servers become slower."
1041,"Privacy Regulation and Online Advertising","Goldfarb, Avi and Tucker, Catherine E.","MANAGEMENT SCIENCE","57","1","57-71","2011","JAN","Privacy;Online Advertising;Targeting","","Advertisers use online customer data to target their marketing appeals. This has heightened consumers' privacy concerns, leading governments to pass laws designed to protect consumer privacy by restricting the use of data and by restricting online tracking techniques used by websites. We use the responses of 3.3 million survey takers who had been randomly exposed to 9,596 online display (banner) advertising campaigns to explore how privacy regulation in the European Union (EU) has influenced advertising effectiveness. This privacy regulation restricted advertisers' ability to collect data on Web users in order to target ad campaigns. We find that, on average, display advertising became far less effective at changing stated purchase intent after the EU laws were enacted, relative to display advertising in other countries. The loss in effectiveness was more pronounced for websites that had general content (such as news sites), where non-data-driven targeting is particularly hard to do. The loss of effectiveness was also more pronounced for ads with a smaller presence on the webpage and for ads that did not have additional interactive, video, or audio features."
1042,"Recruiting for Ideas: How Firms Exploit the Prior Inventions of New Hires","Singh, Jasjit and Agrawal, Ajay","MANAGEMENT SCIENCE","57","1","129-150","2011","JAN","Inventor Mobility;Access To Ideas;Knowledge Spillovers;Learning By Hiring;Difference In Differences;Coarsened Exact Matching;Collaborative Networks;Patent Citations","","When firms recruit inventors, they acquire not only the use of their skills but also enhanced access to their stock of ideas. But do hiring firms actually increase their use of new recruits' prior inventions? Our estimates suggest they do, quite significantly in fact, by approximately 219% on average. However, this does not necessarily reflect widespread learning by hiring. In fact, we estimate that a recruit's exploitation of her own prior ideas accounts for almost half of the above effect, with much of the diffusion to others being limited to the recruit's immediate collaborative network. Furthermore, although one might expect the recruit's role to diminish rapidly as her tacit knowledge diffuses across her new firm, our estimates indicate that her importance is surprisingly persistent over time. We base these findings on an empirical strategy that exploits the variation over time in hiring firms' citations to the recruits' premove patents. Specifically, we employ a difference-indifferences approach to compare premove versus postmove citation rates for the recruits' prior patents and corresponding matched-pair control patents. Our methodology has three benefits compared to previous studies that also examine the link between labor mobility and knowledge flow: (1) it does not suffer from the upward bias inherent in the conventional cross-sectional comparison, (2) it generates results that are robust to a more stringently matched control sample, and (3) it enables a temporal examination of knowledge flow patterns."
1043,"Organizational Structure and Product Choice in Knowledge-Intensive Firms","Wu, Yanhui","MANAGEMENT SCIENCE","61","8","1830-1848","2015","AUG","Strategy And Structure;Strategic Fit;Product Selection;Organizational Design;Problem Solving;Knowledge-Intensive Firms","","This paper formulates a model in which a firm simultaneously chooses its organizational structure and product position. The firm's production is knowledge intensive, requiring employees to solve problems. A vertical hierarchy, in which workers refer unsolved problems to managers facilitates the acquisition and leveraging of managers' superior knowledge. I show that a larger span of control is complementary to the provision of high-value products. Moreover, this complementarity is sustained when employees acquire sufficient knowledge and is further strengthened when the firm enhances its capability of communicating knowledge. The model yields testable implications concerning (1) the fit between a firm's product position and span of control, (2) the effect of information technology on product innovations and skill-biased organizational changes, and (3) the heterogeneity in hierarchical structure and human resource management in professional service firms."
1044,"Product Market Competition and the Financing of New Ventures","de Bettignies, Jean-Etienne and Duchene, Anne","MANAGEMENT SCIENCE","61","8","1849-1867","2015","AUG","Competition;Venture Risk;Bank Financing;Venture Capital","","This paper examines the interaction between venture risk, product market competition, and the entrepreneur's choice between bank financing and venture capital (VC) financing. Under bank financing, a debt-type contract emerges as optimal, which allows the entrepreneur to retain full control of the venture and thus yields strong effort incentives, as long as the entrepreneur can service the debt repayment; however, this leads to liquidation in the case of default, making the venture's success quite sensitive to exogenous, even temporary, shocks that may hinder debt repayment. Under VC financing, an equity-type contract emerges as optimal. Although it is not sensitive to exogenous shocks, this contract requires the entrepreneur to share a fraction of the rents with the financier, thus yielding lower effort incentives for the entrepreneur. There exists a threshold level of venture risk such that bank financing is optimal if and only if venture risk is below that threshold. Product market competition increases the value of stronger entrepreneurial incentives and thus increases the maximum level of risk the entrepreneur is willing to take before switching from bank financing to VC financing. This is a robust result that is shown to hold in various models of competition, including the Hotelling, Salop, Dixit-Stiglitz, and Cournot-to-Bertrand switch."
1045,"Competition in Portfolio Management: Theory and Experiment","Asparouhova, Elena and Bossaerts, Peter and Copic, Jernej and Cornell, Brad and Cvitanic, Jaksa and Meloso, Debrah","MANAGEMENT SCIENCE","61","8","1868-1888","2015","AUG","Delegated Portfolio Management;Asset Pricing Theory;Experimental Finance","","We explore theoretically and experimentally the general equilibrium price and allocation implications of delegated portfolio management when the investor-manager relationship is nonexclusive. Our theory predicts that competition forces managers to promise portfolios that mimic Arrow-Debreu (AD) securities, which investors then combine to fit their preferences. A weak version of the capital asset pricing model (CAPM) obtains, where state prices (relative to state probabilities) implicit in prices of traded securities will be inversely ranked to aggregate wealth across states. Our experiment broadly corroborates the price and choice predictions of the theory. However, price quality deteriorates when only a few managers attract most of the available wealth. Wealth concentration increases because funds flow toward managers who offer portfolios closer to replicating AD securities (as in the theory), but also because funds flow to managers who had better performance in the immediate past (an observation unrelated to the theory)."
1046,"Rational Speculators, Contrarians, and Excess Volatility","Lof, Matthijs","MANAGEMENT SCIENCE","61","8","1889-1901","2015","AUG","Asset Pricing;Heterogeneous Agents;Var Approach","","The vector autoregressive approach for testing present value models is applied to a heterogeneous-agent asset pricing model using historical observations of the S&P 500 index. Besides fundamentalists, who value assets according to expected dividends, the model features rational and contrarian speculators. Agents choose their strategy based on evolutionary considerations. Supplementing the standard present value model with speculative agents dramatically improves the model's ability to replicate observed market dynamics. In particular, the existence of contrarians can explain some of the most volatile episodes including the 1990s bubble, suggesting this was not a rational bubble."
1047,"Do Your Online Friends Make You Pay? A Randomized Field Experiment on Peer Influence in Online Social Networks","Bapna, Ravi and Umyarov, Akhmed","MANAGEMENT SCIENCE","61","8","1902-1920","2015","AUG","Peer Effects;Randomized Experiment;Social Contagion;Nonparametric Inference;Freemium Communities;Online Social Networks","","Demonstrating compelling causal evidence of the existence and strength of peer-to-peer influence has become the holy grail of modern research in online social networks. In these networks, it has been consistently demonstrated that user characteristics and behavior tend to cluster both in space and in time. There are multiple well-known rival mechanisms that compete to be the explanation for this observed clustering. These range from peer influence to homophily to other unobservable external stimuli. These multiple mechanisms lead to similar observational data, yet have vastly different policy implications. In this paper, we present a novel randomized experiment that tests the existence of causal peer influence in the general population-one that did not involve subject recruitment for experimentation-of a particular large-scale online social network. We utilize a unique social feature to exogenously induce adoption of a paid service among a group of randomly selected users, and in the process develop a clean exogenous randomization of treatment and control groups. A variety of nonparametric, semiparametric, and parametric approaches, ranging from resampling-based inference to ego-level random effects to logistic regression to survival models, yield close to identical, statistically and economically significant estimates of peer influence in the general population of a freemium social network. Our estimates show that peer influence causes more than a 60% increase in odds of buying the service due to the influence coming from an adopting friend. In addition, we find that users with a smaller number of friends experience stronger relative increase in the adoption likelihood due to influence from their peers as compared to the users with a larger number of friends. Our nonparametric resampling procedure-based estimates are helpful in situations of networked data that violate independence assumptions. We establish that peer influence is a powerful force in getting users from free to premium levels, a known challenge in freemium communities."
1048,"The Demand Effects of Joint Product Advertising in Online Videos","Kumar, Anuj and Tan, Yinliang (Ricky)","MANAGEMENT SCIENCE","61","8","1921-1937","2015","AUG","Electronic Commerce;Product Advertising;Online Product Networks;Virtual Product Experience;Complementary Products;Demand Spillovers;Randomized Field Experiment;Value Of It;Average Treatment Effect","","Joint product display in videos may help customers to not only evaluate the attributes of products that can influence their individual demands (direct effect) but also learn about the complementarity between them that may cause additional correlation in their demands (spillover effect). To estimate the demand effects, we introduced videos displaying apparel with matching accessories for a few randomly selected apparel on a fashion retailer's website. We found that introducing a video resulted in a 14.5% increase in apparel sales and a 28.3% increase in accessories sales. The estimated increase in accessories sales was largely attributed to the spillover effect of videos. Moreover, introducing videos with other product promotions resulted in a significantly higher effect of videos on product demands. Overall, we show how video display of related products can increase their demands in an online product network."
1049,"On the Failure of Hindsight-Biased Principals to Delegate Optimally","Danz, David and Kuebler, Dorothea and Mechtenberg, Lydia and Schmid, Julia","MANAGEMENT SCIENCE","61","8","1938-1958","2015","AUG","Hindsight Bias;Delegation;Experiments","","With the help of a simple model, we show that the hindsight bias can lead to inefficient delegation decisions. This prediction is tested experimentally. In an online experiment that was conducted during the FIFA World Cup 2010, participants were asked to predict a number of outcomes of the ongoing World Cup and had to recall their assessments after the outcomes had been realized. Their answers were used to construct individual measures of the hindsight bias. The participants also had to make choices in a delegation game. Our data confirm that hindsight-biased subjects more frequently fail to delegate optimally than subjects whom we have classified as not hindsight biased."
1050,"Probabilistic Selling in Quality-Differentiated Markets","Zhang, Zelin and Joseph, Kissan and Subramaniam, Ramanathan","MANAGEMENT SCIENCE","61","8","1959-1977","2015","AUG","Pricing;Services Marketing;Probabilistic Selling;Quality Choice;Quality-Differentiated Markets;Product Line Design;Welfare","","Probabilistic selling-the sale of synthetic products consisting of a lottery between two distinct goods-has been extensively analyzed in horizontal markets. In this research, we investigate probabilistic selling in quality-differentiated markets. This is an important new dimension of inquiry because of the widespread prevalence of quality-differentiated markets as well as significant differences in the preference structure across these markets. In fact, this latter consideration casts doubt as to whether probabilistic selling will even emerge in quality-differentiated markets. We find that probabilistic selling emerges in quality-differentiated markets as a way to profitably dispose excess capacity; moreover, probabilistic selling remains viable even under endogenous quality choice. In addition, in markets where sellers employ strong quality differentiation, the introduction of an intermediate probabilistic good actually causes closer quality levels in a product line and enhances consumer welfare. In contrast, in markets where sellers employ weak quality differentiation, the introduction of an intermediate probabilistic good increases quality separation and degrades consumer welfare. Overall, we view our contribution as one of characterizing the optimality, implementation, and policy implications of probabilistic selling in quality-differentiated markets."
1051,"Why and When Consumers Prefer Products of User-Driven Firms: A Social Identification Account","Dahl, Darren W. and Fuchs, Christoph and Schreier, Martin","MANAGEMENT SCIENCE","61","8","1978-1988","2015","AUG","User Innovation;User Design;User-Generated Products;Crowdsourcing;Social Identity;Corporate Associations;Consumer Preferences;Open Source Software","","B Companies are increasingly drawing on their user communities to generate promising ideas for new products, which are then marketed as user-designed products to the broader consumer market. We demonstrate that nonparticipating, observing consumers prefer to buy from user-rather than designer-driven firms because of an enhanced identification with the firm that has adopted this user-driven philosophy. Three experimental studies validate a newly proposed social identification account underlying this effect. Because consumers are also users, their social identities connect to the user-designers, and they feel empowerment by vicariously being involved in the design process. This formed connection leads to preference for the firm's products. Importantly, this social identification account also effectively predicts when the effect does not materialize. First, we find that if consumers feel dissimilar to participating users, the effects are attenuated. We demonstrate that this happens when the community differs from consumers along important demographics (i.e., gender) or when consumers are nonexperts in the focal domain (i.e., they feel that they do not belong to the social group of participating users). Second, the effects are attenuated if the user-driven firm is only selectively rather than fully open to participation from all users (observing consumers do not feel socially included). These findings advance the emerging theory on user involvement and offer practical implications for firms interested in pursuing a user-driven philosophy."
1052,"Gaining Access by Doing Good: The Effect of Sociopolitical Reputation on Firm Participation in Public Policy Making","Werner, Timothy","MANAGEMENT SCIENCE","61","8","1989-2011","2015","AUG","Reputation;Resource Dependency;Nonmarket Strategy;Corporate Social Responsibility","","This paper examines the role of firms' sociopolitical reputations, as proxied by their perceived engagement in socially responsible practices, in public policy makers' decisions to grant access in the policy-making process. I argue that policy makers' dependencies, motivations, and decision-making processes lead them to evaluate firms by using sociopolitical reputation as a differentiating heuristic. I hypothesize that firms that construct stronger sociopolitical reputations will be granted greater access and that firms' existing political activity and policy makers' partisanship will moderate this relationship. I test these hypotheses using an 11-year panel on congressional testimony, reputation, and political and financial characteristics for the S&P 500 and find support for all three. These findings support the existence of a sociopolitical dimension to firms' reputations that affects how public policy makers evaluate firms, demonstrating that corporate social responsibility pays political benefits."
1053,"Exploring Trade-offs in the Organization of Scientific Work: Collaboration and Scientific Reward","Bikard, Michael and Murray, Fiona and Gans, Joshua S.","MANAGEMENT SCIENCE","61","7","1473-1495","2015","JUL","Science;Collaboration;Academic Science;Productivity;Scientific Credit","","When do scientists and other innovators organize into collaborative teams, and why do they do so for some projects and not others? At the core of this important organizational choice is, we argue, a trade-off scientists make between the productive efficiency of collaboration and the credit allocation that arises after the completion of collaborative work. In this paper, we explore this trade-off by developing a model to structure our understanding of the factors shaping researcher collaborative choices, in particular the implicit allocation of credit among participants in scientific projects. We then use the annual research activity of 661 faculty scientists at the Massachusetts Institute of Technology over a 31-year period to explore the trade-off between collaboration and reward at the individual faculty level and to infer critical parameters in the collaborative organization of scientific work."
1054,"Bonus Payments and Reference Point Violations","Ockenfels, Axel and Sliwka, Dirk and Werner, Peter","MANAGEMENT SCIENCE","61","7","1496-1513","2015","JUL","Reference Points;Bonus Payments;Job Satisfaction;Job Performance;Transparency","","We investigate how bonus payments affect the satisfaction and performance of managers in a large multinational company. We find that falling behind a natural reference standard for a fair bonus payment (a reference point violation) reduces satisfaction and subsequent performance. The effects are mitigated if information about one's relative standing toward the reference point is withheld. A model and a laboratory experiment provide complementary insights and additional robustness checks."
1055,"A New Solution for the Moral Hazard Problem in Team Production","Guillen, Pablo and Merrett, Danielle and Slonim, Robert","MANAGEMENT SCIENCE","61","7","1514-1530","2015","JUL","Team Production;Moral Hazard;Free Riding;Public Goods;Intergroup Competition;Voluntary Contributions Mechanism;Economic Experiments","","We propose an intergroup competition scheme (ICS) to theoretically solve free riding in team production and provide experimental evidence from a voluntary contribution mechanism public goods game. The ICS includes an internal transfer payment from the lowest to highest contributing team proportional to the difference in group contributions. The ICS requires minimal information, makes the efficient contribution a dominant strategy, and is budget balanced. These features make the ICS ideally suited to solve the moral hazard problem in team production. Our experiment demonstrates that the ICS raises contributions to almost reach optimality with the appropriate parameters. We also show experimentally that the success of the ICS can be primarily attributed to the effect of higher returns and to the introduction of competition, and it is not due to the introduction of potential losses or information regarding other groups."
1056,"Inducing Social Norms in Laboratory Allocation Choices","Schram, Arthur and Charness, Gary","MANAGEMENT SCIENCE","61","7","1531-1546","2015","JUL","Economics;Behavior And Behavioral Decision Making;Microeconomic Behavior;Games-Group Decisions","","Social norms involve observation by others and external sanctions for violations, whereas moral norms involve introspection and internal sanctions. To study such norms and their effects, we design a laboratory experiment. We examine dictator choices, where we create a shared understanding by providing advice from peers with no financial payoff at stake. We vary whether advice is given, as well as whether choices are made public. This design allows us to explicitly separate the effects of moral and social norms. We find that choices are in fact affected by a combination of observability and shared understanding."
1057,"Analysis of Tailored Base-Surge Policies in Dual Sourcing Inventory Systems","Janakiraman, Ganesh and Seshadri, Sridhar and Sheopuri, Anshul","MANAGEMENT SCIENCE","61","7","1547-1561","2015","JUL","Inventory/Production Systems;Dual Sourcing;Multiple Suppliers;Optimal Policies","","We study a model of a firm managing its inventory of a single product by sourcing supplies from two supply sources, a regular supplier who offers a lower unit cost and a longer lead time than a second, emergency, supplier. A practically implementable policy for such a firm is a tailored base-surge (TBS) policy [Allon G, Van Mieghem JA (2010) Global dual sourcing: Tailored base-surge allocation to near-and offshore production. Management Sci. 56(1):110-124] to manage its inventory. Under this policy, the firm procures a constant quantity from the regular supplier in every period and dynamically makes procurement decisions for the emergency supplier. Allon and Van Mieghem describe this practice as using the regular supplier to meet a base level of demand and the emergency supplier to manage demand surges, and they conjecture that this practice is most effective when the lead time difference between the two suppliers is large. We confirm these statements in two ways. First, we show the following analytical result: when demand is composed of a base demand random component plus a surge demand random component, which occurs with a certain small probability, the best TBS policy is close to optimal (over all policies) in a well-defined sense. Second, we also numerically investigate the cost effectiveness of the best TBS policy on a test bed of problem instances. The emphasis of this investigation is the study of the effect of the lead time difference between the two suppliers. Our study reveals that the cost difference between the best TBS policy and the optimal policy decreases dramatically as the lead time of the regular supplier increases. On our test bed, this cost difference decreases from an average (over the test bed) of 21% when the lead time from the regular supplier is two periods (the emergency supplier offers instant delivery) to 3.5% when that lead time is seven periods."
1058,"An Empirical Investigation on the Appointments of Supply Chain and Operations Management Executives","Hendricks, Kevin B. and Hora, Manpreet and Singhal, Vinod R.","MANAGEMENT SCIENCE","61","7","1562-1583","2015","JUL","Appointments Of Supply Chain Executives;Stock Market Value;Operating Performance","","This paper provides empirical evidence on the performance effects and choice of appointments of supply chain and operations management executives (SCOMEs). The analysis is based on a sample of 681 SCOME appointments that were publicly announced during the 2000-2011 period. We find that the stock market reaction is positive on the day of the announcement. Categorizing the SCOME appointments as new or old and insider or outsider, we find that the market reaction for newly created SCOME positions is positive. The market also reacts more positively when a SCOME is an outsider rather than an insider. The strongest positive reaction is observed when outsiders are hired for newly created SCOME positions. We find evidence of both poor stock price performance and poor operating performance in the period preceding the appointment of new SCOMEs. New SCOME appointments are not followed by an immediate improvement in stock price and operating performance. However, there is no further decline in performance, suggesting that the decline observed in the preappointment period does not continue after the new SCOME is appointed. We also find that the likelihood of a SCOME being an outsider is greater for firms that are smaller, operate in more concentrated industries, and have experienced poor prior performance."
1059,"Optimal Advance Scheduling","Van-Anh Truong","MANAGEMENT SCIENCE","61","7","1584-1597","2015","JUL","Dynamic Programming;Decision Analysis: Theory;Healthcare: Hospitals;Production Scheduling","","The dynamic assignment of patients to exam days in order to manage daily variations in demand and capacity is a long-standing open research area in appointment scheduling. In particular, the dynamic assignment of advance appointments has been considered to be especially challenging because of its high dimensionality. We consider a canonical model of dynamic advance scheduling with two patient classes: an urgent demand class, which must be served on the day of arrival, and a regular demand class, which can be served at a future date. Patients take the earliest appointments offered and do not differentiate among providers. We derive a surprising characterization of an optimal policy and an algorithm to compute the policy exactly and efficiently. These are, to our knowledge, the first analytical results for the dynamic advance assignment of patients to exam days. We introduce the property of successive refinability, which allows advance schedules to be easily computable and under which there is no cost to the system to making advance commitments to patients. We allow multiple types of capacity to be considered and both demand and capacity to be nonstationary and stochastic."
1060,"A Theory of Market Pioneers, Dynamic Capabilities, and Industry Evolution","Mitchell, Matthew and Skrzypacz, Andrzej","MANAGEMENT SCIENCE","61","7","1598-1614","2015","JUL","Economics;Microeconomic Behavior;Industrial Organization;Firm Objectives;Organization And Behavior Dynamic Programming;Applications","","We analyze a model of industry evolution where the number of active submarkets is endogenously determined by pioneering innovation from incumbents and entrants. Incumbent pioneers enjoy an advantage of additional pioneering innovation via a dynamic capability that takes the form of an improved technology for innovation in young submarkets. Entrants are motivated in part by a desire to acquire the dynamic capability. We show that dynamic capabilities increase total innovation, but whether the capability confers an advantage in terms of marginal or average cost is important in determining how the impact of dynamic capabilities is distributed across incumbent and entrant innovation rates. We complement the existing literature-that focuses on exogenous arrival of submarkets or the steady state of a model with constant submarkets-by describing how competition, free entry, and the dynamic capability of incumbents drive the evolution of an industry. The shift from immature to mature submarkets can lead to a shakeout in firm numbers, and it eventually leads to a reduction in total dynamic capabilities in an industry."
1061,"Linear Tests for Decreasing Absolute Risk Aversion Stochastic Dominance","Post, Thierry and Fang, Yi and Kopa, Milos","MANAGEMENT SCIENCE","61","7","1615-1629","2015","JUL","Stochastic Dominance;Utility Theory;Decreasing Absolute Risk Aversion;Linear Programming;Bootstrapping;Market Portfolio Efficiency;Pricing Kernel;Skewness","","We develop and implement linear formulations of convex stochastic dominance relations based on decreasing absolute risk aversion (DARA) for discrete and polyhedral choice sets. Our approach is based on a piecewise-exponential representation of utility and a local linear approximation to the exponentiation of log marginal utility. An empirical application to historical stock market data suggests that a passive stock market portfolio is DARA stochastic dominance inefficient relative to concentrated portfolios of small-cap stocks. The mean-variance rule and Nth-order stochastic dominance rules substantially underestimate the degree of market portfolio inefficiency because they do not penalize the unfavorable skewness of diversified portfolios, in violation of DARA."
1062,"Corporate Transparency and the Impact of Investor Sentiment on Stock Prices","Firth, Michael and Wang, Kailong (Philip) and Wong, Sonia M. L.","MANAGEMENT SCIENCE","61","7","1630-1647","2015","JUL","Investor Sentiment;Stock Prices;Corporate Transparency;China;Emerging Markets","","Using China's stock market as the testing venue, this study examines how corporate transparency helps explain the sensitivity of stock prices to general investor sentiment. We find that firms with low corporate transparency, measured by a battery of proxies including state ownership, the prevalence of related party transactions, accrual-based earnings management, audit opinions, and the quality of audit firms, are more affected by investor sentiment than are firms with high corporate transparency. Overall, our findings highlight the importance of corporate transparency in mitigating the effects of investor sentiment on stock prices."
1063,"Repurchasing Debt","Mao, Lei and Tserlukevich, Yuri","MANAGEMENT SCIENCE","61","7","1648-1662","2015","JUL","Savings;Debt Repurchase;Debt Overhang","","In this paper we build a theoretical model of a firm repurchasing its corporate debt. We find that firm creditors as a group sell debt to the firm only at face value. However, because of the cross-creditor externalities, buying back debt is cheaper and easier when there are many creditors, e.g., when debt is traded on the open market. We further show that repurchases contribute to flexibility in firms' capital structure and can increase ex ante firm value. The value of repurchases to the shareholders increases with the firm's ability to save cash and delay the repurchase."
1064,"Management Earnings Forecasts and Value of Analyst Forecast Revisions","Kim, Yongtae and Song, Minsup","MANAGEMENT SCIENCE","61","7","1663-1683","2015","JUL","Finance;Accounting;Financial Institutions;Markets","","This study examines the stock-price reactions to analyst forecast revisions around earnings announcements to test whether preannouncement forecasts reflect analysts' private information or piggybacking on confounding events and news. We find that management earnings forecasts influence the timing and precision of analyst forecasts. More importantly, evidence suggests that prior studies' finding of weaker (stronger) stock-price responses to forecast revisions in the period immediately after (before) the prior-quarter earnings announcement disappears once management earnings forecasts are controlled for. To the extent that management earnings forecasts are public disclosures, our results suggest that the importance of analysts' information discovery role documented in prior studies is likely to be overstated."
1065,"Compact Bid Languages and Core Pricing in Large Multi-item Auctions","Goetzendorff, Andor and Bichler, Martin and Shabalin, Pasha and Day, Robert W.","MANAGEMENT SCIENCE","61","7","1684-1703","2015","JUL","Tv Ads;Core-Selecting Auction;Market Design","","We introduce an auction design framework for large markets with hundreds of items and complex bidder preferences. Such markets typically lead to computationally hard allocation problems. Our new framework consists of compact bid languages for sealed-bid auctions and methods to compute second-price rules such as the Vickrey-Clarke-Groves or bidder-optimal, core-selecting payment rules when the optimality of the allocation problem cannot be guaranteed. To demonstrate the efficacy of the approach for a specific, complex market, we introduce a compact bidding language for TV advertising markets and investigate the resulting winner-determination problem and the computation of core payments. For realistic instances of the respective winner-determination problems, very good solutions with a small integrality gap can be found quickly, although closing the integrality gap to find marginally better solutions or prove optimality can take a prohibitively large amount of time. Our subsequent adaptation of a constraint-generation technique for the computation of bidder-optimal core payments to this environment is a practically viable paradigm by which core-selecting auction designs can be applied to large markets with potentially hundreds of items. Such auction designs allow bidders to express their preferences with a low number of parameters, while at the same time providing incentives for truthful bidding. We complement our computational experiments in the context of TV advertising markets with additional results for volume discount auctions in procurement to illustrate the applicability of the approach in different types of large markets."
1066,"Counterfactual Decomposition of Movie Star Effects with Star Selection","Liu, Angela (Xia) and Mazumdar, Tridib and Li, Bo","MANAGEMENT SCIENCE","61","7","1704-1721","2015","JUL","Movie;Star Power;Star Selection;Endogenous Switching Model;Counterfactual Decomposition;Quantile Regression","","We investigate the effects of a movie star on the movie's opening week theater allocations and box office revenue. Because the pairing of a star and a movie involves a bilateral matching process between the studio and the star, the star (hence the nonstar) movie samples are nonrandom and the star variable is potentially endogenous. To assess the star as well as movie characteristics effects, we utilize a switching model to account for endogenous assignment of stars and nonstars into respective movie samples. In addition to controlling for selection biases, the endogenous switching model generates managerially relevant insights into the factors that influence a star's assignment to a movie. Additionally, because the star and nonstar movie characteristics (e.g., movie budget, distribution, genre, etc.) are often systematically different, we counterfactually estimate the theater allocations and revenues that nonstars (stars) would have generated had they acted in movies endowed with the same characteristics as the star (nonstar) movies. The decomposition analysis, conducted at different quantiles of theater and revenue distributions, shows that the presence of a star has a much stronger effect on theater allocations than the movie characteristics have. However, the revenue difference is entirely contributed by the differences in the characteristics of the star and nonstar movies. Thus, the star effects on revenue come indirectly through the theater allocations as well as from the characteristics of the movies in which they participate."
1067,"The Value of Field Experiments","Li, Jimmy Q. and Rusmevichientong, Paat and Simester, Duncan and Tsitsiklis, John N. and Zoumpoulis, Spyros I.","MANAGEMENT SCIENCE","61","7","1722-1740","2015","JUL","Field Experiments;Promotions;Big Data;Sparsity","","The feasibility of using field experiments to optimize marketing decisions remains relatively unstudied. We investigate category pricing decisions that require estimating a large matrix of cross-product demand elasticities and ask the following question: How many experiments are required as the number of products in the category grows? Our main result demonstrates that if the categories have a favorable structure, we can learn faster and reduce the number of experiments that are required: the number of experiments required may grow just logarithmically with the number of products. These findings potentially have important implications for the application of field experiments. Firms may be able to obtain meaningful estimates using a practically feasible number of experiments, even in categories with a large number of products. We also provide a relatively simple mechanism that firms can use to evaluate whether a category has a structure that makes it feasible to use field experiments to set prices. We illustrate how to accomplish this using either a sample of historical data or a pilot set of experiments. We also discuss how to evaluate whether field experiments can help optimize other marketing decisions, such as selecting which products to advertise or promote."
1068,"Do Market Leaders Lead in Business Process Innovation? The Case(s) of E-business Adoption","McElheran, Kristina","MANAGEMENT SCIENCE","61","6","1197-1216","2015","JUN","Information Technology;Innovation;Business Processes;Electronic Commerce;Firm Capabilities;Technological Change","","Are market leaders more likely to be early adopters of business process innovations? Although they tend to enjoy economies of scale in adoption, leaders may find that adjustment costs also increase with scale. Prior work has focused on how misalignment of incumbents' internal capabilities may affect their technology strategy. However, technology-capability misalignment may exist outside the firm boundary as well. In this paper, I build on mainstream product innovation concepts to predict when market leaders will adopt certain business process innovations. I then test these predictions in a large data set on early e-business adoption, leveraging its novel insight into focal firms, their markets, and their customers. I find market leaders were significantly more likely to embrace new information technology-enabled practices-except when customer adjustment costs were a significant concern. These findings highlight the strategic significance of external capabilities in the face of technological change."
1069,"Pay What You Want as a Marketing Strategy in Monopolistic and Competitive Markets","Schmidt, Klaus M. and Spann, Martin and Zeithammer, Robert","MANAGEMENT SCIENCE","61","6","1217-1236","2015","JUN","Customer-Driven Pricing Mechanisms;Pay What You Want;Price Discrimination;Revenue Management;Social Preferences","","Pay what you want (PWYW) can be an attractive marketing strategy to price discriminate between fair-minded and selfish customers, to fully penetrate a market without giving away the product for free, and to undercut competitors that use posted prices. We report on laboratory experiments that identify causal factors determining the willingness of buyers to pay voluntarily under PWYW. Furthermore, to see how competition affects the viability of PWYW, we implement markets in which a PWYW seller competes with a traditional seller. Finally, we endogenize the market structure and let sellers choose their pricing strategy. The experimental results show that outcome-based social preferences and strategic considerations to keep the seller in the market can explain why and how much buyers pay voluntarily to a PWYW seller. We find that PWYW can be viable on a monopolistic market, but it is less successful as a competitive strategy because it does not drive traditional posted-price sellers out of the market. Instead, the existence of a posted-price competitor reduces buyers' payments and prevents the PWYW seller from fully penetrating the market. When given the choice, most sellers opt for setting a posted price rather than a PWYW pricing strategy. We discuss the implications of these results for the use of PWYW as a marketing strategy. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1946."
1070,"An Investigation of the Average Bid Mechanism for Procurement Auctions","Chang, Wei-Shiun and Chen, Bo and Salmon, Timothy C.","MANAGEMENT SCIENCE","61","6","1237-1254","2015","JUN","Procurement Auctions;Average Bid;Bankruptcy;Experiments","","In a procurement context, it can be quite costly for a buyer when the winning seller underestimates the cost of a project and then defaults on the project midway through completion. The average bid auction is one mechanism intended to help address this problem. This format involves awarding the contract to the bidder who has bid closest to the average of the bids submitted. We compare the performance of this mechanism with the standard low price mechanism to determine how successful the average bid format is in preventing bidder losses as well as its impact on the price paid by the buyer. We find the average bid mechanism to be more successful than expected because, surprisingly, bidding behavior remains similar between the average bid and low price auctions. We provide an explanation for the bidding behavior in the average bid auction that is based on subjects having problems processing signals near the extremes of the distribution."
1071,"Sponsored Search Marketing: Dynamic Pricing and Advertising for an Online Retailer","Ye, Shengqi and Aydin, Goker and Hu, Shanshan","MANAGEMENT SCIENCE","61","6","1255-1274","2015","JUN","Sponsored Search Marketing;Dynamic Pricing;Online Retailing","","Consider a retailer using sponsored search marketing together with dynamic pricing. The retailer's bid on a search keyword affects the retailer's rank among the search results. The higher the rank, the higher the customer traffic and the customers' willingness to pay will be. Thus, the question arises: When a retailer bids higher to attract more customers, should the accompanying price also decrease (to strengthen the bid's effect on demand) or increase (to take advantage of higher willingness to pay)? We find that the answer depends on how fast the retailer increases its bid. In particular, as the end of the season approaches, the optimal bid exhibits smooth increases followed by big jumps. The optimal price increases only when the optimal bid increases sharply, including the instances where the bid jumps up. Such big jumps arise, for example, when the customer traffic is an S-shaped function of the retailer's bid."
1072,"The Fixed Charge Transportation Problem: An Exact Algorithm Based on a New Integer Programming Formulation","Roberti, Roberto and Bartolini, Enrico and Mingozzi, Aristide","MANAGEMENT SCIENCE","61","6","1275-1291","2015","JUN","Transportation;Fixed Charge;Column Generation","","The fixed charge transportation problem generalizes the well-known transportation problem where the cost of sending goods from a source to a sink is composed of a fixed cost and a continuous cost proportional to the amount of goods sent. In this paper, we describe a new integer programming formulation with exponentially many variables corresponding to all possible flow patterns to sinks. We show that the linear relaxation of the new formulation is tighter than that of the standard mixed integer programming formulation. We describe different classes of valid inequalities for the new formulation and a column generation method to compute a valid lower bound embedded into an exact branch-and-price algorithm. Computational results on test problems from the literature show that the new algorithm outperforms the state-of-the-art exact methods from the literature and can solve instances with up to 70 sources and 70 sinks. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1947."
1073,"Disclosure Policy and Industry Fluctuations","Bertomeu, Jeremy and Liang, Pierre Jinghong","MANAGEMENT SCIENCE","61","6","1292-1305","2015","JUN","Voluntary Disclosure;Industrial Organization;Competition;Market Structure;Firm Strategy;Business Cycles;Information Sharing","","This paper examines voluntary disclosures in a repeated oligopoly and their association with price-setting behavior and industry profits along industrial fluctuations. The analysis focuses on the collectively optimal equilibrium among oligopoly firms. We show that, in industries that are highly concentrated or feature low cost of capital, nondisclosure is prevalent and results in stable product prices and high profit margins. Otherwise, firms may selectively disclose to soften competition in the product market. Under partial disclosure, firms withhold information during sharp industry expansions or declines. Consequently, the disclosure policy dampens the dissemination of shocks to the industry."
1074,"Experiments on Compound Risk in Relation to Simple Risk and to Ambiguity","Abdellaoui, Mohammed and Klibanoff, Peter and Placido, Laetitia","MANAGEMENT SCIENCE","61","6","1306-1322","2015","JUN","Ambiguity;Ellsberg Paradox;Reduction Of Compound Lotteries","","We conduct experiments measuring individual behavior under compound risk, simple risk, and ambiguity. We focus on (1) treatment of compound risks relative to simple risks and (2) the relationship between compound risk attitudes and ambiguity attitudes. We find that compound risks are valued differently than corresponding reduced simple risks. These differences measure compound risk attitudes. These attitudes display more aversion as the reduced probability of the winning event increases. Like Halevy [Halevy Y (2007) Ellsberg revisited: An experimental study. Econometrica 75:503-536], we find an association between compound risk reduction and ambiguity neutrality. However, in contrast to the almost perfect identification in Halevy's data, we find a substantially weaker relation in both directions. First, a majority of our ambiguity-neutral subjects fail to reduce compound risk. Second, almost a quarter of our subjects who reduce compound risk are nonneutral to ambiguity. All of the latter come from the more quantitatively sophisticated part of our subject pool. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1953."
1075,"The Role of Equity, Royalty, and Fixed Fees in Technology Licensing to University Spin-Offs","Savva, Nicos and Taneri, Niyazi","MANAGEMENT SCIENCE","61","6","1323-1343","2015","JUN","University Technology Transfer;Equity;Royalty;Fixed Fees;Contract Design;Screening Games","","We develop a model based on asymmetric information (adverse selection) that provides a rational explanation for the persistent use of royalties alongside equity in university technology transfer. The model shows how royalties, through their value-destroying distortions, can act as a screening tool that allows a less-informed principal, such as the university's Technology Transfer Office (TTO), to elicit private information from the more informed spin-off. We also show that equity-royalty contracts outperform fixed-fee-royalty contracts because they cause fewer value-destroying distortions. Furthermore, we show that our main result is robust to problems of moral hazard. Beside the coexistence result, the model also offers explanations for the empirical findings that equity generates higher returns than royalty and that TTOs willing to take equity in lieu of fixed fees are more successful in creating spin-offs."
1076,"The Risk Preferences of US Executives","Brenner, Steffen","MANAGEMENT SCIENCE","61","6","1344-1361","2015","JUN","Crra Preferences;Top Executives;Calibration Method","","In this paper, I elicit risk attitudes of U.S. executives by calibrating a subjective option valuation model for option exercising data (1996 to 2008), yielding approximately 65,000 values of relative risk aversion (RRA) for almost 7,000 executives. The observed behavior is generally consistent with moderate risk aversion and a median (mean) RRA close to one (three). Values are validated for chief executive officers (CEOs) by testing theory-based predictions on the influence of individual characteristics on risk preferences such as gender, marital status, religiosity, and intelligence. Senior managers such as CEOs, presidents, and chairpersons of the boards of directors are significantly less risk averse than non-senior executives. RRA heterogeneity is strongly correlated with sector membership and firm-level variables such as size, performance, and capital structure. Alternative factors influencing option exercises are tested for their influence on RRA values."
1077,"Changes in the Composition of Publicly Traded Firms: Implications for the Dividend-Price Ratio and Return Predictability","Jank, Stephan","MANAGEMENT SCIENCE","61","6","1362-1377","2015","JUN","Return Predictability;Dividend-Price Ratio;Sample Selection","","This paper documents how the changing composition of U.S. publicly traded firms has prompted a decline in the long-run mean of the aggregate dividend-price ratio, most notably since the 1970s. Adjusting the dividend-price ratio for such changes resolves several issues with respect to the predictability of stock market returns: the adjusted dividend-price ratio is less persistent, in-sample evidence for predictability is more pronounced, there is greater parameter stability in the predictive regression (particularly during the 1990s), and there is evidence of out-of-sample predictability. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2013.1883."
1078,"Risk Attitude, Beliefs Updating, and the Information Content of Trades: An Experiment","Bisiere, Christophe and Decamps, Jean-Paul and Lovo, Stefano","MANAGEMENT SCIENCE","61","6","1378-1397","2015","JUN","Behavior Under Uncertainty;Risk Attitude;Belief Updating;Financial Market Efficiency;Laboratory Experiment","","We conduct a series of experiments that simulate trading in financial markets. We find that the information content of the order flow varies with the strength of subjects' prior beliefs about fundamentals. The presence of intrinsic uncertainty about the asset's fundamentals reduces informational efficiency. This originates from subjects' risk attitudes and biases in the way some subjects update their beliefs. The behavior of approximately 63% of the subjects is consistent with the expected utility maximization. These subjects are either risk averse (52%) or risk loving (11%). About 22% of the subjects display non-Bayesian updating of beliefs: underconfidence emerges for weak prior beliefs, and confirmation bias occurs for strong prior beliefs. Non-Bayesian belief updating reduces market efficiency when subjects' prior beliefs are weak and increases it when the prior beliefs are strong. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2013.1886."
1079,"How Reduced Search Costs and the Distribution of Bidder Participation Affect Auction Prices","Overby, Eric and Kannan, Karthik","MANAGEMENT SCIENCE","61","6","1398-1420","2015","JUN","Electronic Commerce;Search Costs;Multiple-Object Auctions;Distribution Of Bidder Participation","","Electronic commerce allows bidders to find and participate in auctions regardless of location. This reduction in bidders' search costs has important effects on bidders' participation patterns and sellers' revenue. The demand expansion effect occurs when reduced search costs allow bidders to participate in more auctions. The demand distribution effect occurs when reduced search costs allow bidders to distribute themselves more evenly across auctions. We focus on the latter effect by modeling when a more even distribution of bidder participation across auctions increases seller revenue. We apply our analytical insights to 65,718 sequential auctions (comprising over 10 million vehicles) in the wholesale used vehicle market. We show that reduced search costs can increase seller revenue by smoothing the distribution of bidder participation across auctions, even if the aggregate amount of bidder participation remains constant. This contributes new results to the auction theory literature and generates novel insights for sellers seeking increased revenue."
1080,"Smart People Ask for (My) Advice: Seeking Advice Boosts Perceptions of Competence","Brooks, Alison Wood and Gino, Francesca and Schweitzer, Maurice E.","MANAGEMENT SCIENCE","61","6","1421-1435","2015","JUN","Advice;Advice Seeking;Competence;Impression Management;Egocentrism;Help Seeking","","Although individuals can derive substantial benefits from exchanging information and ideas, many individuals are reluctant to seek advice from others. We find that people are reticent to seek advice for fear of appearing incompetent. This fear, however, is misplaced. We demonstrate that individuals perceive those who seek advice as more competent than those who do not. This effect is moderated by task difficulty, advisor egocentrism, and advisor expertise. Individuals perceive those who seek advice as more competent when the task is difficult rather than when it is easy, when people seek advice from them personally rather than when they seek advice from others and when people seek advice from experts rather than from nonexperts or not at all."
1081,"Does Brand Licensing Increase a Licensor's Shareholder Value?","Robinson, Adina Barbulescu and Tuli, Kapil R. and Kohli, Ajay K.","MANAGEMENT SCIENCE","61","6","1436-1455","2015","JUN","Brand Licensing;Stock Returns;Marketing-Finance Interface","","This study examines 171 brand licensing announcements and subsequent changes in the licensor firms' shareholder values using the event study method. We find that although brand licensing announcements lead to positive abnormal returns on average, nearly 44% of the announcements in our sample are followed by negative abnormal returns. We argue that investors react more favorably to a brand licensing announcement when they believe (i) the brand has greater ability to stimulate licensee product sales (and thus generate higher royalties for the licensor) and (ii) the licensor firm has greater ability to limit licensee opportunism (and thus limit brand dilution and its adverse effect on sales of other products marketed under the brand name). In line with our hypotheses related to a brand's ability to stimulate licensee product sales, the study's findings suggest that investors react more favorably to announcements involving brands with greater brand fit and greater brand breadth. However, investors appear to react less favorably to announcements involving brands with higher advertising investments. In line with our hypotheses related to a licensor firm's ability to limit licensee opportunism, the study's findings suggest that investors react more favorably to announcements involving larger licensors; however, investors' reactions do not appear to be influenced by licensor firms' licensing experience."
1082,"Interpersonal Bundling","Chen, Yongmin and Zhang, Tianle","MANAGEMENT SCIENCE","61","6","1456-1471","2015","JUN","Interpersonal Bundling;Bundling;Group Purchase;Group Discount;Demand Uncertainty","","This paper studies a model of interpersonal bundling, in which a monopolist offers a good for sale under a regular price and a group purchase discount if the number of consumers in a group-the bundle size-belongs to some menu of intervals. We find that this is often a profitable selling strategy in response to demand uncertainty, and it can achieve the highest profit among all possible selling mechanisms. We explain how the profitability of interpersonal bundling with a minimum or maximum group size may depend on the nature of uncertainty and on parameters of the market environment, and we discuss strategic issues related to the optimal design and implementation of these bundling schemes. Our analysis sheds light on popular marketing practices such as group purchase discounts, and it offers insights on potential new marketing innovation."
1083,"Forward-Looking MD&A Disclosures and the Information Environment","Muslu, Volkan and Radhakrishnan, Suresh and Subramanyam, K. R. and Lim, Dongkuk","MANAGEMENT SCIENCE","61","5","931-948","2015","MAY","Disclosure;10-K Filings;Forward Looking","","We use computer-intensive techniques to study the informational properties of forward-looking disclosures in the management discussion and analysis (MD&A) sections of 10-K filings made with the Securities and Exchange Commission. We find that firms make more forward-looking MD&A disclosures when their stock prices have lower informational efficiency, i.e., when their stock prices poorly reflect future earnings information. The greater levels of forward-looking MD&A disclosures help improve yet are unable to completely mitigate the lower informational efficiency of stock prices for such firms. These findings are stronger for operations-related forward-looking disclosures, disclosures that are made prior to 2000, and disclosures made by loss firms."
1084,"The Hidden Cost of Accommodating Crowdfunder Privacy Preferences: A Randomized Field Experiment","Burtch, Gordon and Ghose, Anindya and Wattal, Sunil","MANAGEMENT SCIENCE","61","5","949-962","2015","MAY","Crowdfunding;Privacy;Priming;Anonymity;Randomized Experiment","","Online crowdfunding has received a great deal of attention as a promising avenue to fostering entrepreneurship and innovation. Because online settings bring increased visibility and traceability of transactions, many crowdfunding platforms provide mechanisms that enable a campaign contributor to conceal his or her identity or contribution amount from peers. We study the impact of these information (privacy) control mechanisms on crowdfunder behavior. Employing a randomized experiment at one of the world's largest online crowdfunding platforms, we find evidence of both positive (e.g., comfort) and negative (e.g., privacy priming) causal effects. We find that reducing access to information controls induces a net increase in fund-raising, yet this outcome results from two competing influences-treatment increases willingness to engage with the platform (a 4.9% increase in the probability of contribution) and simultaneously decreases the average contribution (a $5.81 decline). This decline derives from a publicity effect, wherein contributors respond to a lack of privacy by tempering extreme contributions. We unravel the causal mechanisms that drive the results and discuss the implications of our findings for the design of online platforms."
1085,"A Comparison of Milestone-Based and Buyout Options Contracts for Coordinating R&D Partnerships","Bhattacharya, Shantanu and Gaba, Vibha and Hasija, Sameer","MANAGEMENT SCIENCE","61","5","963-978","2015","MAY","R&D Partnerships;Options Contracts;Double-Sided Moral Hazard;Holdup;Risk Preference","","We analyze optimal contractual arrangements in a bilateral research and development (R&D) partnership between a risk-averse provider that conducts early-stage research followed by a regulatory verification stage and a risk-neutral client that performs late-stage development activities, including production, distribution, and marketing. The problem is formulated as a sequential investment game with the client as the principal, where the investments are observable but not verifiable. The model captures the inherent incentive alignment problems of double-sided moral hazard, risk aversion, and holdup. We compare the efficacy of milestone-based options contracts and buyout options contracts from the client's perspective and identify conditions under which they attain the first-best outcome for the client. We find that milestone-based options contracts always attain the first-best outcome for the client when the provider has some bargaining power in renegotiation and identify their applicability to different R&D partnerships."
1086,"Does a Procurement Service Provider Generate Value for the Buyer Through Information About Supply Risks?","Yang, Zhibin (Ben) and Babich, Volodymyr","MANAGEMENT SCIENCE","61","5","979-998","2015","MAY","Supply Disruption;Sourcing Intermediation;Mechanism Design;Supply Diversification;Information Asymmetry","","We consider a supply chain with one buyer and two suppliers who are subject to disruptions and whose likelihoods of disruption are their private information. In such a setting, does the buyer benefit from engaging the services of a better-informed procurement service provider (PSP) compared to procuring directly from the suppliers? Intuition might suggest that hiring a PSP is always the right choice because the PSP's knowledge of the supply base improves supplier selection and management. On the other hand, earlier studies prove that using a PSP purely for its superior knowledge about supply costs is always worse for a buyer than contracting with the suppliers directly. Our answer to this research question is more nuanced. Contrary to the findings of earlier studies, we find that the buyer may benefit from using a PSP. We identify, quantify, and explain all of the benefits and the costs of using a PSP, and describe conditions under which the benefits exceed the costs. The benefits of using a PSP are derived when one supplier is of high reliability and the other is of low reliability, from a reduction of informational costs due to implicit supplier collusion facilitated by the PSP and an improvement of supply availability. The costs of using a PSP are derived when both suppliers are of low reliability, from the loss of direct control over the supplier's production actions, which leads to reduced supply availability and increased informational costs, and from the PSP facilitating implicit supplier collusion. Comparative statics analysis indicates that using the PSP is valuable only if the buyer diversifies with some supplier-type combinations but not others, and that hiring a PSP is not a solution to the problem of an unreliable supply base."
1087,"Interdiction Games on Markovian PERT Networks","Gutin, Eli and Kuhn, Daniel and Wiesemann, Wolfram","MANAGEMENT SCIENCE","61","5","999-1017","2015","MAY","Interdiction Game;Pert Network;Markov Decision Process;Robust Optimization","","In a stochastic interdiction game a proliferator aims to minimize the expected duration of a nuclear weapons development project, and an interdictor endeavors to maximize the project duration by delaying some of the project tasks. We formulate static and dynamic versions of the interdictor's decision problem where the interdiction plan is either precommitted or adapts to new information revealed over time, respectively. The static model gives rise to a stochastic program, whereas the dynamic model is formalized as a multiple optimal stopping problem in continuous time and with decision-dependent information. Under a memoryless probabilistic model for the task durations, we prove that the static model reduces to a mixed-integer linear program, whereas the dynamic model reduces to a finite Markov decision process in discrete time that can be solved via efficient value iteration. We then generalize the dynamic model to account for uncertainty in the outcomes of the interdiction actions. We also discuss a crashing game where the proliferator can use limited resources to expedite tasks so as to counterbalance the interdictor's efforts. The resulting problem can be formulated as a robust Markov decision process."
1088,"The Impact of Advice on Women's and Men's Selection into Competition","Brandts, Jordi and Groenert, Valeska and Rott, Christina","MANAGEMENT SCIENCE","61","5","1018-1035","2015","MAY","Experiments;Advice;Gender Gap In Competitiveness","","We conduct a laboratory experiment to study how advice by a more experienced and better-informed person affects an individual's entry into a real-effort tournament and the gender gap. Our experiment is motivated by the concerns raised by approaching the gender gap through affirmative action policies. Overall, advice improves the entry decision of subjects, in that forgone earnings due to wrong entry decisions go significantly down. The improvements are mainly driven by increased entry of strong-performing women, who also become more confident, and reduced entry of weak-performing men. We find that the overall gender gap persists even though it disappears among low and strong performers. The persistence is due to an emerging gender gap among intermediate performers driven by women (men) following more the advice to stay out of (enter) the tournament in this performance group."
1089,"An Experimental Investigation of Auctions and Bargaining in Procurement","Shachat, Jason and Tan, Lijia","MANAGEMENT SCIENCE","61","5","1036-1051","2015","MAY","Auction;Bargaining;Experiment;Subjective Posterior","","In reverse auctions, buyers often retain the right to bargain further concessions from the winners. The optimal form of such procurement is an English auction followed by an auctioneer's option to engage in ultimatum bargaining with the winners. We study behavior and performance in this procurement format using a laboratory experiment. Sellers closely follow the equilibrium strategy of exiting the auction at their costs and then accepting strictly profitable offers. Buyers generally exercise their option to bargain according to their equilibrium strategy, but their take-it-or-leave-it offers vary positively with auction prices when they should be invariant. We explain this deviation by modeling buyers' subjective posteriors regarding the winners' costs as distortions of the Bayesian posteriors, calculated using a formulation similar to a commonly used probability weighting function. We further test the robustness of the experimental results and the subjective posterior explanation with three additional experimental treatments."
1090,"Global Sourcing and Foreign Knowledge Seeking","Berry, Heather and Kaul, Aseem","MANAGEMENT SCIENCE","61","5","1052-1071","2015","MAY","Offshore Integration And Offshore Outsourcing;Foreign Knowledge Seeking;Research And Development;Multinational Corporations (Mncs);Colocation;Organizational Economics","","We develop and test a rigorous theoretical account of firm global sourcing decisions, distinguishing the antecedents of offshore integration from those of offshore outsourcing. Although traditional theories of global sourcing focus on lowering costs, we argue that as high-performing firms seek to develop new capabilities by tapping into foreign knowledge, they will increasingly turn to offshore integration to reap colocation benefits and overcome expropriation challenges. By contrast, offshore outsourcing will be preferred by less profitable firms seeking to tap into low-cost inputs, especially as investments in information technology lower monitoring costs. Empirical analysis of a comprehensive panel of cross-border product transfers by U.S. manufacturing multinational corporations from 1989 to 2004 reveals support for these arguments. Our study thus highlights the effect of foreign knowledge seeking on global sourcing and helps explain recent trends in this increasingly important phenomenon, especially the increasing reliance on offshore integration in technology intensive industries."
1091,"The Reaction of Stock Returns to News About Fundamentals","Cenesizoglu, Tolga","MANAGEMENT SCIENCE","61","5","1072-1093","2015","MAY","Asset Pricing;Regime Switching Fundamentals;Learning;Asymmetric Reaction;Time-Varying External Signal Precision;Good And Bad Times","","In good times, stock prices react negatively to good news and positively to bad news, whereas in bad times, they react positively to good news and negatively to bad news. To account for this stylized fact, we consider an asset pricing model where the dividend growth rate switches between different values depending on the underlying state of the economy. Investors never observe the true dividend growth rate, but learn about it through not only its realizations but also external signals such as macroeconomic indicators. Under plausible assumptions, the differing precision of external signals across different states of the economy can change the sign of the market reaction to news from external signals in good and bad times."
1092,"Real Options and American Derivatives: The Double Continuation Region","Battauz, Anna and De Donno, Marzia and Sbuelz, Alessandro","MANAGEMENT SCIENCE","61","5","1094-1107","2015","MAY","American Options;Valuation;Optimal Exercise;Real Options;Gold Loan;Collateralized Borrowing;Asymptotic Approximation Of The Free Boundary;Put-Call Symmetry","","We study the nonstandard optimal exercise policy associated with relevant capital investment options and with the prepayment option of widespread collateralized-borrowing contracts like the gold loan. Option exercise is optimally postponed not only when moneyness is insufficient, but also when it is excessive. We extend the classical optimal exercise properties for American options. Early exercise of an American call with a negative underlying payout rate can occur if the option is moderately in the money. We fully characterize the existence, the monotonicity, the continuity, the limits, and the asymptotic behavior at maturity of the double free boundary that separates the exercise region from the double continuation region. We find that the finite-maturity nonstandard policy conspicuously differs from the infinite-maturity one."
1093,"Contractual vs. Actual Separation Pay Following CEO Turnover","Goldman, Eitan Moshe and Huang, Peggy Peiju","MANAGEMENT SCIENCE","61","5","1108-1120","2015","MAY","Executive Compensation;Severance;Separation Pay;Ceo Turnover;Bargaining","","Using hand-collected data, we document the details of the ex ante severance contracts and the ex post separation pay given to S&P 500 chief executive officers (CEOs) upon departing from their companies. We analyze what determines whether or not a CEO receives separation pay in excess of the amount specified in the severance contract. We find that discretionary separation pay is given to about 40% of departing CEOs and is, on average, $8 million, which amounts to close to 242% of a CEO's annual compensation. We investigate the determinants of discretionary separation pay and find, for example, that discretionary separation pay positively correlates with weak internal governance in cases of voluntary CEO turnover but not when the CEO is forced out. We also find that discretionary pay is higher when the CEO has a noncompete clause in her ex ante severance contract. Event study analysis suggests that shareholders benefit from discretionary separation pay in forced turnovers but not in voluntary ones. Our overall results help to shed light on the complex role of discretionary separation pay in the bargaining game between boards and departing executives."
1094,"Sticking with What (Barely) Worked: A Test of Outcome Bias","Lefgren, Lars and Platt, Brennan and Price, Joseph","MANAGEMENT SCIENCE","61","5","1121-1136","2015","MAY","Outcome Bias;Hindsight Bias;Bayesian Updating;Strategy Revision","","Outcome bias occurs when an evaluator considers ex post outcomes when judging whether a choice was correct ex ante. We formalize this cognitive bias in a simple model of distorted Bayesian updating. We then examine strategy changes made by professional basketball coaches. We find that they are more likely to revise their strategy after a loss than a win-even for narrow losses, which are uninformative about team effectiveness. This increased strategy revision following a loss occurs even when a loss was expected and even when failure is due to factors beyond the team's control. These results are consistent with our model's predictions."
1095,"Bang for the Buck: Gain-Loss Ratio as a Driver of Judgment and Choice","de Langhe, Bart and Puntoni, Stefano","MANAGEMENT SCIENCE","61","5","1137-1163","2015","MAY","Gain-Loss Ratio;Efficiency;Decreasing Marginal Sensitivity;Loss Aversion;Probability Weighting;Prospect Theory;Risk Preference;Mixed Gambles","","Prominent decision-making theories propose that individuals (should) evaluate alternatives by combining gains and losses in an additive way. Instead, we suggest that individuals seek to maximize the rate of exchange between positive and negative outcomes and thus combine gains and losses in a multiplicative way. Sensitivity to gain-loss ratio provides an alternative account for several existing findings and implies a number of novel predictions. It implies greater sensitivity to losses and risk aversion when expected value is positive, but greater sensitivity to gains and risk seeking when expected value is negative. It also implies more extreme preferences when expected value is positive than when expected value is negative. These predictions are independent of decreasing marginal sensitivity, loss aversion, and probability weighting-three key properties of prospect theory. Five new experiments and reanalyses of two recently published studies support these predictions."
1096,"Aggregate Impact of Different Brand Development Strategies","Hariharan, Vijay Ganesh and Bezawada, Ram and Talukdar, Debabrata","MANAGEMENT SCIENCE","61","5","1164-1182","2015","MAY","Branding;Brand Extensions;Line Extensions;Cobranding;New Products;Brand Development Strategy;Spillover Effects;Extension Performance;Bayesian Endogenous Switching Model;Empirical Generalization","","Current branding literature investigates the spillover effects and extension effects due to the introduction of product extensions. However, no study so far has evaluated the aggregate market impact of these effects across different brand development strategies or accounted for the strategic decision to introduce the extension. It is important to examine the above given the significant investments and the high failure rates associated with the introduction of new product extensions. In this study, we develop an analytical framework that derives revenue outcome due to an extension introduction as a function of spillover and extension effects. We empirically estimate the above effects through a Bayesian endogenous switching model that jointly models market shares of the extension and its parent brand along with the strategic decision to introduce the extension and the endogeneity in prices. By using a data set that covers 155 extensions introduced across 20 U.S. geographic markets, we obtain several new generalizable empirical insights. Our results show that spillover effects are higher for brand extensions, whereas line extensions benefit through larger extension effects. We find that vertically differentiating a line extension in terms of increased quality mitigates its negative spillover effects. The addition of a new brand name (i.e., sub-branding) lowers spillover effects for line extensions, whereas it increases the market performance for brand extensions. Our findings provide several strategic implications for manufacturers to successfully introduce and manage product extensions."
1097,"Digital Content Provision and Optimal Copyright Protection","Guo, Liang and Meng, Xiangyi","MANAGEMENT SCIENCE","61","5","1183-1196","2015","MAY","Copyright;Piracy;Quality;Search","","Advances in digital technologies have led to an increasing concern about piracy for providers of digital content (e.g., e-books, games, music, software, videos). Yet controversies exist over the influence of copyright protection on firm profitability. The objective of this paper is to provide an alternative rationale for the growing anti-protection trend and to investigate optimal copyright enforcement and quality provision in a monopoly setting. The proposed economic mechanism centers on the influence of copyright protection on consumer search when consumers can get to know the firm's actions (e.g., price, quality) only after costly search. We show that more stringent copyright protection can induce the consumers to rationally expect lower ex post surplus, thus exerting a negative strategic effect on the consumers' willingness to search. This strategic effect may outweigh the positive main effect on the relative attractiveness of the authorized versus the pirated product, which can hence explain the optimality of incomplete and even zero copyright protection policies in markets where consumer prepurchase search is important (e.g., information goods, digital products). It is also because of this strategic effect that the firm may provide lower quality as copyright enforcement increases. Interestingly, quality unobservability can moderate this strategic effect and thus lead to an increasing incentive for copyright protection."
1098,"Human and Financial Capital for Microenterprise Development: Evidence from a Field and Lab Experiment","Berge, Lars Ivar Oppedal and Bjorvatn, Kjetil and Tungodden, Bertil","MANAGEMENT SCIENCE","61","4","707-722","2015","APR","Microenterprise;Human Capital;Financial Capital;Field Experiment;Lab Experiment","","Microenterprises constitute an important source of employment, and developing such enterprises is a key policy concern in most countries. But what is the most efficient tool for microenterprise development? We study this question in a developing country context (Tanzania), where microenterprises are the source of employment for more than half of the labor force, and we report from a field experiment that jointly investigated the importance of a human capital intervention (business training) and a financial capital intervention (business grant). Using data from three survey rounds, a lab experiment, and administrative records of the microfinance institution, we present evidence on business performance, management practices, happiness, business knowledge, and noncognitive abilities. Our study demonstrates strong effects of the combination of the two interventions on male entrepreneurs, while the effects on female entrepreneurs are much more muted. The results suggest that long-term finance is an important constraint for microfinance entrepreneurs, but that business training is essential to transform financial capital into productive investments. Our study also points to the need for more comprehensive measures to promote the businesses of female entrepreneurs."
1099,"On the (Surprising) Sufficiency of Linear Models for Dynamic Pricing with Demand Learning","Besbes, Omar and Zeevi, Assaf","MANAGEMENT SCIENCE","61","4","723-739","2015","APR","Model Misspecification;Inference;Price Optimization;Revenue Management;Myopic Pricing","","We consider a multiperiod single product pricing problem with an unknown demand curve. The seller's objective is to adjust prices in each period so as to maximize cumulative expected revenues over a given finite time horizon; in doing so, the seller needs to resolve the tension between learning the unknown demand curve and maximizing earned revenues. The main question that we investigate is the following: How large of a revenue loss is incurred if the seller uses a simple parametric model that differs significantly (i.e., is misspecified) relative to the underlying demand curve? We measure performance by analyzing the price trajectory induced by this misspecified model and quantifying the magnitude of revenue losses (as a function of the time horizon) relative to an oracle that knows the true underlying demand curve. The price of misspecification is expected to be significant if the parametric model is overly restrictive. Somewhat surprisingly, we show (under reasonably general conditions) that this need not be the case."
1100,"Clumped or Piecewise? Evidence on Preferences for Information","Zimmermann, Florian","MANAGEMENT SCIENCE","61","4","740-753","2015","APR","Reference-Dependent Preferences;Loss Aversion;Information Preferences;News Utility;Anticipatory Emotions;Experiment","","In this paper we examine individuals' attitudes toward the timing of information. We test a theoretical prediction that people prefer to get information clumped together rather than piecewise. We conduct a controlled lab experiment where subjects participate in a lottery and can choose between different resolutions of uncertainty (clumped or piecewise) and analyze which kind of resolution is preferred. Two additional treatments allow us to get a quantitative measure of subjects' preferences over different information structures. Our data provide little support for a systematic aversion to piecewise information on the aggregate level. In additional treatment conditions, we demonstrate the robustness of our findings and explore potential explanations."
1101,"Stress on the Ward: Evidence of Safety Tipping Points in Hospitals","Kuntz, Ludwig and Mennicken, Roman and Scholtes, Stefan","MANAGEMENT SCIENCE","61","4","754-771","2015","APR","Hospital Occupancy;Hospital Mortality;Safety Tipping Point;Capacity Pooling;Flexible Staffing","","Do hospitals experience safety tipping points as utilization increases, and if so, what are the implications for hospital operations management? We argue that safety tipping points occur when managerial escalation policies are exhausted and workload variability buffers are depleted. Front-line clinical staff is forced to ration resources and, at the same time, becomes more error prone as a result of elevated stress hormone levels. We confirm the existence of safety tipping points for in-hospital mortality using the discharge records of 82,280 patients across six high-mortality-risk conditions from 256 clinical departments of 83 German hospitals. Focusing on survival during the first seven days following admission, we estimate a mortality tipping point at an occupancy level of 92.5%. Among the 17% of patients in our sample who experienced occupancy above the tipping point during the first seven days of their hospital stay, high occupancy accounted for one in seven deaths. The existence of a safety tipping point has important implications for hospital management. First, flexible capacity expansion is more cost-effective for safety improvement than rigid capacity, because it will only be used when occupancy reaches the tipping point. In the context of our sample, flexible staffing saves more than 40% of the cost of a fully staffed capacity expansion, while achieving the same reduction in mortality. Second, reducing the variability of demand by pooling capacity in hospital clusters can greatly increase safety in a hospital system, because it reduces the likelihood that a patient will experience occupancy levels beyond the tipping point. Pooling the capacity of nearby hospitals in our sample reduces the number of deaths due to high occupancy by 34%."
1102,"Electric Vehicles with a Battery Switching Station: Adoption and Environmental Impact","Avci, Buket and Girotra, Karan and Netessine, Serguei","MANAGEMENT SCIENCE","61","4","772-794","2015","APR","Sustainable Operations;Transportation;Business Model Innovation;Public Policy;Electric Vehicles","","The transportation sector's carbon footprint and dependence on oil are of deep concern to policy makers in many countries. Use of all-electric drive trains is arguably the most realistic medium-term solution to address these concerns. However, motorist anxiety induced by an electric vehicle's limited range and high battery cost have constrained consumer adoption. A novel switching-station-based solution is touted as a promising remedy. Vehicles use standardized batteries that, when depleted, can be switched for fully charged batteries at switching stations, and motorists only pay for battery use. We build a model that highlights the key mechanisms driving adoption and use of electric vehicles in this new switching-station-based electric vehicle system and contrast it with conventional electric vehicles. Our model employs results from repairable item inventory theory to capture switching-station operation; we embed this model in a behavioral model of motorist use and adoption. Switching-station systems effectively transfer range risk from motorists to the station operator, who, through statistical economies of scale, can better manage it. We find that this transfer of risk can lead to higher electric vehicle adoption than in a conventional system, but it also encourages more driving than a conventional system does. We calibrate our models with motorist behavior data, electric vehicle technology data, operation costs, and emissions data to estimate the relative effectiveness of the two systems under the status quo and other plausible future scenarios. We find that the system that is more effective at reducing emissions is often less effective at reducing oil dependence, and the misalignment between the two objectives is most severe when the energy mix is coal heavy and has advanced battery technology. Increases in gasoline prices (by imposition of taxes, for instance) are much more effective in reducing carbon emissions, whereas battery-price-reducing policy interventions are more effective for reducing oil dependence. Taken together, our results help a policy maker identify the superior system for achieving the desired objectives. They also highlight that policy makers should not conflate the dual objectives of oil dependence and emissions reductions as the preferred system, and the policy interventions that further that system may be different for the two objectives."
1103,"Are All Independent Directors Equally Informed? Evidence Based on Their Trading Returns and Social Networks","Cao, Ying and Dhaliwal, Dan and Li, Zengquan and Yang, Yong George","MANAGEMENT SCIENCE","61","4","795-813","2015","APR","Social Networks;Insider Trading;Independent Directors","","We study the impact of social networks on the ability of independent directors to obtain private information from their firms' executives. We find that independent directors socially connected to their firms' senior executives earn significantly higher returns than unconnected independent directors in stock sales transactions. The network effect on independent directors' trading profitability is stronger in firms with higher information asymmetry and with more powerful executives. In addition, the trading returns of independent directors previously unconnected with firm executives increase after the arrival of a connected executive and drop after the connected executive leaves the firm. Moreover, the net stock sales by connected directors predict future negative news for up to three quarters. As a comparison, the trading returns of connected and unconnected independent directors do not differ significantly in stock purchases. Taken together, our results suggest that social connections help independent directors gain access to private bad news information from firms' senior executives."
1104,"Short-Selling Attacks and Creditor Runs","Liu, Xuewen","MANAGEMENT SCIENCE","61","4","814-830","2015","APR","Short-Selling Attacks;Creditor Runs;Coordination;Information Asymmetry;Feedback","","This paper investigates the mechanism through which short selling of a bank's stocks can trigger the failure of the bank. In the model, creditors, who learn information from stock prices, will grow increasingly unsure about the bank's true fundamentals in facing noisier stock prices; thus a run on the bank is more likely because of creditors' concave payoff. Understanding this, speculators conduct short selling beforehand to amplify (il)liquidity and add noise to stock prices, triggering a bank run, and subsequently profit from the bank's failure. We show that short-selling attacks on a bank involve two runs: the aggressive run among speculators and the conservative run among creditors. These two runs interact and reinforce each other, with compound feedback loops that drastically increase the probability of the collapse of the bank. We discuss policy implications of the model."
1105,"Beating Irrationality: Does Delegating to IT Alleviate the Sunk Cost Effect?","Herrmann, Philipp N. and Kundisch, Dennis O. and Rahman, Mohammad S.","MANAGEMENT SCIENCE","61","4","831-850","2015","APR","Internet Markets;Delegating To It;Sunk Cost Effect;Economics Of Automated Agents;Decision Support Systems;Decision Bias","","We investigate the impact of delegating decision making to information technology (IT) on an important human decision bias-the sunk cost effect. To address our research question, we use a unique data set containing actual market transaction data for approximately 7,000 pay-per-bid auctions. In contrast with the laboratory experiments of previous related studies, our research presents the unique advantage of investigating the effects of IT-enabled automated bidding agents on the occurrence of a decision bias in real market transactions. We identify normatively irrational decision scenarios and analyze consumer behavior in these situations. Our findings show that participants with a higher behavioral investment are more likely to violate the assumption of normative economic rationality because of the sunk cost effect. More importantly, we observe that the delegation of auction participation, i.e., actual bidding, to IT significantly reduces the occurrence of the sunk cost effect in subsequent decisions made by the same individual. We can attribute this reduction to the comparably lower behavioral investments incurred by auction participants who delegate their bidding to IT. In particular, by mitigating different contributors of behavioral investments, delegating to IT reduces the likelihood of the occurrence of the sunk cost effect by more than 50%."
1106,"Bias in Spatial Risk Assessment","Mishra, Himanshu and Mishra, Arul and Moreno, Oscar","MANAGEMENT SCIENCE","61","4","851-863","2015","APR","Spatial Risk;Risk Assessment;Bias;Intuitive Processing","","In instances of decision making under uncertainty with a visual component, we propose that individuals show a bias and estimate a higher probability of a threat affecting them if the threat is located in their left visual field compared to their right visual field. Across four studies we demonstrate the bias in naturalistic settings such as pedestrians assessing the risk of crossing the street, individuals estimating the risk posed from an unsavory person, and people assessing the contamination risk of an object. Moreover, we discuss four potential mechanisms that could cause the proposed effect. Finally, we discuss theoretical, managerial, and policy implications."
1107,"Repeated Auctions with Budgets in Ad Exchanges: Approximations and Design","Balseiro, Santiago R. and Besbes, Omar and Weintraub, Gabriel Y.","MANAGEMENT SCIENCE","61","4","864-884","2015","APR","Auction Design;Revenue Management;Ad Exchange;Display Advertising;Internet;Budget Constraints;Dynamic Games;Mean Field;Fluid Approximation","","Ad exchanges are emerging Internet markets where advertisers may purchase display ad placements, in real time and based on specific viewer information, directly from publishers via a simple auction mechanism. Advertisers join these markets with a prespecified budget and participate in multiple second-price auctions over the length of a campaign. This paper studies the competitive landscape that arises in ad exchanges and the implications for publishers' decisions. The presence of budgets introduces dynamic interactions among advertisers that need to be taken into account when attempting to characterize the bidding landscape or the impact of changes in the auction design. To this end, we introduce the notion of a fluid mean-field equilibrium (FMFE) that is behaviorally appealing and computationally tractable, and in some important cases, it yields a closed-form characterization. We establish that an FMFE approximates well the rational behavior of advertisers in these markets. We then show how this framework may be used to provide sharp prescriptions for key auction design decisions that publishers face in these markets. In particular, we show that ignoring budgets, a common practice in this literature, can result in significant profit losses for the publisher when setting the reserve price."
1108,"Attribute-Level Heterogeneity","Ebbes, Peter and Liechty, John C. and Grewal, Rajdeep","MANAGEMENT SCIENCE","61","4","885-897","2015","APR","Heterogeneity;Mixture Models;Hierarchical Bayes;Conjoint Analysis;Reversible-Jump Mcmc;Segmentation","","Modeling consumer heterogeneity helps practitioners understand market structures and devise effective marketing strategies. In this research we study finite mixture specifications for modeling consumer heterogeneity where each regression coefficient has its own finite mixture-that is, an attribute finite mixture model. An important challenge of such an approach to modeling heterogeneity lies in its estimation. A proposed Bayesian estimation approach, based on recent advances in reversible-jump Markov chain Monte Carlo methods, can estimate parameters for the attribute-based finite mixture model, assuming that the number of components for each finite mixture is a discrete random variable. An attribute specification has several advantages over traditional, vector-based, finite mixture specifications; specifically, the attribute mixture model offers a more appropriate aggregation of information than does the vector specification facilitating estimation. In an extensive simulation study and an empirical application, we show that the attribute model can recover complex heterogeneity structures, making it dominant over traditional (vector) finite mixture regression models and a strong contender compared to mixture-of-normals models for modeling heterogeneity."
1109,"Differentiation with User-Generated Content","Zhang, Kaifu and Sarvary, Miklos","MANAGEMENT SCIENCE","61","4","898-914","2015","APR","Competitive Strategy;Game Theory And Bargaining Theory;Advertising And Media","","This paper studies competition between firms whose products (content) are generated by their customers (users). Video sharing sites, social networks, online games, etc. all rely heavily on user-generated content and have been growing significantly in the last decade. We model a Hotelling style market in which consumers have heterogeneous tastes along a circular city. In a first step, we consider two ex ante identical firms whose offerings entirely depend on user-generated content. Consumers contribute content to the firm they join and benefit from the content provided by the others, their valuation being higher the closer the content contributor is to the content consumer (i.e., there are local network effects). In such a setting, we show that ex ante identical firms can acquire differentiated market positions that spontaneously emerge from user-generated content. Moreover, such differentiation may take interesting patterns, wherein a firm simultaneously attracts multiple distinct consumer segments that are isolated from each other. Greater segregation, measured by the number of disjoint segments in each platform, reduces consumer valuation for content, but interestingly, it intensifies firm competition. We show that this insight can help us refine the set of possible equilibria. In a second step, we consider firms that explicitly differentiate their offerings by generating some content on their own. We show that user-generated content may strengthen or defeat firms' intended positioning (i.e., firms attract consumers located opposite to their chosen positions) and consumer surplus may be higher in the latter case. Finally, we allow multihoming by consumers and show that the previous equilibrium patterns remain valid, but in most equilibria, a subset of consumers (located between rival firms' core clienteles) are multihomers. More multihoming consumers imply reduced differentiation and higher degree of platform competition. We relate these findings to anecdotal evidence and explore their strategic implications for competing firms relying on user-generated content."
1110,"Vertical Scope, Turbulence, and the Benefits of Commitment and Flexibility","Claussen, Jorg and Kretschmer, Tobias and Stieglitz, Nils","MANAGEMENT SCIENCE","61","4","915-929","2015","APR","Turbulence;Vertical Integration;Commitment;Flexibility;Adaptation;Nk Model","","We address the contested state of theory and the mixed empirical evidence on the relationship between turbulence and vertical scope by studying how turbulence affects the benefits of commitment from integrated development of components and the benefits of flexibility from sourcing components externally. We show that increasing turbulence first increases but then decreases the relative value of vertical integration. Moderate turbulence reduces the value of flexibility by making supplier selection more difficult and increases the value of commitment by mitigating the status quo bias of integrated structures. Both effects improve the value of integration. Higher levels of turbulence undermine the adaptive benefits of commitment, but have a less adverse effect on flexibility, making nonintegration more attractive. We also show how complexity and uneven rates of turbulence moderate the nonmonotonic relationship between turbulence and integration."
1111,"Spinoffs and the Mobility of US Merchant Semiconductor Inventors","Cheyre, Cristobal and Klepper, Steven and Veloso, Francisco","MANAGEMENT SCIENCE","61","3","487-506","2015","MAR","Inventor Mobility;Spinoffs;Clusters;Agglomeration Economies","","Data on inventors and assignees of patents are used to analyze the mobility of semiconductor inventors. Exploiting data on the origins of semiconductor producers with larger sales, we argue that the higher mobility of semiconductor inventors in Silicon Valley is in great part due to the entry of spinoffs there. Our empirical evidence suggests that spinoff entry promoted mobility in Silicon Valley even before the industry was clustered there. Agglomeration economies and the ban on noncompete covenants may influence spinoff entry, but spinoffs promote mobility even in the absence of those conditions. Because most of the greater inventor mobility in Silicon Valley corresponds to inventors moving from incumbents to recent entrants, the benefits that arise from greater mobility rates will be disproportionately reaped by new firms."
1112,"Keyword Search Advertising and First-Page Bid Estimates: A Strategic Analysis","Amaldoss, Wilfred and Desai, Preyas S. and Shin, Woochoel","MANAGEMENT SCIENCE","61","3","507-519","2015","MAR","First-Page Bid Estimate;Advertiser-Specific Minimum Bid;Generalized Second-Price Auction;Keyword Search Advertising;Two-Sided Markets","","In using the generalized second-price (GSP) auction to sell advertising slots, a search engine faces several challenges. Advertisers do not truthfully bid their valuations, and the valuations are uncertain. Furthermore, advertisers are budget constrained. In this paper we analyze a stylized model of the first-page bid estimate (FPBE) mechanism first developed by Google and demonstrate its advantages in dealing with these challenges. We show why and when the FPBE mechanism yields higher profits for the search engine compared with the traditional GSP auction and the GSP auction with advertiser-specific minimum bid. In the event that a high-valuation advertiser is budget constrained, the search engine can use the FPBE mechanism to alter the listing order with the intent of keeping the high-valuation advertiser in the auction for a longer time. The resulting increase in the search engine's profits is not necessarily at the expense of the advertisers because the combined profits of the advertisers and the search engine increase."
1113,"Drive More Effective Data-Based Innovations: Enhancing the Utility of Secure Databases","Qian, Yi and Xie, Hui","MANAGEMENT SCIENCE","61","3","520-541","2015","MAR","Database;Digital Economy;Innovation;Nonparametric;Perturbation;Privacy;Shuffling","","Databases play a central role in evidence-based innovations in business, economics, social, and health sciences. In modern business and society, there are rapidly growing demands for constructing analytically valid databases that also are secure and protect sensitive information to meet customer and public expectations, to minimize financial losses, and to comply with privacy regulations and laws. We propose new data perturbation and shuffling (DPS) procedures, named MORE, for this purpose. As compared with existing DPS methods, MORE can substantially increase the utility of secure databases without increasing disclosure risk. MORE is capable of preserving important nonmonotonic relationships among attributes, such as the inverted-U relationship between competition and innovation. Maintaining such relationships is often the key to determining optimal levels of policy and managerial interventions. MORE does not require data to be of particular types or have particular distributional shapes. Instead, it provides unified, flexible, and robust algorithms to mask general types of confidential variables with arbitrary distributions, thereby making it suitable for general-purpose data masking. Since MORE nests the commonly used generalized linear models as special cases, a much wider range of statistical analyses can be conducted by using the secure databases with results similar to those achieved by using the original databases. Unlike existing DPS approaches that typically require a joint model for all variables, MORE requires no modeling of nonconfidential variables and thus further increases the robustness of secure databases. Evaluation of MORE through Monte Carlo simulation studies and empirical applications demonstrates that it performs better than existing data-masking methods."
1114,"Bargaining for an Assortment","Aydin, Goker and Heese, H. Sebastian","MANAGEMENT SCIENCE","61","3","542-559","2015","MAR","Assortment Planning;Bargaining;Game Theory","","A retailer's assortment decision results from a process of give-and-take, during which the retailer may bid manufacturers against one another, and the terms of trade offer plenty of flexibility for allocating the profit among the retailer and manufacturers. We adopt a bargaining framework to capture such an assortment selection process. We investigate the properties of the profit allocations that could emerge in a decentralized supply chain. In our model, the retailer engages in simultaneous bilateral negotiations with all manufacturers. Our model and analysis produce managerial insights that could not be obtained in the absence of a bargaining perspective on assortment planning. For example, we find that when a manufacturer improves its product, such improvements not only benefit the retailer but might even benefit competing manufacturers. In fact, even improvements to out-of-assortment products can increase the profits of the retailer and certain in-assortment manufacturers. Hence, our results suggest that a manufacturer can benefit from collaborating with judiciously chosen competitors."
1115,"Rationing Capacity in Advance Selling to Signal Quality","Yu, Man and Ahn, Hyun-Soo and Kapuscinski, Roman","MANAGEMENT SCIENCE","61","3","560-577","2015","MAR","Advance Selling;Signaling Quality;Capacity Rationing","","We consider a seller who can sell her product over two periods, advance and spot. The seller has private information about the product quality, which is unknown to customers in advance and publicly revealed in spot. The question we consider is whether the seller has an incentive to signal quality in advance and, if so, how she can convey a credible signal of product quality. We characterize the seller's signaling strategy and find that rationing of capacity in the advance period is an effective tool of signaling product quality. We find that the high-quality seller can distinguish herself by allocating less capacity than the low-quality seller in the advance period. We show that this signaling mechanism exists whenever advance selling would be optimal for both the high-quality and low-quality sellers if quality were known by the consumers. Interestingly, the seller's ability to ration (rationing flexibility) sometimes disadvantages the seller; this effect is independent of product quality."
1116,"Decentralized Procurement in Light of Strategic Inventories","Arya, Anil and Frimor, Hans and Mittendorf, Brian","MANAGEMENT SCIENCE","61","3","578-585","2015","MAR","Decentralization;Inventory Management;Supply Chain Coordination","","The centralization versus decentralization choice is perhaps the quintessential organizational structure decision. In the operations realm, this choice is particularly critical when it comes to the procurement function. Why firms may opt to decentralize procurement has been often studied and confirmed to be a multifaceted choice. This paper complements existing studies by detailing the trade-offs in the centralization versus decentralization decision in light of firms' strategic use of inventories to influence supplier pricing. In particular, we demonstrate that a firm's decision to cede procurement choices to its individual divisions can help moderate inventory levels and provide a natural salve on supply chain frictions."
1117,"Prioritization via Stochastic Optimization","Koc, Ali and Morton, David P.","MANAGEMENT SCIENCE","61","3","586-603","2015","MAR","Priority Lists;Activity-Selection Problem;Stochastic Programming;Cutting Planes","","We take a novel approach to decision problems involving binary activity-selection decisions competing for scarce resources. The literature approaches such problems by forming an optimal portfolio of activities. However, often practitioners instead form a rank-ordered list of activities and select those with the highest priority. We account for both viewpoints. We rank activities considering both the uncertainty in the problem parameters and the optimal portfolio that will be obtained once the uncertainty is revealed. We use stochastic integer programming as a modeling framework, and we apply our approach to a facility location problem and a multidimensional knapsack problem. We develop two sets of cutting planes to improve computation."
1118,"The Role of Accounting Quality in the M&A Market","Marquardt, Carol and Zur, Emanuel","MANAGEMENT SCIENCE","61","3","604-623","2015","MAR","Mergers And Acquisitions;Auctions;Negotiations;Accounting Quality","","We examine the role of target firms' accounting quality in the merger and acquisition process. We predict that target firm accounting quality will be positively associated with (1) the likelihood that the deal will be structured as a negotiation rather than as an auction, (2) the speed with which the deal reaches final resolution, and (3) the likelihood that the proposed deal is ultimately completed. Our empirical evidence is consistent with these predictions. These results complement and extend existing findings on target firm accounting quality and provide new evidence that financial accounting quality relates positively to the efficient allocation of the economy's capital resources."
1119,"Are People Risk Vulnerable?","Beaud, Mickael and Willinger, Marc","MANAGEMENT SCIENCE","61","3","624-636","2015","MAR","Background Risk;Incomplete Markets;Portfolio Choice;Risk Vulnerability;Lab Experiment","","We report on a within-subject experiment, with substantial monetary incentives, designed to test whether or not people are risk vulnerable. In the experiment, subjects face the standard portfolio choice problem in which the investor has to allocate part of his wealth between one safe asset and one risky asset. We elicit risk vulnerability by observing each subject's portfolio choice in two different contexts that differ only by the presence or absence of an actuarially neutral background risk. Our main result is that most of the subjects are risk vulnerable: 81% chose a less risky portfolio when exposed to background risk. More precisely, 47% invested a strictly smaller amount in the risky asset, whereas 34% were indifferent. Furthermore, contrasting the predictions provided by competing decision-theoretic models, we conclude that expected utility theory best fits our experimental data."
1120,"Risk Preferences Around the World","Rieger, Marc Oliver and Wang, Mei and Hens, Thorsten","MANAGEMENT SCIENCE","61","3","637-648","2015","MAR","Risk Preferences;Cross-Cultural Comparison;Prospect Theory","","We present results from a large-scale international survey on risk preferences conducted in 53 countries. In all countries, we find, on average, an attitude of risk aversion in gains and of risk seeking in losses. The degree of risk aversion shows significant cross-country differences. Moreover, risk attitudes in our sample depend not only on economic conditions but also on cultural factors, as measured by the Hofstede dimensions individualism and uncertainty avoidance. The data may also serve as an interesting starting point for further research on cultural differences in behavioral economics."
1121,"Speculation Spillovers","Liu, Yu-Jane and Zhang, Zheng and Zhao, Longkai","MANAGEMENT SCIENCE","61","3","649-664","2015","MAR","Speculation;Contagious;Behavioral Bias","","This paper demonstrates that speculative activities can be contagious and spill over across markets. Specifically, we test the hypothesis that during China's warrants bubble period, speculative activities in the warrants market grabbed investors' attention and caused them to trade more speculatively in the underlying stocks. Consistent with this hypothesis, we find that turnover and return volatility of the underlying stocks are positively associated with the warrants' unexpected turnover and price deviation from their fundamental values during the previous day, controlling for information-driven trading and hedging motives, and that such a spillover effect is more pronounced when warrants attract more investor attention."
1122,"The Effect of Content on Global Internet Adoption and the Global Digital Divide","Viard, V. Brian and Economides, Nicholas","MANAGEMENT SCIENCE","61","3","665-686","2015","MAR","Internet;Technology Adoption;Economic Development;Two-Sided Markets;Network Effects;Technology Diffusion;Digital Divide;Language","","A country's human capital and economic productivity increasingly depend on the Internet as a result of its expanding role in providing information and communications. This has prompted a search for ways to increase Internet adoption and narrow its disparity across countries-the global digital divide. Previous work has focused on demographic, economic, and infrastructure determinants of Internet access that are difficult to change in the short run. Internet content increases adoption and can be changed more quickly; however, the magnitude of its impact, and therefore its effectiveness as a policy and strategy tool, has until now been unknown. Quantifying the role of content is challenging because of feedback (network effects) between content and adoption: more content stimulates adoption, which in turn increases the incentive to create content. We develop a methodology to overcome this endogeneity problem. We find a statistically and economically significant effect, implying that policies promoting content creation can substantially increase adoption. Because it is ubiquitous, Internet content is also useful to effect social change across countries. Content has a greater effect on adoption in countries with more disparate languages, making it a useful tool to overcome linguistic isolation. Our results offer guidance for policymakers on country characteristics that influence adoption's responsiveness to content and for Internet firms on where to expand internationally and how to quantify content investments."
1123,"On the Origin of Utility, Weighting, and Discounting Functions: How They Get Their Shapes and How to Change Their Shapes","Stewart, Neil and Reimers, Stian and Harris, Adam J. L.","MANAGEMENT SCIENCE","61","3","687-705","2015","MAR","Utility;Probability Weighting;Subjective Probability;Temporal Discounting;Delay Discounting;Stable Preferences;Decision By Sampling;Range Frequency Theory;Risky Choice;Decision Under Risk;Intertemporal Choice;Decision Under Delay","","We present a theoretical account of the origin of the shapes of utility, probability weighting, and temporal discounting functions. In an experimental test of the theory, we systematically change the shape of revealed utility, weighting, and discounting functions by manipulating the distribution of monies, probabilities, and delays in the choices used to elicit them. The data demonstrate that there is no stable mapping between attribute values and their subjective equivalents. Expected and discounted utility theories, and also their descendants such as prospect theory and hyperbolic discounting theory, simply assert stable mappings to describe choice data and offer no account of the instability we find. We explain where the shape of the mapping comes from and, in describing the mechanism by which people choose, explain why the shape depends on the distribution of gains, losses, risks, and delays in the environment."
1124,"Sex Hormones and Competitive Bidding","Schipper, Burkhard C.","MANAGEMENT SCIENCE","61","2","249-266","2015","FEB","Hormones;Steroids;Testosterone;Estradiol;Progesterone;Cortisol;Contraceptives;Auctions;Gender;Competition;Aggression;Risk Taking;Endocrinological Economics","","We correlate competitive bidding and profits in symmetric independent private value first-price auctions with salivary testosterone, estradiol, progesterone, and cortisol in more than 200 subjects. Bids are significantly positively correlated and profits are significantly negatively correlated with basal salivary progesterone, but only for females who do not use hormonal contraceptives. Surprisingly, we have null findings for basal testosterone, estradiol, and cortisol for both males and females. We show that our finding for progesterone is not mediated by risk aversion or bidding mistakes. No hormone responds to total profits in the auctions except for a small positive response of the stress hormone cortisol in males."
1125,"Identifying Expertise to Extract the Wisdom of Crowds","Budescu, David V. and Chen, Eva","MANAGEMENT SCIENCE","61","2","267-280","2015","FEB","Wisdom Of The Crowd;Forecasting;Dynamic Modeling;Contribution","","Statistical aggregation is often used to combine multiple opinions within a group. Such aggregates outperform individuals, including experts, in various prediction and estimation tasks. This result is attributed to the wisdom of crowds. We seek to improve the quality of such aggregates by eliminating poorly performing individuals from the crowd. We propose a new measure of contribution to assess the judges' performance relative to the group and use positive contributors to build a weighting model for aggregating forecasts. In Study 1, we analyze 1,233 judges forecasting almost 200 current events to illustrate the superiority of our model over unweighted models and models weighted by measures of absolute performance. In Study 2, we replicate our findings by using economic forecasts from the European Central Bank and show how the method can be used to identify smaller crowds of the top positive contributors. We show that the model derives its power from identifying experts who consistently outperform the crowd."
1126,"A Market Discovery Algorithm to Estimate a General Class of Nonparametric Choice Models","van Ryzin, Garrett and Vulcano, Gustavo","MANAGEMENT SCIENCE","61","2","281-300","2015","FEB","Demand Estimation;Random Utility Models;Choice Behavior;Demand Untruncation;Column Generation","","We propose an approach for estimating customer preferences for a set of substitutable products using only sales transactions and product availability data. The underlying demand framework combines a general, nonparametric discrete choice model with a Bernoulli process of arrivals over time. The choice model is defined by a discrete probability mass function (pmf) on a set of possible preference rankings of alternatives, and it is compatible with any random utility model. An arriving customer is assumed to purchase the available option that ranks highest in her preference list. The problem we address is how to jointly estimate the arrival rate and the pmf of the rank-based choice model under a maximum likelihood criterion. Since the potential number of customer types is factorial, we propose a market discovery algorithm that starts with a parsimonious set of types and enlarge it by automatically generating new types that increase the likelihood value. Numerical experiments confirm the potential of our proposal. For a realistic data set in the hospitality industry, our approach improves the root mean square errors between predicted and observed purchases computed under independent demand model estimates by 67%-93%."
1127,"Dynamic Bargaining in a Supply Chain with Asymmetric Demand Information","Feng, Qi and Lai, Guoming and Lu, Lauren Xiaoyuan","MANAGEMENT SCIENCE","61","2","301-315","2015","FEB","Dynamic Bargaining;Asymmetric Information;Screening;Signaling;Forecasting Accuracy","","We analyze a dynamic bargaining game in which a seller and a buyer negotiate over quantity and payment to trade for a product. Both firms are impatient, and they make alternating offers until an agreement is reached. The buyer is privately informed about his type, which can be high or low: the high type's demand is stochastically larger than the low type's. In the dynamic negotiation process, the seller can screen, whereas the buyer can signal information through their offers, and the buyer has an endogenous and type-dependent reservation profit. With rational assumptions on the seller's belief structure, we characterize the perfect Bayesian equilibrium of the bargaining game. Interestingly, we find that both quantity distortion and information rent may be avoided depending on the firms' relative patience, and the seller may reach an agreement with either the high type or the low type first, or with both simultaneously. Furthermore, we explore our model to characterize the effect of demand forecasting accuracy on firm profitability. We find that improved demand forecast benefits the buyer but hurts the seller when the buyer's forecasting accuracy is low. However, once the buyer's forecasting accuracy exceeds a threshold, both firms will benefit from further improvement of the forecast. This observation makes an interesting contrast to previous findings based on the one-shot principal-agent model, in which improvement of forecasting accuracy mostly leads to a win-lose outcome for the two firms, and the buyer has an incentive to improve his forecasting accuracy only when it is extremely low."
1128,"Appointment Scheduling with Limited Distributional Information","Mak, Ho-Yin and Rong, Ying and Zhang, Jiawei","MANAGEMENT SCIENCE","61","2","316-334","2015","FEB","Appointment Scheduling And Sequencing;Service Operations;Robust Optimization","","In this paper, we develop distribution-free models that solve the appointment sequencing and scheduling problem by assuming only moments information of job durations. We show that our min-max appointment scheduling models, which minimize the worst-case expected waiting and overtime costs out of all probability distributions with the given marginal moments, can be exactly formulated as tractable conic programs. These formulations are obtained by exploiting hidden convexity of the problem. In the special case where only the first two marginal moments are given, the problem can be reformulated as a second-order cone program. Based on the structural properties of this formulation, under a mild condition, we derive the optimal time allowances in closed form and prove that it is optimal to sequence jobs in increasing order of job duration variance. We also prove similar results regarding the optimal time allowances and sequence for the case where only means and supports of job durations are known."
1129,"Sorting Effects of Performance Pay","Goldmanis, Maris and Ray, Korok","MANAGEMENT SCIENCE","61","2","335-353","2015","FEB","Accounting;Compensation;Performance Measurement;Management;Agency Theory;Contract Theory","","Compensation not only provides incentives to an existing manager but also affects the type of manager attracted to the firm. This paper examines the dual incentive and sorting effects of performance pay in a simple contracting model of endogenous participation. Unless the manager is highly risk averse, sorting dampens optimal pay-performance sensitivity (PPS) because PPS beyond a nominal amount transfers unnecessary (information) rent to the manager. This helps explain why empirical estimates of PPS are much lower than predictions from models of moral hazard alone. The model also predicts that sorting under asymmetric information causes the firm to turn away more candidates than would be efficient; PPS increases in the cost of hiring the manager and in the manager's outside option, but decreases in output risk, information risk, and managerial risk aversion; and the firm becomes more selective in hiring as either the manager's outside option, the cost of hiring, risk aversion, output risk, or information risk increases."
1130,"Do Temporary Increases in Information Asymmetry Affect the Cost of Equity?","Levi, Shai and Zhang, Xiao-Jun","MANAGEMENT SCIENCE","61","2","354-371","2015","FEB","Information Asymmetry;Liquidity;Earnings Announcements;Cost Of Equity","","Prior literature finds that long-lasting changes in firms' disclosure policies and information environment affect the cost of equity. Information asymmetry, however, also changes during the fiscal quarter. Firms disclose information periodically, and in between disclosure dates, traders can obtain private information, and adverse-selection risk increases. Such temporary increases in information asymmetry are usually considered to be diversifiable or too small to impact expected stock returns. In addition, investors may postpone trades or sell other assets in their portfolio on high information asymmetry days. We, however, find that returns increase significantly on days during the fiscal quarter when adverse-selection risk is high and liquidity low. Consistent with theory, we show that temporary asymmetry affects returns when investors demand liquidity and market makers bear risk for carrying capacity and providing it."
1131,"Do Incumbents Improve Service Quality in Response to Entry? Evidence from Airlines' On-Time Performance","Prince, Jeffrey T. and Simon, Daniel H.","MANAGEMENT SCIENCE","61","2","372-390","2015","FEB","On-Time Performance;Airlines;Quality Competition;Entry;Entry Threat","","We examine if and how incumbent firms respond to entry and entry threats using nonprice modes of competition. Our analysis focuses on airline service quality. We find that incumbent on-time performance (OTP) actually worsens in response to entry, and even entry threats, by Southwest Airlines. Since Southwest is both a top-performing airline in OTP and a low-cost carrier (LCC), we conjecture that this response by incumbents may be due to a cost-cutting strategy that allows for intense postentry price competition along with preentry deterrence, or it may be due to a postentry differentiation strategy along with preentry accommodation. Further analysis of entry and entry threats by other airlines is inconclusive, providing evidence that is partially consistent with both hypotheses. Nonetheless, the phenomenon of worsening OTP can only be observed when the (potential) entrant is a LCC (Southwest, Jet Blue, and AirTran)."
1132,"Strategic Resource Allocation: Top-Down, Bottom-Up, and the Value of Strategic Buckets","Hutchison-Krupat, Jeremy and Kavadias, Stylianos","MANAGEMENT SCIENCE","61","2","391-412","2015","FEB","Resource Allocation Processes;Strategic Buckets;Empowerment;Innovation Strategy;New Product Development Strategy;Corporate Culture","","When senior managers make the critical decision of whether to assign resources to a strategic initiative, they have less precise initiative-specific information than project managers who execute such initiatives. Senior management chooses between a decision process that dictates the resource level ( top-down) and one that delegates the resource decision and gives up control in favor of more precise information ( bottom-up). We investigate this choice and vary the amount of information asymmetry between stakeholders, the penalty for failure imposed upon project managers, and how challenging the initiative is for the firm. We find that no single decision process is the best. Bottom-up processes are beneficial for more challenging initiatives. Increased organizational penalties may prompt the firm to choose a narrower scope and deter the approval of profitable initiatives. Such penalties, however, enable an effective decision process known as strategic buckets that holds the potential to achieve first-best resource allocation levels."
1133,"Macroeconomic Volatilities and Long-Run Risks of Asset Prices","Zhou, Guofu and Zhu, Yingzi","MANAGEMENT SCIENCE","61","2","413-430","2015","FEB","Long-Run Risks;Stochastic Volatility;Predictability;Variance Risk Premium;Vix Term Structure","","In this paper, motivated by existing and growing evidence on multiple macroeconomic volatilities, we extend the long-run risks model by allowing both a long-and a short-run volatility components in the evolution of economic fundamentals. With this extension, the new model not only is consistent with the volatility literature that the stock market is driven by two, rather than one, volatility factors, but also provides significant improvements in fitting various patterns, such as the size of market risk premium, the level of interest rate, degree of dividend yield predictability, and the term structure of variance risk premiums, of both the equity and option data."
1134,"The Effect of Electronic Commerce on Geographic Purchasing Patterns and Price Dispersion","Overby, Eric and Forman, Chris","MANAGEMENT SCIENCE","61","2","431-453","2015","FEB","Electronic Commerce;Electronic Channels;Electronic Markets;Price Dispersion;Geographic Trade;Wholesale Automotive;Auctions;Law Of One Price;Discrete Choice;Coarsened Exact Matching","","The law of one price states that if prices for the same or highly similar goods vary across geographic locations by more than the cost of transport, then traders will shift supply and demand to exploit the price differences. However, several frictions prevent traders from doing this, including lack of information about prices and difficulty trading across locations. Electronic commerce has the potential to reduce these frictions by increasing price visibility and lowering transaction costs. We analyze this by studying how the diffusion of an electronic channel affected geographic trading patterns and price dispersion in the wholesale used vehicle market from 2003 to 2008. We find that buyers used the channel to shift their demand geographically to exploit price differences, which reduced geographic price dispersion. We find that the electronic channel also influenced how sellers distributed supply, but we find little evidence that this led to reduced geographic price dispersion."
1135,"Latent Homophily or Social Influence? An Empirical Analysis of Purchase Within a Social Network","Ma, Liye and Krishnan, Ramayya and Montgomery, Alan L.","MANAGEMENT SCIENCE","61","2","454-473","2015","FEB","Social Network;Latent Homophily;Social Influence;Purchase Timing;Product Choice;Hierarchical Bayesian Model;Marketing","","Consumers who are close to one another in a social network often make similar purchase decisions. This similarity can result from latent homophily or social influence, as well as common exogenous factors. Latent homophily means consumers who are connected to one another are likely to have similar characteristics and product preferences. Social influence refers to the ability of one consumer to directly influence another consumer's decision based upon their communication. We present an empirical study of purchases of caller ring-back tones using data from an Asian mobile network that predicts consumers' purchase timing and choice decisions. We simultaneously measure latent homophily and social influence, while also accounting for exogenous factors. Identification is achieved due to our dynamic, panel data structure and the availability of detailed communication data. We find strong influence effects and latent homophily effects in both the purchase timing and product choice decisions of consumers."
1136,"Timing of Product Allocation: Using Probabilistic Selling to Enhance Inventory Management","Fay, Scott and Xie, Jinhong","MANAGEMENT SCIENCE","61","2","474-484","2015","FEB","Inventory Production;Uncertainty;Marketing;Retailing And Wholesaling;Pricing","","This paper examines probabilistic selling (PS) as an inventory-management mechanism, paying special attention to the impact of the timing of product assignment to buyers of probabilistic goods. In practice, sellers tend to offer probabilistic products only after major demand uncertainty has been resolved. By deferring product assignments, a firm is able to obtain more information about demand for each specific product before deciding which product to assign to consumers. However, our analysis demonstrates that PS can be an effective inventory-management mechanism even if the firm allocates products before knowing which product will be more popular and, thus, scarcer. Interestingly, we show that it can be more profitable for the firm to allocate products to consumers before, rather than after, learning the true demand for a product because, although early allocation imposes higher inventory costs (as a result of larger required inventory levels), it also enables the firm to charge higher prices. Our results also reveal that, when introducing probabilistic goods, the firm should order less inventory (relative to the case where probabilistic goods are not offered) if costs are very low but more inventory otherwise. Finally, we show that PS, as an inventory-management mechanism, can create a win-win situation, both improving profit and increasing social welfare."
1137,"The Asset-Pricing Implications of Government Economic Policy Uncertainty","Brogaard, Jonathan and Detzel, Andrew","MANAGEMENT SCIENCE","61","1","3-18","2015","JAN","Finance;Asset Pricing;Political Uncertainty;Government Policy","","Using the news-based measure of Baker et al. [Baker SR, Bloom N, Davis SJ (2013) Measuring economic policy uncertainty. Working paper, Stanford University, Stanford, CA] to capture economic policy uncertainty (EPU) in the United States, we find that EPU positively forecasts log excess market returns. An increase of one standard deviation in EPU is associated with a 1.5% increase in forecasted three-month abnormal returns (6.1% annualized). Furthermore, innovations in EPU earn a significant negative risk premium in the Fama-French 25 size-momentum portfolios. Among the Fama-French 25 portfolios formed on size and momentum returns, the portfolio with the greatest EPU beta underperforms the portfolio with the lowest EPU beta by 5.53% per annum, controlling for exposure to the Carhart four factors as well as implied and realized volatility. These findings suggest that EPU is an economically important risk factor for equities."
1138,"ICU Admission Control: An Empirical Study of Capacity Allocation and Its Implication for Patient Outcomes","Kim, Song-Hee and Chan, Carri W. and Olivares, Marcelo and Escobar, Gabriel","MANAGEMENT SCIENCE","61","1","19-38","2015","JAN","Healthcare Delivery;Empirical Operations Management;Dynamic Programming;Capacity Allocation;Admission Control;Congestion;Quality Of Service","","This work examines the process of admission to a hospital's intensive care unit (ICU). ICUs currently lack systematic admission criteria, largely because the impact of ICU admission on patient outcomes has not been well quantified. This makes evaluating the performance of candidate admission strategies difficult. Using a large patient-level data set of more than 190,000 hospitalizations across 15 hospitals, we first quantify the cost of denied ICU admission for a number of patient outcomes. We use hospital operational factors as instrumental variables to handle the endogeneity of the admission decisions and identify important specification issues that are required for this approach to be valid. Using the quantified cost estimates, we then provide a simulation framework for evaluating various admission strategies' performance. By simulating a hospital with 21 ICU beds, we find that we could save about $1.9 million per year by using an optimal policy based on observables designed to reduce readmissions and hospital length of stay. We also discuss the role of unobserved patient factors, which physicians may discretionarily account for when making admission decisions, and show that including these unobservables could result in a more than threefold increase in benefits compared to just optimizing the policy over the observable patient factors."
1139,"Waiting Patiently: An Empirical Study of Queue Abandonment in an Emergency Department","Batt, Robert J. and Terwiesch, Christian","MANAGEMENT SCIENCE","61","1","39-59","2015","JAN","Healthcare Operations;Service Operations;Empirical;Queues With Abandonment","","We study queue abandonment from a hospital emergency department. We show that abandonment is influenced by the queue length and the observable queue flows during the waiting exposure, even after controlling for wait time. For example, observing an additional person in the queue or an additional arrival to the queue leads to an increase in abandonment probability equivalent to a 25-minute or 5-minute increase in wait time, respectively. We also show that patients are sensitive to being jumped in the line and that patients respond differently to people more sick and less sick moving through the system. This customer response to visual queue elements is not currently accounted for in most queuing models. Additionally, to the extent the visual queue information is misleading or does not lead to the desired behavior, managers have an opportunity to intervene by altering what information is available to waiting customers."
1140,"Remanufacturing, Third-Party Competition, and Consumers' Perceived Value of New Products","Agrawal, Vishal V. and Atasu, Atalay and van Ittersum, Koert","MANAGEMENT SCIENCE","61","1","60-72","2015","JAN","Remanufacturing;Closed-Loop Supply Chains;Behavioral Operations;Competition","","In this paper, we investigate whether and how the presence of remanufactured products and the identity of the remanufacturer influence the perceived value of new products through a series of behavioral experiments. Our results demonstrate that the presence of products remanufactured and sold by the original equipment manufacturer (OEM) can reduce the perceived value of new products by up to 8%. However, the presence of thirdparty-remanufactured products can increase the perceived value of new products by up to 7%. These results suggest that deterring third-party competition via preemptive remanufacturing may reduce profits, whereas the presence of third-party competition may actually be beneficial for an OEM."
1141,"A Logarithmic Safety Staffing Rule for Contact Centers with Call Blending","Pang, Guodong and Perry, Ohad","MANAGEMENT SCIENCE","61","1","73-91","2015","JAN","Contact Centers;Call Blending;Safety Staffing;Threshold Controls;Many-Server Queues","","We consider large contact centers that handle two types of jobs-inbound and outbound-simultaneously, a process commonly referred to as call blending. Inbound work arrives to the system according to an exogenous arrival process, whereas outbound work is generated by the contact center. We assume that there is an infinite supply of outbound work to process, and that inbound calls are prioritized over the outbound calls. We propose a logarithmic safety staffing rule, combined with a threshold control policy, ensuring that agents' utilization is very close to one at all times, but that there are practically always idle agents present. Specifically, we prove that it is possible to have almost all inbound calls answered immediately upon their arrival, in addition to satisfying a target long-run throughput rate of outbound calls, with at most a negligible proportion of those calls dropped. Simulation experiments demonstrate the effectiveness and accuracy of our analysis."
1142,"Intertemporal Price Discrimination: Structure and Computation of Optimal Policies","Besbes, Omar and Lobel, Ilan","MANAGEMENT SCIENCE","61","1","92-110","2015","JAN","Pricing;Optimization;Intertemporal Pricing;Price Commitment;Price Discrimination;Dynamic Pricing;Strategic Customers;Stockpiling","","We study a firm's optimal pricing policy under commitment. The firm's objective is to maximize its long-term average revenue given a steady arrival of strategic customers. In particular, customers arrive over time, are strategic in timing their purchases, and are heterogeneous along two dimensions: their valuation for the firm's product and their willingness to wait before purchasing or leaving. The customers' patience and valuation may be correlated in an arbitrary fashion. For this general formulation, we prove that the firm may restrict attention to cyclic pricing policies, which have length, at most, twice the maximum willingness to wait of the customer population. To efficiently compute optimal policies, we develop a dynamic programming approach that uses a novel state space that is general, capable of handling arbitrary problem primitives, and that generalizes to finite horizon problems with nonstationary parameters. We analyze the class of monotone pricing policies and establish their suboptimality in general. Optimal policies are, in a typical scenario, characterized by nested sales, where the firm offers partial discounts throughout each cycle, offers a significant discount halfway through the cycle, and holds its largest discount at the end of the cycle. We further establish a form of equivalence between the problem of pricing for a stream of heterogeneous strategic customers and pricing for a pool of heterogeneous customers who may stockpile units of the product."
1143,"Decision Making Under Uncertainty When Preference Information Is Incomplete","Armbruster, Benjamin and Delage, Erick","MANAGEMENT SCIENCE","61","1","111-128","2015","JAN","Expected Utility;Robust Optimization;Stochastic Dominance;Certainty Equivalent","","We consider the problem of optimal decision making under uncertainty but assume that the decision maker's utility function is not completely known. Instead, we consider all the utilities that meet some criteria, such as preferring certain lotteries over other lotteries and being risk averse, S-shaped, or prudent. These criteria extend the ones used in the first- and second-order stochastic dominance framework. We then give tractable formulations for such decision-making problems. We formulate them as robust utility maximization problems, as optimization problems with stochastic dominance constraints, and as robust certainty equivalent maximization problems. We use a portfolio allocation problem to illustrate our results."
1144,"Corporate General Counsel and Financial Reporting Quality","Hopkins, Justin J. and Maydew, Edward L. and Venkatachalam, Mohan","MANAGEMENT SCIENCE","61","1","129-145","2015","JAN","Corporate Counsel;Financial Reporting;Accounting Quality;Earnings Management;Incentives","","We examine the role of general counsel (GC) in firms' financial reporting quality. GCs have a broad oversight role within the firm, including keeping the firm in compliance with laws and regulations and dealing with potential violations with respect to financial reporting. Several high-profile U.S. Securities and Exchange Commission (SEC) investigations have resulted in lawsuits or indictments against GCs for perpetrating financial fraud and caused many to ask: where were the gatekeepers? As such, we examine the conditions under which GCs may stray from their primary role as gatekeepers. Mainly, we empirically investigate claims that compensation can impair the independence or compromise the professional judgment of a GC. We measure the level of compensation using the GC's presence or absence in the top five officers of the firm by compensation. Results are consistent with GCs straying from their role as gatekeepers, to some extent, when highly compensated in a manner similar to the CEO and CFO. In particular, firms with highly compensated GCs have lower financial reporting quality and more aggressive accounting practices, including management of the litigation reserve. However, the results also show that highly compensated GCs play an important gatekeeping role in keeping the firm in compliance with generally accepted accounting principles. Thus, highly compensated GCs appear to tolerate moderately aggressive behavior but constrain it such that it would not result in violation of securities laws and jeopardize their standing within the firm."
1145,"Naivete, Projection Bias, and Habit Formation in Gym Attendance","Acland, Dan and Levy, Matthew R.","MANAGEMENT SCIENCE","61","1","146-160","2015","JAN","Behavioral Economics;Experimental Economics;Habit Formation;Present Bias;Projection Bias","","We implement a gym-attendance incentive intervention and elicit subjects' predictions of their postintervention attendance. We find that subjects greatly overpredict future attendance, which we interpret as evidence of partial naivete with respect to present bias. We find a significant postintervention attendance increase, which we interpret as habit formation, and which subjects appear not to predict ex ante. These results are consistent with a model of projection bias with respect to habit formation. Neither the intervention incentives, nor the small posttreatment incentives involved in our elicitation mechanism, appear to crowd out existing intrinsic motivation. The combination of naivete and projection bias in gym attendance can help to explain limited take-up of commitment devices by dynamically inconsistent agents, and points to new forms of contracts. Alternative explanations of our results are discussed."
1146,"Shopping for Information? Diversification and the Network of Industries","Anjos, Fernando and Fracassi, Cesare","MANAGEMENT SCIENCE","61","1","161-183","2015","JAN","Corporate Diversification;Networks;Innovation;Input-Output Tables","","We propose and test a view of corporate diversification as a strategy that exploits internal information markets, by bringing together information that is scattered across the economy. First, we construct an interindustry network using input-output data, to proxy for the economy's information structure. Second, we introduce a new measure of conglomerate informational advantage, named excess centrality, which captures how much more central conglomerates are relative to specialized firms operating in the same industries. We find that high-excess-centrality conglomerates have greater value, and produce more and better patents. Consistent with the internal-information-markets view, we also show that excess centrality has a greater effect in industries covered by fewer analysts and in industries where soft information is important."
1147,"Marketplace or Reseller?","Hagiu, Andrei and Wright, Julian","MANAGEMENT SCIENCE","61","1","184-203","2015","JAN","Intermediation;Multisided Platforms;Control Rights;Marketing","","Intermediaries can choose between functioning as a marketplace (in which suppliers sell their products directly to buyers) or as a reseller (by purchasing products from suppliers and selling them to buyers). We model this as a decision between whether control rights over a noncontractible decision variable (the choice of some marketing activity) are better held by suppliers (the marketplace mode) or by the intermediary (the reseller mode). Whether the marketplace or the reseller mode is preferred depends on whether independent suppliers or the intermediary have more important information relevant to the optimal tailoring of marketing activities for each specific product. We show that this trade-off is shifted toward the reseller mode when marketing activities create spillovers across products and when network effects lead to unfavorable expectations about supplier participation. If the reseller has a variable cost advantage (respectively, disadvantage) relative to the marketplace, then the trade-off is shifted toward the marketplace for long-tail (respectively, short-tail) products. We thus provide a theory of which products an intermediary should offer in each mode. We also provide some empirical evidence that supports our main results."
1148,"Vice-Virtue Bundles","Liu, Peggy J. and Haws, Kelly L. and Lamberton, Cait and Campbell, Troy H. and Fitzsimons, Gavan J.","MANAGEMENT SCIENCE","61","1","204-228","2015","JAN","Consumer Choice;Goal Pursuit;Bundles;Vices;Virtues;Self-Control;Health;Taste;Balancing Goals","","We introduce a simple solution to help consumers manage choices between healthy and unhealthy food options: vice-virtue bundles. Vice-virtue bundles are item aggregates with varying proportions of both vice and virtue, holding overall quantity constant. Four studies compare choice and perceptions of differently composed vice-virtue bundles relative to one another and to pure vice and pure virtue options. Although multiple consumer segments can be identified, results suggest that people overall tend to prefer vice-virtue bundles with small (1 4) to medium (12) proportions of vice rather than large (3 4) proportions of vice. Moreover, people generally rate vice-virtue bundles with small vice proportions as healthier but similarly tasty as bundles with larger vice proportions. For most individuals, choice patterns are different from those predicted by variety-seeking accounts alone. Instead, these findings provide evidence of asymmetric effectiveness of small vice and virtue proportions at addressing taste and health goals, respectively."
1149,"Competing with Privacy","Casadesus-Masanell, Ramon and Hervas-Drane, Andres","MANAGEMENT SCIENCE","61","1","229-246","2015","JAN","Information Acquisition;Information Disclosure;Online Privacy;Privacy Regulation","","We analyze the implications of consumer privacy for competition in the marketplace. Firms compete for consumer information and derive revenues both from consumer purchases as well as from disclosing consumer information in a secondary market. Consumers choose which firm to patronize and how much personal information to provide it with. We show that firms maximize profits by focusing on a single revenue source and competing at the extensive rather than the intensive margin, outperforming competitors by attracting a larger customer base. We also show that competition drives the provision of services with a low level of consumer information disclosure (high level of privacy), but higher competition intensity in the marketplace need not improve privacy when consumers exhibit low willingness to pay. Our findings are relevant to the business models of Internet firms and contribute to inform the regulatory debate on consumer privacy."
1150,"The Distinct Effects of Information Technology and Communication Technology on Firm Organization","Bloom, Nicholas and Garicano, Luis and Sadun, Raffaella and Van Reenen, John","MANAGEMENT SCIENCE","60","12","","2014","NOV","Organization;Delegation;Information Technology;Communication Technology;The Theory Of The Firm","","Guided by theories of management by exception, we study the impact of information and communication technology on worker and plant manager autonomy and span of control. The theory suggests that information technology is a decentralizing force, whereas communication technology is a centralizing force. Using a new data set of American and European manufacturing firms, we find indeed that better information technologies (enterprise resource planning (ERP) for plant managers and computer-assisted design/computer-assisted manufacturing for production workers) are associated with more autonomy and a wider span of control, whereas technologies that improve communication (like data intranets) decrease autonomy for workers and plant managers. Using instrumental variables (distance from ERP's place of origin and heterogeneous telecommunication costs arising from regulation) strengthens our results. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.2013."
1151,"Yield Optimization of Display Advertising with Ad Exchange","Balseiro, Santiago R. and Feldman, Jon and Mirrokni, Vahab and Muthukrishnan, S.","MANAGEMENT SCIENCE","60","12","2886-2907","2014","NOV","Dynamic Programming-Optimal Control;Internet Advertising;Revenue Management","","It is clear from the growing role of ad exchanges in the real-time sale of advertising slots that Web publishers are considering a new alternative to their more traditional reservation-based ad contracts. To make this choice, the publisher must trade off, in real-time, the short-term revenue from ad exchange with the long-term benefits of delivering good spots to the reservation ads. In this paper we formalize this combined optimization problem as a multiobjective stochastic control problem and derive an efficient policy for online ad allocation in settings with general joint distribution over placement quality and exchange prices. We prove the asymptotic optimality of this policy in terms of any arbitrary trade-off between the quality of delivered reservation ads and revenue from the exchange, and we show that our policy approximates any Pareto-optimal point on the quality-versus-revenue curve. Experimental results on data derived from real publisher inventory confirm that there are significant benefits for publishers if they jointly optimize over both channels. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.2017."
1152,"The Value of Operational Flexibility in the Presence of Input and Output Price Uncertainties with Oil Refining Applications","Dong, Lingxiu and Kouvelis, Panos and Wu, Xiaole","MANAGEMENT SCIENCE","60","12","2908-2926","2014","NOV","Operational Flexibility;Oil Refining;Petroleum Industry;Spot Markets;Stochastic Models","","Refining is indispensable to almost every natural-resource-based commodity industry. It involves a series of complex processes that transform inputs with a wide range of quality characteristics into refined finished products sold to end markets. In this paper, we take the perspective of a profit-maximizing refiner that considers upgrading its existing simple refinery to include intermediate-conversion flexibility, i.e., the capability of converting heavy intermediate components to light ones. We present a stylized two-stage stochastic programming model of a petroleum refinery to investigate the value drivers of conversion flexibility and the impact of input and output market conditions on its economic potential. Conversion flexibility adds value to refineries by either transforming a nonprofitable situation into a profitable one (referred to as purchase benefit) or improving profitability of an already profitable situation (referred to as unit revenue benefit). In a real-data-calibrated numerical study, we find the value of conversion flexibility (VoC) to be significant, accounting for 40% of the expected profit with conversion, and the purchase benefit and unit revenue benefit are equally important. Contrary to the intuition that, as a recourse action, conversion offers higher value for greater input price volatility, we find that VoC may decrease in input price volatility as a result of the differential impacts of increasing price volatility on the purchase benefit and the unit revenue benefit. Refineries also vary in their range flexibility, i.e., the ability to accommodate a narrow or wide range of inputs of different quality levels. Whether the range flexibility increases or decreases the value of conversion flexibility is affected by the direction in which the refinery expands its processing range and the heaviness of crude oils."
1153,"Buy-It-Now or Take-a-Chance: Price Discrimination Through Randomized Auctions","Celis, L. Elisa and Lewis, Gregory and Mobius, Markus and Nazerzadeh, Hamid","MANAGEMENT SCIENCE","60","12","2927-2948","2014","NOV","Online Advertising;Real-Time Bidding;Advertisement Exchange;Optimal Auctions","","Increasingly detailed consumer information makes sophisticated price discrimination possible. At fine levels of aggregation, demand may not obey standard regularity conditions. We propose a new randomized sales mechanism for such environments. Bidders can buy-it-now at a posted price, or take-a-chance in an auction where the top d > 1 bidders are equally likely to win. The randomized allocation incentivizes high-valuation bidders to buy-it-now. We analyze equilibrium behavior and apply our analysis to advertiser bidding data from Microsoft Advertising Exchange. In counterfactual simulations, our mechanism increases revenue by 4.4% and consumer surplus by 14.5% compared to an optimal second-price auction."
1154,"Mean Field Equilibria of Dynamic Auctions with Learning","Iyer, Krishnamurthy and Johari, Ramesh and Sundararajan, Mukund","MANAGEMENT SCIENCE","60","12","2949-2970","2014","NOV","Mean Field Equilibrium;Conjoint Valuation;Dynamic Auction Markets","","We study learning in a dynamic setting where identical copies of a good are sold over time through a sequence of second-price auctions. Each agent in the market has an unknown independent private valuation that determines the distribution of the reward she obtains from the good; for example, in sponsored search settings, advertisers may initially be unsure of the value of a click. Though the induced dynamic game is complex, we simplify analysis of the market using an approximation methodology known as mean field equilibrium (MFE). The methodology assumes that agents optimize only with respect to long-run average estimates of the distribution of other players' bids. We show a remarkable fact: In a mean field equilibrium, the agent has an optimal strategy where she bids truthfully according to a conjoint valuation. The conjoint valuation is the sum of her current expected valuation, together with an overbid amount that is exactly the expected marginal benefit of one additional observation about her true private valuation. Under mild conditions on the model, we show that an MFE exists, and that it is a good approximation to a rational agent's behavior as the number of agents increases. Formally, if every agent except one follows the MFE strategy, then the remaining agent's loss on playing the MFE strategy converges to zero as the number of agents in the market increases. We conclude by discussing the implications of the auction format and design on the auctioneer's revenue. In particular, we establish the revenue equivalence of standard auctions in dynamic mean field settings, and discuss optimal selection of reserve prices in dynamic auctions."
1155,"Capital Structure, Product Market Dynamics, and the Boundaries of the Firm","Hackbarth, Dirk and Mathews, Richmond and Robinson, David","MANAGEMENT SCIENCE","60","12","2971-2993","2014","NOV","Capital Structure;Corporate Investment;Organizational Design;Real Options","","We model a new product market opportunity as an option and ask whether it is best exploited by a large incumbent firm (integration) or by a small separate firm (nonintegration). Starting from a standard framework, in which value-maximizing investment and financing decisions are jointly determined, we show that integration protects assets in place value, whereas nonintegration protects option value and maximizes financial flexibility. We show that increases in standard measures of cash flow risk predict exploitation of new opportunities by specialized firms, whereas increases in product market competition (e. g., the risk of competitive preemption) predict exploitation by incumbents. We also show that alliances organized as licensing agreements or revenue-sharing contracts sometimes better balance the sources of value and thus may dominate more traditional forms of organization. These organizational equilibria arise from the dynamic interaction of the new opportunity's option-like features with realistic competitive forces."
1156,"What Death Can Tell: Are Executives Paid for Their Contributions to Firm Value?","Bang Dang Nguyen and Nielsen, Kasper Meisner","MANAGEMENT SCIENCE","60","12","2994-3010","2014","NOV","Executive Compensation;Managerial Ability;Sudden Death;Corporate Governance;Value Of Top Executive","","Using stock price reactions to sudden deaths of top executives as a measure of expected contribution to shareholder value, we examine the relationship between executive pay and managerial contribution to shareholder value. We find, first, that the managerial labor market is characterized by positive sorting: managers with high perceived contributions to shareholder value obtain higher pay. The executive pay-contribution relationship is stronger for professional executives and for executives with high compensation. We estimate, second, that an average top executive (chief executive officer) appears to retain 71% (65%) of the marginal rent from the firm-manager relationship. We examine, third, how the executive pay-contribution relationship varies with individual, firm, and industry characteristics. Overall, our results are informative for the ongoing discussion about the level of executive compensation."
1157,"Bargaining Ability and Competitive Advantage: Empirical Evidence from Medical Devices","Grennan, Matthew","MANAGEMENT SCIENCE","60","12","3011-3025","2014","NOV","Economics;Game Theory;Bargaining Theory;Healthcare;Industrial Organization;Market Structure;Firm Strategy;Market Performance;Microeconomics;Market Pricing","","In markets where buyers and suppliers negotiate, supplier costs, buyer willingness to pay, and competition determine only a range of potential prices, leaving the final price dependent on other factors (e. g., negotiating skill), which I call bargaining ability. I use a model of buyer demand and buyer-supplier bargaining, combined with detailed data on prices and quantities at the buyer-supplier relationship level, to estimate firm-bargaining abilities in the context of the coronary stent industry where different hospitals (buyers) pay different prices for the exact same product from the same supplier. I estimate that (1) variation in bargaining abilities explains 79% of this price variation, (2) bargaining ability has a large firm-specific component, and (3) changes in the distribution of bargaining abilities over time suggest learning as an important channel influencing bargaining ability. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.2006."
1158,"Emergent Life Cycle: The Tension Between Knowledge Change and Knowledge Retention in Open Online Coproduction Communities","Kane, Gerald C. and Johnson, Jeremiah and Majchrzak, Ann","MANAGEMENT SCIENCE","60","12","3026-3048","2014","NOV","Online Communities;Peer Production;Knowledge Creation;Social Media;Wiki;Longitudinal","","Online coproduction communities often face a challenge of whether to change or retain the knowledge they have created. Disparate and often conflicting theoretical models have been used to explain how these communities respond to this tension. We conducted a case study of how one online coproduction community-the nine-year history of the Wikipedia article on autism-handles this tension. We find that the nature of the change-retain tension and the community's response to it fluctuates considerably over the life of the community. These changes bear striking similarities to processes associated with traditional software development life cycles, despite the absence of traditional control mechanisms. What initially appear to be conflicts in the extant literature actually describe different roles and production focus at the different stages of development. Disruptive events signal the need for the community to shift production focus, which often involves members joining and leaving the production process, rather than adopting new roles."
1159,"Improving Penetration Forecasts Using Social Interactions Data","Toubia, Olivier and Goldenberg, Jacob and Garcia, Rosanna","MANAGEMENT SCIENCE","60","12","3049-3066","2014","NOV","Forecasting;Marketing;New Products;Probability;Diffusion","","We propose an approach for using individual-level data on social interactions (e. g., number of recommendations received by consumers, number of recommendations given by adopters, number of social ties) to improve the aggregate penetration forecasts made by extant diffusion models. We capture social interactions through an individual-level hazard rate in such a way that the resulting aggregate penetration process is available in closed form and nests extant diffusion models. The parameters of the model may be estimated by combining early aggregate penetration data with social interactions data collected from a sample of consumers in as few as one time period. We illustrate our approach by applying it to the mixed influence model (Bass model) and the more recent asymmetric influence model. A field study conducted in collaboration with a consumer packaged goods company and a marketing research company confirms that incorporating social interactions data using the proposed approach has the potential to result in improved aggregate penetration forecasts in managerially relevant settings."
1160,"When to Sell Your Idea: Theory and Evidence from the Movie Industry","Luo, Hong","MANAGEMENT SCIENCE","60","12","3067-3086","2014","NOV","Market For Ideas;Asymmetry Information;Expropriation Risk;Intermediary;Intellectual Property Protection","","I study a model of investment and sale of ideas and test its empirical implications using a novel data set from the market for original movie ideas. Consistent with the theoretical results, I find that buyers are reluctant to meet unproven sellers for early-stage ideas, which restricts sellers to either developing the ideas fully (to sell them later) or abandoning them. In contrast, experienced sellers can attract buyers at any stage, and they sell worse ideas sooner and better ideas later. These results have important managerial implications for buyers and sellers and show that, in such contexts, policy interventions that discourage buyer participation-such as stronger intellectual property protection-may diminish the market for ideas and hurt inexperienced sellers."
1161,"Selecting the Best? Spillover and Shadows in Elimination Tournaments","Brown, Jennifer and Minor, Dylan B.","MANAGEMENT SCIENCE","60","12","3087-3102","2014","NOV","Elimination Tournament;Dynamic Contest;Contest Design;Effort Choice;Betting Markets","","We consider how past, current, and future competition within an elimination tournament affect the probability that the stronger player wins. We present a two-stage model that yields the following main results: (1) a shadow effect wherein the stronger the expected future competitor, the lower the probability that the stronger player wins in the current stage; and (2) an effort spillover effect wherein previous effort reduces the probability that the stronger player wins in the current stage. We test our theory predictions using data from high-stakes tournaments. Empirical results suggest that shadow and spillover effects influence match outcomes and have already been priced into betting markets."
1162,"Dynamic Commercialization Strategies for Disruptive Technologies: Evidence from the Speech Recognition Industry","Marx, Matt and Gans, Joshua S. and Hsu, David H.","MANAGEMENT SCIENCE","60","12","3103-3123","2014","NOV","Technology Commercialization Strategy;Disruptive Innovation","","When start-up innovation involves a potentially disruptive technology-initially lagging in the predominant performance metric, but with a potentially favorable trajectory of improvement-incumbents may be wary of engaging in cooperative commercialization with the start-up. While the prevailing theory of disruptive innovation suggests that this will lead to (exclusively) competitive commercialization and the eventual replacement of incumbents, we consider a dynamic strategy involving product market entry before switching to a cooperative commercialization strategy. Empirical evidence from the automated speech recognition industry from 1952 to 2010 confirms our main hypothesis."
1163,"Seeing Stars: Matthew Effects and Status Bias in Major League Baseball Umpiring","Kim, Jerry W. and King, Brayden G.","MANAGEMENT SCIENCE","60","11","2619-2644","2014","NOV","Status;Bias;Organizational Studies;Decision Making","","This paper tests the assumption that evaluators are biased to positively evaluate high-status individuals, irrespective of quality. Using unique data from Major League Baseball umpires' evaluation of pitch quality, which allow us to observe the difference in a pitch's objective quality and in its perceived quality as judged by the umpire, we show that umpires are more likely to overrecognize quality by expanding the strike zone, and less likely to underrecognize quality by missing pitches in the strike zone for high-status pitchers. Ambiguity and the pitcher's reputation as a control pitcher moderate the effect of status on umpire judgment. Furthermore, we show that umpire errors resulting from status bias lead to actual performance differences for the pitcher and team."
1164,"Conscience Accounting: Emotion Dynamics and Social Behavior","Gneezy, Uri and Imas, Alex and Madarasz, Kristof","MANAGEMENT SCIENCE","60","11","2645-2658","2014","NOV","Emotion Dynamics;Bracketing;Social Norms;Moral Constraints;Prosocial Behavior","","This paper presents theory and experiments where people's prosocial attitudes fluctuate over time following the violation of an internalized norm. We report the results of two experiments in which people who first made an immoral choice were then more likely to donate to charity than those who did not. In addition, those who knew that a donation opportunity would follow the potentially immoral choice behaved more unethically than those who did not know. We interpret this increase in charitable behavior as being driven by a temporal increase in guilt induced by past immoral actions. We term such behavior conscience accounting and discuss its importance in charitable giving and in the identification of social norms in choice behavior through time inconsistency."
1165,"Strategic Ignorance and the Robustness of Social Preferences","Grossman, Zachary","MANAGEMENT SCIENCE","60","11","2659-2665","2014","NOV","Social Preferences;Strategic Ignorance;Moral Wiggle Room;Default Effects;Status Quo Bias;Self-Deception;Self-Signaling;Dictator Games","","Participants in dictator games frequently avoid learning whether their choice to maximize their own earnings will help or hurt the recipient and then choose selfishly, exploiting the moral wiggle room provided by their ignorance. However, this is found in an environment in which the dictator must actively learn the true payoffs, so inaction means ignorance. Does this effect persist when one must actively choose either to be ignorant or to be informed or when one must actively choose to remain ignorant? In fact, whereas 45% of dictators remain ignorant when one must click to become informed, this drops to 25% when one must click in either case and to 3% when one must click to remain ignorant. Although the exploitation of moral wiggle room is not merely an artifact, it is, much like social behavior itself, subject to environmental and psychological factors that may reinforce or undermine its impact."
1166,"Push, Pull, or Both? A Behavioral Study of How the Allocation of Inventory Risk Affects Channel Efficiency","Davis, Andrew M. and Katok, Elena and Santamaria, Natalia","MANAGEMENT SCIENCE","60","11","2666-2683","2014","NOV","Behavioral Operations Management;Inventory Risk Allocation;Supply Chain Contracts","","In this paper we experimentally investigate how the allocation of inventory risk in a two-stage supply chain affects channel efficiency and profit distribution. We first evaluate two common wholesale price contracts that differ in which party incurs the risk associated with unsold inventory: a push contract in which the retailer incurs the risk and a pull contract in which the supplier incurs the risk. Our experimental results show that a pull contract achieves higher channel efficiency than that of a push contract, and that behavior systematically deviates from the standard theory in three ways: (1) stocking quantities are set too low, (2) wholesale prices are more favorable to the party stocking the inventory, and (3) some contracts are erroneously accepted or rejected. To account for these systematic regularities, we extend the existing theory and structurally estimate a number of behavioral models. The estimates suggest that a combination of loss aversion with errors organizes our data remarkably well. We apply our behavioral model to the advance purchase discount (APD) contract, which combines features of push and pull by allowing both parties to share the inventory risk, in a separate experiment as an out-of-sample test, and we find that it accurately predicts channel efficiency and qualitatively matches decisions. Two practical implications of our work are that (1) the push contract performs close to standard theoretical benchmarks, which implies that it is robust to behavioral biases, and (2) the APD contract weakly Pareto dominates the push contract; retailers are better off and suppliers are no worse off under the APD contract."
1167,"Efficiency Analysis of Cournot Competition in Service Industries with Congestion","Perakis, Georgia and Sun, Wei","MANAGEMENT SCIENCE","60","11","2684-2700","2014","NOV","Efficiency Analysis;Price Of Anarchy;Congestion;Convex Costs;Service Industries","","We consider Cournot competition in the presence of congestion effects. Our model consists of several service providers with differentiated services, each competing for users who are sensitive to both price and congestion. We distinguish two types of congestion effects, depending on whether spillover costs exist, that is, where one service provider's congestion cost increases with the other providers' output level. We quantify the efficiency of an unregulated oligopoly with respect to the optimal social welfare with tight upper and lower bounds. We show that, when there is no spillover, the welfare loss in an unregulated oligopoly is limited to 25% of the social optimum, even in the presence of highly convex costs. On the other hand, when spillover cost is present, there does not exist a constant lower bound on the efficiency of an unregulated oligopoly, even with affine cost. We show that the efficiency depends on the relative magnitude between the marginal spillover cost and the marginal benefit to consumers."
1168,"The Assortment Packing Problem: Multiperiod Assortment Planning for Short-Lived Products","Caro, Felipe and Martinez-de-Albeniz, Victor and Rusmevichientong, Paat","MANAGEMENT SCIENCE","60","11","2701-2721","2014","NOV","Analysis Of Algorithms;Suboptimal Algorithms;Marketing;Product Policy;Fractional Programming;Attraction Model;Assortment Optimization","","Motivated by retailers' frequent introduction of new items to refresh product lines and maintain their market shares, we present the assortment packing problem in which a firm must decide, in advance, the release date of each product in a given collection over a selling season. Our formulation models the trade-offs among profit margins, preference weights, and limited life cycles. A key aspect of the problem is that each product is short-lived in the sense that, once introduced, its attractiveness lasts only a few periods and vanishes over time. The objective is to determine when to introduce each product to maximize the total profit over the selling season. Even for two periods, the corresponding optimization problem is shown to be NP-complete. As a result, we study a continuous relaxation of the problem that approximates the problem well, when the number of products is large. When margins are identical and product preferences decay exponentially, its solution can be characterized: it is optimal to introduce products with slower decays earlier. The structural properties of the relaxation also help us to develop several heuristics, for which we establish performance guarantees. We test our heuristics with data on sales and release dates of women's handbags from an accessories retailer. The numerical experiments show that the heuristics perform very well and can yield significant improvements in profitability."
1169,"Do Relationships Matter? Evidence from Loan Officer Turnover","Drexler, Alejandro and Schoar, Antoinette","MANAGEMENT SCIENCE","60","11","2722-2736","2014","NOV","Information;Incentives;Corporate Finance;Banking;Intermediation;Organizational Studies;Performance","","We show that the cost of employee turnover in firms that rely on decentralized knowledge and personal relationships depends on the firms' planning horizons and the departing employees' incentives to transfer information. Using exogenous shocks to the relationship between borrowers and loan officers, we document that borrowers whose loan officers are on leave are less likely to receive new loans from the bank, are more likely to apply for credit from other banks, and are more likely to miss payments or go into default. These costs are smaller when turnover is expected, as in the case of maternity leave, or when loan officers have incentives to transfer information, as in the case of voluntary resignations."
1170,"Portfolio Choice with Illiquid Assets","Ang, Andrew and Papanikolaou, Dimitris and Westerfield, Mark M.","MANAGEMENT SCIENCE","60","11","2737-2761","2014","NOV","Asset Allocation;Liquidity;Alternative Assets;Liquidity Crises","","We present a model of optimal allocation to liquid and illiquid assets, where illiquidity risk results from the restriction that an asset cannot be traded for intervals of uncertain duration. Illiquidity risk leads to increased and state-dependent risk aversion and reduces the allocation to both liquid and illiquid risky assets. Uncertainty about the length of the illiquidity interval, as opposed to a deterministic nontrading interval, is a primary determinant of the cost of illiquidity. We allow market liquidity to vary from normal periods, when all assets are fully liquid, to illiquidity crises, when some assets can only be traded infrequently. The possibility of a liquidity crisis leads to limited arbitrage in normal times. Investors are willing to forgo 2% of their wealth to hedge against illiquidity crises occurring once every 10 years."
1171,"Rational Information Leakage","Indjejikian, Raffi and Lu, Hai and Yang, Liyan","MANAGEMENT SCIENCE","60","11","2762-2775","2014","NOV","Information Leakage;Insider Trading;Securities Regulations","","Empirical evidence suggests that information leakage in capital markets is common. We present a trading model to study the incentives of an informed trader (e. g., a well-informed insider) to voluntarily leak information about an asset's value to one or more independent traders. Our model shows that, although leaking information dissipates the insider's information advantage about the asset's value, it enhances his information advantage about the asset's execution price relative to other informed traders. The profit impact of these two effects are countervailing. When there are a sufficient number of other informed traders, the profit impact from enhanced information dominates. Hence, the insider has incentives to leak some of his private information. We label this rational information leakage and discuss its implications for the regulation of insider trading."
1172,"Do Parents Matter? Effects of Lender Affiliation Through the Mortgage Boom and Bust","Gartenberg, Claudine","MANAGEMENT SCIENCE","60","11","2776-2793","2014","NOV","Corporate Finance;Financial Institutions;Banks;Organization Studies;Strategy;Real Estate","","It is widely acknowledged that the 2007 mortgage crisis was preceded by a broad deterioration in underwriting diligence. This paper shows that this deterioration varied by the industry affiliation of mortgage lenders. Loans issued by homebuilders and stand-alone lenders were significantly less likely to default than loans issued by depository banks and affiliates of major financial institutions. I argue that homebuilders and stand-alone lenders had the least financial capacity to hold mortgages, and their resulting need to sell loans quickly on the secondary market forced them to issue safer loans. Tests of other explanations, including differences in information and incentives to avoid foreclosure externalities, receive little support. This study highlights a novel means by which firm boundaries influence firm adaptation to changing market conditions by defining the boundaries of the internal capital markets and hence the relative constraints of constituent units."
1173,"Positioning on a Multiattribute Landscape","Adner, Ron and Csaszar, Felipe A. and Zemsky, Peter B.","MANAGEMENT SCIENCE","60","11","2794-2815","2014","NOV","Competitive Positioning;Trade-Offs;Value-Based Strategy;Nk Landscape","","Competitive positioning is a central, yet understudied, topic in strategy. Understanding positioning requires understanding two distinct mappings: how underlying policies are transformed into positions, and how positions are transformed into market performance. A complete treatment of positioning requires incorporating organizational design in the presence of policy interdependence; consumer choice in the presence of trade-offs among multiple product attributes; and competitive interactions among firms. We develop a model that integrates these elements. We show that in a multiattribute setting, trade-offs have critical, nonmonotonic effects on a range of strategy questions including the relationship between positions that are operationally efficient and those that remain viable in the face of competition as well as the concentration of market share in the industry. Of particular interest are implications for firm heterogeneity. We show that increases in business policy interdependence can decrease positioning heterogeneity among firms in an industry, depending on the nature of trade-offs. We also show that the relationship between strategy heterogeneity and positioning heterogeneity is moderated by the extent of policy interdependence."
1174,"Price Advertising by Manufacturers and Dealers","Xu, Linli and Wilbur, Kenneth C. and Siddarth, S. and Silva-Risso, Jorge M.","MANAGEMENT SCIENCE","60","11","2816-2834","2014","NOV","Advertising;Automobiles;Channels;Choice Modeling;Demand Estimation","","The central prediction of the current paper is that manufacturer price advertising may be a less effective tool for influencing demand than retailer price advertising. We manipulate the source of a price advertisement in an experiment run on a sample of pickup truck owners. Manufacturer price advertising leads to lower indicators of potential demand than dealer price advertising, even among consumers who are experienced with the brand. An econometric analysis of pickup truck sales, price, and advertising data shows that this effect is large enough to detect in market data. Manufacturer and dealer price advertising both increase the demand intercept and the responsiveness of demand to price, but the effects of dealer price advertising are larger. Although dealer price advertising is more effective than manufacturer price advertising, manufacturer price advertising may still be useful to reduce channel conflict."
1175,"The Impact of Corporate Sustainability on Organizational Processes and Performance","Eccles, Robert G. and Ioannou, Ioannis and Serafeim, George","MANAGEMENT SCIENCE","60","11","2835-2857","2014","NOV","Organizational Studies;Strategy;Effectiveness Performance;Behavior;Sustainability","","We investigate the effect of corporate sustainability on organizational processes and performance. Using a matched sample of 180 U. S. companies, we find that corporations that voluntarily adopted sustainability policies by 1993-termed as high sustainability companies-exhibit by 2009 distinct organizational processes compared to a matched sample of companies that adopted almost none of these policies-termed as low sustainability companies. The boards of directors of high sustainability companies are more likely to be formally responsible for sustainability, and top executive compensation incentives are more likely to be a function of sustainability metrics. High sustainability companies are more likely to have established processes for stakeholder engagement, to be more long-term oriented, and to exhibit higher measurement and disclosure of nonfinancial information. Finally, high sustainability companies significantly outperform their counterparts over the long term, both in terms of stock market and accounting performance."
1176,"Counterfeiters: Foes or Friends? How Counterfeits Affect Sales by Product Quality Tier","Qian, Yi","MANAGEMENT SCIENCE","60","10","2381-2400","2014","OCT","Counterfeit;Intellectual Property Rights;China;Fashion","","A key concern about counterfeits and weak intellectual property protection is that they may hamper innovation by displacing legitimate sales. This paper combines a natural policy experiment with randomized lab experiments to estimate the heterogeneous impacts of counterfeiting on the sales and consumer purchase intent related to branded products of various quality levels. I collect new product-line-level panel data (1993-2004) on Chinese shoe companies. I identify heterogeneous effects of counterfeit entry on sales of authentic products of three quality tiers, finding that counterfeits have both advertising effects for a brand and substitution effects for authentic products, additionally the effects linger for some years. The advertising effect dominates the substitution effect for high-end authentic product sales, and the substitution effect outweighs the advertising effect for low-end product sales. The positive effect of counterfeits is most pronounced for high-fashion products (such as women's high-leg boots and dress shoes), shoes tailored to young customers, and high-end products of brands not yet well-known at the time of counterfeiter entry."
1177,"A Demand Estimation Procedure for Retail Assortment Optimization with Results from Implementations","Fisher, Marshall and Vaidyanathan, Ramnath","MANAGEMENT SCIENCE","60","10","2401-2415","2014","OCT","Assortment Planning;Retailer Operations;Statistics;Estimation","","We consider the problem of choosing, from a set of N potential stock-keeping units (SKUs) in a retail category, K SKUs to be carried at each store to maximize revenue or profit. Assortments can vary by store, subject to a maximum number of different assortments. We view a SKU as a set of attribute levels and also model possible substitutions when a customer's first choice is not in the assortment. We apply maximum likelihood estimation to sales history of the SKUs currently carried by the retailer to estimate the demand for attribute levels and substitution probabilities, and from this, the demand for any potential SKU, including those not currently carried by the retailer. We specify several alternative heuristics for choosing SKUs to be carried in an assortment. We apply this approach to optimize assortments for three real examples: snack cakes, tires, and automotive appearance chemicals. A portion of our recommendations for tires and appearance chemicals were implemented and produced sales increases of 5.8% and 3.6%, respectively, which are significant improvements relative to typical retailer annual comparable store revenue increases. We also forecast sales shares of 1, 11, and 25 new SKUs for the snack cake, tire, and automotive appearance chemical applications, respectively, with mean absolute percentage errors (MAPEs) of 16.2%, 19.1%, and 28.7%, which compares favorably to the 30.7% MAPE for chain sales of two new SKUs reported by Fader and Hardie (1996)."
1178,"Does Inventory Productivity Predict Future Stock Returns? A Retailing Industry Perspective","Alan, Yasin and Gao, George P. and Gaur, Vishal","MANAGEMENT SCIENCE","60","10","2416-2434","2014","OCT","Operations-Finance Interface;Retail Operations;Inventory Productivity;Empirical Asset Pricing","","We find that inventory productivity strongly predicts future stock returns among a sample of publicly listed U. S. retailers during the period from 1985 to 2010. A zero-cost portfolio investment strategy, which consists of buying from the two highest and selling from the two lowest quintiles formed on inventory turnover, earns more than 1% average monthly abnormal return benchmarked to the Fama-French-Carhart four-factor model. Our results are robust to different measures of inventory productivity, distinct from the well-known firm characteristics known to generate abnormal returns, and not driven by a particular subsample period. A longitudinal analysis of portfolio returns over longer holding periods shows that although inventory productivity is predictive of stock returns, its information dissipates about one to two years after release."
1179,"Trust, Trustworthiness, and Information Sharing in Supply Chains Bridging China and the United States","Oezer, Oezalp and Zheng, Yanchong and Ren, Yufei","MANAGEMENT SCIENCE","60","10","2435-2460","2014","OCT","Trust;Trustworthiness;Collectivism;Individualism;Western Stereotypes;Guanxi;China;Forecast Information;Behavioral Economics;Experimental Economics","","Whether and how trust and trustworthiness differ between a collectivist society, e. g., China, and an individualistic one, e. g., the United States, generates much ongoing scientific debate and bears significant practical values for managing cross-country transactions. We experimentally investigate how supply chain members' countries of origin-China versus the United States-affect trust, trustworthiness, and strategic information sharing behavior in a cross-country supply chain. We consider a two-tier supply chain in which the upstream supplier solicits demand forecast information from the retailer to plan production; but the retailer has an incentive to manipulate her forecast to ensure abundant supply. The levels of trust and trustworthiness in the supply chain and supplier's capability to determine the optimal production quantity affect the efficacy of forecast sharing and the resulting profits. We develop an experimental design to disentangle these three aspects and to allow for real-time interactions between geographically distant and culturally heterogeneous participants. We observe that, when there is no prospect for long-term interactions, our Chinese participants consistently exhibit lower spontaneous trust and trustworthiness than their U. S. counterparts do. We quantify the differences in trust and trustworthiness between the two countries, and the resulting impact on supply chain efficiency. We also show that Chinese individuals exhibit higher spontaneous trust toward U. S. partners than Chinese ones, primarily because they perceive that individuals from the United States are more trusting and trustworthy in general. This positive perception toward U. S. people is indeed consistent with the U. S. participants' behavior in forecast sharing. In addition, we quantify that a Chinese supply chain enjoys a larger efficiency gain from repeated interactions than a U. S. one does, as the prospect of building a long-term relationship successfully sustains trust and trustworthiness by Chinese partners. We advocate that companies can reinforce the positive perception of westerners held by the Chinese population and commit to long-term relationships to encourage trust by Chinese partners. Finally, we also observe that both populations exhibit similar pull-to-center bias when solving a decision problem under uncertainty (i.e., the newsvendor problem). Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1905."
1180,"Subsidizing the Distribution Channel: Donor Funding to Improve the Availability of Malaria Drugs","Taylor, Terry A. and Xiao, Wenqiang","MANAGEMENT SCIENCE","60","10","2461-2477","2014","OCT","Global Health Supply Chains;Developing Country Supply Chains;Subsidies","","In countries that bear the heaviest burden of malaria, most patients seek medicine for the disease in the private sector. Because the availability and affordability of recommended malaria drugs provided by the private-sector distribution channel is poor, donors (e. g., the Global Fund) are devoting substantial resources to fund subsidies that encourage the channel to improve access to these drugs. A key question for a donor is whether it should subsidize the purchases and/or the sales of the private-sector distribution channel. We show that the donor should only subsidize purchases and should not subsidize sales. We characterize the robustness of this result to four key assumptions: the product's shelf life is long, the retailer has flexibility in setting the price, the retailer is the only level in the distribution channel, and retailers are homogeneous."
1181,"Turnover: Liquidity or Uncertainty?","Barinov, Alexander","MANAGEMENT SCIENCE","60","10","2478-2495","2014","OCT","Liquidity;Idiosyncratic Volatility;Uncertainty;Turnover;Aggregate Volatility Risk","","I show that turnover is unrelated to several alternative measures of liquidity risk and in most cases negatively, not positively, related to liquidity. Consequently, neither liquidity nor liquidity risk explains why higher turnover predicts lower future returns. I find that the aggregate volatility risk factor explains why higher turnover predicts lower future returns. This paper shows that the negative relation between turnover and future returns is stronger for firms with option-like equity, and this regularity is also explained by the aggregate volatility risk factor."
1182,"Marriage and Managers' Attitudes to Risk","Roussanov, Nikolai and Savor, Pavel","MANAGEMENT SCIENCE","60","10","2496-2508","2014","OCT","Marriage;Risk;Ceo;Investment;Volatility;Divorce","","Marital status can both reflect and affect individual preferences. We explore the impact of marriage on corporate chief executive officers (CEOs) and find that firms run by single CEOs exhibit higher stock return volatility, pursue more aggressive investment policies, and do not respond to changes in idiosyncratic risk. These effects are weaker for older CEOs. Our findings continue to hold when we use variation in divorce laws across states to instrument for CEO marital status, which supports the hypothesis that marriage itself drives choices rather than it just reflecting innate heterogeneity in preferences. We explore various potential explanations for why single CEOs may be less risk averse. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1926."
1183,"Information Aggregation and Allocative Efficiency in Smooth Markets","Iyer, Krishnamurthy and Johari, Ramesh and Moallemi, Ciamac C.","MANAGEMENT SCIENCE","60","10","2509-2524","2014","OCT","Information Aggregation;Perfect Bayesian Equilibrium;Risk Aversion","","Recent years have seen extensive investigation of the information aggregation properties of markets. However, relatively little is known about conditions under which a market will aggregate the private information of rational risk-averse traders who optimize their portfolios over time; in particular, what features of a market encourage traders to ultimately reveal their private information through trades? We consider a market model involving finitely many informed risk-averse traders interacting with a market maker. Our main result identifies a basic asymptotic smoothness condition on prices in the market that ensures information is aggregated as long as portfolios converge; furthermore, under this assumption, the allocation achieved is ex post Pareto efficient. Asymptotic smoothness is fairly mild: it requires that, eventually, infinitesimal purchases or sales should see the same per-unit price. Notably, we demonstrate that, under some mild conditions, algorithmic markets based on cost functions (or, equivalently, markets based on market scoring rules) aggregate the information of traders."
1184,"Sequential Search and Learning from Rank Feedback: Theory and Experimental Evidence","Palley, Asa B. and Kremer, Mirko","MANAGEMENT SCIENCE","60","10","2525-2542","2014","OCT","Sequential Search;Optimal Stopping;Behavioral Decision Making;Secretary Problem","","T his paper studies the effect of limited information in a sequential search setting where a single selection is to be made from a set of random potential options. We consider both a full-information problem, where the decision maker observes the exact value of each option as she searches, and a partial-information problem, in which the decision maker only learns the rank of the current option relative to the options that have already been observed. We develop a model that allows for a sharp contrast between search behavior in the two information settings, both theoretically and empirically. We present the results of an experiment that tests, and supports, the key prediction of our model analysis-limited information induces longer search. Our data further suggest systematic deviations from the theoretical benchmarks in both informational settings. Importantly, subjects in our partial-information conditions are prone to stop prematurely during early stages of the search process and to suboptimally continue the search during late stages. We propose a simple model that succinctly captures the interplay of two symmetric choice and judgment biases that have asymmetric (but opposing) effects on the length of search. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1902."
1185,"Electronic Medical Records and Physician Productivity: Evidence from Panel Data Analysis","Bhargava, Hemant K. and Mishra, Abhay Nath","MANAGEMENT SCIENCE","60","10","2543-2562","2014","OCT","Arellano-Bond Gmm Estimation;Dynamic Panel Model;Electronic Medical Records;Emr;Emr Productivity;Health Informatics;It Productivity;Physician Learning;Physician Productivity;Task-Technology Fit;Work Relative Value Units","","This paper studies the impact of an electronic medical record (EMR) system on the productivity of physicians. Physicians influence a vast majority of treatment decisions and are central to the care delivery process; thus, it is important to understand how EMRs may impact the nature of their work. Our research builds on prior literature on physician productivity, IT productivity, and task-technology fit theory. We use a unique panel data set comprising 87 physicians specializing in internal medicine, pediatrics, and family practice, located in 12 primary care clinics of an academic healthcare system in the western United States. We employ the Arellano-Bond system generalized method of moments estimation technique on our data set, which contains 3,186 physician-month productivity observations collected over 39 months. We find that productivity drops sharply immediately after technology implementation and recovers partly over the next few months. The ultimate, longer-term impact depends on physician specialty. The net impact of the EMR system is more benign on internal medicine physicians than on pediatricians and family practitioners. We postulate that the fit provided by an EMR system to the task requirements of physicians of various specialties may be key to disentangling the productivity dynamics. Our research finds that on one hand, present-day EMR systems do not produce the kind of productivity gain that could lead to substantial savings in healthcare; at the same time, EMRs do not cause a major productivity loss on a sustained basis, as many physicians fear."
1186,"The Fresh Start Effect: Temporal Landmarks Motivate Aspirational Behavior","Dai, Hengchen and Milkman, Katherine L. and Riis, Jason","MANAGEMENT SCIENCE","60","10","2563-2582","2014","OCT","Goals;Motivation;Self-Control;Temporal Landmarks;Mental Accounting","","The popularity of New Year's resolutions suggests that people are more likely to tackle their goals immediately following salient temporal landmarks. If true, this little-researched phenomenon has the potential to help people overcome important willpower problems that often limit goal attainment. Across three archival field studies, we provide evidence of a fresh start effect. We show that Google searches for the term diet (Study 1), gym visits (Study 2), and commitments to pursue goals (Study 3) all increase following temporal landmarks (e. g., the outset of a new week, month, year, or semester; a birthday; a holiday). We propose that these landmarks demarcate the passage of time, creating many new mental accounting periods each year, which relegate past imperfections to a previous period, induce people to take a big-picture view of their lives, and thus motivate aspirational behaviors. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1901."
1187,"Constrained Assortment Optimization for the Nested Logit Model","Gallego, Guillermo and Topaloglu, Huseyin","MANAGEMENT SCIENCE","60","10","2583-2601","2014","OCT","Assortment Optimization;Nested Logit Model;Revenue Management","","We study assortment optimization problems where customer choices are governed by the nested logit model and there are constraints on the set of products offered in each nest. Under the nested logit model, the products are organized in nests. Each product in each nest has a fixed revenue associated with it. The goal is to find a feasible set of products, i.e., a feasible assortment, to maximize the expected revenue per customer. We consider cardinality and space constraints on the offered assortment, which limit the number of products and the total space consumption of the products offered in each nest, respectively. We show that the optimal assortment under cardinality constraints can be obtained efficiently by solving a linear program. The assortment optimization problem under space constraints is NP-hard. We show how to obtain an assortment with a performance guarantee of 2 under space constraints. This assortment also provides a performance guarantee of 1/(1 - is an element of) when the space requirement of each product is at most a fraction. of the space availability in each nest. Building on our results for constrained assortment optimization, we show that we can efficiently solve joint assortment optimization and pricing problems under the nested logit model, where we choose the assortment of products to offer to customers, as well as the prices of the offered products. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1931."
1188,"Conflicting Social Codes and Organizations: Hygiene and Authenticity in Consumer Evaluations of Restaurants","Lehman, David W. and Kovacs, Balazs and Carroll, Glenn R.","MANAGEMENT SCIENCE","60","10","2602-2617","2014","OCT","Organizations;Institutions;Social Codes;Authenticity;Regulatory Noncompliance;Consumer Value Ratings;Restaurants;Health Grades","","Organization theory highlights the spread of norms of rationality in contemporary life. Yet rationality does not always spread without friction; individuals often act based on other beliefs and norms. We explore this problem in the context of restaurants and diners. We argue that consumers potentially apply either of two social codes when forming value judgments about restaurants: (1) an apparently rational science-based code of hygiene involving compliance with local health regulations or (2) a context-activated code of authenticity involving conformity to cultural norms. We propose that violations of the hygiene code recede in importance when the authenticity code is activated. This claim is supported by empirical analyses of 442,086 online consumer reviews and 52,740 governmental health inspections conducted from 2004 to 2011."
1189,"Are Consumers Strategic? Structural Estimation from the Air-Travel Industry","Li, Jun and Granados, Nelson and Netessine, Serguei","MANAGEMENT SCIENCE","60","9","2114-2137","2014","SEP","Econometrics;Structural Estimation;Air Travel;Strategic Customer Behavior","","Consumers often consider delaying a purchase strategically, anticipating that prices might decrease. Combining two unique data sources from the air-travel industry (posted fare data and booking data), we use a structural model to estimate the fraction of strategic consumers in the population, assuming different levels of sophistication in consumers' perception of future prices: perfect foresight and weak-and strong-form rational expectations. We find that 5.2% to 19.2% of the population is strategic across markets, measured by the first and third quartiles. Our intermarket analysis indicates that shorter trips with more attractive outside options are populated with more strategic consumers. Using a nonparametric approach, we further find that most strategic consumers arrive either at the beginning of the booking horizon or close to departure. Finally, our counterfactual analysis shows that, contrary to conventional wisdom, the presence of strategic consumers does not necessarily hurt revenues. Rather, the impact varies by market. Commitment to a nondecreasing pricing strategy is more likely to benefit business markets than leisure markets, or it could even hurt leisure markets. Intermarket analysis shows that city pairs with lower Internet penetration, higher average price, and shorter distances tend to benefit more from such commitment as well."
1190,"Crowdsourcing New Product Ideas Under Consumer Learning","Huang, Yan and Singh, Param Vir and Srinivasan, Kannan","MANAGEMENT SCIENCE","60","9","2138-2159","2014","SEP","Crowdsourcing;Structural Modeling;Dynamic Learning;Heterogeneity;Econometric Analyses;Utility","","We propose a dynamic structural model that illuminates the economic mechanisms shaping individual behavior and outcomes on crowdsourced ideation platforms. We estimate the model using a rich data set obtained from IdeaStorm.com, a crowdsourced ideation initiative affiliated with Dell. We find that, on IdeaStorm.com, individuals tend to significantly underestimate the costs to the firm for implementing their ideas but overestimate the potential of their ideas in the initial stages of the crowdsourcing process. Therefore, the idea market is initially overcrowded with ideas that are less likely to be implemented. However, individuals learn about both their abilities to come up with high-potential ideas as well as the cost structure of the firm from peer voting on their ideas and the firm's response to contributed ideas. We find that individuals learn rather quickly about their abilities to come up with high-potential ideas, but the learning regarding the firm's cost structure is quite slow. Contributors of low-potential ideas eventually become inactive, whereas the high-potential idea contributors remain active. As a result, over time, the average potential of generated ideas increases while the number of ideas contributed decreases. Hence, the decrease in the number of ideas generated represents market efficiency through self-selection rather than its failure. Through counterfactuals, we show that providing more precise cost signals to individuals can accelerate the filtering process. Increasing the total number of ideas to respond to and improving the response speed will lead to more idea contributions. However, failure to distinguish between high-and low-potential ideas and between high-and low-ability idea generators leads to the overall potential of the ideas generated to drop significantly."
1191,"Should Event Organizers Prevent Resale of Tickets?","Cui, Yao and Duenyas, Izak and Sahin, Oezge","MANAGEMENT SCIENCE","60","9","2160-2179","2014","SEP","Events;Ticket Resale;Fixed Pricing;Multiperiod Pricing;Options","","We are interested in whether preventing resale of tickets benefits the capacity providers for sporting and entertainment events. Common wisdom suggests that ticket resale is harmful to event organizers' revenues, and event organizers have tried to prevent resale of tickets. For instance, Ticketmaster recently proposed paperless (nontransferrable) ticketing, which would severely limit the opportunity to resell tickets. We consider a model that allows resale from both consumers and speculators with different transaction costs for each party. Surprisingly, we find that this wisdom is incorrect when event organizers use fixed pricing policies; in fact, event organizers benefit from reductions in consumers' (and speculators') transaction costs of resale. Even when multiperiod pricing policies are used, we find that an event organizer may still benefit from ticket resale if his capacity is small. Although paperless ticketing is suggested as a way to reduce ticket resale and prevent speculators from buying tickets, our results suggest that it may reduce the capacity providers' revenues in many situations. Instead, we propose ticket options as a novel ticket pricing mechanism. We show that ticket options (where consumers would initially buy an option to buy a ticket and then exercise at a later date) naturally reduce ticket resale significantly and result in significant increases in event organizers' revenues. Furthermore, since a consumer only risks the option price (and not the whole ticket price) if she cannot attend the event, options may face less consumer resistance than paperless tickets."
1192,"Commissions and Sales Targets Under Competition","Gallego, Guillermo and Talebian, Masoud","MANAGEMENT SCIENCE","60","9","2180-2197","2014","SEP","Provider-Broker Competition;Contract Theory;Quantity Discount;Game Theory","","We consider a game between two capacity providers that compete for customers through a broker who earns commissions on sales and sells to both loyal and nonloyal customers. The providers compete by selecting commission margins and sales targets above which the margins on total sales increase. We study the contract form in equilibrium and the effect that sales targets have on the profit split between the providers and the broker. We show that in equilibrium, contracts require positive sales targets that can be best described as a mechanism for the larger provider to profit at the expense of the smaller provider. The effect of sales targets is different when commission margins are exogenous and the providers compete by setting targets. In this case, it is the low-margin provider who benefits from sales targets at the expense of the broker, who in this context resists the imposition of targets."
1193,"Contracts, Biases, and Consumption of Access Services","Leider, Stephen and Sahin, Oezge","MANAGEMENT SCIENCE","60","9","2198-2222","2014","SEP","Economics;Behavior And Behavioral Decision Making;Marketing;Pricing;Microeconomics;Intertemporal Choice;Decision Analysis;Applications;Industrial Organization;Market Structure;Firm Strategy;Market Performance","","W e study theoretically and empirically the consumption of access services. We demonstrate that consumption is affected by contract structure (pay-per-use versus three-part tariffs) even if the optimal consumption plans are identical. We find that, although there is extensive individual heterogeneity, on average, consumers' choices follow a structure that is similar to a nearly optimal heuristic and correctly react to imbalances between the number of free calls and call opportunities remaining. However, consumers use the free units too quickly, leading to overconsumption and lost surplus. These errors are partially driven by mistaken beliefs about the value distribution. We also measure subjects' willingness to pay for a contract with free access units, and we find that nearly half of subjects are willing to pay at least the full per-unit price, with a substantial fraction willing to overpay. In response, the optimal firm strategy offers a three-part tariff at a very small discount, which increases revenue by 8%-14% compared to only offering a pay-per-use contract."
1194,"Environmental Externalities and Cost of Capital","Chava, Sudheer","MANAGEMENT SCIENCE","60","9","2223-2247","2014","SEP","Environmental Externalities;Financial Institutions;Banks;Cost Of Capital;Finance;Investment","","I analyze the impact of a firm's environmental profile on its cost of equity and debt capital. Using implied cost of capital derived from analysts' earnings estimates, I find that investors demand significantly higher expected returns on stocks excluded by environmental screens (such as hazardous chemical, substantial emissions, and climate change concerns) compared to firms without such environmental concerns. Lenders also charge a significantly higher interest rate on the bank loans issued to firms with these environmental concerns. I provide evidence that the environmental profile of a firm is not simply proxying for an omitted component of its default risk. Further, firms with these environmental concerns have lower institutional ownership and fewer banks participate in their loan syndicate than firms without such environmental concerns. These results suggest that exclusionary socially responsible investing and environmentally sensitive lending can have a material impact on the cost of equity and debt capital of affected firms."
1195,"Nonlinear Kalman Filtering in Affine Term Structure Models","Christoffersen, Peter and Dorion, Christian and Jacobs, Kris and Karoui, Lotfi","MANAGEMENT SCIENCE","60","9","2248-2268","2014","SEP","Kalman Filtering;Nonlinearity;Term Structure Models;Swaps;Caps;Particle Filtering","","The extended Kalman filter, which linearizes the relationship between security prices and state variables, is widely used in fixed-income applications. We investigate whether the unscented Kalman filter should be used to capture nonlinearities and compare the performance of the Kalman filter with that of the particle filter. We analyze the cross section of swap rates, which are mildly nonlinear in the states, and cap prices, which are highly nonlinear. When caps are used to filter the states, the unscented Kalman filter significantly outperforms its extended counterpart. The unscented Kalman filter also performs well when compared with the much more computationally intensive particle filter. These findings suggest that the unscented Kalman filter may be a good approach for a variety of problems in fixed-income pricing."
1196,"What Do Credit Markets Tell Us About the Speed of Leverage Adjustment?","Elkamhi, Redouane and Pungaliya, Raunaq S. and Vijh, Anand M.","MANAGEMENT SCIENCE","60","9","2269-2290","2014","SEP","Capital Structure;Speed Of Adjustment;Bond Spread;Cds Spread;Predicted Leverage","","This paper proposes a new methodology to infer investors' expectations about the speed of leverage adjustment implicit in the prices of credit instruments. On average, the credit markets imply a fairly rapid annual speed of adjustment of 26% toward a firm's predicted leverage. The speed varies considerably across partitions formed by the differential implications of the pecking order, market timing, and trade-off theories of capital structure. This finding suggests that investors' expectations are formed in accordance with all three theories. We also show that the addition of firm fixed effects in the predicted leverage model gives noisier estimates of investors' expectations of future leverage, and that a firm's initial leverage is a poor estimate of its future leverage."
1197,"Optimal Credit Swap Portfolios","Giesecke, Kay and Kim, Baeho and Kim, Jack and Tsoukalas, Gerry","MANAGEMENT SCIENCE","60","9","2291-2307","2014","SEP","Finance;Investments;Portfolio Optimization;Credit Swaps","","This paper formulates and solves the selection problem for a portfolio of credit swaps. The problem is cast as a goal program that entails a constrained optimization of preference-weighted moments of the portfolio value at the investment horizon. The portfolio value takes account of the exact timing of protection premium and default loss payments, as well as any mark-to-market profits and losses realized at the horizon. The constraints address collateral and solvency requirements, initial capital, position limits, and other trading constraints that credit swap investors often face in practice. The multimoment formulation accommodates the complex distribution of the portfolio value, which is a nested expectation under risk-neutral and actual probabilities. It also generates computational tractability. Numerical results illustrate the features of optimal portfolios. In particular, we find that credit swap investment constraints can have a significant impact on optimal portfolios, even for simple investment objectives. Our problem formulation and solution approach extend to corporate bond portfolios and mixed portfolios of corporate bonds and credit derivatives."
1198,"Financing and Investment Efficiency, Information Quality, and Accounting Biases","Nan, Lin and Wen, Xiaoyan","MANAGEMENT SCIENCE","60","9","2308-2323","2014","SEP","Accounting;Cost-Benefit Analysis;Decision Analysis","","In this paper, we investigate the effect of accounting biases on firms' financing decisions and the role of accounting biases in endogenous information quality. We show that in industries with generally low-profit prospects, a downward-biased accounting system performs better than a neutral accounting system, and a more downward bias helps mitigate both investment and financing inefficiency; whereas for industries with generally high-profit prospects, an upward-biased accounting system is better than a neutral accounting system, and a more upward bias helps improve financing efficiency. In addition, we find that a more downward-biased accounting system motivates good firms to exert more effort to improve the information quality, which improves overall efficiency."
1199,"Does Short Selling Amplify Price Declines or Align Stocks with Their Fundamental Values?","Curtis, Asher and Fargher, Neil L.","MANAGEMENT SCIENCE","60","9","2324-2340","2014","SEP","Short Selling;Price Declines;Fundamental Analysis;Market Regulation","","Critics of short selling argue that short sellers amplify price declines by targeting firms with falling prices in an unwarranted manner. Contrary to this viewpoint, we find that increases in short interest for firms following a price decline are associated with measures of overpricing based on financial statement analysis. Our results extend to short-selling activity following marketwide declines. We also find evidence consistent with the profitability of short selling following price declines being driven by valuation-based positions. Overall, our findings suggest short sellers primarily undertake valuation-based strategies following price declines and have implications for regulators. Limiting short selling following price declines is likely to impede efficient price discovery."
1200,"Friendships and Search Behavior in Labor Markets","Sterling, Adina D.","MANAGEMENT SCIENCE","60","9","2341-2354","2014","SEP","Labor;Organizational Studies;Networks","","This paper examines how organizations use employee networks to contend with job seekers' search behavior. According to prior research, in markets where job seekers engage in nonsequential job search, organizations respond with tactics such as exploding offers and recruiting candidates earlier. In this paper, I posit that organizations have a social structural response. I argue that in an attempt to avoid problems related to candidates' job search, organizations are more likely to provide job offers to candidates with friends in the hiring organization than to those without friends. I test and find support for this hypothesis in a study of entry-level professionals in business and law. After a period of trial employment, candidates were more likely to receive job offers from organizations if they had a friend employed there than if they did not. The implications of this study for research on labor markets, networks, and inequality are discussed."
1201,"Does Social Proximity Enhance Business Partnerships? Theory and Evidence from Ethnicity's Role in US Venture Capital","Hegde, Deepak and Tumlinson, Justin","MANAGEMENT SCIENCE","60","9","2355-2380","2014","SEP","Venture Capital;Entrepreneurship;Homophily;Social Capital;Social Networks","","W e develop a formal model to understand the selection and influence effects of social proximity (homophily) between business partners. Consistent with the model's predictions, we find that U.S. venture capitalists (VCs) are more likely to select start-ups with coethnic executives for investment, particularly when the probability of the start-up's success appears low. Ethnic proximity between VCs and the start-ups they invest in is positively related to performance, measured by the probability of the companies' successful exit through acquisitions and initial public offerings (IPOs) and net income after IPO. Two-stage regression estimates suggest that these positive performance outcomes are largely due to influence, that is, superior communication and coordination between coethnic VCs and start-up executives after the investment. To the extent that VCs expect to work better with coethnic start-ups, they invest in coethnic ventures that are of lower observable quality than noncoethnic ventures."
1202,"Financial Literacy, Financial Education, and Downstream Financial Behaviors","Fernandes, Daniel and Lynch, Jr., John G. and Netemeyer, Richard G.","MANAGEMENT SCIENCE","60","8","1861-1883","2014","AUG","Behavioral Economics;Household Finance;Consumer Behavior;Education Systems;Public Policy;Government Programs;Statistics;Causal Effects;Design Of Experiments;Meta-Analysis;Financial Education;Financial Literacy","","Policy makers have embraced financial education as a necessary antidote to the increasing complexity of consumers' financial decisions over the last generation. We conduct a meta-analysis of the relationship of financial literacy and of financial education to financial behaviors in 168 papers covering 201 prior studies. We find that interventions to improve financial literacy explain only 0.1% of the variance in financial behaviors studied, with weaker effects in low-income samples. Like other education, financial education decays over time; even large interventions with many hours of instruction have negligible effects on behavior 20 months or more from the time of intervention. Correlational studies that measure financial literacy find stronger associations with financial behaviors. We conduct three empirical studies, and we find that the partial effects of financial literacy diminish dramatically when one controls for psychological traits that have been omitted in prior research or when one uses an instrument for financial literacy to control for omitted variables. Financial education as studied to date has serious limitations that have been masked by the apparently larger effects in correlational studies. We envisage a reduced role for financial education that is not elaborated or acted upon soon afterward. We suggest a real but narrower role for just-in-time financial education tied to specific behaviors it intends to help. We conclude with a discussion of the characteristics of behaviors that might affect the policy maker's mix of financial education, choice architecture, and regulation as tools to help consumer financial behavior."
1203,"Volume Flexibility in Services: The Costs and Benefits of Flexible Labor Resources","Kesavan, Saravanan and Staats, Bradley R. and Gilland, Wendell","MANAGEMENT SCIENCE","60","8","1884-1906","2014","AUG","Labor Mix;Retail Operations;Volume Flexibility;Demand Spikes","","Organizations can create volume flexibility-the ability to increase capacity up or down to meet demand for a single service-through the use of flexible labor resources (e.g., part-time and temporary workers, as compared to full-time workers). Although organizations are increasingly using these resources, the relationship between flexible labor resources and financial performance has not been examined empirically in the service setting. We use two years of archival data from 445 stores of a large retailer to study this relationship. We hypothesize and find that increasing the labor mix of temporary or part-time workers shows an inverted U-shaped relationship with sales and profit while temporary labor mix has a U-shaped relationship with expenses. Thus, although flexible labor resources can create volume flexibility for a firm along multiple dimensions, it is possible to have too much of a good thing."
1204,"Retail Store Density and the Cost of Greenhouse Gas Emissions","Cachon, Gerard P.","MANAGEMENT SCIENCE","60","8","1907-1925","2014","AUG","Sustainability;K-Median;Traveling Salesman Problem;Carbon Tax;Cap-And-Trade","","The density, size, and location of stores in a retailer's network influences both the retailer's and the consumers' costs. With stores few and far between, consumers must travel a long distance to shop, whereas shopping trips are shorter with a dense network of stores. The layout of the retail supply chain is of interest to retailers who have emission reduction targets and urban planners concerned with sprawl. Are small local shops preferred over large, big-box retailers? A model of the retail supply chain is presented that includes operating costs (such as fuel and rent for floor space) as well as a cost for environmental externalities associated with carbon emissions. A focus on exclusively minimizing operating costs may substantially increase emissions (by 67% in one scenario) relative to the minimum level of emissions. A price on carbon is an ineffective mechanism for reducing emissions. The most attractive option is to improve consumer fuel efficiency-doubling the fuel efficiency of cars reduces long-run emissions by about one-third, whereas an improvement in truck fuel efficiency has a marginal impact on total emissions."
1205,"Giving Feedback to Clients","Ho, Teck-Hua and Yeung, Catherine","MANAGEMENT SCIENCE","60","8","1926-1944","2014","AUG","Opportunism;Altruism;Overconfidence;Feedback Giving Game;Client-Agent Interaction;Behavioral Economics","","We examine a prevalent form of client-agent interaction through a feedback-giving game. In this game, a client undertakes a nontrivial task and is compensated based on her task performance, which is only made known to her when the client-agent interaction ends. Meanwhile, her performance is disclosed to an agent, who must then give the client feedback on her performance. Upon receiving the feedback, the client reports her happiness level, which in turn determines the agent's payoff. In eight studies involving 928 subjects, we vary the way the agent's cash earnings depend on the client's reported happiness. When we make the agent's earnings proportional to the client's reported happiness, the agent inflates his feedback, and the client reports a higher level of happiness (than that reported in a control condition where the agent always provides honest feedback). We show that neither the agent nor the client behaves altruistically in their reporting. The client reports being happier because she overestimates her performance and mistakenly believes that the agent's feedback is genuine. The agent stops inflating his feedback when doing so no longer benefits him. Finally, our main findings are shown to be robust with respect to several factors, including making the agent's feedback consequential in affecting the client's payoff. In summary, we show that the agent behaves opportunistically, and the client's overconfidence of her own performance is what makes this strategy successful."
1206,"The Long-Run Role of the Media: Evidence from Initial Public Offerings","Liu, Laura Xiaolei and Sherman, Ann E. and Zhang, Yong","MANAGEMENT SCIENCE","60","8","1945-1964","2014","AUG","Finance;Corporate Finance;Securities;Financial Institutions;Markets;Initial Public Offerings;Media Coverage","","The unique characteristics of the U.S. initial public offering (IPO) process, particularly the strict quiet period regulations, allow us to explore the effects of media coverage when the coverage does not contain genuine news (i.e., hard information that was previously unknown). We show that a simple, objective measure of pre-IPO media coverage is positively related to the stock's long-term value, liquidity, analyst coverage, and institutional investor ownership. Our results are robust to additional controls for size, to using abnormal or excess media, and to an instrumental variable approach. We also find that pre-IPO media coverage is negatively related to future expected returns, measured by the implied cost of capital. In all, we find a long-term role for media coverage, consistent with Merton's attention or investor recognition hypothesis."
1207,"Compensation and Peer Effects in Competing Sales Teams","Chan, Tat Y. and Li, Jia and Pierce, Lamar","MANAGEMENT SCIENCE","60","8","1965-1984","2014","AUG","Peer Effects;Compensation;Sales Force;Productivity;Selling Strategy;Marketing;Competitive Strategy;Market Performance","","This paper examines how compensation systems impact peer effects and competition in collocated sales teams. We use department store sales data to show that compensation systems influence worker incentives to help and compete with peers within the same firm, which in turn changes the capability of the firm to compete with rivals. Compensation also affects how salespeople impact peers at collocated competing firms, thereby impacting market competition. Moreover, compensation influences how salespeople strategically discount prices in response to peers. Our results suggest that heterogeneity in worker ability enhances firm performance under team-based compensation while hurting individual-based firms and that peer interactions are critical considerations in designing sales force incentive plans and broader firm strategy."
1208,"Differences in Trading and Pricing Between Stock and Index Options","Lemmon, Michael and Ni, Sophie Xiaoyan","MANAGEMENT SCIENCE","60","8","1985-2001","2014","AUG","Options;Volatility Smile;Sentiment;Speculation;Behavior","","We find that the demand for stock options that increases exposure to the underlying is positively related to the individual investor sentiments and past market returns, whereas the demand for index options is invariant to these factors. These differences in trading patterns are also reflected in the differences in the composition of traders with different types of options-options on stocks are actively traded by individual investors, whereas trades in index options are more often motivated by the hedging demand of sophisticated investors. Consistent with a demand-based view of option pricing, the individual investor sentiments and past market returns are related to time-series variations in the slope of the implied volatility smile of stock options, but they have little impact on the prices of index options. The pricing impact is more pronounced in options with a higher concentration of unsophisticated investors and those with higher delta hedging costs. Our results provide evidence that factors not related to fundamentals also impact security prices."
1209,"Balancing Acquisition and Retention Spending for Firms with Limited Capacity","Ovchinnikov, Anton and Boulu-Reshef, Beatrice and Pfeifer, Phillip E.","MANAGEMENT SCIENCE","60","8","2002-2019","2014","AUG","Behavioral Operations;Revenue Management;Limited Capacity;Customer Relationship Management;Customer Lifetime Value","","This paper discusses the interaction between revenue management and customer relationship management for a firm that operates in a customer retention situation but faces limited capacity. We present a dynamic programming model for how the firm balances investments in customer acquisition and retention, as well as retention across multiple customer types. We characterize the optimal policy and discuss how the policy changes depending on capacity limitations. We then contrast the modeling results with those of a behavioral experiment in which subjects acted as managers making acquisition and retention decisions. In the modeling part of the paper, we introduce a concept of the value of an incremental customer (VIC), and show that when capacity is unlimited, VIC equals customer lifetime value (CLV), but when capacity is limited, VIC is much smaller and changes dynamically depending on the number of customers and their mix. As a result, the optimal spending is constant and depends on CLV for the firms with unlimited capacity, but changes dynamically and is generally unrelated to CLV when capacity is limited. In the experimental part, we introduce a concept of conditional optimality for the analysis of state-dependent decisions. Applying this concept to our data, we document a number of decision biases, specifically the subjects' tendency to overspend on retaining high-value customers and underspend on lower-value customers retention and acquisition. We show that providing CLV information exacerbates these biases and leads to a loss of net revenue when capacity is limited, but providing information about the marginal costs of acquisition and retention eliminated these biases and increases net revenue."
1210,"Crowdsourcing with All-Pay Auctions: A Field Experiment on Taskcn","Liu, Tracy Xiao and Yang, Jiang and Adamic, Lada A. and Chen, Yan","MANAGEMENT SCIENCE","60","8","2020-2037","2014","AUG","Crowdsourcing;Field Experiment;All-Pay Auctions","","To explore the effects of different incentives on crowdsourcing participation and submission quality, we conduct a randomized field experiment on Taskcn, a large Chinese crowdsourcing site using mechanisms with features of an all-pay auction. In our study, we systematically vary the size of the reward as well as the presence of a soft reserve, or early high-quality submission. We find that a higher reward induces significantly more submissions and submissions of higher quality. In comparison, we find that high-quality users are significantly less likely to enter tasks where a high-quality solution has already been submitted, resulting in lower overall quality in subsequent submissions in such soft reserve treatments."
1211,"Information Content When Mutual Funds Deviate from Benchmarks","Jiang, Hao and Verbeek, Marno and Wang, Yu","MANAGEMENT SCIENCE","60","8","2038-2053","2014","AUG","Mutual Funds;Benchmarks;Private Information;Market Efficiency;Fund Performance","","The consensus wisdom of active mutual fund managers, as reflected in their average over- and underweighting decisions, contains valuable information about future stock returns. Analyzing a comprehensive sample of active U.S. equity funds from 1984 to 2008, we find that stocks heavily overweighted by active funds out-perform their underweighted counterparts by more than 7% per year, after adjustments for their loadings on the market, size, value, and momentum factors. This large premium dissipates quickly as the consensus view becomes publicly available. These results are consistent with the notion that informed investing by active mutual funds enhances the informativeness of stock prices. In addition, active mutual funds invest only a small portion of fund assets in high alpha stocks, in accordance with the consensus view that active mutual funds on average fail to outperform passive benchmarks."
1212,"Money Talks: Rebate Mechanisms in Reputation System Design","Li, Lingfang (Ivy) and Xiao, Erte","MANAGEMENT SCIENCE","60","8","2054-2072","2014","AUG","Reputation;Trust;Feedback Mechanism;Asymmetric Information;Public Good;Experimental Economics","","Reputation systems that rely on voluntary feedback from traders are important in creating and sustaining trust in markets. Feedback nevertheless is a public good, and providing it is often costly. We combine theory with a laboratory experiment to study the effect of a seller precommitment mechanism: Sellers have an option to commit by providing a rebate to reduce the buyer's feedback reporting cost before making purchasing decisions. Our theory predicts that this mechanism induces noncooperative sellers to cooperate in the listed-price market. Using a buyer-seller trust game with a unilateral feedback scheme, we find that the seller's rebate decision has a significant impact on the buyer's purchasing decision via signaling the seller's cooperative type. More importantly, market efficiency under the precommitment mechanism increases with the probability that sellers will provide a rebate. Compared with the no rebate mechanism market, more efficient trades can be achieved when the sellers offer a rebate to the buyers in the market with the rebate mechanism, even when the rebate does not cover the full cost of feedback reporting."
1213,"Firm-Level Productivity, Risk, and Return","Imrohoroglu, Ayse and Tuezel, Selale","MANAGEMENT SCIENCE","60","8","2073-2090","2014","AUG","Firm-Level Productivity;Cross Section Of Returns","","This paper provides new evidence about the link between firm-level total factor productivity (TFP) and stock returns. We estimate firm-level TFP and show that it is strongly related to several firm characteristics such as size, the book-to-market ratio, investment, and hiring rate. Low productivity firms earn a significant premium over high productivity firms in the following year, and this premium is countercyclical. We show that a production-based asset pricing model calibrated to match the cross section of measured firm-level TFPs can replicate the empirical relationship between TFP, many firm characteristics, and stock returns. Our results offer an explanation as to how these firm characteristics rationally predict returns."
1214,"Timing Ability of Government Bond Fund Managers: Evidence from Portfolio Holdings","Huang, Jing-Zhi and Wang, Ying","MANAGEMENT SCIENCE","60","8","2091-2109","2014","AUG","Government Bond Funds;Market Timing;Bond Fund Holdings;Macroeconomic News Announcements","","This study examines the ability of government bond fund managers to time the bond market, based on their monthly or quarterly holdings of Treasury securities during the 1997-2006 period. We find that, on average, government bond funds exhibit significantly positive timing ability at the one-month horizon under an unconditional holdings-based timing measure. However, our results indicate that managers' actions based on public information can explain the documented positive timing ability-namely, the average government bond fund has neutral or even slightly negative conditional market timing ability once public information is controlled for. Nonetheless, we find evidence that fund managers specializing in Treasury securities can better interpret public information than general government bond fund managers do."
1215,"When Kerry Met Sally: Politics and Perceptions in the Demand for Movies","Roos, Jason M. T. and Shachar, Ron","MANAGEMENT SCIENCE","60","7","1617-1631","2014","JUL","Marketing;Leisure Industries;New Products;Forecasting","","Movie producers and exhibitors make various decisions requiring an understanding of moviegoer's preferences at the local level. Two examples of such decisions are exhibitors' allocation of screens to movies and producers' allocation of advertising across different regions of the country. This study presents a predictive model of local demand for movies with two unique features. First, arguing that consumers' political tendencies have an unutilized predictive power for marketing models, we allow consumers' heterogeneity to depend on their voting tendencies. Second, instead of relying on the commonly used genre classifications to characterize movies, we estimate latent movie attributes. These attributes are not determined a priori by industry professionals but rather reflect consumers' perceptions, as revealed by their moviegoing behavior. Box-office data over five years from 25 counties in the U.S. Midwest provide support for this model. First, consumers' preferences are related to their political tendencies. For example, we find that counties that voted for congressional Republicans prefer movies starring young, Caucasian, female actors over those starring African American, male actors. Second, perceived attributes provide new insights into consumers' preferences. For example, one of these attributes is the movie's degree of seriousness. Finally, and most importantly, the two improvements proposed here have a meaningful impact on forecasting error, decreasing it by 12.6%."
1216,"Examining the Impact of Ranking on Consumer Behavior and Search Engine Revenue","Ghose, Anindya and Ipeirotis, Panagiotis G. and Li, Beibei","MANAGEMENT SCIENCE","60","7","1632-1654","2014","JUL","Travel Search Engine;Randomized Experiments;Hierarchical Bayesian Methods;Information Systems;It Policy And Management;Electronic Commerce","","In this paper, we study the effects of three different kinds of search engine rankings on consumer behavior and search engine revenues: direct ranking effect, interaction effect between ranking and product ratings, and personalized ranking effect. We combine a hierarchical Bayesian model estimated on approximately one million online sessions from Travelocity, together with randomized experiments using a real-world hotel search engine application. Our archival data analysis and randomized experiments are consistent in demonstrating the following: (1) A consumer-utility-based ranking mechanism can lead to a significant increase in overall search engine revenue. (2) Significant interplay occurs between search engine ranking and product ratings. An inferior position on the search engine affects higher-class hotels more adversely. On the other hand, hotels with a lower customer rating are more likely to benefit from being placed on the top of the screen. These findings illustrate that product search engines could benefit from directly incorporating signals from social media into their ranking algorithms. (3) Our randomized experiments also reveal that an active personalized ranking system (wherein users can interact with and customize the ranking algorithm) leads to higher clicks but lower purchase propensities and lower search engine revenue compared with a passive personalized ranking system (wherein users cannot interact with the ranking algorithm). This result suggests that providing more information during the decision-making process may lead to fewer consumer purchases because of information overload. Therefore, product search engines should not adopt personalized ranking systems by default. Overall, our study unravels the economic impact of ranking and its interaction with social media on product search engines."
1217,"The Ability of Global Stock Exchange Mechanisms to Mitigate Home Bias: Evidence from Euronext","Pownall, Grace and Vulcheva, Maria and Wang, Xue","MANAGEMENT SCIENCE","60","7","1655-1676","2014","JUL","Home Bias;Exchange Merger;Exchange Segmentation","","This paper examines the effects on equity home bias of two mechanisms adopted by Euronext when it was formed by the merger of four European countries' stock exchanges in 2002. The two structural mechanisms are the integration of trading platforms across the four predecessor exchanges and the creation of named segments of the integrated exchange on which firms could voluntarily list by precommitting to enhanced disclosure and transparency. Employing a difference-in-differences research design using other European Union companies as a control group, we document that the integration of the Euronext market was associated with a reduction in home bias for firms listed on the named segments of the Euronext exchange, but not for the nonsegment Euronext firms. Our results suggest that the reduction in transaction costs from the integration of the trading platforms did not make the nonsegment Euronext firms more attractive to the specific investors for whom the transaction costs were reduced. On the other hand, the decrease in information costs due to the precommitments to enhanced transparency made the segment firms more attractive to all categories of foreign investors, consistent with the information costs hypothesis."
1218,"Diasporas and Outsourcing: Evidence from oDesk and India","Ghani, Ejaz and Kerr, William R. and Stanton, Christopher","MANAGEMENT SCIENCE","60","7","1677-1697","2014","JUL","Diaspora;Ethnicity;Outsourcing;Odesk;Networks;India;South Asia","","We examine the role of the Indian diaspora in the outsourcing of work to India. Our data are taken from oDesk, the world's largest online platform for outsourced contracts. Despite oDesk minimizing many of the frictions that diaspora connections have traditionally overcome, diaspora connections still matter on oDesk, with ethnic Indians substantially more likely to choose a worker in India. This higher placement is the result of a greater likelihood of choosing India for the initial contract and substantial path dependence in location choices. We further examine wage and performance outcomes of outsourcing as a function of ethnic connections. Our examination of potential rationales for the greater ethnic-based placement of contracts assesses taste-based preferences and information differences."
1219,"Integration and Productivity: Satellite-Tracked Evidence","Natividad, Gabriel","MANAGEMENT SCIENCE","60","7","1698-1718","2014","JUL","Organizational Studies;Strategy;Productivity;Economics;Boundaries Of The Firm;Geographic Information Systems","","This paper introduces satellite-tracked real-time data from a large fishing firm managing its vertically, horizontally, and geographically linked ships to study the causal impact of integration on total factor productivity (TFP) after the firm acquired its vertically unintegrated contractual fish suppliers. TFP increased 16% among newly integrated ships, whereas it did not vary for already owned ships. Some classic mechanisms such as increased effort due to monitoring do not systematically explain TFP gains under integration, whereas evidence on hold-up threat alleviation is mixed. Importantly, enhanced knowledge transfer and hierarchical authority enacting productivity-improving operational practices among newly integrated ships are more likely explanations of the results."
1220,"Split-Award Auctions for Supplier Retention","Chaturvedi, Aadhaar and Beil, Damian R. and Martinez-de-Albeniz, Victor","MANAGEMENT SCIENCE","60","7","1719-1737","2014","JUL","Auctions;Split Awards;Multisourcing;Supply Base","","To stay abreast of current supply-market pricing, it is common for procurement managers to frequently organize auctions among a pool of qualified suppliers (the supply base). Sole awards can alienate losing suppliers and cause them to defect from the supply base. To maintain the supply base and thereby control the high costs of finding and qualifying new suppliers, buyers often employ split awards, which in turn inflate purchase costs. This results in a trade-off that we investigate in an infinite-horizon stationary setting in which the relative cost position of each supplier is randomly drawn in every period. We characterize the optimal split award that minimizes long-run costs (purchasing and qualification) and show that maintaining a constant supply-base size-using a qualify-up-to policy-is optimal for the buyer. We find that neither the extent of multisourcing nor the buyer's value of split awards compared with winner-take-all auctions are monotonic in the qualification cost and that split-award auctions can increase ex ante system, buyer, and supplier benefits simultaneously. To our knowledge, this is the first paper studying split-award auctions for supply-base maintenance, and it will hopefully galvanize further research on this important topic."
1221,"Mobile Targeting","Luo, Xueming and Andrews, Michelle and Fang, Zheng and Phang, Chee Wei","MANAGEMENT SCIENCE","60","7","1738-1756","2014","JUL","Mobile Commerce;Mobile Targeting;Randomized Field Experiment","","Mobile technologies enable marketers to target consumers by time and location. This study builds on a large-scale randomized experiment of short message service (SMS) texts sent to 12,265 mobile users. We draw on contextual marketing theory to hypothesize how different combinations of mobile targeting determine consumer responses to mobile promotions. We identify that temporal targeting and geographical targeting individually increase sales purchases. Surprisingly, the sales effects of employing these two strategies simultaneously are not straightforward. When targeting proximal mobile users, our findings reveal a negative sales-lead time relationship; sending same-day mobile promotions yields an increase in the odds of consumer purchases compared with sending them two days prior to the promoted event. However, when targeting nonproximal mobile users, there is an inverted-U, curvilinear relationship. Sending one-day prior SMSs yields an increase in the odds of consumer purchases by 9.5 times compared with same-day SMSs and an increase in the odds of consumer purchases by 71% compared with two-day prior SMSs. These results are robust to unobserved heterogeneity, alternative estimation models, bootstrapped resamples, randomization checks, consumer mobile usage behavior, and segmentation of consumer scenarios. In addition, we conducted follow-up surveys to delve into the psychological mechanisms explaining the findings in our field experiment. In line with consumer construal arguments, consumers who received SMSs close (far) in time and location formed a more (less) concrete mental construal, which in turn, increased their involvement and purchase intent. These findings suggest that understanding the when, where, and how of mobile targeting strategies is crucial. Marketers can save money by carefully designing their mobile targeting campaigns."
1222,"Wallflowers: Experimental Evidence of an Aversion to Standing Out","Jones, Daniel and Linardi, Sera","MANAGEMENT SCIENCE","60","7","1757-1771","2014","JUL","Economics;Behavior And Behavioral Decision Making;Organizational Studies;Motivation-Incentives;Microeconomic Behavior","","An extensive literature on reputation signaling in prosocial settings has focused on an intrinsic desire for positive reputation. In this paper, we provide experimental evidence that some individuals are averse to both positive and negative reputation and will therefore respond to visibility by signaling that they are an '' average altruism type '' relative to their audience. We formalize our hypotheses about '' wallflower '' behavior in a theoretical model. Our experimental results show that instead of uniformly increasing contributions, visibility draws contributions toward the middle of others' contributions. As a result, visibility is associated with higher levels of giving only in scenarios where others are giving a large amount. We also observe heterogeneity in reputation concerns: wallflower behavior is particularly strong for women and can be observed in several different settings."
1223,"Forecasting the Equity Risk Premium: The Role of Technical Indicators","Neely, Christopher J. and Rapach, David E. and Tu, Jun and Zhou, Guofu","MANAGEMENT SCIENCE","60","7","1772-1791","2014","JUL","Equity Risk Premium Predictability;Macroeconomic Variables;Moving Averages;Momentum;Volume;Sentiment;Out-Of-Sample Forecasts;Asset Allocation;Business Cycle","","Academic research relies extensively on macroeconomic variables to forecast the U.S. equity risk premium, with relatively little attention paid to the technical indicators widely employed by practitioners. Our paper fills this gap by comparing the predictive ability of technical indicators with that of macroeconomic variables. Technical indicators display statistically and economically significant in-sample and out-of-sample predictive power, matching or exceeding that of macroeconomic variables. Furthermore, technical indicators and macroeconomic variables provide complementary information over the business cycle: technical indicators better detect the typical decline in the equity risk premium near business-cycle peaks, whereas macroeconomic variables more readily pick up the typical rise in the equity risk premium near cyclical troughs. Consistent with this behavior, we show that combining information from both technical indicators and macroeconomic variables significantly improves equity risk premium forecasts versus using either type of information alone. Overall, the substantial countercyclical fluctuations in the equity risk premium appear well captured by the combined information in technical indicators and macroeconomic variables."
1224,"Optimal Multiperiod Pricing with Service Guarantees","Borgs, Christian and Candogan, Ozan and Chayes, Jennifer and Lobel, Ilan and Nazerzadeh, Hamid","MANAGEMENT SCIENCE","60","7","1792-1811","2014","JUL","Dynamic Pricing;Strategic Customers;Nonlinear Programming;Dynamic Programming","","We study the multiperiod pricing problem of a service firm with capacity levels that vary over time. Customers are heterogeneous in their arrival and departure periods as well as valuations, and are fully strategic with respect to their purchasing decisions. The firm's problem is to set a sequence of prices that maximizes its revenue while guaranteeing service to all paying customers. We provide a dynamic programming based algorithm that computes the optimal sequence of prices for this problem in polynomial time. We show that due to the presence of strategic customers, available service capacity at a time period may bind the price offered at another time period. This phenomenon leads the firm to utilize the same price in multiple periods, in effect limiting the number of different prices that the service firm utilizes in optimal price policies. Also, when customers become more strategic ( patient for service), the firm offers higher prices. This may lead to the underutilization of capacity, lower revenues, and reduced customer welfare. We observe that the firm can combat this problem if it has an ability, beyond posted prices, to direct customers to different service periods."
1225,"The Judgment of Garbage: End-of-Pipe Treatment and Waste Reduction","Dutt, Nilanjana and King, Andrew A.","MANAGEMENT SCIENCE","60","7","1812-1828","2014","JUL","Waste Treatment;Environmental Management;Operations Design","","M any scholars have argued that systems for treating waste impede organizations from preventing waste in the first place. They theorize that end-of-pipe (EOP) treatment diminishes the incentive to avoid creating waste in the production process and obscures the information necessary to devise prevention techniques. This prediction has been widely accepted, influencing both policy and practice, despite both a lack of supporting empirical evidence and the existence of a counterprediction. In this paper, we use data describing U.S. manufacturing establishments from 1991 to 2005 to test the connection between EOP treatment and waste reduction. Our findings show that EOP treatment is associated with an initial jump in reported waste, followed by ongoing reduction. We analyze these results by exploring mechanisms that may drive this relationship. For practitioners, our paper provides critical guidance about strategies for reducing waste. For scholars of environmental management, our paper provides new insight on when facilities accomplish source reduction of process waste. For broader management theories of operations and organizational design, our analysis provides new insight on boundary conditions for extrapolation from existing theories. Finally, our paper provides new guidance for the formulation of effective regulatory policy."
1226,"Targeted Advertising in Magazine Markets and the Advent of the Internet","Chandra, Ambarish and Kaiser, Ulrich","MANAGEMENT SCIENCE","60","7","1829-1843","2014","JUL","Targeted Advertising;Magazines;Advertising Rates;Internet Complementarity;Multihoming","","T his paper examines how the ability of traditional media firms to engage in targeted advertising has changed with the advent of the Internet. We find that the premium for reaching a homogeneous audience increases for magazines that have a companion website, as well as for those whose readers are more likely to be online. This indicates a complementarity between offline and online channels with respect to targeted advertising. We hypothesize that this result is driven by multihoming consumers who enhance the value of targeted advertising, in contrast to the usual assumption that multiple advertising messages are redundant."
1227,"Eliciting Prospect Theory When Consequences Are Measured in Time Units: Time Is Not Money","Abdellaoui, Mohammed and Kemel, Emmanuel","MANAGEMENT SCIENCE","60","7","1844-1859","2014","JUL","Time Risk;Expected Utility;Prospect Theory;Reference Point;Utility;Probability Weighting","","We elicited the prospect theory components (utility, probability weighting, and loss aversion) when consequences are expressed as the time dedicated to a specific task or activity. A similar elicitation was performed for monetary consequences to allow an across-attribute (time/money) comparison of the elicited components (at the individual level). We obtained less concave utility and smaller loss aversion for time than for money. Moreover, while the probability weighting was predominantly inverse S-shaped for both attributes, it was less sensitive to probabilities and more elevated for time than for money. This finding implies more optimism for gains and more pessimism for losses."
1228,"Tie Strength, Embeddedness, and Social Influence: A Large-Scale Networked Experiment","Aral, Sinan and Walker, Dylan","MANAGEMENT SCIENCE","60","6, SI","1352-1370","2014","JUN","Peer Influence;Social Contagion;Social Networks;Viral Marketing;Information Systems;Randomized Experiment","","We leverage the newly emerging business analytical capability to rapidly deploy and iterate large-scale, microlevel, in vivo randomized experiments to understand how social influence in networks impacts consumer demand. Understanding peer influence is critical to estimating product demand and diffusion, creating effective viral marketing, and designing network interventions to promote positive social change. But several statistical challenges make it difficult to econometrically identify peer influence in networks. Though some recent studies use experiments to identify influence, they have not investigated the social or structural conditions under which influence is strongest. By randomly manipulating messages sent by adopters of a Facebook application to their 1.3 million peers, we identify the moderating effect of tie strength and structural embeddedness on the strength of peer influence. We find that both embeddedness and tie strength increase influence. However, the amount of physical interaction between friends, measured by coappearance in photos, does not have an effect. This work presents some of the first large-scale in vivo experimental evidence investigating the social and structural moderators of peer influence in networks. The methods and results could enable more effective marketing strategies and social policy built around a new understanding of how social structure and peer influence spread behaviors in society."
1229,"Simultaneously Discovering and Quantifying Risk Types from Textual Risk Disclosures","Bao, Yang and Datta, Anindya","MANAGEMENT SCIENCE","60","6, SI","1371-1391","2014","JUN","Topic Modeling;Latent Dirichlet Allocation;Text Analysis;Econometric Analysis;Risk Disclosures","","Managers and researchers alike have long recognized the importance of corporate textual risk disclosures. Yet it is a nontrivial task to discover and quantify variables of interest from unstructured text. In this paper, we develop a variation of the latent Dirichlet allocation topic model and its learning algorithm for simultaneously discovering and quantifying risk types from textual risk disclosures. We conduct comprehensive evaluations in terms of both conventional statistical fit and substantive fit with respect to the quality of discovered information. Experimental results show that our proposed method outperforms all competing methods, and could find more meaningful topics (risk types). By taking advantage of our proposed method for measuring risk types from textual data, we study how risk disclosures in 10-K forms affect the risk perceptions of investors. Different from prior studies, our results provide support for all three competing arguments regarding whether and how risk disclosures affect the risk perceptions of investors, depending on the specific risk types disclosed. We find that around two-thirds of risk types lack informativeness and have no significant influence. Moreover, we find that the informative risk types do not necessarily increase the risk perceptions of investors-the disclosure of three types of systematic and liquidity risks will increase the risk perceptions of investors, whereas the other five types of unsystematic risks will decrease them. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1930."
1230,"Path to Purchase: A Mutually Exciting Point Process Model for Online Advertising and Conversion","Xu, Lizhen and Duan, Jason A. and Whinston, Andrew","MANAGEMENT SCIENCE","60","6, SI","1392-1412","2014","JUN","Attribution Model;Online Advertising;Conversion;Mutually Exciting Point Process;Multivariate Stochastic Model;Search Advertisement;Display Advertisement;Business Analytics","","This paper studies the effects of various types of online advertisements on purchase conversion by capturing the dynamic interactions among advertisement clicks themselves. It is motivated by the observation that certain advertisement clicks may not result in immediate purchases, but they stimulate subsequent clicks on other advertisements, which then lead to purchases. We develop a novel model based on mutually exciting point processes, which consider advertisement clicks and purchases as dependent random events in continuous time. We incorporate individual random effects to account for consumer heterogeneity and cast the model in the Bayesian hierarchical framework. We construct conversion probability to properly evaluate the conversion effects of online advertisements. We develop simulation algorithms for mutually exciting point processes to compute the conversion probability and for out-of-sample prediction. Model comparison results show the proposed model outperforms the benchmark models that ignore exciting effects among advertisement clicks. Using a proprietary data set, we find that display advertisements have relatively low direct effect on purchase conversion, but they are more likely to stimulate subsequent visits through other advertisement formats. We show that the commonly used measure of conversion rate is biased in favor of search advertisements and underestimates the conversion effect of display advertisements the most. Our model also furnishes a useful tool to predict future purchases and advertisement clicks for the purpose of targeted marketing and customer relationship management."
1231,"An Empirical Analysis of Digital Music Bundling Strategies","Danaher, Brett and Huang, Yan and Smith, Michael D. and Telang, Rahul","MANAGEMENT SCIENCE","60","6, SI","1413-1433","2014","JUN","Information Goods;Bundling;Digital Music;Price Elasticity;Natural Experiment","","We use panel data on digital song and album sales coupled with a quasi-random price experiment to determine own- and cross-price elasticities for songs and albums. We then develop a structural model of consumer demand to estimate welfare under various policy relevant counterfactual scenarios. This approach represents an early application of the big data management paradigm within the media industries and provides managers with detailed guidance on optimal pricing and marketing strategies for digital music. Our results show that tiered pricing coupled with reduced album pricing increases revenue to the labels by 18% relative to uniform pricing policies traditionally preferred by digital marketplaces while also increasing consumer surplus by 23%. Thus, optimal tiered pricing can yield a Pareto improvement over the prior status quo. Additionally, our results indicate that even without tiered pricing, unbundling albums outperforms album-only pricing policies that dominated the era of physical CD/cassette sales."
1232,"Integration of Online and Offline Channels in Retail: The Impact of Sharing Reliable Inventory Availability Information","Gallino, Santiago and Moreno, Antonio","MANAGEMENT SCIENCE","60","6, SI","1434-1451","2014","JUN","Retail Operations;Inventory Availability;Empirical Operations Management;Business Analytics;Online Retail;Ecommerce","","Using a proprietary data set, we analyze the impact of the implementation of a buy-online, pick-up-in-store (BOPS) project. The implementation of this project is associated with a reduction in online sales and an increase in store sales and traffic. These results can be explained by two simultaneous phenomena: (1) additional store sales from customers who use the BOPS functionality and buy additional products in the stores (cross-selling effect) and (2) the shift of some customers from the online to the brick-and-mortar channel and the conversion of noncustomers into store customers (channel-shift effect). We explain these channel-shift patterns as an increase in research online, purchase offline behavior enabled by BOPS implementation, and we validate this explanation with evidence from the change of cart abandonment and conversion rates of the brick-and-mortar and online channels. We interpret these results in light of recent operations management literature that analyzes the impact of sharing inventory availability information. Our analysis illustrates the limitations of drawing conclusions about complex interventions using single-channel data."
1233,"Big Data Investment, Skills, and Firm Value","Tambe, Prasanna","MANAGEMENT SCIENCE","60","6, SI","1452-1469","2014","JUN","Information Systems;It Policy And Management;Economics Of Is;Strategic Management Of It;Management Of It Human Resources;Hadoop;Big Data;Business Analytics;Technical Skills;It Value;It Productivity;It Workforce","","This paper analyzes how labor market factors have shaped early returns on big data investment using a new data source-the LinkedIn skills database. The data source enables firm-level measurement of the employment of workers with technical skills such as Hadoop, MapReduce, and Apache Pig. From 2006 to 2011, Hadoop investments were associated with 3% faster productivity growth, but only for firms (a) with significant data assets and (b) in labor markets where similar investments by other firms helped to facilitate the development of a cadre of workers with complementary technical skills. The benefits of labor market concentration decline for investments in mature data technologies, such as Structured Query Language-based databases, for which the complementary skills can be acquired by workers through universities or other channels. These findings underscore the importance of geography, corporate investment, and skill acquisition channels for explaining productivity growth differences during the spread of new information technology innovations."
1234,"Estimating Demand for Mobile Applications in the New Economy","Ghose, Anindya and Han, Sang Pil","MANAGEMENT SCIENCE","60","6, SI","1470-1488","2014","JUN","Mobile Apps;Demand Estimation;Apple;Google;App Characteristics;In-App Purchases;In-App Advertising;Mobile Analytics;Mobile Marketing","","In 2013, the global mobile app market was estimated at over US$50 billion and is expected to grow to $150 billion in the next two years. In this paper, we build a structural econometric model to quantify the vibrant platform competition between mobile (smartphone and tablet) apps on the Apple iOS and Google Android platforms and estimate consumer preferences toward different mobile app characteristics. We find that app demand increases with the in-app purchase option wherein a user can complete transactions within the app. On the contrary, app demand decreases with the in-app advertisement option where consumers are shown ads while they are engaging with the app. The direct effects on app revenue from the inclusion of an in-app purchase option and an in-app advertisement option are equivalent to offering a 28% price discount and increasing the price by 8%, respectively. We also find that a price discount strategy results in a greater increase of app demand in Google Play compared with Apple App Store, and app developers can maximize their revenue by providing a 50% discount on their paid apps. Using the estimated demand function, we find that mobile apps have enhanced consumer surplus by approximately $33.6 billion annually in the United States, and we discuss various implications for mobile marketing analytics, app pricing, and app design strategies."
1235,"A General Multiple Distributed Lag Framework for Estimating the Dynamic Effects of Promotions","Kappe, Eelco and Blank, Ashley Stadler and DeSarbo, Wayne S.","MANAGEMENT SCIENCE","60","6, SI","1489-1510","2014","JUN","Distributed Lag Models;Dynamic Effects;Econometric Models;Major League Baseball;Promotions;Sports Marketing","","Game attendance resulting from ticket sales is the single largest revenue stream for Major League Baseball (MLB) teams. We propose a general multiple distributed lag framework following the Koyck family of models for estimating MLB attendance drivers and focus specifically on the differential direct and carryover effects of in-game promotions. By setting various model constraints, the proposed framework incorporates different forms of serial correlation and promotion-specific dynamic effects. Using information model-selection heuristics, we select an optimal model of attendance drivers for the Pittsburgh Pirates' 2010-2012 MLB seasons. We demonstrate that our newly proposed model with an unrestricted serial correlation structure performs best. We find that although kids promotions have the highest direct effect on attendance, giveaway and entertainment promotions have substantial carryover effects and the largest total effects. We use our results to optimize the Pirates' promotional schedule and find that a reallocation of resources across promotional categories can increase profits between 39% and 88%. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2013.1856."
1236,"On Theoretical and Empirical Aspects of Marginal Distribution Choice Models","Mishra, Vinit Kumar and Natarajan, Karthik and Padmanabhan, Dhanesh and Teo, Chung-Piaw and Li, Xiaobo","MANAGEMENT SCIENCE","60","6, SI","1511-1531","2014","JUN","Discrete Choice Model;Convex Optimization;Machine Learning;Applied Probability","","In this paper, we study the properties of a recently proposed class of semiparametric discrete choice models (referred to as the marginal distribution model (MDM)), by optimizing over a family of joint error distributions with prescribed marginal distributions. Surprisingly, the choice probabilities arising from the family of generalized extreme value models of which the multinomial logit model is a special case can be obtained from this approach, despite the difference in assumptions on the underlying probability distributions. We use this connection to develop flexible and general choice models to incorporate consumer and product level heterogeneity in both partworths and scale parameters in the choice model. Furthermore, the extremal distributions obtained from the MDM can be used to approximate the Fisher's information matrix to obtain reliable standard error estimates of the partworth parameters, without having to bootstrap the method. We use simulated and empirical data sets to test the performance of this approach. We evaluate the performance against the classical multinomial logit, mixed logit, and a machine learning approach that accounts for partworth heterogeneity. Our numerical results indicate that MDM provides a practical semiparametric alternative to choice modeling."
1237,"Real-Time Optimization of Personalized Assortments","Golrezaei, Negin and Nazerzadeh, Hamid and Rusmevichientong, Paat","MANAGEMENT SCIENCE","60","6, SI","1532-1551","2014","JUN","Personalization;Assortment Optimization;Choice Models;Online Algorithms","","Motivated by the availability of real-time data on customer characteristics, we consider the problem of personalizing the assortment of products for each arriving customer. Using actual sales data from an online retailer, we demonstrate that personalization based on each customer's location can lead to over 10% improvements in revenue compared to a policy that treats all customers the same. We propose a family of index-based policies that effectively coordinate the real-time assortment decisions with the back-end supply chain constraints. We allow the demand process to be arbitrary and prove that our algorithms achieve an optimal competitive ratio. In addition, we show that our algorithms perform even better if the demand is known to be stationary. Our approach is also flexible and can be combined with existing methods in the literature, resulting in a hybrid algorithm that brings out the advantages of other methods while maintaining the worst-case performance guarantees."
1238,"Business Analytics for Flexible Resource Allocation Under Random Emergencies","Angalakudati, Mallik and Balwani, Siddharth and Calzada, Jorge and Chatterjee, Bikram and Perakis, Georgia and Raad, Nicolas and Uichanco, Joline","MANAGEMENT SCIENCE","60","6, SI","1552-1573","2014","JUN","Resource Allocation;Stochastic Emergencies;Scheduling;Gas Pipeline Maintenance;Utility;Optimization","","In this paper, we describe both applied and analytical work in collaboration with a large multistate gas utility. The project addressed a major operational resource allocation challenge that is typical to the industry. We study the resource allocation problem in which some of the tasks are scheduled and known in advance, and some are unpredictable and have to be addressed as they appear. The utility has maintenance crews that perform both standard jobs (each must be done before a specified deadline) as well as respond to emergency gas leaks (that occur randomly throughout the day and could disrupt the schedule and lead to significant overtime). The goal is to perform all the standard jobs by their respective deadlines, to address all emergency jobs in a timely manner, and to minimize maintenance crew overtime. We employ a novel decomposition approach that solves the problem in two phases. The first is a job scheduling phase, where standard jobs are scheduled over a time horizon. The second is a crew assignment phase, which solves a stochastic mixed integer program to assign jobs to maintenance crews under a stochastic number of future emergencies. For the first phase, we propose a heuristic based on the rounding of a linear programming relaxation formulation and prove an analytical worst-case performance guarantee. For the second phase, we propose an algorithm for assigning crews that is motivated by the structure of an optimal solution. We used our models and heuristics to develop a decision support tool that is being piloted in one of the utility's sites. Using the utility's data, we project that the tool will result in a 55% reduction in overtime hours."
1239,"When Does the Devil Make Work? An Empirical Study of the Impact of Workload on Worker Productivity","Tan, Tom Fangyun and Netessine, Serguei","MANAGEMENT SCIENCE","60","6, SI","1574-1593","2014","JUN","Econometrics;Empirical Study On Staffing;Worker Productivity;Business Analytics;Restaurant Operations;Behavioral Operations Management;Quality/Speed Trade-Off","","we analyze a large, detailed operational data set from a restaurant chain to shed new light on how workload (defined as the number of tables or diners that a server simultaneously handles) affects servers' performance (measured as sales and meal duration). We use an exogenous shock-the implementation of labor scheduling software-and time-lagged instrumental variables to disentangle the endogeneity between demand and supply in this setting. We show that servers strive to maximize sales and speed efforts simultaneously, depending on the relative values of sales and speed. As a result, we find that, when the overall workload is small, servers expend more and more sales efforts with the increase in workload at a cost of slower service speed. However, above a certain workload threshold, servers start to reduce their sales efforts and work more promptly with the further rise in workload. In the focal restaurant chain, we find that this saturation point is currently not reached and, counterintuitively, the chain can reduce the staffing level and achieve both significantly higher sales (an estimated 3% increase) and lower labor costs (an estimated 17% decrease)."
1240,"Website Morphing 2.0: Switching Costs, Partial Exposure, Random Exit, and When to Morph","Hauser, John R. and Liberali, Guilherme (Gui) and Urban, Glen L.","MANAGEMENT SCIENCE","60","6, SI","1594-1616","2014","JUN","Automated Marketing;Bayesian Methods;Clickstream Analysis;Dynamic Programming;Internet Marketing;Optimization;Switching Costs;Website Design;Website Morphing","","Website morphing infers latent customer segments from clickstreams and then changes websites' look and feel to maximize revenue. The established algorithm infers latent segments from a preset number of clicks and then selects the best morph using expected Gittins indices. Switching costs, potential website exit, and all clicks prior to morphing are ignored. We model switching costs, potential website exit, and the (potentially differential) impact of all clicks to determine when to morph for each customer. Morphing earlier means more customer clicks are based on the optimal morph; morphing later reveals more about the customer's latent segment. We couple this within-customer optimization to between-customer expected Gittins index optimization to determine which website look and feel to give to each customer at each click. We evaluate the improved algorithm with synthetic data and with a proof-of-feasibility application to Japanese bank card loans. The proposed algorithm generalizes the established algorithm, is feasible in real time, performs substantially better when tuning parameters are identified from calibration data, and is reasonably robust to misspecification. Data, as supplemental material, are available at http://dx.doi.org/10.1287/mnsc.2014.1961."
1241,"Gender Interactions Within the Family Firm","Amore, Mario Daniele and Garofalo, Orsola and Minichilli, Alessandro","MANAGEMENT SCIENCE","60","5","1083-1097","2014","MAY","Female Ceos;Female Directors;Firm Performance","","We analyze whether gender interactions at the top of the corporate hierarchy affect corporate performance. Using a comprehensive data set of family-controlled firms in Italy, we find that female directors significantly improve the operating profitability of female-led companies. To mitigate endogeneity concerns, we assess executive transitions using a triple-difference approach complemented by propensity score matching and instrumental variables. Finally, we show that the positive effect of female interactions on profitability is reduced when the firm is located in geographic areas characterized by gender prejudices and when the firm is large."
1242,"Working Harder or Hardly Working? Posting Performance Eliminates Social Loafing and Promotes Social Laboring in Workgroups","Lount, Jr., Robert B. and Wilk, Steffanie L.","MANAGEMENT SCIENCE","60","5","1098-1106","2014","MAY","Organizational Studies;Effectiveness Performance;Motivation;Productivity","","The current paper examines how posting performance-an act that triggers increased social comparisons between workers-influences employees' motivation when working in groups. In the study, posting employee performance moderated the relationship between groupwork and employee motivation. When individual performance was publicly posted in the workplace, employees working in a group performed better than when working alone (i.e., social laboring); however, when individual performance was not posted, employees working in a group performed worse than when working alone (i.e., social loafing). The findings shed light on how social comparisons can have positive implications for employee performance in groups."
1243,"Rewarding Volunteers: A Field Experiment","Lacetera, Nicola and Macis, Mario and Slonim, Robert","MANAGEMENT SCIENCE","60","5","1107-1129","2014","MAY","Prosocial Behavior;Volunteer Organizations;Incentives;Field Experiments","","We conducted a field experiment with the American Red Cross (ARC) to study the effects of economic incentives on volunteer activities. The experiment was designed to assess local and short-term effects as well as spatial and temporal substitution, heterogeneity, and spillovers. Subjects offered $5, $10, and $15 gift cards to give blood were more likely to donate and more so for the higher reward values. The incentives also led to spatial displacement and a short-term shift in the timing of donation activity, but they had no long-term effects. Many of the effects were also heterogeneous in the population. We also detected a spillover effect whereby informing some individuals of rewards through official ARC channels led others who were not officially informed to be more likely to donate. Thus, the effect of incentives on prosocial behavior includes not only the immediate local effects but also spatial displacement, social spillovers, and dramatic heterogeneity. We discuss the implications of these findings for organizations with activities that rely on volunteers for the supply of key inputs or products as well as for government agencies and public policy."
1244,"Partnership Formation: The Role of Social Status","Bhattacharya, Haimanti and Dugar, Subhasish","MANAGEMENT SCIENCE","60","5","1130-1147","2014","MAY","Partnership;Status;Laboratory Experiment","","We experimentally test for the effect of social status on the likelihood of partnership formation. We consider a two-player game where the opportunity to perform a hidden action by one player may render partnership formation difficult. In this context, we study how the assignment of partners' status to the top, middle, or bottom position of a preexisting status hierarchy affects collaboration. We find that partnership formation is remarkably sensitive to the partners' status affiliations. Collaboration is easiest when both partners share the same social status, and the probability of partnership formation decreases significantly as the status gap between the partners increases, entailing massive inefficiency."
1245,"Crowding Out in the Labor Market: A Prosocial Setting Is Necessary","Hossain, Tanjim and Li, King King","MANAGEMENT SCIENCE","60","5","1148-1160","2014","MAY","Social Preference;Labor Supply;Crowding Out;Intrinsic And Extrinsic Motivations;Natural Field Experiment","","Recent studies, mostly from prosocial settings, suggest that monetary rewards may crowd out effort exertion by economic agents. We design a field experiment with data entry workers to investigate the extent of such crowding-out effects in a labor market. Using simple variations in the job description of a task, we induce a natural work setting under the work frame and emphasize social preference under the social frame. We find that crowding out of labor participation critically depends on framing-whereas small monetary rewards reduce the participation rate under the social frame, the participation rate is nondecreasing in the wage rate under the work frame. Moreover, among the workers who participate in the task, those who receive a positive wage perform a considerably higher amount of work than those who are paid zero wage under either frame. Thus, there is weak evidence of crowding out only when the task is explicitly given a prosocial flavor and not under a regular work setting. Furthermore, emphasizing social preference in the labor market in such a way reduces the overall labor supply and seems to have an adverse effect on the quality of work."
1246,"A Bayesian Semiparametric Approach for Endogeneity and Heterogeneity in Choice Models","Li, Yang and Ansari, Asim","MANAGEMENT SCIENCE","60","5","1161-1179","2014","MAY","Discrete Choice;Endogeneity;Semiparametric Bayesian;Centered Dirichlet Process Mixtures;Heterogeneity","","Marketing variables that are included in consumer discrete choice models are often endogenous. Extant treatments using likelihood-based estimators impose parametric distributional assumptions, such as normality, on the source of endogeneity. These assumptions are restrictive because misspecified distributions have an impact on parameter estimates and associated elasticities. The normality assumption for endogeneity can be inconsistent with some marginal cost specifications given a price-setting process, although they are consistent with other specifications. In this paper, we propose a heterogeneous Bayesian semiparametric approach for modeling choice endogeneity that offers a flexible and robust alternative to parametric methods. Specifically, we construct centered Dirichlet process mixtures (CDPM) to allow uncertainty over the distribution of endogeneity errors. In a similar vein, we also model consumer preference heterogeneity nonparametrically via a CDPM. Results on simulated data show that incorrect distributional assumptions can lead to poor recovery of model parameters and price elasticities, whereas the proposed semiparametric model is able to robustly recover the true parameters in an efficient fashion. In addition, the CDPM offers the benefits of automatically inferring the number of mixture components that are appropriate for a given data set and is able to reconstruct the shape of the underlying distributions for endogeneity and heterogeneity errors. We apply our approach to two scanner panel data sets. Model comparison statistics indicate the superiority of the semiparametric specification and the results show that parameter and elasticity estimates are sensitive to the choice of distributional forms. Moreover, the CDPM specification yields evidence of multimodality, skewness, and outlying observations in these real data sets."
1247,"Measuring the Performance of Large-Scale Combinatorial Auctions: A Structural Estimation Approach","Kim, Sang Won and Olivares, Marcelo and Weintraub, Gabriel Y.","MANAGEMENT SCIENCE","60","5","1180-1201","2014","MAY","Combinatorial Auctions;Procurement;Empirical;Structural Estimation;Auction Design;Public Sector Applications","","The main advantage of a procurement combinatorial auction (CA) is that it allows suppliers to express cost synergies through package bids. However, bidders can also strategically take advantage of this flexibility, by discounting package bids and inflating bid prices for single items, even in the absence of cost synergies; the latter behavior can hurt the performance of the auction. It is an empirical question whether allowing package bids and running a CA improves performance in a given setting. In this paper, we develop a structural estimation approach that estimates the firms' cost structure using bidding data and use these estimates to evaluate the performance of the auction. To overcome the computational difficulties arising from the large number of bids observed in large-scale CAs, we propose a novel simplified model of bidders' behavior based on pricing package characteristics. We apply our method to the Chilean school meals auction, in which the government procures half a billion dollars' worth of meal services every year and bidders submit thousands of package bids. Our estimates suggest that bidders' cost synergies are economically significant in this application (similar to 5%), and the current CA mechanism achieves high allocative efficiency (similar to 98%) and reasonable margins for the bidders (similar to 5%). Overall, this work develops the first practical tool to evaluate the performance of large-scale first-price CAs commonly used in procurement settings."
1248,"Managing Global Sourcing: Inventory Performance","Jain, Nitish and Girotra, Karan and Netessine, Serguei","MANAGEMENT SCIENCE","60","5","1202-1222","2014","MAY","Global Sourcing;Inventory Performance;Imports;Supply Diversification;Sourcing Strategy;Empirical Analysis;Panel Data","","The use of global suppliers has increased considerably over the last three decades. Operations management theory establishes that global sourcing requires more units of inventory, but since these units are often procured at a lower cost from global suppliers the capital invested in inventory and the consequent financial burden may increase or decrease with global sourcing. This study provides rigorous firm-level empirical evidence that links the global sourcing practices of public U. S. firms and their inventory investments. We process bill of lading manifests (customs forms) to extract information on over half a million sea shipments from global suppliers to U. S. public firms and link this information with quarterly financial data from the Compustat database. We provide stylized facts on the participation of different firms and sectors in global trade. Using a simultaneous equation model, we find that an increase in global sourcing results in an increase in inventory investment. A 10% shift in sourcing from domestic to global suppliers increases the inventory investment by 8.8% for an average firm in our sample. We also find that increasing the number of suppliers can mitigate this increase in inventory investment: for example, going from single to dual sourcing reduces inventory investment by about 11%. We illustrate the use of our estimates to identify the impact of changing global sourcing strategy on inventory investment and operational performance metrics."
1249,"Home or Overseas? An Analysis of Sourcing Strategies Under Competition","Wu, Xiaole and Zhang, Fuqiang","MANAGEMENT SCIENCE","60","5","1223-1240","2014","MAY","Offshoring;Backshoring;Sourcing Strategy;Cournot Competition;Supply Responsiveness;Information Correlation","","Motivated by the recent backshoring trend, this paper studies a sourcing game where competing firms may choose between efficient sourcing (e. g., sourcing from overseas) and responsive sourcing (e. g., sourcing from a home country). Efficient sourcing usually provides a cost advantage, whereas responsive sourcing allows a firm to obtain more accurate demand information when making procurement decisions. By characterizing the equilibrium outcome, we find some interesting results driven by the strategic interaction between the firms. First, a firm may still use efficient sourcing in equilibrium even when the cost advantage associated with efficient sourcing does not exist. This is because the firm can dampen competition by reducing the correlation between its own demand information and the competitor's. Second, a cost hike in efficient sourcing (e. g., the rising labor cost in Asia) may benefit all the firms in the industry. The reason is that the cost hike may alleviate competition by inducing a new equilibrium sourcing structure. This paper also sheds some light on the recent backshoring trend. First, our analysis indicates that more firms will shift from efficient sourcing to responsive sourcing in equilibrium (i.e., backshore) if the market size shrinks, the demand becomes more volatile, or the sourcing costs rise simultaneously. Second, a firm's backshoring behavior reduces the competition on the cost dimension, but it also has an ambiguous informational impact on the other firms in the market. In particular, some firms may benefit from increased correlation of their demand information under Cournot competition with substitutable products. Overall, the backshoring behavior can be beneficial to all the firms sticking to their original sourcing strategies under certain conditions."
1250,"Dynamic Pricing of Perishable Assets Under Competition","Gallego, Guillermo and Hu, Ming","MANAGEMENT SCIENCE","60","5","1241-1259","2014","MAY","Revenue Management;Oligopoly;Dynamic Pricing;Open-Loop;Feedback Strategy;Differential Game;Stochastic Game;Approximate Dynamic Programming","","We study dynamic price competition in an oligopolistic market with a mix of substitutable and complementary perishable assets. Each firm has a fixed initial stock of items and competes in setting prices to sell them over a finite sales horizon. Customers sequentially arrive at the market, make a purchase choice, and then leave immediately with some likelihood of no purchase. The purchase likelihood depends on the time of purchase, product attributes, and current prices. The demand structure includes time-variant linear and multinomial logit demand models as special cases. Assuming deterministic customer arrival rates, we show that any equilibrium strategy has a simple structure, involving a finite set of shadow prices measuring capacity externalities that firms exert on each other: equilibrium prices can be solved from a one-shot price competition game under the current-time demand structure, taking into account capacity externalities through the time-invariant shadow prices. The former reflects the transient demand side at every moment, and the latter captures the aggregate supply constraints over the sales horizon. This simple structure sheds light on dynamic revenue management problems under competition, which helps capture the essence of the problems under demand uncertainty. We show that the equilibrium solutions from the deterministic game provide precommitted and contingent heuristic policies that are asymptotic equilibria for its stochastic counterpart, when demand and supply are sufficiently large."
1251,"Inside Debt and the Design of Corporate Debt Contracts","Anantharaman, Divya and Fang, Vivian W. and Gong, Guojin","MANAGEMENT SCIENCE","60","5","1260-1280","2014","MAY","Executive Compensation;Inside Debt;Debt-Like Compensation;Debt Contracting","","Theory posits that managerial holdings of debt (inside debt) align managers' incentives with those of outside debtholders. Executive pensions, consisting of rank-and-file (RAF) plans and supplemental executive retirement plans (SERPs), and other deferred compensation (ODC) have debt-like payoffs, and could therefore function as inside debt. However, whereas SERPs are often unfunded and unsecured, RAF plans are funded and secured to some extent, and ODC may be invested in equity and withdrawn flexibly before retirement. Special arrangements in executive debt-like compensation could hence weaken or even nullify any incentive-alignment effect. We find that higher CEO debt-like compensation leads to lower promised yield and fewer covenants in a sample of loans originated in 2006-2008. This effect is driven entirely by benefits accrued under SERPs, consistent with SERPs more closely resembling risky corporate debt; balances accrued under RAF and ODC plans do not provide similar effects. Furthermore, promised yields are lower when debt-like compensation claims can be withdrawn only after outside debt claims are expected to settle. Our findings persist after accounting for endogeneity using state personal income tax rates as an instrument for CEOs' willingness to defer compensation. Overall, the evidence suggests that executive debt-like compensation is only effective at resolving stockholder-debtholder conflicts when its payoffs are truly debt-like and that lenders' perceptions are affected not only by the magnitude of debt-like compensation but also by its seniority."
1252,"Economic Uncertainty, Disagreement, and Credit Markets","Buraschi, Andrea and Trojani, Fabio and Vedolin, Andrea","MANAGEMENT SCIENCE","60","5","1281-1296","2014","MAY","Credit Risk;Credit Spreads;Heterogeneous Beliefs;Uncertainty","","We study how the equilibrium risk sharing of agents with heterogeneous perceptions of aggregate consumption growth affects bond and stock returns. Although credit spreads and their volatilities increase with the degree of heterogeneity, the decreasing risk premium on moderately levered equity can produce a violation of basic capital structure no-arbitrage relations. Using bottom-up proxies of aggregate belief dispersion, we give empirical support to the model predictions and show that risk premia on corporate bond and stock returns are systematically explained by their exposures to aggregate disagreement shocks."
1253,"Investment Banks' Entry into New IPO Markets and IPO Underpricing","Fung, Simon Yu Kit and Gul, Ferdinand A. and Radhakrishnan, Suresh","MANAGEMENT SCIENCE","60","5","1297-1316","2014","MAY","Ipo Underpricing;Market Share;Investment Banks;Hong Kong","","We examine the relationship between investment banks' initial public offering (IPO) market shares and their prior IPO underpricing in the new IPO market for China-based companies on the Hong Kong Stock Exchange. To gain expertise in Chinese business practices, investment banks have the incentive to obtain business in this new IPO market by providing high offer prices to the issuer, leading to less underpricing and less money on the table. We hypothesize and find that the less an investment bank underprices China-based company IPOs, the greater its subsequent market share of China-based company IPOs in the Hong Kong Stock Exchange. Furthermore, this relationship is driven by a bank's initial China-based company IPO deals. These results suggest that in new IPO markets, investment banks' initial market shares, obtained through lower underpricing, help them grow their market shares in later periods, possibly through the expertise gained in the initial business."
1254,"A Branch-and-Cut Method for Dynamic Decision Making Under Joint Chance Constraints","Zhang, Minjiao and Kucukyavuz, Simge and Goel, Saumya","MANAGEMENT SCIENCE","60","5","1317-1333","2014","MAY","Chance Constraints;Branch-And-Cut;Multistage;Probabilistic Lot Sizing;Service Levels","","In this paper, we consider a finite-horizon stochastic mixed-integer program involving dynamic decisions under a constraint on the overall performance or reliability of the system. We formulate this problem as a multistage (dynamic) chance-constrained program, whose deterministic equivalent is a large-scale mixed-integer program. We study the structure of the formulation and develop a branch-and-cut method for its solution. We illustrate the efficacy of the proposed model and method on a dynamic inventory control problem with stochastic demand in which a specific service level must be met over the entire planning horizon. We compare our dynamic model with a static chance-constrained model, a dynamic risk-averse optimization model, a robust optimization model, and a pseudo-dynamic approach and show that significant cost savings can be achieved at high service levels using our model."
1255,"Observation Bias: The Impact of Demand Censoring on Newsvendor Level and Adjustment Behavior","Rudi, Nils and Drake, David","MANAGEMENT SCIENCE","60","5","1334-1345","2014","MAY","Inventory Management;Behavioral Operations;Decision Analysis","","In an experimental newsvendor setting, we investigate three phenomena: level behavior-the decision maker's average ordering tendency; adjustment behavior-the tendency to adjust period-to-period order quantities; and observation bias-the tendency to let the degree of demand feedback influence order quantities. We find that, in three of four conditions, the portion of mismatch cost that results from adjustment behavior exceeds the portion of mismatch cost caused by level behavior. Observation bias is studied through censored demand feedback, a situation that arguably represents most newsvendor settings. When demands are uncensored, subjects tend to order below the normative quantity when they face high margin and above the normative quantity when they face low margin, but in neither case do they order beyond mean demand (the pull-to-center effect). Censoring in general leads to lower quantities, magnifying the below-normative-level behavior when they face high margin but partially counterbalancing the above-normative-level behavior when they face low margin, violating the pull-to-center effect in both cases."
1256,"Will the Global Village Fracture Into Tribes? Recommender Systems and Their Effects on Consumer Fragmentation","Hosanagar, Kartik and Fleder, Daniel and Lee, Dokyun and Buja, Andreas","MANAGEMENT SCIENCE","60","4","805-823","2014","APR","Information Systems;Electronic Commerce;Recommendation Systems;Collaborative Filtering;Filter Bubble","","Personalization is becoming ubiquitous on the World Wide Web. Such systems use statistical techniques to infer a customer's preferences and recommend content best suited to him (e.g., Customers who liked this also liked ...). A debate has emerged as to whether personalization has drawbacks. By making the Web hyperspecific to our interests, does it fragment Internet users, reducing shared experiences and narrowing media consumption? We study whether personalization is in fact fragmenting the online population. Surprisingly, it does not appear to do so in our study. Personalization appears to be a tool that helps users widen their interests, which in turn creates commonality with others. This increase in commonality occurs for two reasons, which we term volume and product-mix effects. The volume effect is that consumers simply consume more after personalized recommendations, increasing the chance of having more items in common. The product-mix effect is that, conditional on volume, consumers buy a more similar mix of products after recommendations."
1257,"Who Lives in the C-Suite? Organizational Structure and the Division of Labor in Top Management","Guadalupe, Maria and Li, Hongyi and Wulf, Julie","MANAGEMENT SCIENCE","60","4","824-844","2014","APR","Communication;Organizational Design;Functions;Centralization;M-Form;Hierarchy;Top Management Team;C-Suite;Information Technology;Activities;Diversification","","Top management structures in large U.S. firms have changed significantly since the mid-1980s. The size of the executive team-the group of managers reporting directly to the CEO-doubled during this period. This growth was driven primarily by an increase in functional managers rather than general managers, a phenomenon we term functional centralization. Using panel data on senior management positions, we show that changes in the structure of the executive team are tightly linked to changes in firm diversification and information technology investments. These relationships depend crucially on the function involved; those closer to the product (product functions, e.g., marketing and R&D) behave differently from functions further from the product (administrative functions, e.g., finance, law, and human resources). We argue that this distinction is driven by differences in the information-processing activities associated with each function and apply this insight to refine and extend existing theories of centralization. We also discuss the implications of our results for organizational forms beyond the executive team."
1258,"From the Horse's Mouth: Economic Conditions and Investor Expectations of Risk and Return","Amromin, Gene and Sharpe, Steven A.","MANAGEMENT SCIENCE","60","4","845-866","2014","APR","Investor Sentiment;Expected Stock Returns;Portfolio Choice;Asset Pricing","","Data obtained from monthly Gallup/UBS surveys from 1998 to 2007 and from a special supplement to the Michigan Surveys of Consumer Attitudes and Behavior, run in 22 monthly surveys between 2000 and 2005, are used to analyze stock market beliefs and portfolio choices of household investors. We show that the key variables found to be positive predictors of actual stock returns in the asset-pricing literature are also highly correlated with investor's subjective expected returns, but with the opposite sign. Moreover, our analysis of the microdata indicates that subjective expectations of both risk and returns on stocks are strongly influenced by perceptions of economic conditions. In particular, when investors believe macroeconomic conditions are more expansionary, they tend to expect both higher returns and lower volatility. This is difficult to reconcile with the canonical view that expected returns on stocks rise during recessions to compensate household investors for increased exposure or sensitivity to macroeconomic risks. Finally, the relevance of these investors' subjective expectations is supported by the finding of a significant link between their expectations and portfolio choices. In particular, we show that portfolio equity positions tend to be higher for those respondents that anticipate higher expected returns or lower uncertainty."
1259,"Entrepreneurial Exits and Innovation","Aggarwal, Vikas A. and Hsu, David H.","MANAGEMENT SCIENCE","60","4","867-887","2014","APR","Entrepreneurial Exits;Innovation;Information Confidentiality","","We examine how initial public offerings (IPOs) and acquisitions affect entrepreneurial innovation as measured by patent counts and forward patent citations. We construct a firm-year panel data set of all venture capital-backed biotechnology firms founded between 1980 and 2000, tracked yearly through 2006. We address the possibility of unobserved self-selection into exit mode by using coarsened exact matching, and in two additional ways: (1) comparing firms that filed for an IPO (or announced a merger) with those not completing the transaction for reasons unrelated to innovation, and (2) using an instrumental variables approach. We find that innovation quality is highest under private ownership and lowest under public ownership, with acquisition intermediate between the two. Together with a set of within-exit mode analyses, these results are consistent with the proposition that information confidentiality mechanisms shape innovation outcomes. The results are not explained by inventor-level turnover following exit events or by firms' preexit window dressing behavior."
1260,"Do Private Equity Returns Result from Wealth Transfers and Short-Termism? Evidence from a Comprehensive Sample of Large Buyouts","Harford, Jarrad and Kolasinski, Adam","MANAGEMENT SCIENCE","60","4","888-902","2014","APR","Finance;Corporate Finance;Private Equity;Leveraged Buyouts","","We test whether the well-documented high returns of private equity sponsors result from wealth transfers from other financial claimants and counterparties and from a focus on short-term profits at the expense of long-term value. Debt investors who finance buyouts, as well as buyers of private equity portfolio companies, represent the two potential sources of wealth transfers. However, we find that, on average, public companies benefit when they buy financial sponsors' portfolio companies, experiencing positive abnormal returns upon the announcement of the acquisition and long-run posttransaction abnormal returns indistinguishable from zero. We further find that large portfolio company payouts to private equity on average have no relation to future portfolio company distress, suggesting that debt investors are not suffering systematic wealth losses either. However, we find some evidence of wealth transfers from both strategic buyers and debt investors in some special situations. Finally, we find that portfolio companies invest no differently than a matched sample of public control firms, even when they are not profitable, an observation inconsistent with short-termism."
1261,"Dynamics of Consumer Adoption of Financial Innovation: The Case of ATM Cards","Yang, Botao and Ching, Andrew T.","MANAGEMENT SCIENCE","60","4","903-922","2014","APR","Financial Innovation;Adoption Costs;Atm Cards;Cash Demand Model;Consumer Life-Cycle Model;Limited Time Promotional Offer;Permanent Promotional Offer;Dynamic Programming","","We develop a structural consumer life-cycle model to investigate consumers' adoption and usage decisions of ATM cards. If consumers are forward-looking with a known discount factor, our framework can control for the heterogeneous life span faced by consumers of different ages, and hence measure adoption costs more accurately. Moreover, our framework can recover the monetary value of total adoption costs. To estimate our model, we use an Italian panel data set, which contains information on consumers' adoption decisions for ATM cards, and their cash withdrawal patterns before and after adoption. Our results suggest that one could significantly overestimate adoption costs for the elderly when ignoring their shorter life span. Our policy experiments show that a sign-up bonus targeted to the elderly could be much more effective if implemented as a limited-time offer rather than a permanent offer. Interestingly, if the sign-up bonus is permanent, younger consumers may strategically postpone adoption."
1262,"Fast or Rational? A Response-Times Study of Bayesian Updating","Achtziger, Anja and Alos-Ferrer, Carlos","MANAGEMENT SCIENCE","60","4","923-938","2014","APR","Belief Updating;Dual Processes;Reinforcement;Response Times","","We present a simple model for decision making under uncertainty building on dual-process theories from psychology, and use it to illustrate a possible component of intuitive decision making of particular relevance for managerial settings. Decisions are the result of the interaction between two decision processes. The first one captures optimization based on Bayesian updating of beliefs. The second corresponds to a form of reinforcement learning capturing the tendency to rely on past performance. The model predicts that (i) in the case of conflict between the two processes, correct responses are associated with longer response times, but (ii) if both processes are aligned, errors are slower. Furthermore, (iii) response times in the case of conflict are longer than in the case of alignment. We confirm the predictions of the model in an experiment using a paradigm where an associative win-stay, lose-shift process conflicted with rational belief updating."
1263,"Do Individuals Have Preferences Used in Macro-Finance Models? An Experimental Investigation","Brown, Alexander L. and Kim, Hwagyun","MANAGEMENT SCIENCE","60","4","939-958","2014","APR","Finance;Portfolio;Utility-Preference;Microeconomics: Intertemporal Choice;Experimental Economics","","Recent financial studies often assume that agents have Epstein-Zin preferences-preferences that require agents to care about when uncertainty is resolved. Under this recursive-preference framework, the preference for uncertainty resolution is entirely determined by an agent's preferences for risk and intertemporal substitution. To test the implications of this model, this paper presents an experiment designed to elicit subject preferences on risk, time, intertemporal substitution, and uncertainty resolution. Results reveal that most subjects prefer early resolution of uncertainty and have relative risk aversion greater than the reciprocal of the elasticity of intertemporal substitution, consistent with the predictions by recursive preferences. Subjects are classified in a finite mixture model by their risk, time, and intertemporal-substitution parameters. Regression results show that types predicted by the Epstein-Zin model to prefer early resolution choose early resolution with 20%-50% higher probability."
1264,"Can Analysts Analyze Mergers?","Tehranian, Hassan and Zhao, Mengxing and Zhu, Julie L.","MANAGEMENT SCIENCE","60","4","959-979","2014","APR","Merger And Acquisition;Analyst Coverage;Forecast Accuracy;Merger Performance","","After the completion of a merger and acquisition (M&A) transaction, the target firm is delisted, but some analysts who covered it retain coverage of the merged firm. We hypothesize that this decision is based on two factors: the analyst's ability to cover the merged firm and his or her assessment of the M&A deal. Consistent with these hypotheses, we find that the remaining target analysts provide more accurate earnings forecasts and more optimistic stock recommendations and growth forecasts for the merged firms than do the remaining acquirer analysts. We also find that a higher percentage of target analysts choosing to cover the merged firm is associated with better operating and long-term stock performance of that firm, but we do not find this relation with acquirer analysts. Our results extend the literature by showing that target analysts' coverage decisions reveal valuable information about a merged firm's future performance."
1265,"How Do Firms Become Different? A Dynamic Model","Selove, Matthew","MANAGEMENT SCIENCE","60","4","980-989","2014","APR","Marketing;New Products;Product Policy;Competitive Strategy","","This paper presents a dynamic investment game in which firms that are initially identical develop assets that are specialized to different market segments. The model assumes that there are increasing returns to investment in a segment, for example, as a result of word-of-mouth or learning curve effects. I derive three key results: (1) Under certain conditions there is a unique equilibrium in which firms that are only slightly different focus all of their investment in different segments, causing small random differences to expand into large permanent differences. (2) If, on the other hand, sufficiently large random shocks are possible, firms over time repeatedly change their strategies, switching focus from one segment to another. (3) A firm might want to reduce its own assets in the smaller segment in order to entice its competitor to shift focus to this segment."
1266,"Should Sellers Prefer Auctions? A Laboratory Comparison of Auctions and Sequential Mechanisms","Davis, Andrew M. and Katok, Elena and Kwasnica, Anthony M.","MANAGEMENT SCIENCE","60","4","990-1008","2014","APR","Behavioral Operations Management;Auctions;Experimental Economics;Behavioral Mechanism Design","","When bidders incur a cost to learn their valuations, bidder entry can impact auction performance. Two common selling mechanisms in this environment are an English auction and a sequential bidding process. Theoretically, sellers should prefer the auction, because it generates higher expected revenues, whereas bidders should prefer the sequential mechanism, because it generates higher expected bidder profits. We compare the two mechanisms in a controlled laboratory environment, varying the entry cost, and find that, contrary to the theoretical predictions, average seller revenues tend to be higher under the sequential mechanism, whereas average bidder profits are approximately the same. We identify three systematic behavioral deviations from the theoretical model: (1) in the auction, bidders do not enter 100% of the time; (2) in the sequential mechanism, bidders do not set preemptive bids according to the predicted threshold strategy; and (3) subsequent bidders tend to overenter in response to preemptive bids by first bidders. We develop a model of noisy bidder-entry costs that is consistent with these behaviors, and we show that our model organizes the experimental data well."
1267,"A Branch and Bound Algorithm for a Class of Biobjective Mixed Integer Programs","Stidsen, Thomas and Andersen, Kim Allan and Dammann, Bernd","MANAGEMENT SCIENCE","60","4","1009-1032","2014","APR","Biobjective Optimization;Integer Programming;Branch And Bound","","Most real-world optimization problems are multiobjective by nature, involving noncomparable objectives. Many of these problems can be formulated in terms of a set of linear objective functions that should be simultaneously optimized over a class of linear constraints. Often there is the complicating factor that some of the variables are required to be integral. The resulting class of problems is named multiobjective mixed integer programming (MOMIP) problems. Solving these kinds of optimization problems exactly requires a method that can generate the whole set of nondominated points (the Pareto-optimal front). In this paper, we first give a survey of the newly developed branch and bound methods for solving MOMIP problems. After that, we propose a new branch and bound method for solving a subclass of MOMIP problems, where only two objectives are allowed, the integer variables are binary, and one of the two objectives has only integer variables. The proposed method is able to find the full set of nondominated points. It is tested on a large number of problem instances, from six different classes of MOMIP problems. The results reveal that the developed biobjective branch and bound method performs better on five of the six test problems, compared with a generic two-phase method. At this time, the two-phase method is the most preferred exact method for solving MOMIP problems with two criteria and binary variables."
1268,"Analysis of Product Rollover Strategies in the Presence of Strategic Customers","Liang, Chao and Cakanyildirim, Metin and Sethi, Suresh P.","MANAGEMENT SCIENCE","60","4","1033-1056","2014","APR","Product Rollover;Strategic Customers;Product Cannibalization;Dynamic Pricing","","Frequent product introductions emphasize the importance of product rollover strategies. With single rollover, when a new product is introduced, the old product is phased out from the market. With dual rollover, the old product remains in the market along with the new product. Anticipating the introduction of the new product and the potential markdown of the old product, strategic customers may delay their purchases. We study the interaction between product rollover strategies and strategic customer purchasing behavior and find that single rollover is more valuable when the new product's innovation is low and the number of strategic customers is high. Interestingly and counter to intuition, the firm may have to charge a lower price for the old product as well as receive a lower profit with a higher value disposal (outside) option for the old product under single rollover. Facing a market composed of both strategic and myopic customers, the firm does not necessarily reduce the stocking level as more myopic customers become strategic."
1269,"Prospect Theory and the Newsvendor Problem","Nagarajan, Mahesh and Shechter, Steven","MANAGEMENT SCIENCE","60","4","1057-1062","2014","APR","Prospect Theory;Newsvendor Problem;Risk Preference","","The newsvendor problem is a fundamental decision problem in operations management. Various independent experimental studies in laboratory settings have shown similar deviations from the theoretical optimal order quantity. We clarify that Prospect Theory, a prevalent framework for decision making under uncertainty, cannot explain the consistent empirical findings."
1270,"Integrating Problem Solvers from Analogous Markets in New Product Ideation","Franke, Nikolaus and Poetz, Marion K. and Schreier, Martin","MANAGEMENT SCIENCE","60","4","1063-1081","2014","APR","Open Innovation;Distant Search;Exploration;Problem Solving;New Product Development;Analogical Transfer;Analogy;Creativity","","Who provides better inputs to new product ideation tasks, problem solvers with expertise in the area for which new products are to be developed or problem solvers from analogous markets that are distant but share an analogous problem or need? Conventional wisdom appears to suggest that target market expertise is indispensable, which is why most managers searching for new ideas tend to stay within their own market context even when they do search outside their firms' boundaries. However, in a unique symmetric experiment that isolates the effect of market origin, we find evidence for the opposite: Although solutions provided by problem solvers from analogous markets show lower potential for immediate use, they demonstrate substantially higher levels of novelty. Also, compared to established novelty drivers, this effect appears highly relevant from a managerial perspective: we find that including problem solvers from analogous markets versus the target market accounts for almost two-thirds of the well-known effect of involving lead users instead of average problem solvers. This effect is further amplified when the analogous distance between the markets increases, i.e., when searching in far versus near analogous markets. Finally, results indicate that the analogous market effect is particularly strong in the upper tail of the novelty distribution, which again underscores the effect's practical importance. All of this suggests that it might pay to systematically search across firm-external sources of innovation that were formerly out of scope for most managers."
1271,"Optimal Software Reuse in Incremental Software Development: A Transfer Pricing Approach","Ceran, Yasin and Dawande, Milind and Liu, Dengpan and Mookerjee, Vijay","MANAGEMENT SCIENCE","60","3","541-559","2014","MAR","Software Reuse;Transfer Pricing;Information Asymmetry;Conflict Resolution","","This study develops optimal transfer pricing schemes that manage software reuse in incremental software development, namely, a development regime wherein users begin utilizing parts of the system that are released to them even before the system is entirely completed. In this setting, conflicts can arise between developers and users from divergent interests concerning the release of functionalities in the project. The release of functionalities is influenced by reuse, i.e., the effort spent by the development team to write code that can be reused within the same project or in future projects. For example, the development team may choose to spend extra effort to make certain portions of the system reusable because doing so could reduce the effort needed to develop the entire system. However, the additional effort spent on reuse could delay the release of certain critical functionality, making such a strategy suboptimal for the users. Thus, optimal reuse decisions for developers and users could be different. In addition, from the firm's perspective, reuse decisions must not only balance the objectives of developers and users for the current project, but reuse effort may be spent to benefit future projects. Our study also highlights the fact that reuse may not always be beneficial for the firm. To this end, we consider different instances of the user-developer conflict and provide transfer pricing schemes that operate under information asymmetry and achieve two key properties: firm-level optimality and truth revelation."
1272,"Don't Ask Me If You Will Not Listen: The Dilemma of Consultative Participation","Corgnet, Brice and Hernan Gonzalez, Roberto","MANAGEMENT SCIENCE","60","3","560-585","2014","MAR","Organizational Behavior;Participative Decision Making;Principal-Agent Model","","We study the effect of consultative participation in an experimental principal-agent game, where the principal can consult the agent's preferred option regarding the cost function of the transfer to be implemented in the final stage of the game. We show that consulting the agent was beneficial to principals as long as they followed the agent's choice. Ignoring the agent's choice was detrimental to the principal because it engendered negative emotions and low levels of transfers. Nevertheless, the majority of principals were reluctant to change their mind and adopt the agent's proposal. Our results suggest that the ability to change one's own mind is an important dimension of managerial success."
1273,"Relationship Organization and Price Delegation: An Experimental Study","Lim, Noah and Ham, Sung H.","MANAGEMENT SCIENCE","60","3","586-605","2014","MAR","Sales Management;Experimental Economics;Behavioral Economics;Price Delegation","","Price delegation to the salesforce is a practice widely adopted by firms. This paper examines the relationship between price delegation and managerial profits using a laboratory economics experiment. A novel feature of our experiment is that we study how varying the relationship organization of the sales manager and salesperson to allow for (1) requests by the salesperson for the manager to choose price delegation, and for (2) the manager to award a small bonus after observing the salesperson's decisions, can affect behavior. The results show that, contrary to the theoretical prediction, managers choose price delegation frequently and salespeople respond reciprocally, leading to higher manager profits under price delegation. Moreover, this behavior increases when requests and bonuses are allowed. We show that a behavioral economics model that incorporates positive reciprocity can explain these results well."
1274,"Optimal Design of Social Comparison Effects: Setting Reference Groups and Reference Points","Roels, Guillaume and Su, Xuanming","MANAGEMENT SCIENCE","60","3","606-627","2014","MAR","Social Comparisons;Reference Points;Behavioral Operations;Noncooperative Game Theory","","In this paper, we study how social planners should exploit social comparisons to pursue their objectives. We consider two modes of social comparison, referred to as behind-averse and ahead-seeking behaviors, depending on whether individuals experience a utility loss from underperforming or a utility gain from overperforming relative to their peers. Modeling social comparison as a game between players, we find that ahead-seeking behavior leads to output polarization, whereas behind-averse behavior leads to output clustering. A social planner can mitigate these effects in two ways: (i) by providing the full reference distribution of outputs instead of an aggregate reference point based on the average output and (ii) by assigning players into uniform rather than diverse reference groups. Social planners may thus need to tailor the reference structure to the predominant mode of social comparison and their objective. A performance-focused social planner may set the reference structure so as to maximize the output of either the top or the bottom player depending on whether she puts greater marginal weight to larger or smaller outputs. When the social planner also cares about utility, she faces a dilemma because performance optimization may not be aligned with utility maximization. Inevitably, the social planner will have to confront equity issues because better performance may not reflect greater effort or greater ability."
1275,"The Effect of Giving It All Up on Valuation: A New Look at the Endowment Effect","Schurr, Amos and Ritov, Ilana","MANAGEMENT SCIENCE","60","3","628-637","2014","MAR","Endowment Effect;Loss Aversion;Reference Dependence;End State","","In three experiments we show that the endowment effect-the tendency to demand more money for relinquishing owned goods than one is willing to pay for the same goods-fails to emerge when sellers are not fully depleted of their endowment. This finding is incompatible with prospect theory's account of the effect as stemming primarily from aversion to loss relative to the individual's current state. We suggest a new account of the endowment effect as reflecting the human aversion to giving it all up rather than simply an aversion to incurring any loss relative to the status quo. Experiments 1 and 2 show the effect employing a pricing paradigm. Experiment 3 examines what constitutes all in the giving-it-all-up effect."
1276,"Outsourcing Information Security: Contracting Issues and Security Implications","Cezar, Asunur and Cavusoglu, Huseyin and Raghunathan, Srinivasan","MANAGEMENT SCIENCE","60","3","638-657","2014","MAR","Outsourcing;Information Security;Contracting;Managed Security Service Providers;It Security Services","","A unique challenge in information security outsourcing is that neither the outsourcing firm nor the managed security service provider (MSSP) perfectly observes the outcome, the occurrence of a security breach, of prevention effort. Detection of security breaches often requires specialized effort. The current practice is to outsource both prevention and detection to the same MSSP. Some security experts have advocated outsourcing prevention and detection to different MSSPs. We show that the former outsourcing contract leads to a significant disincentive to provide detection effort. The latter contract alleviates this problem but introduces misalignment of incentives between the firm and the MSSPs and eliminates the advantages offered by complementarity between prevention and detection functions, which may lead to a worse outcome than the current contract. We propose a new contract that is superior to these two on various dimensions."
1277,"A Closer Look at the Short-Term Return Reversal","Da, Zhi and Liu, Qianqiu and Schaumburg, Ernst","MANAGEMENT SCIENCE","60","3","658-674","2014","MAR","Short-Term Return Reversal;Liquidity;Sentiment;Fundamental News","","Stock returns unexplained by fundamentals, such as cash flow news, are more likely to reverse in the short run than those linked to fundamental news. Making novel use of analyst forecast revisions to measure cash flow news, a simple enhanced reversal strategy generates a risk-adjusted return four times the size of the standard reversal strategy. Importantly, isolating the component of past returns not driven by fundamentals provides a cleaner setting for testing existing theories of short-term reversals. Using this approach, we find that both liquidity shocks and investor sentiment contribute to the observed short-term reversal, but in different ways: Specifically, the reversal profit is attributable to liquidity shocks on the long side because fire sales more likely demand liquidity, and it is attributable to investor sentiment on the short side because short-sale constraints prevent the immediate elimination of overvaluation."
1278,"Informed Bond Trading, Corporate Yield Spreads, and Corporate Default Prediction","Han, Song and Zhou, Xing","MANAGEMENT SCIENCE","60","3","675-694","2014","MAR","Corporate Bond Yield Spreads;Information Asymmetry;Information Risk Premium;Credit Risk;Corporate Default Prediction","","Taking advantage of recently augmented corporate bond transaction data, we examine the pricing implications of informed trading in corporate bonds and its ability to predict corporate defaults. We find that microstructure measures of information asymmetry seem to capture adverse selection in corporate bond trading reasonably well. We demonstrate that information asymmetry in bond trading has explanatory power for corporate bond yield spreads, and this result holds after controlling for the transaction costs of liquidity, credit risk, and other traditional bond pricing factors. Furthermore, information asymmetry can help forecast corporate defaults after conditioning on other default prediction variables. Such forecasting ability of informed bond trading is especially useful for private firms because the bond market constitutes the only venue for informed traders to exploit their information advantages."
1279,"Entropy-Based Optimization of Nonlinear Separable Discrete Decision Models","Nakagawa, Yuji and James, Ross J. W. and Rego, Cesar and Edirisinghe, Chanaka","MANAGEMENT SCIENCE","60","3","695-707","2014","MAR","Multidimensional Nonlinear Knapsack;Separable Discrete Optimization;Combinatorial Optimization;Surrogate Constraints;Problem Difficulty Estimation;Entropy","","This paper develops a new way to help solve difficult linear and nonlinear discrete-optimization decision models more efficiently by introducing a problem-difficulty metric that uses the concept of entropy from information theory. Our entropy metric is employed to devise rules for problem partitioning within an implicit enumeration method, where branching is accomplished based on the subproblem complexity. The only requirement for applying our metric is the availability of (upper) bounds on branching subproblems, which are often computed within most implicit enumeration methods such as branch-and-bound (or cutting-plane-based) methods. Focusing on problems with a relatively small number of constraints, but with a large number of variables, we develop a hybrid partitioning and enumeration solution scheme by combining the entropic approach with the recently developed improved surrogate constraint (ISC) method to produce the new method we call ISCENT. Our computational results indicate that ISCENT can be an order of magnitude more efficient than commercial solvers, such as CPLEX, for convex instances with no more than eight constraints. Furthermore, for nonconvex instances, ISCENT is shown to be significantly more efficient than other standard global solvers."
1280,"Resource Flexibility and Capital Structure","Chod, Jiri and Zhou, Jianer","MANAGEMENT SCIENCE","60","3","708-729","2014","MAR","Flexibility;Capacity;Leverage;Capital Structure;Agency;Asset Substitution;Underinvestment","","This paper examines how the optimal investment in the capacity of flexible and nonflexible resources is affected by financial leverage and, conversely, how a firm's resource flexibility affects its optimal capital structure. We consider a two-product firm that invests in the optimal capacity of product-flexible and product-dedicated resources in the presence of demand uncertainty. Before investing in capacity, the firm issues the optimal amount of debt, trading off the tax benefit and lower transaction cost of debt financing against the cost of financial distress and the agency cost associated with leverage. We show that in the presence of debt, resource flexibility has benefits in addition to reducing the mismatch between supply and demand. Namely, resource flexibility mitigates the shareholder-debtholder agency conflict as well as the risk of costly default. Most interestingly, we show that resource flexibility mitigates the underinvestment problem because it reduces the probability that a firm will go bankrupt with some of its capacity being fully utilized. When lenders anticipate that a firm will choose a relatively flexible capacity mix, they should provide more favorable credit terms, to which the firm should respond by issuing more debt. The main empirical predictions are that resource flexibility is negatively related to the cost of borrowing and positively related to debt."
1281,"Pricing and Revenue Management: The Value of Coordination","Kocabiyikoglu, Ayse and Popescu, Ioana and Stefanescu, Catalina","MANAGEMENT SCIENCE","60","3","730-752","2014","MAR","Revenue Management;Pricing;Coordination;Price-Sensitive Stochastic Demand;Hierarchical Policies;Lost Sales Rate Elasticity","","The integration of systems for pricing and revenue management must trade off potential revenue gains against significant practical and technical challenges. This dilemma motivates us to investigate the value of coordinating decisions on prices and capacity allocation in a stylized setting. We propose two pairs of sequential policies for making static decisions-on pricing and revenue management-that differ in their degree of integration (hierarchical versus coordinated) and their pricing inputs (deterministic versus stochastic). For a large class of stochastic, price-dependent demand models, we prove that these four heuristics admit tractable solutions satisfying intuitive sensitivity properties. We further evaluate numerically the performance of these policies relative to a fully coordinated model, which is generally intractable. We find it interesting that near-optimal performance is usually achieved by a simple hierarchical policy that sets prices first, based on a nonnested stochastic model, and then uses these prices to optimize nested capacity allocation. This tractable policy largely outperforms its counterpart based on a deterministic pricing model. Jointly optimizing price and allocation decisions for the high-end segment improves performance, but the largest revenue benefits stem from adjusting prices to account for demand risk."
1282,"Equilibrium Discovery and Preopening Mechanisms in an Experimental Market","Biais, Bruno and Bisiere, Christophe and Pouget, Sebastien","MANAGEMENT SCIENCE","60","3","753-769","2014","MAR","Cheap Talk;Experimental Markets;Equilibrium Discovery;Preopening Period;Preplay Communication","","We experimentally analyze how to design preopening mechanisms facilitating coordination on high equilibrium liquidity and gains from trade. We allow a call auction to be preceded by a preopening or not, preopening orders to be binding or not, and the opening time to be deterministic or random. When the preopening is nonbinding, traders place manipulative orders, reducing the credibility of preplay communication. Random market opening deters manipulation, but also hinders communication by making it costly. Gains from trade are maximized when preopening orders are binding. This enables some traders to place early limit orders, attracting further liquidity."
1283,"Simultaneously Learning and Optimizing Using Controlled Variance Pricing","den Boer, Arnoud V. and Zwart, Bert","MANAGEMENT SCIENCE","60","3","770-783","2014","MAR","Dynamic Pricing;Sequential Decision Problems;Statistical Learning","","Price experimentation is an important tool for firms to find the optimal selling price of their products. It should be conducted properly, since experimenting with selling prices can be costly. A firm, therefore, needs to find a pricing policy that optimally balances between learning the optimal price and gaining revenue. In this paper, we propose such a pricing policy, called controlled variance pricing (CVP). The key idea of the policy is to enhance the certainty equivalent pricing policy with a taboo interval around the average of previously chosen prices. The width of the taboo interval shrinks at an appropriate rate as the amount of data gathered gets large; this guarantees sufficient price dispersion. For a large class of demand models, we show that this procedure is strongly consistent, which means that eventually the value of the optimal price will be learned, and derive upper bounds on the regret, which is the expected amount of money lost due to not using the optimal price. Numerical tests indicate that CVP performs well on different demand models and time scales."
1284,"Product Line Design with Seller-Induced Learning","Xiong, Hui and Chen, Ying-Ju","MANAGEMENT SCIENCE","60","3","784-795","2014","MAR","Product Line Design;Consumer Uncertainty;Dynamic Mechanism Design;Seller-Induced Learning","","In practice, some well-established service providers (sellers) offer one-time experiences or product demonstrations for the services that have been introduced to the market for years. Such activities, labeled as seller-induced learning, not only help the consumers learn more about themselves but also exploit the consumers by elaborating on the consumer heterogeneity. When the seller-induced learning completely resolves the consumers' valuation uncertainty, it can facilitate a more sophisticated price discrimination scheme and may give rise to a relatively more efficient allocation. Nevertheless, if there is residual valuation uncertainty, the seller may abandon the seller-induced learning to avoid the exacerbated ex post cannibalization. We show that an exploding offer shall sometimes be offered in conjunction with the seller-induced learning to encourage immediate purchases when uncertainty arises in only some consumers. We identify regimes under which the seller-induced learning is charged at a strictly positive price. Under these regimes, the seller need not sacrifice the ex post efficiency upon inducing consumer learning. Therefore, our result indicates that the seller-induced learning may eliminate the conflict between rent extraction and efficiency initiatives. However, quality distortion prevails when the seller provides an identical menu for all the consumers or the free seller-induced learning."
1285,"On Portfolio Choice with Savoring and Disappointment","Jouini, Elyes and Karehnke, Paul and Napp, Clotilde","MANAGEMENT SCIENCE","60","3","796-804","2014","MAR","Endogenous Beliefs;Anticipatory Feelings;Disappointment;Optimism;Portfolio Choice;Skewness;Underdiversification","","We revisit the model proposed by Gollier and Muermann [Gollier C, Muermann A (2010) Optimal choice and beliefs with ex ante savoring and ex post disappointment. Management Sci. 56(8): 1272-1284; hereafter, GM]. In the GM model, for a given lottery, agents form anticipated expected payoffs and the set of possible anticipations is assumed to be exogenously fixed. We propose sets of possible anticipations that are endogenously determined. This permits us to compare and evaluate in a consistent manner lotteries with different supports and to revisit the portfolio choice problem. We obtain new conclusions and interesting insights. Our extended model can rationalize a variety of empirically observed puzzles such as a positive demand for assets with negative expected returns, preference for skewed returns, and underdiversification of portfolios."
1286,"Broadband in School: Impact on Student Performance","Belo, Rodrigo and Ferreira, Pedro and Telang, Rahul","MANAGEMENT SCIENCE","60","2","265-282","2014","FEB","Broadband;School;Education;Instrumental Variables","","This paper examines the effects of providing broadband to schools on students' performance. We use a rich panel of data on broadband use and students' grades from all middle schools in Portugal. Employing a first-differences specification to control for school-specific unobserved effects and instrumenting the quality of broadband to account for unobserved time-varying effects, we show that high levels of broadband use in schools were detrimental for grades on the ninth-grade national exams in Portugal. For the average broadband use in schools, grades reduced 0.78 of a standard deviation from 2005 to 2009. We also show that broadband has a negative impact on exam scores regardless of gender, subject, or school quality and that the way schools allow students to use the Internet affects their performance. In particular, students in schools that block access to websites such as YouTube perform relatively better."
1287,"Holding the Hunger Games Hostage at the Gym: An Evaluation of Temptation Bundling","Milkman, Katherine L. and Minson, Julia A. and Volpp, Kevin G. M.","MANAGEMENT SCIENCE","60","2","283-299","2014","FEB","Commitment Devices;Temptation Bundling;Self-Control;Field Experiment;Exercise","","We introduce and evaluate the effectiveness of temptation bundling-a method for simultaneously tackling two types of self-control problems by harnessing consumption complementarities. We describe a field experiment measuring the impact of bundling instantly gratifying but guilt-inducing want experiences (enjoying page-turner audiobooks) with valuable should behaviors providing delayed rewards (exercising). We explore whether such bundles increase should behaviors and whether people would pay to create these restrictive bundles. Participants were randomly assigned to a full treatment condition with gym-only access to tempting audio novels, an intermediate treatment involving encouragement to restrict audiobook enjoyment to the gym, or a control condition. Initially, full and intermediate treatment participants visited the gym 51% and 29% more frequently, respectively, than control participants, but treatment effects declined over time (particularly following Thanksgiving). After the study, 61% of participants opted to pay to have gym-only access to iPods containing tempting audiobooks, suggesting demand for this commitment device."
1288,"Investor Flows and the 2008 Boom/Bust in Oil Prices","Singleton, Kenneth J.","MANAGEMENT SCIENCE","60","2","300-318","2014","FEB","Economics;Econometric Dynamics;Finance;Asset Pricing;Forecasting;Time Series","","This paper explores the impact of investor flows and financial market conditions on returns in crude oil futures markets. I argue that informational frictions and the associated speculative activity may induce prices to drift away from fundamental values, and may result in price booms and busts. Particular attention is given to the interplay between imperfect information about real economic activity, including supply, demand, and inventory accumulation, and speculative activity in oil markets. Furthermore, I present new evidence that there were economically and statistically significant effects of investor flows on futures prices, after controlling for returns in the United States and emerging-economy stock markets, a measure of the balance sheet flexibility of large financial institutions, open interest, the futures/spot basis, and lagged returns on oil futures. The largest impacts on futures prices were from intermediate-term growth rates of index positions and managed-money spread positions. Moreover, my findings suggest that these effects were through risk or informational channels distinct from changes in convenience yield. Finally, the evidence suggests that hedge fund trading in spread positions in futures impacted the shape of term structure of oil futures prices."
1289,"Governance and CEO Turnover: Do Something or Do the Right Thing?","Fisman, Raymond J. and Khurana, Rakesh and Rhodes-Kropf, Matthew and Yim, Soojin","MANAGEMENT SCIENCE","60","2","319-337","2014","FEB","Corporate Finance;Management;Organizational Studies;Decision Making;Ceo Turnover;Governance;Entrenchment;Entrenched Ceos","","We study how corporate governance affects firm value through the decision of whether to fire or retain the chief executive officer (CEO). We present a model in which weak governance-which prevents shareholders from controlling the board-protects inferior CEOs from dismissal, while at the same time insulates the board from pressures by biased or uninformed shareholders. Whether stronger governance improves retain/replace decisions depends on which of these effects dominates. We use our theoretical framework to assess the effect of governance on the quality of firing and hiring decisions using data on the CEO dismissals of large U.S. corporations during 1994-2007. Our findings are most consistent with a beneficent effect of weak governance on CEO dismissal decisions, suggesting that insulation from shareholder pressure may allow for better long-term decision making."
1290,"Job Hopping, Information Technology Spillovers, and Productivity Growth","Tambe, Prasanna and Hitt, Lorin M.","MANAGEMENT SCIENCE","60","2","338-355","2014","FEB","It Spillovers;Labor Mobility;General-Purpose Technologies;High-Tech Clusters;Regional Growth;Productivity;It Labor;It Value","","The movement of information technology (IT) workers among firms is believed to be an important mechanism by which IT-related innovations diffuse throughout the economy. We use a newly developed source of employee microdata-an online resume database-to model IT workers' mobility patterns. We find that firms derive significant productivity benefits from the IT investments of other firms from which they hire IT labor. Our estimates indicate that over the last two decades, productivity spillovers from the IT investments of other firms transmitted through this channel have contributed 20%-30% as much to productivity growth as firms' own IT investments. Moreover, we find that the productivity benefits of locating near other IT-intensive firms can primarily be explained by the mobility of technical workers within the region. Our results are unique to the flow of IT workers among firms, not other occupations, which rules out some alternative explanations related to the similarity of firms that participate in the same labor flow network."
1291,"Horizontal Mergers in Multitier Decentralized Supply Chains","Cho, Soo-Haeng","MANAGEMENT SCIENCE","60","2","356-379","2014","FEB","Cournot Oligopoly;Horizontal Merger;Operating Synergy;Supply Chain Competition","","The well-known economic theory predicts that consumer price will fall after a horizontal merger when the amount of marginal cost reduction from operating synergies exceeds the premerger markup of a merging firm. However, when a horizontal merger occurs in a multitier decentralized supply chain where a finite number of firms compete at each tier, we show that this result holds only when a merger occurs at the tier that acts as the leader in the supply chain. In this supply chain, a horizontal merger at any other tier will decrease consumer price when the cost reduction exceeds a certain threshold that is larger than the premerger markup. Moreover, this threshold is increasing as the supply chain gets longer and can be substantially larger than the premerger markup. When accounting for subsequent entry after a merger in long-run equilibrium, contrary to a common belief, a larger synergy from a merger does not necessarily benefit consumers more."
1292,"How Do Industry Peers Respond to Control Threats?","Servaes, Henri and Tamayo, Ane","MANAGEMENT SCIENCE","60","2","380-399","2014","FEB","Hostile Takeover;Agency Costs;Investment Decisions;Capital Structure","","This paper studies how industry peers respond when another firm in the industry is the subject of a hostile takeover attempt. The industry peers cut their capital spending, free cash flows, and cash holdings, and increase their leverage and payouts to shareholders. They also adopt more takeover defenses. The stock price reaction upon announcement of the takeover is positive and larger for peer firms with higher capital spending and higher free cash flows. Before the takeover attempt, the peer firms borrow less and invest more than predicted. Both stock returns and performance improve after the takeover attempt. These results are consistent with the argument that the control threat has important spillover effects for the other firms in the industry."
1293,"Turn-and-Earn Incentives with a Product Line","Cohen-Vernik, Dinah A. and Purohit, Devavrat","MANAGEMENT SCIENCE","60","2","400-414","2014","FEB","Supply Chain;Game Theory;Inventory Allocation","","When manufacturers do not have sufficient capacity to meet demand and cannot increase prices, they have to determine other methods to allocate goods among retailers. A common allocation mechanism is based on a retailer's sales history: a retailer that has ordered larger quantities in the past should get a greater allocation than a retailer that has historically ordered smaller quantities. This mechanism, known as a turn-and-earn allocation rule, is commonly used in many industries such as automobiles, microprocessors, video game consoles, etc. The existing literature has considered the effect of turn-and-earn allocation rules when a manufacturer sells a single product. However, when we consider a product line, it is not clear whether the manufacturer is better off basing its allocation on the sales history of the entire product line or solely on the sales history of the product in short supply. In particular, a shortage of one product can lead retailers and consumers to move toward other products in the line. This, in turn, can have an effect on the manufacturer's optimal allocation mechanism. We examine this issue by developing a model of a supplier selling two substitutable goods through two retailers. Within this setup, we introduce a general turn-and-earn allocation rule that allows the entire sales history to influence allocation levels. Counter to previous work, we show that certain turn-and-earn rules not only help the manufacturer but can also help the retailer and increase total supply chain profits."
1294,"Managing Retention in Service Relationships","Aflaki, Sam and Popescu, Ioana","MANAGEMENT SCIENCE","60","2","415-433","2014","FEB","Service Relationships;Retention;Customer Satisfaction;Service Quality;Lifetime Value Optimization","","In a repeat business context, past experiences with a service provider affect customers' decisions to renew their contract. How should a strategic firm manage customized service over time to maximize the long-term value from each customer relationship? We propose a dynamic model that relies on behavioral theories and empirical evidence to capture the effect of past service experiences on service quality expectations, customer satisfaction, and retention. Although firms can benefit from managing service expectations at the beginning of a relationship, we find that varying service in the long run is not optimal. Behavioral regularities explain the structure of optimal service policies and limit the value of responsive service. Loss aversion expands the range of optimal constant policies; however, if satisfying experiences are more salient, then firms should constantly vary service levels. Loyal or high-margin customers need not warrant better service; those who anchor less on past service experiences do-provided that retention is improved by better past experiences. The effect of customer memory on service levels is determined by whether habituation or rather goodwill drives defection decisions."
1295,"Gender Differences in Willingness to Guess","Baldiga, Katherine","MANAGEMENT SCIENCE","60","2","434-448","2014","FEB","Economics;Behavior;Behavioral Decision Making;Microeconomic Behavior;Education Systems","","We present the results of an experiment that explores whether women are less willing than men to guess on multiple-choice tests. Our test consists of practice questions from SAT II history tests; we vary whether a penalty is imposed for a wrong answer and the salience of the evaluative nature of the task. We find that when no penalty is assessed for a wrong answer, all test takers answer every question. But, when there is a penalty for wrong answers, women answer significantly fewer questions than men. We see no differences in knowledge of the material or confidence in the test takers, and differences in risk preferences explain less than half of the observed gap. Making the evaluative aspect of the test more salient does not impact the gender gap. We show that, conditional on their knowledge of the material, test takers who skip questions do significantly worse on our test."
1296,"Supplier Encroachment Under Asymmetric Information","Li, Zhuoxin and Gilbert, Stephen M. and Lai, Guoming","MANAGEMENT SCIENCE","60","2","449-462","2014","FEB","Direct And Indirect Channel;Information Asymmetry;Supplier Encroachment","","Prior literature has shown that, for a symmetric information setting, supplier encroachment into a reseller's market can mitigate double marginalization and benefit both the supplier and the reseller. This paper extends the investigation of supplier encroachment to the environment where the reseller might be better informed than the supplier. We find that the launch of the supplier's direct channel can result in costly signaling behavior on the part of the reseller, in which he reduces his order quantity when the market size is small. Such a downward order distortion can amplify double marginalization. As a result, in addition to the win-win and win-lose outcomes for the supplier and the reseller, supplier encroachment can also lead to lose-lose and lose-win outcomes, particularly when the reseller has a significant efficiency advantage in the selling process and the prior probability of a large market is low. We further explore the implications of those findings for information management in supply chains. Complementing the conventional understanding, we show that with the ability to encroach, the supplier may prefer to sell to either a better informed or an uninformed reseller in different scenarios. On the other hand, as a result of a supplier developing encroachment capability, a reseller either may choose not to develop an advanced informational capability or may become more willing to find a means of credibly sharing his information."
1297,"Trimmed Opinion Pools and the Crowd's Calibration Problem","Jose, Victor Richmond R. and Grushka-Cockayne, Yael and Lichtendahl, Jr., Kenneth C.","MANAGEMENT SCIENCE","60","2","463-475","2014","FEB","Trimming;Probability Forecasts;Expert Combination;Linear Opinion Pool;Underconfidence;Overconfidence;Scoring Rules;Wisdom Of Crowds;Diversity","","We introduce an alternative to the popular linear opinion pool for combining individual probability forecasts. One of the well-known problems with the linear opinion pool is that it can be poorly calibrated. It tends toward underconfidence as the crowd's diversity increases, i.e., as the variance in the individuals' means increases. To address this calibration problem, we propose the exterior-trimmed opinion pool. To form this pool, forecasts with low and high means, or cumulative distribution function (cdf) values, are trimmed away from a linear opinion pool. Exterior trimming decreases the pool's variance and improves its calibration. A linear opinion pool, however, will remain overconfident when individuals are overconfident and not very diverse. For these situations, we suggest trimming away forecasts with moderate means or cdf values. This interior trimming increases variance and reduces overconfidence. Using probability forecast data from U.S. and European Surveys of Professional Forecasters, we present empirical evidence that trimmed opinion pools can outperform the linear opinion pool."
1298,"Responses to Entry in Multi-Sided Markets: The Impact of Craigslist on Local Newspapers","Seamans, Robert and Zhu, Feng","MANAGEMENT SCIENCE","60","2","476-493","2014","FEB","Multi-Sided Markets;Entry Responses;Craigslist;Newspaper Industry","","How do firms respond to entry in multi-sided markets? We address this question by studying the impact of Craigslist, a website providing classified-advertising services, on local U.S. newspapers. We exploit temporal and geographical variation in Craigslist's entry to show that newspapers with greater reliance on classified-ad revenue experience a larger drop in classified-ad rates after Craigslist's entry. The impact of Craigslist's entry on the classified-ad side appears to propagate to other sides of the newspapers' market. On the subscriber side, these newspapers experience an increase in subscription prices, a decrease in circulation, and an increase in differentiation from each other. On the display-ad side, affected newspapers experience a decrease in display-ad rates. We also find evidence that affected newspapers are less likely to make their content available online. Finally, we estimate that Craigslist's entry leads to $5.0 billion (year 2000 dollars) in savings to classified-ad buyers during 2000-2007."
1299,"The Strategic Value of High-Cost Customers","Subramanian, Upender and Raju, Jagmohan S. and Zhang, Z. John","MANAGEMENT SCIENCE","60","2","494-507","2014","FEB","Competitive Strategy;Customer Lifetime Value;Customer Profitability;Customer Relationship Management;Dynamic Competition;Price Discrimination;Game Theory","","Many firms today manage their existing customers differentially based on profit potential, providing fewer incentives to less profitable customers and firing unprofitable customers. Although researchers and industry experts advocate this practice, results have been mixed. We examine this practice explicitly accounting for competition and find that some conventional prescriptions may not always hold. We analyze a setting where customers differ in their cost to serve. We find that when a firm can discriminate among its customers but the rival cannot, customer base composition influences the rival's poaching behavior. Consequently, even though a low-cost customer is more profitable when viewed in isolation, a high-cost customer may be strategically more valuable by discouraging poaching. Therefore, contrary to conventional advice, it can be profitable for a firm to retain unprofitable customers. Moreover, some customers may become more valuable to retain and receive better incentives when they are less profitable. We further show that, in competitive settings, traditional customer lifetime value metrics may lead to poor retention decisions because they do not account for the competitive externality that actions toward some customers impose on the cash flows from other customers. Our results suggest that firms may need to evolve from a segmentation mindset, which views each customer in isolation, to a customer portfolio mindset, which recognizes that the value of different customers is interlinked."
1300,"Financial Product Differentiation over the State Space in the Mutual Fund Industry","Li, Shujing and Qiu, Jiaping","MANAGEMENT SCIENCE","60","2","508-520","2014","FEB","Mutual Fund Styles;Product Differentiation;Market Share;Fee;Stochastic","","By distancing themselves from others in risk factor loadings, mutual funds yield distinct returns and become better-performing funds in different market situations. This enables mutual funds to obtain stochastic market power and charge higher fees than they could otherwise. This strategy fundamentally differs from the conventional market segmentation strategy that targets investors with heterogeneous preferences. We present a model to study this novel form of financial product differentiation over the states of nature. Empirically, we find that the return attributable to risk factor loadings has a significant impact on a fund's market share. Fund fees are related to the positions of their factor loadings in the industry and funds with more extreme risk factor loadings charge higher fees."
1301,"Forward-Looking Market Risk Premium","Duan, Jin-Chuan and Zhang, Weiqi","MANAGEMENT SCIENCE","60","2","521-538","2014","FEB","Risk Premium;Forward Looking;Garch;Options;Volatility Spread;Skewness;Kurtosis","","A method for computing forward-looking market risk premium is developed in this paper. We first derive a theoretical expression that links forward-looking risk premium to investors' risk aversion and forward-looking volatility, skewness, and kurtosis of cumulative return. In addition, investors' risk aversion is theoretically linked to volatility spread, defined as the gap between the risk- neutral volatility deduced from option data and the physical return volatility exhibited by return data. The volatility spread formula serves as the basis for using the generalized method of moments to estimate investors' risk aversion. We adopt the generalized autoregressive conditional heteroskedasticity model for the physical return process and estimate the model using the S&P 500 daily index returns and then deduce the forward-looking variance, skewness, and kurtosis of the corresponding cumulative return. The forward-looking risk premiums are estimated monthly over the sample period of 2001-2010, and all are found to be positive. Furthermore, two asset pricing tests are conducted. First, change in forward-looking risk premiums is negatively related to the S&P 500 holding period return, reflecting that an increase in discount rate reduces current stock prices. Second, market illiquidity positively affects forward-looking risk premium, indicating that forward-looking risk premium contains an illiquidity risk premium component."
1302,"Analyst Recommendations, Mutual Fund Herding, and Overreaction in Stock Prices","Brown, Nerissa C. and Wei, Kelsey D. and Wermers, Russ","MANAGEMENT SCIENCE","60","1","1-20","2014","JAN","Mutual Fund Herding;Analyst Recommendations;Return Reversals;Managerial Myopia","","This paper documents that mutual funds herd (trade together) into stocks with consensus sell-side analyst upgrades, and herd out of stocks with consensus downgrades. This influence of analyst recommendation changes on fund herding is stronger for downgrades, and among managers with greater career concerns. These findings indicate that career-concerned managers are incentivized to follow analyst information, and that managers have a greater tendency to herd on negative stock information, given the greater reputational and litigation risk of holding losing stocks. Furthermore, starting in the mid-1990s (when aggregate mutual fund equity ownership is significantly higher), stocks traded by career-concerned herds of fund managers in response to analyst recommendation changes experience a significant same-quarter price impact, followed by a sharp subsequent price reversal. Our evidence suggests that analyst recommendation revisions induce herding by career-concerned fund managers, and that this type of trading has become price destabilizing with the increasing level of mutual fund ownership of stocks."
1303,"Celebrity Endorsements, Firm Value, and Reputation Risk: Evidence from the Tiger Woods Scandal","Knittel, Christopher R. and Stango, Victor","MANAGEMENT SCIENCE","60","1","21-37","2014","JAN","Celebrity Endorsers;Event Studies;Reputation Risk","","We estimate the stock market effects of the Tiger Woods scandal on his sponsors and sponsors' competitors. In the 10-15 trading days after the onset of the scandal, the full portfolio of sponsors lost more than 2% of market value, with losses concentrated among the core three sponsors: Electronic Arts, Nike, and PepsiCo (Gatorade). Sponsors' day-by-day losses correlate strongly with Google search intensity regarding the endorsement-related impact of the scandal, as well as with qualitative indicators of endorsement-related news. At least some sponsors' losses were competitors' gains, suggesting that endorsement deals are partially a business-stealing strategy. However, competitors who were themselves celebrity endorsement intensive fared relatively worse than those who were not endorsement intensive, and that difference also correlates day by day with news/search intensity regarding the scandal. It appears that the scandal sent a negative marketwide signal about the reputation risk associated with celebrity endorsements."
1304,"The Dark Side of Competition for Status","Charness, Gary and Masclet, David and Villeval, Marie Claire","MANAGEMENT SCIENCE","60","1","38-55","2014","JAN","Status;Ranking;Feedback;Sabotage;Doping;Competitive Preferences;Experiment","","Unethical behavior within organizations is not rare. We investigate experimentally the role of status-seeking behavior in sabotage and cheating activities aiming at improving one's performance ranking in a flat-wage environment. We find that average effort is higher when individuals are informed about their relative performance. However, ranking feedback also favors disreputable behavior. Some individuals do not hesitate to incur a cost to improve their rank by sabotaging others' work or by increasing artificially their own performance. Introducing sabotage opportunities has a strong detrimental effect on performance. Therefore, ranking incentives should be used with care. Inducing group identity discourages sabotage among peers but increases in-group rivalry."
1305,"Television Advertising and Online Search","Joo, Mingyu and Wilbur, Kenneth C. and Cowgill, Bo and Zhu, Yi","MANAGEMENT SCIENCE","60","1","56-73","2014","JAN","Advertising;Information Search;Media;Search Engine Marketing;Television","","Despite a 20-year trend toward integrated marketing communications, advertisers seldom coordinate television and search advertising campaigns. We find that television advertising for financial services brands increases both the number of related Google searches and searchers' tendency to use branded keywords in place of generic keywords. The elasticity of a brand's total searches with respect to its TV advertising is 0.17, an effect that peaks in the morning. These results suggest that practitioners should account for cross-media effects when planning, executing, and evaluating both television and search advertising campaigns."
1306,"Onshore and Offshore Hedge Funds: Are They Twins?","Aragon, George and Liang, Bing and Park, Hyuna","MANAGEMENT SCIENCE","60","1","74-91","2014","JAN","Offshore Hedge Funds;Lockup Provision;Liquidity Risk;Master-Feeder Structure","","Contrary to offshore hedge funds, U.S.-domiciled (onshore) funds are subject to strict marketing prohibitions, accredited investor requirements, a limited number of investors, and taxable accounts. We exploit these differences to test predictions about organizational design, investment strategy, capital flows, and fund performance. We find that onshore funds are associated with greater share restrictions, more liquid assets, and a reduced sensitivity of capital flows to superior past performance. We also find some evidence that onshore funds outperform offshore funds, depending on the sample period. The results suggest that a fund's investment and financial policies reflect differences in investor clienteles and the regulatory environment."
1307,"Matthew: Effect or Fable?","Azoulay, Pierre and Stuart, Toby and Wang, Yanbo","MANAGEMENT SCIENCE","60","1","92-109","2014","JAN","Sociology Of Science;Status;Stratification;Matthew Effect","","In a market context, a status effect occurs when actors are accorded differential recognition for their efforts depending on their location in a status ordering, holding constant the quality of these efforts. In practice, because it is very difficult to measure quality, this ceteris paribus proviso often precludes convincing empirical assessments of the magnitude of status effects. We address this problem by examining the impact of a major status-conferring prize that shifts actors' positions in a prestige ordering. Specifically, using a precisely constructed matched sample, we estimate the effect of a scientist becoming a Howard Hughes Medical Institute (HHMI) Investigator on citations to articles the scientist published before the prize was awarded. We do find evidence of a postappointment citation boost, but the effect is small and limited to a short window of time. Consistent with theories of status, however, the effect of the prize is significantly larger when there is uncertainty about article quality, and when prize winners are of (relatively) low status at the time of election to the HHMI Investigator Program."
1308,"Optimal Hiring and Retention Policies for Heterogeneous Workers Who Learn","Arlotto, Alessandro and Chick, Stephen E. and Gans, Noah","MANAGEMENT SCIENCE","60","1","110-129","2014","JAN","Learning Curves;Heterogeneous Workers;Bayesian Learning;Call Center;Hiring And Retention;Operations Management;Gittins Index;Bandit Problem","","We study the hiring and retention of heterogeneous workers who learn over time. We show that the problem can be analyzed as an infinite-armed bandit with switching costs, and we apply results from Bergemann and Valimaki [Bergemann D, Valimaki J (2001) Stationary multi-choice bandit problems. J. Econom. Dynam. Control 25(10): 1585-1594] to characterize the optimal hiring and retention policy. For problems with Gaussian data, we develop approximations that allow the efficient implementation of the optimal policy and the evaluation of its performance. Our numerical examples demonstrate that the value of active monitoring and screening of employees can be substantial."
1309,"Pareto Efficiency in Robust Optimization","Iancu, Dan A. and Trichakis, Nikolaos","MANAGEMENT SCIENCE","60","1","130-147","2014","JAN","Robust Optimization;Pareto Optimality;Linear Programming","","This paper formalizes and adapts the well-known concept of Pareto efficiency in the context of the popular robust optimization (RO) methodology for linear optimization problems. We argue that the classical RO paradigm need not produce solutions that possess the associated property of Pareto optimality, and we illustrate via examples how this could lead to inefficiencies and suboptimal performance in practice. We provide a basic theoretical characterization of Pareto robustly optimal (PRO) solutions and extend the RO framework by proposing practical methods that verify Pareto optimality and generate solutions that are PRO. Critically important, our methodology involves solving optimization problems that are of the same complexity as the underlying robust problems; hence, the potential improvements from our framework come at essentially limited extra computational cost. We perform numerical experiments drawn from three different application areas (portfolio optimization, inventory management, and project management), which demonstrate that PRO solutions have a significant potential upside compared with solutions obtained using classical RO methods."
1310,"Sale of Price Information by Exchanges: Does It Promote Price Discovery?","Cespa, Giovanni and Foucault, Thierry","MANAGEMENT SCIENCE","60","1","148-165","2014","JAN","Sale Of Market Data;Transparency;Price Discovery","","Exchanges sell both trading services and price information. We study how the joint pricing of these products affects price discovery and the distribution of gains from trade in an asset market. A wider dissemination of price information reduces pricing errors and the transfer from liquidity traders to speculators. This effect reduces the fee that speculators are willing to pay for trading. Therefore, to raise its revenue from trading, a for-profit exchange optimally charges a high fee for price information so that only a fraction of speculators buy this information. As a result, price discovery is not as efficient as it would be with free price information. This problem is less severe if the exchange must compensate liquidity traders for a fraction of their losses."
1311,"Governance Institutions and Adaptation Costs: Evidence from the Fall of the Berlin Wall","Frank, Douglas H.","MANAGEMENT SCIENCE","60","1","166-187","2014","JAN","Adaptation;Governance;Institutions;Labor Markets;Labor Economics;Organizations","","This paper investigates how institutions governing the employment relationship influence firms' adaptation to environmental changes. After the Berlin Wall fell, migration from East Germany accounted for an abrupt increase in the supply of a key resource-labor-in the West. I study responses to this disruption among firms in the economically important machinery and equipment industry. I find that western firms adapted to migration by increasing employment unless they were affiliated with a works council, an institution that limits the firm's autonomy in managing its workforce. I also find evidence of institution-contingent responses to migration in two areas of firm strategy: vertical boundaries and the focus on exploration versus exploitation. The results suggest that hybrid (i.e., less hierarchical) governance institutions increase adaptation costs. The results also indicate that such adaptation costs have implications for multiple aspects of firm decision making that are nominally beyond the scope of those governance institutions."
1312,"Consumer Favorites and the Design of News","Xiang, Yi and Soberman, David","MANAGEMENT SCIENCE","60","1","188-205","2014","JAN","Information Processing;Media Competition;Game Theory","","The objective of this paper is to better understand the factors that competitive news providers consider to design or deliver news programmes. The focus is broadcast news where, in any programming time period, a viewer watches (or consumes) one programme. We assume that each viewer is interested in a limited set of topics and that her utility only comes from the most interesting news she observes. The key questions we address are as follows: (a) Should firms adopt designs that facilitate the delivery of more information in their news programmes? (b) Does the decision of firms to implement such strategies depend on the complexity of the news programme (i.e., the number of news stories covered in the news product)? (c) How do such strategies influence competition? We show that firms may or may not benefit by providing better-designed news. The incentive to do this is strongly affected by the complexity of the news product and the intensity of competition between news providers."
1313,"Uncertainty, Risk, and Incentives: Theory and Evidence","He, Zhiguo and Li, Si and Wei, Bin and Yu, Jianfeng","MANAGEMENT SCIENCE","60","1","206-226","2014","JAN","Executive Compensation;Optimal Contracting;Learning;Uncertainty;Risk-Incentive Trade-Off","","Uncertainty has qualitatively different implications than risk in studying executive incentives. We study the interplay between profitability uncertainty and moral hazard, where profitability is multiplicative with managerial effort. Investors who face greater uncertainty desire faster learning, and consequently offer higher managerial incentives to induce higher effort from the manager. In contrast to the standard negative risk-incentive trade-off, this learning-by-doing effect generates a positive relation between profitability uncertainty and incentives. We document empirical support for this prediction."
1314,"Understanding the Effect of Advertising on Stock Returns and Firm Value: Theory and Evidence from a Structural Model","Vitorino, Maria Ana","MANAGEMENT SCIENCE","60","1","227-245","2014","JAN","Advertising;Brand Value;Stock Returns;Structural Model;Marketing And Finance","","This paper brings structural modeling to the literature on financial research in marketing. I propose a dynamic investment-based model to understand the impact of advertising expenditures on stock returns and firm value. In addition, by interpreting advertising expenditures as an investment in brand capital, the approach in this paper provides a novel way to measure brand equity grounded in economic theory. Using the Euler equations from the firm's maximization problem, I derive closed-form expressions for the firm's equilibrium stock returns and market value, which depend on observable firm characteristics. I test the model's predictions by the generalized method of moments and data from a large cross section of publicly traded firms. The model is able to match simultaneously the pattern of average stock returns and firm values of portfolios sorted on advertising expenditures that standard asset pricing models cannot. The estimation results also show that brand equity accounts for a substantial fraction of firm market value (about 23%), and that this value varies substantially across industries. Implications of the findings for research at the intersection of marketing and finance are discussed."
1315,"Corporate Risk Management: Integrating Liquidity, Hedging, and Operating Policies","Gamba, Andrea and Triantis, Alexander J.","MANAGEMENT SCIENCE","60","1","246-264","2014","JAN","Finance;Corporate Finance;Risk Management;Hedging;Operating Flexibility, Cash Management","","We analyze the value created by a dynamic integrated risk management strategy involving liquidity management, derivatives hedging, and operating flexibility, in the presence of several frictions. We show that liquidity serves a critical and distinct role in risk management, justifying high levels of cash. We find that the marginal value associated with derivatives hedging is likely to be low, though we explain why some empirical studies find a higher value. We explore the complex interactions between operating flexibility and financial risk management, finding that substitution effects are nonmonotonic and are affected by operating leverage, the nature of operating flexibility, and the effectiveness of the hedging instrument."
1316,"Blogs, Advertising, and Local-Market Movie Box Office Performance","Gopinath, Shyam and Chintagunta, Pradeep K. and Venkataraman, Sriram","MANAGEMENT SCIENCE","59","12","2635-2654","2013","DEC","Consumer-Generated Media;Social Media;Online Word Of Mouth;Blogs;Advertising;Motion Pictures;Endogeneity;Instrumental Variables","","We measure the effects of pre- and postrelease blog volume, blog valence, and advertising on the performance of 75 movies in 208 geographic markets in the United States. We attribute the variation in blog effects across markets to differences in demographic characteristics of markets combined with differences across demographic groups in their access and exposure to blogs as well as their responsiveness conditional on access. We study the effects of prerelease factors on opening day box office performance and of pre- and postrelease factors on box office performance one month after release. Our estimation accounts for confounding factors in the measurement of these effects via the use of instrumental variables. We find considerable heterogeneity in the effects across consumer- and firm-generated media and across geographic markets, with gender, income, race, and age driving across-market differences. Release day performance is impacted most by prerelease blog volume and advertising, whereas postrelease performance is influenced by postrelease blog valence and advertising. Across markets, there is more variance in advertising and blog valence (postrelease) elasticities than there is in blog volume (prerelease) elasticities. We identify the top 20 markets in terms of their elasticities to each of these three instruments. Further, we classify markets in terms of their sensitivities across these three instruments to identify the most sensitive markets that studios can target with their limited release strategies. Finally, we characterize the extent to which studios could have improved their limited release strategies by identifying the overlap between the actual release markets and the most responsive ones. We find that at the time of first-release studios cover only 53% of the most responsive advertising markets and 44% of the most responsive markets to prerelease blog volume in their limited release"
1317,"User-Generated Content and Bias in News Media","Yildirim, Pinar and Gal-Or, Esther and Geylani, Tansev","MANAGEMENT SCIENCE","59","12","2655-2666","2013","DEC","Media Competition;Bias In News;User-Generated Content;Product Line","","In this study, we investigate newspapers' decision to expand their product lines by adding online editions that incorporate user-generated content. We demonstrate that such product line extensions mitigate the extent of slanting in print media. The results also show that as the extent of discretion of users to generate online content increases, print versions of newspapers become more polarized. Furthermore, adding online editions results in reduced profits for newspapers as the additional product variants increase the intensity of competition in the market and the discretion awarded to users limits the ability of newspapers to extract rents from consumers."
1318,"Incentives' Effect in Influenza Vaccination Policy","Yamin, Dan and Gavious, Arieh","MANAGEMENT SCIENCE","59","12","2667-2686","2013","DEC","Influenza Vaccination;Game Theory;Incentive;Sir Model;Economic Epidemiology","","In the majority of developed countries, the level of influenza vaccination coverage in all age groups is suboptimal. Hence, the authorities offer different kinds of incentives for people to become vaccinated such as subsidizing immunization or placing immunization centers in malls to make the process more accessible. We built a theoretical epidemiological game model to find the optimal incentive for vaccination and the corresponding expected level of vaccination coverage. The model was supported by survey data from questionnaires about people's perceptions about influenza and the vaccination against it. Results suggest that the optimal magnitude of the incentives should be greater when less contagious seasonal strains of influenza are involved and greater for the nonelderly population rather than the elderly, and should rise as high as $57 per vaccinated individual so that all children between the ages of six months and four years will be vaccinated."
1319,"The Impact of Acquisitions on the Performance of Existing Organizational Units in the Acquiring Firm: The Case of an Agribusiness Company","Mingo, Santiago","MANAGEMENT SCIENCE","59","12","2687-2701","2013","DEC","Corporate Strategy;Acquisitions;Mergers;Intraorganizational Performance;Managerial Distraction;Resource Transfer;Knowledge Sharing","","Companies frequently expand their production capacity through the acquisition of new organizational unit. This study analyzes how the performance of existing units is affected by the acquisition of another unit. The research focuses on three mechanisms: managerial distraction, resource transfer, and knowledge sharing. These mechanisms are studied in the context of existing units and acquired units with different levels of proximity and similarity between them. Using a detailed data set from an agribusiness company, empirical analysis shows that after an acquisition event there is a temporary decrease in the performance of existing units that are geographically proximate to the acquired unit. Data analysis also shows that after an acquisition event there is an increase in the performance of existing units that have similar characteristics to the acquired unit. In this latter case, the rate of increase in performance diminishes over time. This research demonstrates that the acquisition of an organizational unit can have differing dynamic effects on different parts of the organization."
1320,"The Influence of Software Process Maturity and Customer Error Reporting on Software Release and Pricing","August, Terrence and Niculescu, Marius Florin","MANAGEMENT SCIENCE","59","12","2702-2726","2013","DEC","Software Quality;Software Reliability;Software Security;Software Economics;Software Process Maturity;Network Effects;Software Error Reporting;Diffusion Of Innovation","","Software producers are making greater use of customer error reporting to discover defects and improve the quality of their products. We study how software development differences among producers (e.g., varying levels of process maturity) and software class and functionality differences (e.g., operating system versus productivity software) affect how these producers coordinate software release timing and pricing to optimally harness error reporting contributions from users. In settings where prices are fixed, we characterize the optimal release time and demonstrate why in some cases it can actually be preferable to delay release when customer error reporting rates increase. The manner in which a firm's optimal release time responds to increases in software functionality critically hinges on whether the added functionality enhances or dilutes user error reporting; in both cases, the effect of added functionality on release timing can go in either direction, depending on both firm and product market characteristics. For example, when processing costs are relatively large compared with goodwill costs, firms with lower process maturity will release earlier when per-module error reporting contributions become diluted and release later when these contributions become enhanced. We also examine how a firm adapts price with changes in error reporting levels and software functionality, and finally, we provide implications of how beta testing influences release timing."
1321,"Structural Estimation of Callers' Delay Sensitivity in Call Centers","Aksin, Zeynep and Ata, Baris and Emadi, Seyed Morteza and Su, Che-Lin","MANAGEMENT SCIENCE","59","12","2727-2746","2013","DEC","Queues;Abandonment;Dynamic Programming","","We model the decision-making process of callers in call centers as an optimal stopping problem. After each waiting period, a caller decides whether to abandon a call or continue to wait. The utility of a caller is modeled as a function of her waiting cost and reward for service. We use a random-coefficients model to capture the heterogeneity of the callers and estimate the cost and reward parameters of the callers using the data from individual calls made to an Israeli call center. We also conduct a series of counterfactual analyses that explore the effects of changes in service discipline on resulting waiting times and abandonment rates. Our analysis reveals that modeling endogenous caller behavior can be important. when major changes (such as a change in service discipline) are implemented and that using a model with an exogenously specified abandonment distribution may be misleading."
1322,"Context-Dependent Preferences and Innovation Strategy","Chen, Yuxin and Turut, Ozge","MANAGEMENT SCIENCE","59","12","2747-2765","2013","DEC","Context-Dependent Preferences;New Product Development;Entry Strategy","","Disruptive innovations introduce a new performance dimension into a product category, but often suffer from inferior performance on key performance dimensions of their existing substitutes. Hence, the followers of these innovations face an important decision to make: they must choose to improve the new technology either on the key performance dimension shared with the old technology or on the new performance dimension. This paper investigates which path firms should choose when they face such a dilemma in the absence of any cost or capability issues. In doing so, we integrate customer response into the theory of technological evolution and allow preferences on the product choices to be context dependent. We show that context-dependent preferences may encourage the follower to improve the new technology on the new performance dimension. Later, we extend our game to a dynamic one and show that the context-dependent preferences may cause the pioneer to innovate less."
1323,"Can Margin Differences in Vertical Marketing Channels Lead to Contracts with Slotting Fees?","Dhar, Tirtha","MANAGEMENT SCIENCE","59","12","2766-2771","2013","DEC","Marketing;Channels Of Distribution;Retailing And Wholesaling;Slotting Fees;Product Assortment","","In this paper, we show that slotting fees can be part of an equilibrium solution if per-unit downstream margin is smaller than the per-unit upstream margin. In recent literature, a similar margin-based argument is made by Klein and Wright (2007), whereas intense downstream retail competition coupled with high upstream margin causes upstream manufacturers to offer slotting fees for promotional shelf space. In this paper, we generalize this argument and show that it is possible to have the margin-based argument without any downstream retail competition and competition between products within a retail chain. Interestingly we show that slotting fees will be larger if the products sold by a retailer are complements rather than substitutes. Using a model. of a channel bargaining game, we also provide the necessary and sufficient conditions for the existence of slotting fees and show that for contracts with slotting fees under full vertical coordination, upstream marginal cost functions need to be increasing. Broadly, our findings provide new insights into the strategic role of downstream product assortment on equilibrium-marketing-channel contracts with slotting fees."
1324,"Coproduct Technologies: Product Line Design and Process Innovation","Chen, Ying-Ju and Tomlin, Brian and Wang, Yimin","MANAGEMENT SCIENCE","59","12","2772-2789","2013","DEC","Quality Segmentation;Process Technology;Pricing","","The simultaneous production of different outputs (coproducts) is observed in the chemical, material, mineral, and semiconductor industries among others. Often, as with microprocessors, the outputs differ in quality in the vertical sense and firms classify the output into different grades (products). We analyze product line design and production for a firm operating a vertical coproduct technology. We examine how the product line and profit are influenced by the production cost and output distribution of the technology. We prove that production cost influences product line design in a fundamentally different manner for coproduct technologies than for uniproduct technologies where the firm can produce products independently. For example, with coproducts, the size and length of the product line can both increase in the production cost. Contrary to the oft-held view that variability is bad, we prove the firm benefits from a more variable output distribution if the production or classification cost is low enough."
1325,"Entrepreneurial Spawning and Firm Characteristics","Habib, Michel A. and Hege, Ulrich and Mella-Barral, Pierre","MANAGEMENT SCIENCE","59","12","2790-2804","2013","DEC","Spawning;Spinoffs;Spinouts;General And Specialized Resources;Firm Organization;Organizational Fit;Firm Size;Focus;Profitability;Innovativeness;Spawning Dynamics","","We analyze the implications of the decision to spawn or to retain a new product for the nature and evolution of the firm. In our model, a new product is spawned if the fit between the product and its parent firm organization is not adequate. We focus on the impact of the firm's history of spawning decisions on firm characteristics such as size, focus, profitability, and innovativeness, and analyze its role in shaping firm dynamics. In accordance with the empirical literature, our model predicts that older firms innovate less, spawn less, are more diversified and less profitable, and that firms with more valuable general or specialized resources innovate and spawn more. Echoing seemingly contradictory empirical findings, our model predicts that small, focused firms (large, diversified firms) innovate and spawn more, and are more profitable when sample heterogeneity is driven by the importance of organizational fit (the value of general resources)."
1326,"Simultaneous vs. Sequential Group-Buying Mechanisms","Hu, Ming and Shi, Mengze and Wu, Jiahua","MANAGEMENT SCIENCE","59","12","2805-2822","2013","DEC","Promotion;Group Buying;Coordination Game","","This paper studies the design of group-buying mechanisms in a two-period game where cohorts of consumers I arrive at a deal and make sign-up decisions sequentially. A firm can adopt either a sequential mechanism where the firm discloses to second-period arrivals the number of sign-ups accumulated in the first period, or a simultaneous mechanism where the firm does not post the number of first-period sign-ups and hence each cohort of consumers faces uncertainty about another cohort's size and valuations when making sign-up decisions. Our analysis shows that, compared with the simultaneous mechanism, the sequential mechanism leads to higher deal success rates and larger expected consumer surpluses. This result holds for a multiperiod extension and when the firm offers a price discount schedule with multiple breakpoints. Finally, when the firm can manage the sequence of arrivals, it should inform the smaller cohort of consumers first."
1327,"Should Managers Use Team-Based Contests?","Chen, Hua and Lim, Noah","MANAGEMENT SCIENCE","59","12","2823-2836","2013","DEC","Group Incentives;Contests;Behavioral Economics;Experimental Economics","","When designing contests to motivate employees, should managers organize employees to compete in teams or as individuals? We develop a behavioral economics model that shows that if contestants are averse to being responsible for the team's loss, a team-based (TB) contest can yield higher effort than an individual-based (IB) contest. This prediction is contrary to those of standard economics models, which favor IB contests over TB contests. We test the competing predictions using laboratory economics experiments. The results show that when contestants do not know each other, average effort levels in the TB and TB contests are not different. When contestants are allowed to socialize with potential teammates before making effort decisions, TB contests yield higher effort relative to TB contests. We also show that the relative efficacy of TB contests is driven by contestants' aversion to letting their team down."
1328,"A Person-Organization Discontinuity in Contract Perception: Why Corporations Can Get Away with Breaking Contracts But Individuals Cannot","Haran, Uriel","MANAGEMENT SCIENCE","59","12","2837-2853","2013","DEC","Corporate Personhood;Moral Judgment;Breach Of Contract;Moral Heuristics;Corporate Regulation;Organizational Perception;Contract Theory","","Most legal systems in the world follow the principle of corporate personhood, which grants organizations the same legal status as natural persons. Although debate over the notion of corporate personhood has been fierce, whether and how this principle is applied in people's beliefs and intuitions has yet to be empirically examined. This work addresses the gap in the literature, in the context of formal contracts. While contracts are typically seen as either morally binding promises or morally neutral business instruments, the data presented here show that contracts of individuals are associated more strongly with promises than are contracts of organizations. As a result, breach of contract by an individual is seen as a moral transgression. The same behavior by an organization, however, is viewed more as a legitimate business decision. This paper also finds that contractual obligations should be phrased in promise terms to eliminate this person organization discontinuity."
1329,"Which U.S. Market Interactions Affect CEO Pay? Evidence from UK Companies","Gerakos, Joseph J. and Piotroski, Joseph D. and Srinivasan, Suraj","MANAGEMENT SCIENCE","59","11","2413-2434","2013","NOV","Ceo Compensation;Corporate Governance;Cross-Listing;Executive Pay;Globalization;Incentives;International Pay Differences","","This paper examines how different types of interactions with U.S. markets by non-U.S. firms are associated 1 with higher levels of CEO pay, greater emphasis on incentive-based compensation, and smaller pay gaps with U.S. firms. Using a sample of CEOs of UK firms and using both broad cross-sectional and narrow event-window tests, we find that capital market relationship in the form of a U.S. exchange listing is related to higher UK CEO pay; however, the effect is similar when UK firms have a listing in any foreign country, implying a foreign listing effect not unique to the United States. Product market relationships measured by the extent of sales in the United States by UK companies are associated with higher pay, greater use of U.S.-style pay arrangements, and a reduction in the U.S. UK pay gap. The product market effect is incremental to the effect of a U.S. exchange listing, the extent of the firm's non-U.S. foreign market interactions, and the characteristics of the executive. The U.S. UK CEO pay gap reduces in UK firms that make U.S. acquisitions. Furthermore, the firm's use of a U.S. compensation consultant increases the sensitivity of UK pay practices to U.S. product market relationships."
1330,"Learning from My Success and from Others' Failure: Evidence from Minimally Invasive Cardiac Surgery","Diwas, K. C. and Staats, Bradley R. and Gino, Francesca","MANAGEMENT SCIENCE","59","11","2435-2449","2013","NOV","Failure;Healthcare;Knowledge Work;Learning;Quality;Attribution Theory","","Learning from past experience is central to an organization's adaptation and survival. A key dimension of prior experience is whether an outcome was successful or unsuccessful. Although empirical studies have investigated the effects of success and failure in organizational learning, to date, the phenomenon has received little attention at the individual level. Drawing on attribution theory in psychology, we investigate how individuals learn from their own past experiences with both failure and success and from the experiences of others. For our empirical analyses, we use 10 years of data from 71 cardiothoracic surgeons who completed more than 6,500 procedures using a new technology for cardiac surgery. We find that individuals learn more from their own successes than from their own failures, but they learn more from the failures of others than from others' successes. We also find that individuals' prior successes and others' failures can help individuals overcome their inability to learn from their own failures. Together, these findings offer both theoretical and practical insights into how individuals learn directly from their prior experience and indirectly from the experiences of others."
1331,"Price Competition with Consumer Confusion","Chioveanu, Ioana and Zhou, Jidong","MANAGEMENT SCIENCE","59","11","2450-2469","2013","NOV","Bounded Rationality;Framing;Oligopoly Markets;Frame Dispersion;Price Dispersion","","This paper proposes a model in which identical sellers of a homogeneous product compete in both prices and price frames (i.e., ways to present price information). Frame choices affect the comparability of price offers and may cause consumer confusion and lower price sensitivity. In equilibrium, firms randomize their frame choices to obfuscate price comparisons and sustain positive profits. The nature of the equilibrium depends on whether frame differentiation or frame complexity is more confusing. Moreover, an increase in the number of competitors induces firms to rely more on frame complexity and this may boost industry profits and lower consumer surplus."
1332,"Missing Links: Referrer Behavior and Job Segregation","Rubineau, Brian and Fernandez, Roberto M.","MANAGEMENT SCIENCE","59","11","2470-2489","2013","NOV","Organizational Studies;Personnel;Simulation;Applications;Behavior;Labor;Referral Networks;Screening","","The importance of networks in labor markets is well known, and their job-segregating effects in organizations is a given. Conventional wisdom attributes this segregation to the homophilous nature of contact networks, and leaves little role for organizational influences. Yet employee referrals are necessarily initiated within a firm by employee referrers subject to organizational policies. We build theory regarding the role of referrers in the segregating effects of network recruitment. Using mathematical and computational models, we investigate how empirically documented referrer behaviors affect job segregation. We show that referrer behaviors can segregate jobs beyond the effects of homophilous network recruitment. Furthermore, and contrary to past understandings, we show that referrer behaviors can also mitigate most, if not all, of the segregating effects of network recruitment. Although largely neglected in previous labor market network scholarship, referrers are the missing links revealing opportunities for organizations to influence the effects of network recruitment."
1333,"Salesforce Compensation with Inventory Considerations","Dai, Tinglong and Jerath, Kinshuk","MANAGEMENT SCIENCE","59","11","2490-2501","2013","NOV","Salesforce Compensation;Inventory;Marketing-Operations Interface","","We study a scenario in which a firm designs the compensation contract for a salesperson who exerts unobservable effort to increase the level of uncertain demand and, jointly, the firm also decides the inventory level to be stocked. We use a newsvendor-type model in which actual sales depend on the realized demand but are limited by the inventory available, and unfulfilled demand cannot be observed. In this setup, under the optimal contract, the agent is paid a bonus for meeting a sales quota. Our key result is that it may be optimal for the firm to stock more than the first-best inventory level, because this enables the firm to obtain a more precise indicator of the salesperson's effort. The possibility of stockouts due to limited inventory also leads to several counterintuitive results, including the following: (i) relative to when stockouts are not considered, it may be optimal for the firm to pay a higher bonus even though limited inventory constrains sales; (ii) as inventory becomes more expensive, thereby forcing the firm to lower its inventory, the firm may nevertheless pay the agent a higher bonus; and (iii) if there is a lower probability that the agent's effort exertion leads to high demand, rather than lowering inventory due to the lower sales potential, the firm may increase inventory."
1334,"Overconfidence in Newsvendor Orders: An Experimental Study","Ren, Yufei and Croson, Rachel","MANAGEMENT SCIENCE","59","11","2502-2517","2013","NOV","Overconfidence;Overprecision;Newsvendor;Experiment;Behavioral Operations Management","","Previous studies have shown that individuals make suboptimal decisions in a variety of supply chain and inventory settings. We hypothesize that one cause is that individuals are overconfident (in particular, overprecise) in their estimation of order variation. Previous work has shown theoretically that underestimating the variance of demand causes orders to deviate from optimal in predictable ways. We provide two experiments supporting this theoretical link. In the first, we elicit the precision of each individual's beliefs and demonstrate that overprecision significantly correlates with order bias. We find that overprecision explains almost one-third of the observed ordering mistakes and that the effect of overprecision is robust to learning and other dynamic considerations. In the second, we introduce a new technique to exogenously reduce overprecision. We find that participants randomly assigned to this treatment demonstrate less overprecision and less biased orders than do those in a control group."
1335,"When Smaller Menus Are Better: Variability in Menu-Setting Ability","Goldreich, David and Halaburda, Hanna","MANAGEMENT SCIENCE","59","11","2518-2535","2013","NOV","Menu;Menu Setting;Choice;Pension Plans;401(K)","","Are large menus better than small menus? Recent literature argues that individuals' apparent preference for smaller menus can be explained by their behavioral biases or informational limitations. These explanations imply that absent behavioral or informational effects, larger menus would be objectively better. However, in an important economic context-401(k) pension plans we find that larger menus are objectively worse than smaller menus, as measured by the maximum Sharpe ratio achievable. We propose a model in which menu setters differ in their ability to preselect the menu. We show that when the cost of increasing the menu size is sufficiently small, a lower-ability menu setter optimally offers more items in the menu than a higher-ability menu setter. Nevertheless, the menu optimally offered by a higher-ability menu setter remains superior. This results in a negative relation between menu size and menu quality: smaller menus are better than larger menus."
1336,"Invariant Probabilistic Sensitivity Analysis","Baucells, Manel and Borgonovo, Emanuele","MANAGEMENT SCIENCE","59","11","2536-2549","2013","NOV","Probabilistic Sensitivity;Investment Valuation;Risk Analysis;Decision Analysis;Scale Invariance","","In evaluating opportunities, investors wish to identify key sources of uncertainty. We propose a new way to measure how sensitive model outputs are to each probabilistic input (e.g., revenues, growth, idiosyncratic risk parameters). We base our approach on measuring the distance between cumulative distributions (risk profiles) using a metric that is invariant to monotonic transformations. Thus, the sensitivity measure will not vary by alternative specifications of the utility function over the output. To measure separation, we propose using either Kuiper's metric or Kolmogorov-Smirnov's metric. We illustrate the advantages of our proposed sensitivity measure by comparing it with others, most notably, the contribution-to-variance measures. Our measure can be obtained as a by-product of a Monte Carlo simulation. We illustrate our approach in several examples, focusing on investment analysis situations."
1337,"Are Analysts' Forecasts Informative to the General Public?","Altinkilic, Oya and Balashov, Vadim S. and Hansen, Robert S.","MANAGEMENT SCIENCE","59","11","2550-2565","2013","NOV","Analysts' Forecasts;Financial Analysts;Financial Markets;Investment Banking;Market Efficiency;Security Analysts","","Contrary to the common view that analysts are important information agents, intraday returns evidence shows that announcements of analysts' forecast revisions release little new information, on average. Further cross-sectional evidence from returns around the announcements confirms that revisions are virtually information free. Daily announcement returns used in the literature appear to overstate the analyst's role as information agent, because forecast announcements are often issued directly after reports of significant news about the followed firm. The evidence reveals a sequential relationship between events and news and forecast revisions indicative of analyst piggybacking, not prophecy. These new findings about the most sought-after analyst reports broaden significantly the evidence indicating that price reactions to analysts' reports reveal little new information."
1338,"When the Tail Wags the Dog: Industry Leaders, Limited Attention, and Spurious Cross-Industry Information Diffusion","Cen, Ling and Chan, Kalok and Dasgupta, Sudipto and Gao, Ning","MANAGEMENT SCIENCE","59","11","2566-2585","2013","NOV","Limited Attention;Category Learning;Industry Information Diffusion","","Within industry, stock returns of larger firms lead those of smaller firms, suggesting an intraindustry information diffusion process. Most industry leaders, however, have business segments in other industries (henceforth, minor-segment industries), whereas most small firms are pure players operating in one industry only. If investors cannot filter out the irrelevant information from the leaders' minor segments, the pure players will be mispriced due to spurious cross-industry information diffusion (SCIID). Consistent with the SCUD hypothesis, we document both a strong contemporaneous and a lead-lag relation in stock returns between firms from industry leaders' minor-segment industries and pure players in the industry leaders' major-segment industry. Our results are not due to potential missing common factors or economic relationships between pure. players and firms in the minor-segment industries."
1339,"How Does Rivals' Presence Affect Firms' Decision to Enter New Markets? Economic and Sociological Explanations","Kocak, Ozgecan and Ozcan, Serden","MANAGEMENT SCIENCE","59","11","2586-2603","2013","NOV","Market Entry;Multimarket Contact;Forbearance;Density Dependence;Mimetic Isomorphism;Spillovers;Strategic Groups","","Four distinct theoretical programs have examined market entry decisions of multiunit firms, advancing different explanations for the relationship between a firm's likelihood of entry into a geographical market and the number of rivals that are already present in the target market. Within the strategy literature, theory of strategic interactions explains that firms will want to establish a foothold in markets where their multimarket competitors are scarce, but avoid markets where there are many multimarket competitors. Within economic geography, positive externalities such as increase in demand explain firms' desire to locate close to their rivals whereas negative externalities such as competition explain their desire to avoid them. Within the ecological tradition, density dependence theory explains this relationship in terms of legitimation of an organizational form in a particular market and subsequently increased competition for resources there. Within new institutional theory, the presence of rivals is seen as a signal that a particular market is suitable for entry. Although generally quoted and mentioned in the literature, these four explanations have not been sufficiently separated to indicate whether these four mechanisms all operate simultaneously or whether one of them might account for the often found inverse-U-shaped relationship. Distinguishing firms with different strategies and using various moderators, we test the four explanations jointly and demonstrate their scope of operation."
1340,"The Impact of Consumer Attentiveness and Search Costs on Firm Quality Disclosure: A Competitive Analysis","Ghosh, Bikram and Galbreth, Michael R.","MANAGEMENT SCIENCE","59","11","2604-2621","2013","NOV","Consumer Attentiveness;Quality Disclosure;Search Costs;Competition","","Firms can invest to disclose quality information about their products to consumers, but consumers are not always perfectly attentive to these disclosures. Indeed, technologies such as digital video recorders have increased the ease with which disclosures can be avoided by consumers. Although such inattention may result in a consumer missing information from one or more competing firms, consumers who have missed disclosures might decide to search for quality information to become fully informed before making a purchase decision. In this paper we incorporate consumer attentiveness, as well as the related endogenous search decision, into a model of quality disclosure. Our results suggest that firms should disclose less quality information as the share of partially informed consumers (informed about one firm but not the other) increases, or as consumer search costs increase. We also provide insights into the potential impact of consumer trends toward lower attentiveness and lower search costs."
1341,"How Video Rental Patterns Change as Consumers Move Online","Zentner, Alejandro and Smith, Michael and Kaya, Cuneyd","MANAGEMENT SCIENCE","59","11","2622-2634","2013","NOV","Long Tail;Movie Rentals;Natural Experiment;Empirical Estimation","","How will consumption patterns for popular and long-tail products change when consumers move from brick-and-mortar to Internet markets? We address this question using customer-level panel data obtained from a national video rental chain as it was closing many of its local stores. These data allow us to use the closure of a consumer's local video store as an instrument, breaking the inherent endogeneity between channel choice and product choice. Our results suggest that when consumers move from brick-and-mortar to online channels, they are significantly more likely to rent niche titles relative to blockbusters. This suggests that a significant amount of niche product consumption online is due to the direct influence of the channel on consumer behavior, not just due to selection effects from the types of consumers who decide to use the Internet channel or the types of products that consumers decide to purchase online."
1342,"License to Cheat: Voluntary Regulation and Ethical Behavior","Gino, Francesca and Krupka, Erin L. and Weber, Roberto A.","MANAGEMENT SCIENCE","59","10","2187-2203","2013","OCT","Ethical Behavior;Dishonesty;Regulation;Selection;Social Norms","","Although monitoring and regulation can be used to combat socially costly unethical conduct, their intended targets can often avoid regulation or hide their behavior. This surrenders at least part of the effectiveness of regulatory policies to firms' and individuals' decisions to voluntarily submit to regulation. We study individuals' decisions to avoid monitoring or regulation and thus enhance their ability to engage in unethical conduct. We conduct a laboratory experiment in which participants engage in a competitive task and can decide between having the opportunity to misreport their performance or having their performance verified by an external monitor. To study the effect of social factors on the willingness to be subject to monitoring, we vary whether participants make this decision simultaneously with others or sequentially, as well as whether the decision is private or public. Our results show that the opportunity to avoid being submitted to regulation produces more unethical conduct than situations in which regulation is either exogenously imposed or entirely absent."
1343,"Do Job Seekers Benefit from Contacts? A Direct Test with Contemporaneous Searches","Obukhova, Elena and Lan, George","MANAGEMENT SCIENCE","59","10","2204-2216","2013","OCT","Labor Markets;Social Capital;Job Search;Network Causality;School-To-Work Transition","","Although it is intuitively plausible that a job seeker benefits by using contacts in her job search, the literature is plagued by theoretical disagreements and inconclusive empirical evidence. Single-firm studies consistently find that job seekers applying through referrals achieve better labor-market outcomes than job seekers applying without referrals, but the evidence from job-seeker studies is mixed. To solve this puzzle, we clarify the distinction between having social capital and using contacts as a search method. We present theoretical reasons to suggest that the lack of an association between a job seeker's social capital and whether or not she uses social networks to search for a job should not be taken to imply that job seekers who use social networks to search for jobs do not benefit from using contacts. We exploit a strategic research setting, the school-to-work transition of 291 university graduates who engaged in 3,112 contemporaneous job searches, to show that although a job seeker's social capital may not affect whether or not she uses contacts to search for a job, using contacts as a job-search method does improve her job-search outcomes. We conclude by discussing the implications of our findings for the literature on job search and social networks."
1344,"The Impact of New Product Introduction on Plant Productivity in the North American Automotive Industry","Gopal, Anandasivam and Goyal, Manu and Netessine, Serguei and Reindorp, Matthew","MANAGEMENT SCIENCE","59","10","2217-2236","2013","OCT","Econometrics;Automotive;Productivity;New Product Launch;Organization Learning","","Product launch-an event when a new product debuts for production in a plant-is an important phase in product development. But launches disrupt manufacturing operations, resulting in productivity losses. Using data from North American automotive plants from years 1999-2007, we estimate that a product launch entails an average productivity loss of 12%-15% at the plant level. This translates to a monetary loss of $42-$53 million per launch in lost productivity. We identify several ways to mitigate the decrease in productivity. Product (or mix) flexibility in the body shop is critical for reducing the productivity loss. A plant's past experiences with product launches as well as with manufacturing similar products (specifically, on the same platform as the launch product) temper the productivity losses even further. Nevertheless, there are subtle differences in the accrued learning with these two types of experiences: whereas the positive impact of platform experience persists over time, the learning accrued with launching other products in the same plant decays more quickly. Altogether, our results suggest that launching products at a flexible plant with appropriate platform experience could recover approximately $31 million per launch in lost productivity."
1345,"Nursevendor Problem: Personnel Staffing in the Presence of Endogenous Absenteeism","Green, Linda V. and Savin, Sergei and Savva, Nicos","MANAGEMENT SCIENCE","59","10","2237-2256","2013","OCT","Healthcare;Hospitals;Nursing;Newsvendor;Econometrics;Organizational Studies;Manpower Planning","","The problem of determining nurse staffing levels in a hospital environment is a complex task because of variable patient census levels and uncertain service capacity caused by nurse absenteeism. In this paper, we combine an empirical investigation of the factors affecting nurse absenteeism rates with an analytical treatment of nurse staffing decisions using a novel variant of the newsvendor model. Using data from the emergency department of a large urban hospital, we find that absenteeism rates are consistent with nurses exhibiting an aversion to higher levels of anticipated workload. Using our empirical findings, we analyze a single-period nurse staffing problem considering both the case of constant absenteeism rate (exogenous absenteeism) as well as an absenteeism rate that is a function of the number of nurses scheduled (endogenous absenteeism). We provide characterizations of the optimal staffing levels in both situations and show that the failure to incorporate absenteeism as an endogenous effect results in understaffing."
1346,"Organizational Decision Making: An Information Aggregation View","Csaszar, Felipe A. and Eggers, J. P.","MANAGEMENT SCIENCE","59","10","2257-2277","2013","OCT","Organizational Structure;Decision Making;Knowledge;Environmental Change","","We study four information aggregation structures commonly used by organizations to evaluate opportunities: individual decision making, delegation to experts, majority voting, and averaging of opinions. Using a formal mathematical model, we investigate how the performance of each of these structures is contingent upon the breadth of knowledge within the firm and changes in the environment. Our model builds on work in the Carnegie tradition and in the group and behavioral decision-making literatures. We use the model to explore when delegation is preferable to other structures, such as voting and averaging. Our model shows that delegation is the most effective structure when there is diversity of expertise, when accurate delegation is possible, and when there is a good fit between the firm's knowledge and the knowledge required by the environment. Otherwise, depending on the knowledge breadth of the firm, voting or averaging may be the most effective structure. Finally, we use our model to shed light on which structures are more robust to radical environmental change and when crowd-based decision making may outperform delegation."
1347,"No-Arbitrage Taylor Rules with Switching Regimes","Li, Haitao and Li, Tao and Yu, Cindy","MANAGEMENT SCIENCE","59","10","2278-2294","2013","OCT","Taylor Rule;Term Structure;Regime Switching;Mcmc","","We study the time-varying nature of U.S. monetary policies summarized by the Taylor rule based on a continuous-time regime-switching term structure model. In this model, the spot rate follows the Taylor rule and government bonds at different maturities are priced by no arbitrage. We allow the coefficients of the Taylor rule and the dynamics of inflation and output gap to be regime dependent and estimate the model using government bond yields. We find that the Fed is proactive in controlling inflation in one regime and accommodative for growth in another. Moreover, proactive monetary policies are associated with more stable inflation and output gap and therefore could have contributed to the Great Moderation. Our analysis also highlights the importance of switching regimes for term structure modeling. Without the regimes, inflation and output can explain less than 50% of the variations of bond yields. With the regimes, the two variables can explain more than 80% of the variations of bond yields."
1348,"Coinsurance Within Business Groups: Evidence from Related Party Transactions in an Emerging Market","Jia, Nan and Shi, Jing and Wang, Yongxiang","MANAGEMENT SCIENCE","59","10","2295-2313","2013","OCT","Organizational Studies;Strategy;Industrial Organization;Firm Objectives;Organization And Behavior","","Using novel transaction-level data on Chinese business groups, this study provides the first direct evidence of the coinsurance theory of business groups by investigating when different types of internal resources are transferred within a business group. We find that in Chinese business groups, a credit crunch experienced by the controlling shareholding firm (the controller) of a publicly listed firm increases the loan-based related party transactions (RPTs) including loan guarantees and intercorporate loans provided by the listed firm to the controller. In turn, when the listed firm's performance dips, the controller and its son firms provide more support to the listed firm in the form of non-loan-based RPTs. These findings directly show the dynamic interactions of members within business groups."
1349,"Ad Revenue and Content Commercialization: Evidence from Blogs","Sun, Monic and Zhu, Feng","MANAGEMENT SCIENCE","59","10","2314-2331","2013","OCT","Ad-Sponsored Business Model;Media Content;Blog;Revenue Sharing;User-Generated Content;Platform-Based Markets","","Many scholars argue that when incentivized by ad revenue, content providers are more likely to tailor their content to attract eyeballs, and as a result, popular content may be excessively supplied. We empirically test this prediction by taking advantage of the launch of an ad-revenue-sharing program initiated by a major Chinese portal site in September 2007. Participating bloggers allow the site to run ads on their blogs and receive 50% of the revenue generated by these ads. After analyzing 4.4 million blog posts, we find that, relative to nonparticipants, popular content increases by about 13 percentage points on participants' blogs after the program takes effect. About 50% of this increase can be attributed to topics shifting toward three domains: the stock market, salacious content, and celebrities. Meanwhile, relative to nonparticipants, participants' content quality increases after the program takes effect. We also find that the program effects are more pronounced for participants with moderately popular blogs, and seem to persist after participants enroll in the program."
1350,"Simple Auctions for Supply Contracts","Duenyas, Izak and Hu, Bin and Beil, Damian R.","MANAGEMENT SCIENCE","59","10","2332-2342","2013","OCT","Newsvendor;Optimal Procurement Mechanism;Competing Suppliers;Open-Descending Auction","","This paper studies an optimal procurement mechanism for a newsvendor-like problem where the buyer's (newsvendor's) purchase price of the supplies is not fixed, but determined through interaction with candidate suppliers. The buyer has priors on the suppliers' costs but does not know their costs exactly. Recent literature has shown how the buyer can implement the optimal procurement mechanism by announcing a revenue function (specifying a payment for each quantity the buyer may purchase), then auctioning off the supply contract with the specified revenue function. In this paper, we show that a simple modified version of the standard open-descending auction for a fixed quantity is also an optimal mechanism for obtaining supplies. What distinguishes this mechanism is its simplicity and familiarity for the suppliers-open-descending auctions are very easy to run and ubiquitous in practice, whereas auctioning supply contracts with a specified revenue function is much less observed and more difficult to explain to suppliers. Furthermore, we show that this simple mechanism can be easily generalized to ex ante asymmetric suppliers and a class of nonlinear production costs."
1351,"Credit Risk Spillovers Among Financial Institutions Around the Global Credit Crisis: Firm-Level Evidence","Yang, Jian and Zhou, Yinggang","MANAGEMENT SCIENCE","59","10","2343-2359","2013","OCT","Credit Risk;Financial Network;Systemic Risk;Structural Var","","Using credit default swap data, we propose a novel empirical framework to identify the structure of credit risk networks across international major financial institutions around the recent global credit crisis. Specifically, we identify three groups of players, including prime senders, exchange centers, and prime receivers of credit risk information. Leverage ratios and, particularly, the short-term debt ratio appear to be significant determinants of the roles of financial institutions in credit risk transfer, while corporate governance indexes, size, liquidity, and asset write-downs are not significant. Our findings carry important implications for a new regulatory standard on capital subcharge and liquidity coverage ratio."
1352,"Media, Aggregators, and the Link Economy: Strategic Hyperlink Formation in Content Networks","Dellarocas, Chrysanthos and Katona, Zsolt and Rand, William","MANAGEMENT SCIENCE","59","10","2360-2379","2013","OCT","Media Economics;News And Journalism;Content Strategies;Network Formation;Marketing","","A defining property of the World Wide Web is a content site's ability to place virtually costless hyperlinks to third-party content as a substitute or complement to its own content. Costless hyperlinking has enabled new types of players, usually referred to as content aggregators, to successfully enter content ecosystems, attracting traffic and revenue by hosting links to the content of others. This, in turn, has sparked a heated controversy between content creators and aggregators regarding the legitimacy and costs/benefits of uninhibited free linking. To our knowledge, this work is the first to model the complex interplay between content and links in settings where a set of sites compete for traffic. We develop a series of analytical models that distill how hyperlinking affects the (a) incentives of content nodes to produce quality content versus link to third-party content, (b) profits of the various stakeholders, (c) average quality of content that becomes available to consumers, and (d) impact of content aggregators. Our results provide a nuanced view of the so-called link economy, highlighting both the beneficial consequences and the drawbacks of free hyperlinks for content creators and consumers."
1353,"Tempus Fugit: Time Pressure in Risky Decisions","Kocher, Martin G. and Pahlke, Julius and Trautmann, Stefan T.","MANAGEMENT SCIENCE","59","10","2380-2391","2013","OCT","Time Pressure;Risk Aversion;Loss Aversion;Gain Seeking;Aspiration Levels","","We study the effects of time pressure on risky decisions for pure gain prospects, pure loss prospects, and mixed prospects involving both gains and losses. In two experiments we find that time pressure has no effect on risk attitudes for gains, but increases risk aversion for losses. For mixed prospects, subjects become simultaneously more loss averse and more gain seeking under time pressure, depending on the framing of the prospects. The results suggest the importance of aspiration levels, and thus the overall probability to break even, under time pressure. We discuss the implications of our findings for decision-making situations that involve time pressure."
1354,"Investors' Heterogeneity and Implied Volatility Smiles","Li, Tao","MANAGEMENT SCIENCE","59","10","2392-2412","2013","OCT","Equilibrium Model;Heterogeneous Beliefs;Heterogeneous Preferences;Learning;Option Pricing;Volatility Smile","","Heterogeneity in beliefs and time preferences among investors make stock volatility stochastic, even though the volatility of the underlying dividend is constant. Prices of the European options written on this stock admit closed-form solutions, hence their hedging deltas. The Black-Scholes implied volatility surface, which depends on wealth distribution, investors' beliefs, and time preferences, exhibits observed patterns that are widely documented in various options markets. Along with benchmark models, the model is calibrated weekly to the S&P 500 index options from January 1996 to April 2006. It shows comparable performance to the stochastic volatility and jump model and outperforms the traders' rules and two no-arbitrage models (stochastic volatility, and stochastic volatility and stochastic interest rate) in terms of out-of-sample pricing errors."
1355,"A Meta-Analysis of Multibrand, Multioutlet Channel Systems","Lee, Eunkyu and Staelin, Richard and Yoo, Weon Sang and Du, Rex","MANAGEMENT SCIENCE","59","9","1950-1969","2013","SEP","Channel Coordination;Channel Structure;Demand Formulation;Multichannel Pricing;Product Line Pricing","","In today's multibrand, multichannel marketplace, optimal channel design involves issues such as distribution intensity, channel exclusivity, vertical and horizontal coordination, and online offline mixed structures. We investigate how a firm's choice in these design issues affects its profitability under varying levels of brand and outlet differentiation. Our spatial model explicitly captures heterogeneous consumer preference for brand position, store location, and outlet type, under various consumer behavior assumptions. We apply this same underlying model to 10 different channel structures, deriving associated demand functions and equilibrium solutions. We perform a meta-analysis over the entire set of results to estimate a general model that summarizes the linkages among the factors shaping optimal channel structure decisions in a multibrand, multioutlet market. This general model efficiently describes the complex interactions of channel characteristics with industry structure and consumer characteristics, providing new findings as well as greater clarity to some results in the literature. A predictive analysis applied to additional channel structures exhibits strong generalizability in qualitative findings."
1356,"Unpacking the Future: A Nudge Toward Wider Subjective Confidence Intervals","Jain, Kriti and Mukherjee, Kanchan and Bearden, J. Neil and Gaba, Anil","MANAGEMENT SCIENCE","59","9","1970-1987","2013","SEP","Confidence Intervals;Overconfidence;Time Unpacking","","Subjective probabilistic judgments in forecasting are inevitable in many real-life domains. A common way to obtain such judgments is to assess fractiles or confidence intervals. However, these judgments tend to be systematically overconfident. Further, it has proved particularly difficult to debias such forecasts and improve the calibration. This paper proposes a simple process that systematically leads to wider confidence intervals, thus reducing overconfidence. With a series of experiments, including with professionals, we show that unpacking the distal future into intermediate more proximal futures systematically improves calibration. We refer to this phenomenon as the time unpacking effect, find it is robust to different elicitation formats, and address the possible reasons behind it. We further show that this results in better overall forecasting performance when improved calibration is traded off against less sharpness, and that substantive benefits can be obtained even from just one level of time unpacking."
1357,"Insiders' Sales Under Rule 10b5-1 Plans and Meeting or Beating Earnings Expectations","Shon, John and Veliotis, Stanley","MANAGEMENT SCIENCE","59","9","1988-2002","2013","SEP","Insider Trading;Meet Or Beat Expectations;Securities Exchange Act Of 1934;Rule 10B5-1;Planned Trade","","We find that firms with insider sales executed under Rule 10b5-1 plans exhibit a higher likelihood of meeting or beating analysts' earnings expectations (MBE). This relation between MBE and plan sales is more pronounced for the plan sales of chief executive officers (CEOs) and chief financial officers (CEOs) and is nonexistent for other key insiders. The market reactions to firms that successfully meet or beat expectations are relatively positive compared with their peers that fail to do so. One interpretation of our results is that CEOs and CFOs who sell under these plans may be more likely to engage in strategic behavior to meet or beat expectations in an effort to maximize their proceeds from plan sales. However, readers should exercise caution in making inferences, because the potential presence of limit order transactions makes it difficult to unambiguously determine the direction of causality of the relation we document."
1358,"Organization and Bargaining: Sales Process Choice at Auto Dealerships","Bennett, Victor Manuel","MANAGEMENT SCIENCE","59","9","2003-2018","2013","SEP","Organizational Studies;Organizational Design;Personnel;Strategy;Games-Group Decisions;Bargaining;Industrial Organization;Firm Objectives;Organization And Behavior","","This paper examines how firms' organizational form affects prices negotiated. Negotiated prices are one factor determining whether a vendor or customer captures the value from a transaction. Firms that systematically negotiate more effectively capture more value. Research has investigated individual- and market-level determinants of negotiation outcomes, but little has been done on the firm-level determinants of negotiated prices. I present a first look at one feature, sales process: whether salespeople handle the entire sale in parallel or customers begin with less experienced salespeople who can escalate difficult assignments. I model firms' choice of sales process as a biform game and test predictions of the model using a combination of transaction-level data on new car purchases in the United States and a unique survey of dealership management practices. I find that a serial process has implications consistent with improving firms' bargaining power and reducing customers' outside options."
1359,"Do Customers Learn from Experience? Evidence from Retail Banking","Ater, Itai and Landsman, Vardit","MANAGEMENT SCIENCE","59","9","2019-2035","2013","SEP","Tariff Choice;Nonlinear Pricing;Switching;Learning;Flat Rate","","We study customers' adoption and subsequent switching decisions with regard to a menu of three-part tariff plans offered by a commercial bank. Using a rich panel data set covering 70,510 fee-based checking accounts over 30 months, before and after the introduction of the plans, we find that most customers adopt non-cost-minimizing plans, preferring plans with large monthly allowances and high fixed payments. Furthermore, after adoption, customers who exceed their allowances and consequently pay overage fees are more likely to switch to plans with larger allowances than customers who do not experience such fees. Notably, after switching, these overage-paying customers pay higher monthly payments than before. In contrast, switching customers who did not pay overage payments before switching pay less after switching. Our findings, unlike those of previous research on experience-based learning, suggest that the behavior of experienced customers does not converge to the predictions of neoclassical models. We propose that overage aversion,which is closely related to loss aversion and mental accounting, is the most plausible explanation for our findings."
1360,"Asset-Pricing Implications of Dividend Volatility","Li, Yan and Yang, Liyan","MANAGEMENT SCIENCE","59","9","2036-2055","2013","SEP","Asset Pricing;Dividend Volatility;Loss Aversion;Narrow Framing;Return Predictability;Volatility","","This paper establishes dividend volatility as a fundamental risk metric that prices assets. We theoretically incorporate dividend volatility clustering into a model in which narrow-framing investors are loss averse over fluctuations in the value of their investments. Our model shows that dividend volatility positively predicts future asset returns, with the predictive power increasing with the forecasting horizon; our model also sheds light on a variety of other asset-pricing phenomena. We further provide supporting empirical evidence that dividend volatility is indeed priced in the data. More specifically, aggregate dividend volatility predicts and is predicted by aggregate price-to-dividend ratios; aggregate dividend volatility predicts future aggregate market returns; and dividend volatility of portfolios sorted by size, book-to-market ratios, and past returns predicts future portfolio-level returns, respectively."
1361,"Geographic Constraints on Knowledge Spillovers: Political Borders vs. Spatial Proximity","Singh, Jasjit and Marx, Matt","MANAGEMENT SCIENCE","59","9","2056-2078","2013","SEP","Knowledge Spillovers;Borders;Distance;Economic Geography;Patent Citation;Innovation;Institutions","","Geographic localization of knowledge spillovers is a central tenet in multiple streams of research. However, prior work has typically examined this phenomenon considering only one geographic unit-country, state, or metropolitan area-at a time and has rarely accounted for spatial distance. We disentangle these multiple effects by using a regression framework employing choice-based sampling to estimate the likelihood of citation between random patents. We find both country and state borders to have independent effects on knowledge diffusion beyond what just geographic proximity in the form of metropolitan collocation or shorter within-region distances can explain. An identification methodology comparing inventor-added and examiner-added citation patterns points to an even stronger role of political borders. The puzzling state border effect remains robust on average across analyses, though it is found to have waned with time. The country effect has, in contrast, not only remained robust but even strengthened over time."
1362,"Inventory Management for an Assembly System Subject to Supply Disruptions","DeCroix, Gregory A.","MANAGEMENT SCIENCE","59","9","2079-2092","2013","SEP","Inventory;Production;Multi-Item;Multiechelon;Multistage;Stochastic;Approximations;Heuristics;Dynamic Programming","","We consider an assembly system with a single end product and a general assembly structure, where one or more of the component suppliers or (sub)assembly production processes is subject to random supply disruptions. We present a method for reducing the system to an equivalent system with some subsystems replaced by a series structure. This reduction simplifies the computation of optimal ordering policies and can also allow for comparison of disruption impacts across systems with different supply chain structures. We identify conditions under which a state-dependent echelon base-stock policy is optimal. Based on this result, we propose a heuristic policy for solving the assembly system with disruptions and test its performance in numerical trials. Using additional numerical trials, we explore a variety of strategic questions. For example, contrary to what is typically observed in systems without disruptions, we find that choosing a supplier with a longer lead time can sometimes yield lower system costs. We also find that backup supply is more valuable for a supplier with a shorter lead time than one with a longer lead time. In addition, because of component complementarities, we find that choosing suppliers whose disruptions are perfectly correlated yields lower system costs than choosing suppliers whose disruptions are independent, in contrast to the strategy that is typically preferred when choosing backup suppliers for a single product."
1363,"Price-Quoting Strategies of an Upstream Supplier","Hu, Bin and Beil, Damian R. and Duenyas, Izak","MANAGEMENT SCIENCE","59","9","2093-2110","2013","SEP","Multitier Supply Chain;Auctions;Price Discrimination","","This paper studies an upstream supplier who quotes prices for a key component to multiple sellers that compete for an end-buyer's indivisible contract. At most one of the supplier's quotes may result in downstream contracting and hence produce revenue for her. We characterize the supplier's optimal price-quoting strategies and show that she will use one of two possible types of strategies, with her choice depending on the sellers' profit potentials relative to their uncertainties: secure, whereby she will always have business; or risky, whereby she may not have business. Addressing potential fairness concerns, we also study price-quoting strategies in which all sellers receive equal quotes. Finally, we show that the supplier's optimal mechanism resembles auctioning a single quote among the sellers. This paper can assist upstream suppliers in their pricing decisions and provides general insights into multitier supply chains' pricing dynamics."
1364,"Contract Design with a Dominant Retailer and a Competitive Fringe","Kolay, Sreya and Shaffer, Greg","MANAGEMENT SCIENCE","59","9","2111-2116","2013","SEP","Marketing;Channels Of Distribution;Competitive Strategy;Pricing","","We show that under some conditions, quantity discounts and two-part tariffs are equivalent as mechanisms for channel coordination when an upstream firm sells its product in a downstream market that is characterized by a dominant retailer and a competitive fringe. We consider a setting in which discriminatory offers are feasible and a setting in which the same menu of options must be offered to all retailers. We find that the upstream firm's profit in both settings is independent of whether quantity discounts or two-part tariffs are used. The implication of this finding is that the firm's choice of contract design may turn on which one is easier to implement."
1365,"The Role of Risk Preferences in Pay-to-Bid Auctions","Platt, Brennan C. and Price, Joseph and Tappen, Henry","MANAGEMENT SCIENCE","59","9","2117-2134","2013","SEP","Penny Auction;Bid Fees;Risk-Loving Preferences","","We analyze a new auction format in which bidders pay a fee each time they increase the auction price. Bidding fees are the primary source of revenue for the seller but produce the same expected revenue as standard auctions (assuming risk-neutral bidders). If risk-loving preferences are incorporated in the model, expected revenue increases. Our model predicts a particular distribution of ending prices, which we test against observed auction data. The degree of fit depends on how unobserved parameters are chosen; in particular, a slight preference for risk has the biggest impact in explaining auction behavior, suggesting that pay-to-bid auctions are a mild form of gambling."
1366,"Demand Uncertainty and Excess Supply in Commodity Contracting","Popescu, Dana G. and Seshadri, Sridhar","MANAGEMENT SCIENCE","59","9","2135-2152","2013","SEP","Forward And Spot Market;Excess Supply;Speculators;Cournot Competition","","We examine how different characteristics of product demand and market impact the relative sales volume in the forward and spot markets for a commodity whose aggregate demand is uncertain. In a setting where either the forward contracts are binding quantity commitments between buyers and suppliers or the forward production takes place before the uncertainty in demand is resolved, we find that a combination of factors that include market concentration, demand risk, and price elasticity of demand will determine whether a commodity will be sold mainly through forward contracts or in the spot market. Previous findings in the literature show that when participants are risk neutral, the ratio of forward sales to spot sales is a function of market concentration alone; also, the lower the concentration, the higher this ratio. These findings hold under the assumption that demand is either deterministic or, if demand is uncertain, all production takes place after uncertainty is fully resolved and production plans can be altered instantaneously and costlessly. In our setting, however, we find that even a low level of demand risk can reverse the nature of supply in a highly competitive (low concentration) market, by shifting it from predominantly forward-driven to predominantly spot-driven supply. In markets with high concentration, the price elasticity of demand will determine whether the supply will be predominantly spot-driven or forward-driven. Our analysis suggests various new hypotheses on the structure of supply in commodity markets."
1367,"Is There One Unifying Concept of Utility? An Experimental Comparison of Utility Under Risk and Utility Over Time","Abdellaoui, Mohammed and Bleichrodt, Han and l'Haridon, Olivier and Paraschiv, Corina","MANAGEMENT SCIENCE","59","9","2153-2169","2013","SEP","Decision Under Risk;Intertemporal Choice;Nature Of Utility;Prospect Theory;Discounting;Loss Aversion","","The nature of utility is controversial. Whereas decision theory commonly assumes that utility is context specific, applied and empirical decision analysis typically assumes one unifying concept of utility applicable to all decision problems. This controversy has hardly been addressed empirically because of the absence of methods to measure utility outside the context of risk. We introduce a method to measure utility over time and compare utility under risk and utility over time. We distinguish between gains and losses and also measure loss aversion. In two experiments we found that utility under risk and utility over time differed and were uncorrelated. Utility under risk was more curved than utility over time. Subjects were loss averse both for risk and for time, but loss aversion was more pronounced for risk. Loss aversion over risk and time were uncorrelated. This suggests that loss aversion, although important in both decision contexts, is volatile and subject to framing."
1368,"Mixed Bundling of Two Independently Valued Goods","Bhargava, Hemant K.","MANAGEMENT SCIENCE","59","9","2170-2185","2013","SEP","Bundling;Price Discrimination;Pricing;Marketing;Information Systems","","This paper develops analytical results and insights for the mixed bundling problem of pricing a product line consisting of two component goods (with valuations distributed uniformly and independently in [0, a(1)] and [0, a(2)], respectively, with a(1) < a(2)) and a bundle of the two goods. This setting has previously been considered analytically intractable. By deriving component good prices as exact algebraic functions of the optimal bundle price, I reduce the multiproduct pricing problem to a univariate nonlinear optimization problem in the bundle price. When the two component goods are sufficiently asymmetric in valuations, the optimal solution is partial mixed bundling (one component good is not sold separately), for which I derive exact conditions and optimal prices. An exact analytical solution is also given for mixed bundling of two information goods (component goods with zero marginal costs). For the general case, I derive a closed-form approximation of the optimal bundle price: P-B = 0.5724w(1) + 0.5695w(2) + 0.3516a(1) + 0.4889a(2) + 0.0054(a(2)/a(1))w(1)-0.0201(a(2)/a(1))w(2). The approximation is highly 'accurate (the resulting profit is within a percent of the exact optimal profit), efficient (instant solutions for specific problem instances), and useful in other applications where mixed bundling is a subproblem. I demonstrate this by applying the solution to the mixed bundle problem in a vertical channel where a retailer must bundle and price component goods from multiple independent manufacturers."
1369,"Customer-Driven Misconduct: How Competition Corrupts Business Practices","Bennett, Victor Manuel and Pierce, Lamar and Snyder, Jason A. and Toffel, Michael W.","MANAGEMENT SCIENCE","59","8","1725-1742","2013","AUG","Environment;Pollution;Government;Regulations;Judicial;Legal;Crime Prevention;Organizational Studies;Strategy;Microeconomics;Market Structure And Pricing","","Competition among firms yields many benefits but can also encourage firms to engage in corrupt or unethical activities. We argue that competition can lead organizations to provide services that customers demand but that violate government regulations, especially when price competition is restricted. Using 28 million vehicle emissions tests from more than 11,000 facilities, we show that increased competition is associated with greater inspection leniency, a service quality attribute that customers value but is illegal and socially costly. Firms with more competitors pass customer vehicles at higher rates and are more likely to lose customers whom they fail, suggesting that competition intensifies pressure on facilities to provide illegal leniency. We also show that, at least in markets in which pricing is restricted, firms use corrupt and unethical practices as an entry strategy."
1370,"Measuring the Effect of Queues on Customer Purchases","Lu, Yina and Musalem, Andres and Olivares, Marcelo and Schilkrut, Ariel","MANAGEMENT SCIENCE","59","8","1743-1763","2013","AUG","Queuing;Service Operations;Retail;Choice Modeling;Empirical Operations Management;Operations/Marketing Interface;Bayesian Estimation;Service Quality","","We conduct an empirical study to analyze how waiting in queue in the context of a retail store affects customers' purchasing behavior. Our methodology combines a novel data set with periodic information about the queuing system (collected via video recognition technology) with point-of-sales data. We find that waiting in queue has a nonlinear impact on purchase incidence and that customers appear to focus mostly on the length of the queue, without adjusting enough for the speed at which the line moves. An implication of this finding is that pooling multiple queues into a single queue may increase the length of the queue observed by customers and thereby lead to lower revenues. We also find that customers' sensitivity to waiting is heterogeneous and negatively correlated with price sensitivity, which has important implications for pricing in a multiproduct category subject to congestion effects."
1371,"How Do Firm Financial Conditions Affect Product Quality and Pricing?","Phillips, Gordon and Sertsios, Giorgo","MANAGEMENT SCIENCE","59","8","1764-1782","2013","AUG","Finance;Corporate Finance;Industrial Organization;Market Structure;Firm Strategy;Market Performance;Firm Objectives;Organization And Behavior","","We analyze the interaction of firm product quality and pricing decisions with financial distress and bankruptcy in the airline industry. We consider an airline's choices of quality and price as dynamic decisions that trade off current cash flows for future revenue. We examine how airline mishandled baggage, on-time performance, and pricing are related to financial distress and bankruptcy, controlling for the endogeneity of financial distress and bankruptcy. We find that an airline's quality decisions are differentially affected by financial distress and bankruptcy. Product quality decreases when airlines are in financial distress, consistent with financial distress reducing a firm's incentive to invest in quality. In contrast, in bankruptcy product quality increases relative to financial distress. In addition, we find that firms price more aggressively when in financial distress consistent with firms trying to increase short-term market share and revenues."
1372,"The Emergence of Opinion Leaders in a Networked Online Community: A Dyadic Model with Time Dynamics and a Heuristic for Fast Estimation","Lu, Yingda and Jerath, Kinshuk and Singh, Param Vir","MANAGEMENT SCIENCE","59","8","1783-1799","2013","AUG","User-Generated Content;Opinion Leaders;Social Networks;Network Growth;Proportional Hazard Model;Weighted Exogenous Sampling","","We study the drivers of the emergence of opinion leaders in a networked community where users establish links to others, indicating their trust for the link receiver's opinion. This leads to the formation of a network, with high in-degree individuals being the opinion leaders. We use a dyad-level proportional hazard model with time-varying covariates to model the growth of this network. To estimate our model, we use Weighted Exogenous Sampling with Bayesian Inference, a methodology that we develop for fast estimation of dyadic models on large network data sets. We find that, in the Epinions network, both the widely studied preferential attachment effect based on the existing number of inlinks (i.e., a network-based property of a node) and the number and quality of reviews written (i.e., an intrinsic property of a node) are significant drivers of new incoming trust links to a reviewer (i.e., inlinks to a node). Interestingly, we find that time is an important moderator of these effects-intrinsic node characteristics are a stronger short-term driver of additional inlinks, whereas the preferential attachment effect has a smaller impact but it persists for a longer time. Our novel insights have important managerial implications for the design of online review communities."
1373,"Designing Buyback Contracts for Irrational But Predictable Newsvendors","Becker-Peth, Michael and Katok, Elena and Thonemann, Ulrich W.","MANAGEMENT SCIENCE","59","8","1800-1816","2013","AUG","Newsvendor;Behavioral Operations;Experimental;Order Behavior;Contract Optimization","","One of the main assumptions in research on designing supply contracts is that decision makers act in a way that maximizes their expected profit. A number of laboratory experiments demonstrate that this assumption does not hold. Specifically, faced with uncertain demand, decision makers place orders that systematically deviate from the expected profit maximizing levels. We have added to this body of knowledge by demonstrating that ordering decisions also systematically depend on individual contract parameters and by developing a behavioral model that captures this systematic behavior. We proceed to test our behavioral model using laboratory experiments and use the data to derive empirical model parameters. We then test our approach in out-of-sample validation experiments that confirm that, indeed, contracts designed using the behavioral model perform better than contracts designed using the standard model."
1374,"Price Competition Under Mixed Multinomial Logit Demand Functions","Aksoy-Pierson, Margaret and Allon, Gad and Federgruen, Awi","MANAGEMENT SCIENCE","59","8","1817-1835","2013","AUG","Marketing;Competitive Strategy;Pricing","","In this paper, we postulate a general class of price competition models with mixed multinomial logit demand functions under affine cost functions. In these models, the market is partitioned into a finite set of market segments. We characterize the equilibrium behavior of this class of models in the case where each product in the market is sold by a separate, independent firm. We identify a simple and very broadly satisfied condition under which a pure Nash equilibrium exists and the set of Nash equilibria coincides with the solutions of the system of first-order-condition equations, a property of essential importance to empirical studies. This condition specifies that in every market segment, each firm captures less than 50% of the potential customer population when pricing at a specific level that, under the condition, is an upper bound for a rational price choice for the firm irrespective of the competitors' prices. We show that under a somewhat stronger, but still broadly satisfied, version of the above condition, a unique equilibrium exists. We complete the picture by establishing the existence of a Nash equilibrium, indeed a unique Nash equilibrium, for markets with an arbitrary degree of concentration, under sufficiently tight price bounds. We discuss how our results extend to a continuum of customer types. A discussion of the multiproduct case is included. The paper concludes with a discussion of implications for structural estimation methods."
1375,"Alleviating the Patient's Price of Privacy Through a Partially Observable Waiting List","Sandikci, Burhaneddin and Maillart, Lisa M. and Schaefer, Andrew J. and Roberts, Mark S.","MANAGEMENT SCIENCE","59","8","1836-1854","2013","AUG","Dynamic Programming;Partially And Completely Observable Markov Decision Process Models;Medical Decision Making;Liver Transplantation;Value Of Information","","In the United States, end-stage liver disease patients join a waiting list and then make accept/reject decisions for transplantation as deceased-donor organs are offered to them over time. These decisions are largely influenced by the patient's prospect for future offers, which can be ascertained most accurately by knowing the entire composition of the waiting list. Under the current transplantation system, however, the United Network for Organ Sharing (UNOS), in an effort to strike a balance between privacy and transparency, only publishes an aggregated version of the waiting list. However, it is not clear whether the published information is good enough (compared with perfect information) to help patients make optimal decisions that maximize their individual life expectancies. We provide a novel model of this accept/reject problem from an individual patient's perspective using a partially observed Markov decision process (POMDP) framework, which incorporates the imperfect waiting list information as published currently into the patient's decision making. We analyze structural properties of this model. In particular, we establish conditions that guarantee a monotone value function and a threshold-type optimal policy with respect to the partially observable rank state that captures the imperfect waiting list information. Furthermore, we develop an improved solution methodology to solve a generic POMDP model. This solution method guarantees, for any fixed grid, the best possible approximation to the optimal value function by solving linear programs to compute the optimal weights used for the approximation. Finally, we compare, in a clinically driven numerical study, the results of this model with those of an existing Markov decision process model that differs from our model in assuming the availability of perfect waiting list information. This comparison allows us to assess the quality of the published imperfect information as measured by a patient's so-called price of privacy (i.e., the opportunity loss in expected life days due to a lack of perfect waiting list information). Previous work estimates a significant loss in a patient's life expectancy, on average, when the patient has no waiting list information compared with full information. In this paper, we find that the currently published partial information is nearly sufficient to eliminate this loss, resulting in a negligible price of privacy and supporting current UNOS practice."
1376,"What Are Investors Willing to Pay to Customize Their Investment Product?","Vrecko, Dennis and Langer, Thomas","MANAGEMENT SCIENCE","59","8","1855-1870","2013","AUG","Behavioral Economics;Investment Behavior;Customization;Distribution Builder;Decision Support;Experimental Economics;Prospect Theory","","Even though buy-and-hold (B&H) investment strategies can take the risk tolerance of an investor into account by specifying a suitable stock proportion, the outcome profiles of B&H strategies are restricted to a specific class of return distributions. For investors with particular risk preferences, further customization should thus provide additional value. The objective of this paper is to investigate the strength of preference for such customized distributions and to draw conclusions about the demand for personalized investment products. In two experimental studies, 256 participants could adjust the return distribution of an initially chosen B&H investment by using an interactive software program. Our main finding is that most investors make extensive use of the customization option and many are willing to pay a substantial fee for this additional flexibility. We further find that the willingness to pay for customization is lower if the fee is integrated into the display of the return distribution, making its impact on final returns more obvious. We also observe that investors can be clustered into distinct subgroups via their adjustment patterns, but individually elicited prospect theory parameters are barely able to explain and predict these adjustments. As a robustness check, we also survey real investors at an investors fair to compare their preferences with those of our main pool of student subjects. We find that the willingness to pay for customization is slightly lower for these real investors and the main effect of fee integration is also less pronounced. In summary, we observe a strong willingness to pay for additional flexibility even though the actual benefits of customization vary markedly according to the individual. In many cases the accepted fees are so high that standard B&H strategies stochastically dominate the customized distributions after fee integration."
1377,"Consideration Set Formation with Multiproduct Firms: The Case of Within-Firm and Across-Firm Evaluation Costs","Liu, Lin and Dukes, Anthony","MANAGEMENT SCIENCE","59","8","1871-1886","2013","AUG","Consideration Set Formation;Multiproduct Firms;Within-Firm Search;Product Line;Pricing","","We consider a theoretical setting in which firms carry multiple products and consumers incur evaluation costs not only across firms but also within firms. Consumers judiciously decide the number of firms to include in their consideration sets as well as how many products from those firms. This decision depends on the relative trade-offs of evaluating an additional product and whether it is from a firm already included in the consideration set or from an entirely new firm. The composition of consumers' consideration set affects how firms compete in prices and in the number of products to offer. Contrary to previous literature, we find that firm differentiation can reduce firms' product lines and within-firm evaluation costs have either a positive or a negative effect on firms' prices. Interestingly, we show that within-firm evaluation costs and across-firm evaluation costs are different constructs. The number of products firms offer in equilibrium can exceed the socially optimal level if within-firm evaluation costs are significant."
1378,"Do Hedge Funds Outperform Stocks and Bonds?","Bali, Turan G. and Brown, Stephen J. and Demirtas, K. Ozgur","MANAGEMENT SCIENCE","59","8","1887-1903","2013","AUG","Hedge Funds;Stocks;Bonds;Almost Stochastic Dominance;Manipulation-Proof Performance Measure","","H edge funds' extensive use of derivatives, short selling, and leverage and their dynamic trading strategies create significant nonnormalities in their return distributions. Hence, the traditional performance measures fail to provide an accurate characterization of the relative strength of hedge fund portfolios. This paper uses the utility-based nonparametric and parametric performance measures to determine which hedge fund strategies outperform the U. S. equity and/or bond markets. The results from the realized and simulated return distributions indicate that the long/short equity hedge and emerging markets hedge fund strategies outperform the U. S. equity market, and the long/short equity hedge, multistrategy, managed futures, and global macro hedge fund strategies dominate the U.S. Treasury market."
1379,"Mixed Bundling in Two-Sided Markets in the Presence of Installed Base Effects","Chao, Yong and Derdenger, Timothy","MANAGEMENT SCIENCE","59","8","1904-1926","2013","AUG","Mixed Bundling;Two-Sided Markets;Installed Base;Video Game Industry","","We analyze mixed bundling in two-sided markets where installed base effects are present and find that the pricing structure deviates from traditional bundling as well as the standard two-sided markets literature-we determine prices on both sides fall with bundling. Mixed bundling acts as a price discrimination tool segmenting the market more efficiently. Consequently, as a by-product of this price discrimination, the two sides are better coordinated, and social welfare is enhanced. We show unambiguously that platform participations increase on both sides of the market. After theoretically evaluating the impact mixed bundling has on prices and welfare, we take the model predictions to data from the portable video game console market. We find empirical support for all theoretical predictions."
1380,"Implications of Hyperbolic Discounting for Optimal Pricing and Scheduling of Unpleasant Services That Generate Future Benefits","Plambeck, Erica L. and Wang, Qiong","MANAGEMENT SCIENCE","59","8","1927-1946","2013","AUG","Organizational Studies;Behavior;Queues;Optimization;Probability;Stochastic Model Applications;Pricing;Service","","People tend to lack the self-control to undergo an unpleasant service that would generate future benefits. This paper derives a tractable quasi-hyperbolic discounting model of that behavioral tendency (for a queueing system in which service time is short relative to the time horizon for its benefits). Planning in advance, people may naively overestimate their self-control. This paper shows how customers' lack of self-control and naivete affect optimal pricing and scheduling. The welfare-maximizing usage fee and the revenue-maximizing usage fee decrease with customers' lack of self-control. Charging for subscription, in addition to or instead of per use, increases revenue, especially when subscribers are naive. If the manager can charge for subscription or per use, subscription is optimal for revenue maximization, whereas usage-based pricing is optimal for welfare maximization. If customers are heterogeneous in their self-control and naivete, priority scheduling can dramatically increase welfare and revenue."
1381,"The Loser's Curse: Decision Making and Market Efficiency in the National Football League Draft","Massey, Cade and Thaler, Richard H.","MANAGEMENT SCIENCE","59","7","1479-1495","2013","JUL","Overconfidence;Judgment Under Uncertainty;Efficient Market Hypothesis;Organizational Studies;Decision Making","","A question of increasing interest to researchers in a variety of fields is whether the biases found in judgment and decision-making research remain present in contexts in which experienced participants face strong economic incentives. To investigate this question, we analyze the decision making of National Football League teams during their annual player draft. This is a domain in which monetary stakes are exceedingly high and the opportunities for learning are rich. It is also a domain in which multiple psychological factors suggest that teams may overvalue the chance to pick early in the draft. Using archival data on draft-day trades, player performance, and compensation, we compare the market value of draft picks with the surplus value to teams provided by the drafted players. We find that top draft picks are significantly overvalued in a manner that is inconsistent with rational expectations and efficient markets, and consistent with psychological research."
1382,"Is Pay for Performance Detrimental to Innovation?","Ederer, Florian and Manso, Gustavo","MANAGEMENT SCIENCE","59","7","1496-1513","2013","JUL","Organizational Studies;Motivation Incentives;Personnel;Research And Development;Innovation","","Previous research in economics shows that compensation based on the pay-for-performance principle is effective in inducing higher levels of effort and productivity. On the other hand, research in psychology argues that performance-based financial incentives inhibit creativity and innovation. How should managerial compensation be structured if the goal is to induce managers to pursue more innovative business strategies? In a controlled laboratory setting, we provide evidence that the combination of tolerance for early failure and reward for long-term success is effective in motivating innovation. Subjects under such an incentive scheme explore more and are more likely to discover a novel business strategy than subjects under fixed-wage and standard pay-for-performance incentive schemes. We also find evidence that the threat of termination can undermine incentives for innovation, whereas golden parachutes can alleviate these innovation-reducing effects."
1383,"The Impact of Gender Diversity on the Performance of Business Teams: Evidence from a Field Experiment","Hoogendoorn, Sander and Oosterbeek, Hessel and van Praag, Mirjam","MANAGEMENT SCIENCE","59","7","1514-1528","2013","JUL","Gender Diversity;Team Performance;Field Experiment;Entrepreneurship Education;Board Effectiveness","","This paper reports on a field experiment conducted to estimate the impact of the share of women in business teams on their performance. Teams consisting of undergraduate students in business studies start up a venture as part of their curriculum. We manipulated the gender composition of teams and assigned students randomly to teams, conditional on their gender. We find that teams with an equal gender mix perform better than male-dominated teams in terms of sales and profits. We explore various mechanisms suggested in the literature to explain this positive effect of gender diversity on performance (including complementarities, learning, monitoring, and conflicts) but find no support for them."
1384,"Ethnic Innovation and US Multinational Firm Activity","Foley, C. Fritz and Kerr, William R.","MANAGEMENT SCIENCE","59","7","1529-1544","2013","JUL","Foreign Direct Investment;Technology Transfer;Patents;Innovation;Research And Development;Ethnic Networks;Diasporas","","This paper studies the impact that ethnic innovators have on the global activities of U.S. firms by analyzing I detailed data on patent applications and on the operations of the foreign affiliates of U.S. multinational firms. The results indicate that increases in the share of a firm's innovation performed by inventors of a particular ethnicity are associated with increases in the share of that firm's affiliate activity in countries related to that ethnicity Ethnic innovators also appear to facilitate the disintegration of innovative activity across borders and to allow U.S. multinationals to form new affiliates abroad without the support of local joint venture partners."
1385,"Shouting to Be Heard in Advertising","Anderson, Simon P. and de Palma, Andre","MANAGEMENT SCIENCE","59","7","1545-1556","2013","JUL","Information Overload;Congestion;Advertising;Lottery;Junk Mail;E-Mail;Telemarketing;Multiple Equilibria;Ad Caps","","Advertising competes for scarce consumer attention, so more profitable advertisers send more messages to break through the others' clutter. Multiple equilibria can arise: more messages in aggregate induce more shouting to be heard, dissipating profit. Equilibria can involve a small range of loud shouters or large range of quiet whisperers. All advertisers prefer there to be less shouting. There is the largest diversity in message levels for a middling width of advertiser types: both very wide and very narrow widths have only one message per advertiser. The number of advertisers at each message level decreases with the level if the profit distribution is log-convex. Increasing the cost of sending messages can make all advertisers better off. A new technique is given for describing multiple equilibria, by determining how much examination is consistent with a given marginal advertiser."
1386,"Infrastructure Planning for Electric Vehicles with Battery Swapping","Mak, Ho-Yin and Rong, Ying and Shen, Zuo-Jun Max","MANAGEMENT SCIENCE","59","7","1557-1575","2013","JUL","Electric Vehicles;Green Transportation;Infrastructure Investment;Robust Optimization;Facility Location","","Electric vehicles (EVs) have been proposed as a key technology to help cut down the massive greenhouse gas emissions from the transportation sector. Unfortunately, because of the limited capacity of batteries, typical EVs can only travel for about 100 miles on a single charge and require hours to be recharged. The industry has proposed a novel solution centered around the use of swapping stations, at which depleted batteries can be exchanged for recharged ones in the middle of long trips. The possible success of this solution hinges on the ability of the charging service provider to deploy a cost-effective infrastructure network, given only limited information regarding adoption rates. We develop robust optimization models that aid the planning process for deploying battery-swapping infrastructure. Using these models, we study the potential impacts of battery standardization and technology advancements on the optimal infrastructure deployment strategy."
1387,"Does Pooling Purchases Lead to Higher Profits?","Hu, Bin and Duenyas, Izak and Beil, Damian R.","MANAGEMENT SCIENCE","59","7","1576-1593","2013","JUL","Games;Inventory;Production;Policies;Pricing;Scale;Diseconomies;Principal-Agent;Demand Variability","","Consider two buyers facing uncertain demands who need to purchase a common critical component from a powerful sole-source supplier. If the two buyers pool their demands and purchase from the supplier as a single entity, will they necessarily earn higher profits than purchasing separately? We show that when a powerful supplier extracts profits from the buyers through optimal contract design, the demand variability reduction achieved by pooling can harm the buyers because it makes extracting profits easier for the supplier. We characterize cases when pooling is disadvantageous and also provide insights into when it is still advantageous. Our result is in contrast to the case where the price of the component is exogenous (typically assumed in most of the pooling literature), in which case pooling demands is always beneficial for the buyers."
1388,"Is It Better to Average Probabilities or Quantiles?","Lichtendahl, Jr., Kenneth C. and Grushka-Cockayne, Yael and Winkler, Robert L.","MANAGEMENT SCIENCE","59","7","1594-1611","2013","JUL","Probability Forecasts;Quantile Forecasts;Expert Combination;Linear Opinion Pooling","","We consider two ways to aggregate expert opinions using simple averages: averaging probabilities and averaging quantiles. We examine analytical properties of these forecasts and compare their ability to harness the wisdom of the crowd. In terms of location, the two average forecasts have the same mean. The average quantile forecast is always sharper: it has lower variance than the average probability forecast. Even when the average probability forecast is overconfident, the shape of the average quantile forecast still offers the possibility of a better forecast. Using probability forecasts for gross domestic product growth and inflation from the Survey of Professional Forecasters, we present evidence that both when the average probability forecast is overconfident and when it is underconfident, it is outperformed by the average quantile forecast. Our results show that averaging quantiles is a viable alternative and indicate some conditions under which it is likely to be more useful than averaging probabilities."
1389,"Product Market Competition, Managerial Compensation, and Firm Size in Market Equilibrium","Subramanian, Ajay","MANAGEMENT SCIENCE","59","7","1612-1630","2013","JUL","Product Market Competition;Managerial Compensation;Firm Size;Market Equilibrium","","We develop a tractable equilibrium model of competing firms in an industry to show how the distribution of firm qualities, moral hazard, and product market characteristics interact to affect firm size, managerial compensation, and market structure. Different determinants of product market competition have contrasting effects on firm size and managerial compensation. Although both firm size and managerial compensation increase with the entry cost, they increase with the elasticity of substitution if and only if firm size exceeds a high threshold but decrease if it is below a low threshold. Aggregate shocks to the firm productivity distribution affect incentives in our equilibrium framework. We show statistically and economically significant empirical support for several hypotheses derived from the theory that relates product market characteristics to managerial compensation, firm size, and the number of firms in the industry Different determinants of competition indeed have contrasting effects, as predicted by the theory."
1390,"Guilt by Association: Strategic Failure Prevention and Recovery Capacity Investments","Kim, Sang-Hyun and Tomlin, Brian","MANAGEMENT SCIENCE","59","7","1631-1649","2013","JUL","Supply Chain Disruption;Business Continuity;System Reliability;Game Theory","","We examine technological systems that display the following characteristics: (i) unplanned outages incur significant costs, (ii) the system experiences an outage if one or more of its subsystems fails, (iii) subsystem failures may occur simultaneously, and (iv) subsystem recovery requires specific resources and capabilities that are provided by different firms. Firms may invest in two measures to enhance system availability namely, failure prevention and recovery capacity. If recovery capacity investment is the only option, we find that the firms in a decentralized setting overinvest in capacity resulting in higher system availability but at a higher cost. If both investments can be made, we find that the firms underinvest in failure prevention and overinvest in recovery capacity That is, firms in a decentralized setting shift their focus from preventing failures to responding to failures. The net effect is lower system availability reversing the conclusion above. We also find that, unexpectedly, firms are more willing to let their subsystems fail if a joint failure is more likely to occur."
1391,"A Game-Theoretic Model of International Influenza Vaccination Coordination","Mamani, Hamed and Chick, Stephen E. and Simchi-Levi, David","MANAGEMENT SCIENCE","59","7","1650-1670","2013","JUL","Healthcare Management;Game Theory;Incentives And Contracting;Public Policy","","Influenza vaccination decisions in one country can influence the size of an outbreak in other countries due to interdependent risks from infectious disease transmission. This paper examines the inefficiency in the allocation of influenza vaccines that is due to interdependent risk of infection across borders and proposes a contractual mechanism to reduce such inefficiencies. The proposed contract is based on an epidemic model that accounts for intranational transmission and that from a source country where the dominant strain emerges. The contract reduces the overall financial burden of infection globally and improves the total number infected by seasonal influenza outbreaks. This is consistent with recent recommendations to improve pandemic preparedness. Numerical experiments demonstrate that the benefits of the contract can prevent millions of influenza cases and save tens of millions of dollars, and that the benefits are even greater when cross-border transmission is higher, even if cross-border transmission parameters have moderate estimation errors."
1392,"Entrepreneurs Under Uncertainty: An Economic Experiment in China","Holm, Hakan J. and Opper, Sonja and Nee, Victor","MANAGEMENT SCIENCE","59","7","1671-1687","2013","JUL","Economics;Behavior And Behavioral Decision Making;Decision Analysis Risk;Microeconomic Behavior","","This study reports findings from the first large-scale experiment investigating whether entrepreneurs differ 1 from other people in their willingness to expose themselves to various forms of uncertainty. A stratified random sample of 700 chief executive officers from the Yangzi delta region in China is compared to 200 control group members. Our findings suggest that in economic decisions, entrepreneurs are more willing to accept strategic uncertainty related to multilateral competition and trust. However, entrepreneurs do not differ from ordinary people when it comes to nonstrategic forms of uncertainty, such as risk and ambiguity."
1393,"Do Analysts Sacrifice Forecast Accuracy for Informativeness?","Louis, Henock and Sun, Amy X. and Urcan, Oktay","MANAGEMENT SCIENCE","59","7","1688-1708","2013","JUL","Analyst Forecasts;Forecast Accuracy;Forecast Informativeness;Management Forecasts;Earnings Management","","Analysts deviate from management guidance to correct for perceived earnings management. Although the deviations reduce forecast accuracy, they improve forecast informativeness, bringing the forecasts closer to the unmanaged earnings and reducing accruals mispricing. An implicit assumption in the literature is that more accurate analyst forecasts (i.e., estimates that are closer to the reported earnings) are better for investors, and that analysts' objective is to forecast the reported (managed) earnings accurately. Our analysis suggests that this is not necessarily the case and that an inaccurate forecast can actually be more informative than an accurate one. Prior studies on analysts' deviations from management guidance focus on analysts' incentives to issue estimates that managers can beat. These studies implicitly assume that analysts side with, management against the interests of their clients. Our analysis indicates that analysts could also deviate from management guidance to provide useful valuation information to their clients."
1394,"Trade Promotion Decisions Under Demand Uncertainty: A Market Experiment Approach","Yuan, Hong and Gomez, Miguel I. and Rao, Vithala R.","MANAGEMENT SCIENCE","59","7","1709-1724","2013","JUL","Channels Of Distribution;Trade Promotion;Competitive Strategy;Market Experiment","","In this paper, we examine trade promotion decisions in manufacturer-retailer channels where retailers face consumer demand uncertainty. We first present the theoretical analysis for two types of markets where trade promotion discounts are offered either as off-invoices or as scan-backs. We derive propositions by comparing wholesale and retail prices, retailer order quantities, and profits given the same trade promotion discount. Next, we extend the basic model so that the amount of trade promotion discount influences market expansion and solve for the optimal discount level. To test our theory, we then employ market experiments where we manipulate demand uncertainty and market expansion. Consistent with our theoretical predictions, we find that wholesale and retail prices are higher and retailer order quantities lower when the same amount of trade promotion discount is allocated to scan-backs versus off-invoices. In the market expansion condition, we find that manufacturers offer deeper discounts when trade promotions are allocated to off-invoices versus scan-backs. Overall, our research suggests that market experiments can shed light on trade promotion outcomes for which industry data are sparse or nonexistent."
1395,"Teams Make You Smarter: How Exposure to Teams Improves Individual Decisions in Probability and Reasoning Tasks","Maciejovsky, Boris and Sutter, Matthias and Budescu, David V. and Bernau, Patrick","MANAGEMENT SCIENCE","59","6","1255-1270","2013","JUN","Markets;Group Decision Making;Wason Selection Task;Monty Hall Dilemma;Team Decision Making","","Many important decisions are routinely made by transient and temporary teams, which perform their duty and disperse. Team members often continue making similar decisions as individuals. We study how the experience of team decision making affects subsequent individual decisions in two seminal probability and reasoning tasks, the Monty Hall problem and the Wason selection task. Both tasks are hard and involve a general rule, thus allowing for knowledge transfers, and can be embedded in the context of markets that offer identical incentives to teams and individuals. Our results show that teams, trade closer to the rational level, learn the solution faster, and achieve this with weaker, less specific performance feedback than individuals. Most importantly, we observe significant knowledge transfers from team, decision making to subsequent individual performances that take place up to five weeks later, indicating that exposure to team decision making has strong positive spillovers on the quality of individual decisions."
1396,"Inferring Reporting-Related Biases in Hedge Fund Databases from Hedge Fund Equity Holdings","Agarwal, Vikas and Fos, Vyacheslav and Jiang, Wei","MANAGEMENT SCIENCE","59","6","1271-1289","2013","JUN","Hedge Funds;Mandatory And Voluntary Disclosure;Reporting And Selection Biases","","This paper formally analyzes the biases related to self-reporting in hedge fund databases by matching the quarterly equity holdings of a complete list of 13F-filing hedge fund companies to the union of five major commercial databases of self-reporting hedge funds between 1980 and 2008. We find that funds initiate self-reporting after positive abnormal returns that do not persist into the reporting period. Termination of self-reporting, is followed by both return deterioration and outflows from the funds. The propensity to self-report is consistent with the trade-offs between the benefits (e.g., access to prospective investois) and costs (e.g., partial loss of trading secrecy and flexibility in selective marketing). Finally, returns of self-reporting funds are higher than that of nonreporting funds using characteristic-based benchmarks. However, the difference is not significant using alternative choices of performance measures."
1397,"Price Dispersion and Loss-Leader Pricing: Evidence from the Online Book Industry","Li, Xinxin and Gu, Bin and Liu, Hongju","MANAGEMENT SCIENCE","59","6","1290-1308","2013","JUN","Price Dispersion;Loss-Leader Strategy;Competitive Pricing;Cross-Selling Capability","","In this paper, we develop a theoretical model to analyze the pricing strategies of competing retailers with asymmetric cross-selling capabilities when product demand changes. Our results suggest that retailers with better opportunities for cross-selling have higher incentives to adopt loss-leader pricing on high-demand products than retailers with low cross-selling capabilities. As a result, price dispersion of a product across retailers rises when its demand increases. The predictions of our model are consistent with the empirical evidence from the online book retailing industry. Using product breadth as a proxy for cross-selling capability, we find that retailers with high cross-selling capabilities reduce prices on best sellers more aggressively than retailers with low cross-selling capabilities. As a result, price dispersion increases when a book makes it to the best-seller list, and the increase is mainly driven by the difference in pricing behavior between retailers with different cross-selling capabilities. Our empirical results are robust against a number of alternative explanations."
1398,"Treatment Effectiveness and Side Effects: A Model of Physician Learning","Chan, Tat and Narasimhan, Chakravarthi and Xie, Ying","MANAGEMENT SCIENCE","59","6","1309-1325","2013","JUN","Multiple-Dimensional Learning;Advertising;New Product;Pharmaceutical Marketing","","In this paper we study how treatment effectiveness and side effects impact the prescription decision of a risk-averse physician, and how detailing and patient feedback help reduce the physician's uncertainty in these two attributes in the erectile dysfunction category. To separately identify the impacts of effectiveness and side effects, we augment the observed prescription choices with unique data on self-reported reasons for switching in our estimation. Results show that the two new drugs Levitra and Cialis have higher mean effectiveness than the existing drug Viagra, but physicians have large uncertainty regarding the effectiveness for Levitra and side effects for Cialis: Detailing is effective in reducing the uncertainty for effectiveness but much less so for side effects. Based on the results, we investigate the roles of effectiveness and side effects in physicians' prescription choices, and the importance of detailing for new entrants in competing with incumbent drugs."
1399,"Capital Markets and Firm Organization: How Financial Development Shapes European Corporate Groups","Belenzon, Sharon and Berkovitz, Tomer and Rios, Luis A.","MANAGEMENT SCIENCE","59","6","1326-1343","2013","JUN","Corporate Groups;Financial Development;Internal Capital Markets","","We investigate the effect of financial development on the formation of European corporate groups. Because cross-country regressions are hard to interpret in a causal sense, we exploit exogenous industry measures to investigate a specific channel through which financial development may affect group affiliation: internal capital markets. Using a comprehensive firm-level data set on European corporate groups in 15 countries, we find that countries with less developed financial markets have a higher percentage of group affiliates in more capital-intensive industries. This relationship is more pronounced for young and small firms and for affiliates Of large and diversified groups. Our findings are consistent with the view that internal capital markets may, under some conditions, be more efficient than prevailing external markets, and that this may drive group affiliation even in developed economies."
1400,"The Fragility of Commitment","Morgan, John and Vardy, Felix","MANAGEMENT SCIENCE","59","6","1344-1353","2013","JUN","Cournot;Bertrand;Stackelberg;Observation Cost;Value Of Commitment;First-Mover Advantage;Second-Mover Advantage;Costly Leader Game","","We show that the value of commitment is fragile in many standard games. When the follower faces a small cost to observe the leader's action, equilibrium payoffs are identical to the case where the leader's actions are unobservable. Applications of our result include standard Stackelberg-Cournot and differentiated product Bertrand games, as well as forms of indirect commitment, highlighted in Bulow et al. [Bulow J, Geanakoplos J, Klemperer P (1985) Multimarket oligopoly: Strategic substitutes and strategic complements. J. Political Econom. 93:488-511]. Weakening full rationality in favor of boundedly rational solution concepts such as quantal-response equilibrium restores the value of commitment."
1401,"Total Cost Control in Project Management via Satisficing","Goh, Joel and Hall, Nicholas G.","MANAGEMENT SCIENCE","59","6","1354-1372","2013","JUN","Project Management;Time And Cost Control Under Uncertainty;Robust Optimization And Satisficing;Linear Decision Rule","","We consider projects with uncertain activity times and the possibility of expediting, or crashing, them. Activity times come from a partially specified distribution within a family of distributions. This family is described by one or more of the following details about the uncertainties: support, mean, and covariance. We allow correlation between past and future activity time performance across activities. Our objective considers total completion time penalty plus crashing and overhead costs. We develop a robust optimization model that uses a conditional value-at-risk satisficing measure. We develop linear and piecewise-linear decision rules for activity start time and crashing decisions. These rules are designed to perform robustly against all possible scenarios of activity time uncertainty, when implemented in either static or rolling horizon mode. We compare our procedures against the previously available Program Evaluation and Review Technique and Monte Carlo simulation procedures. Our computational studies show that, relative to previous approaches, our crashing policies provide both a higher level of performance, i.e., higher success rates and lower budget overruns, and substantial robustness to activity time distributions. The relative advantages and information requirements of the static and rolling horizon implementations are discussed."
1402,"An Axiomatic Approach to Systemic Risk","Chen, Chen and Iyengar, Garud and Moallemi, Ciamac C.","MANAGEMENT SCIENCE","59","6","1373-1388","2013","JUN","Systemic Risk;Risk Measures;Contagion;Risk Attribution","","Systemic risk refers to the risk of collapse of an entire complex system as a result of the actions taken by the individual component entities or agents that comprise the system. Systemic risk is an issue of great concern in modern financial markets as well as, more broadly, in the management of complex business and engineering systems. We propose an axiomatic framework for the measurement and management of systemic risk based on the simultaneous analysis of outcomes across agents in the system and over scenarios of nature. Our framework defines a broad class of systemic risk measures that accomodate a rich set of regulatory preferences. This general class of systemic risk measures captures many specific measures of systemic risk that have recently been proposed as special cases and highlights their implicit assumptions. Moreover, the systemic risk measures that satisfy our conditions yield decentralized decompositions; i.e., the systemic risk can be decomposed into risk due to individual agents. Furthermore, one can associate a shadow price for systemic risk to each agent that correctly accounts for the externalities of the agent's individual decision making on the entire system."
1403,"Sourcing for Supplier Effort and Competition: Design of the Supply Base and Pricing Mechanism","Li, Cuihong","MANAGEMENT SCIENCE","59","6","1389-1406","2013","JUN","Sourcing;Supply Base;Supplier Competition;Supplier Effort;Commitment;Renegotiation","","We study a buyer's sourcing strategy along two dimensions: the supply base design and the pricing mechanism, considering supplier competition and cost-reduction effort. The supply base design concerns the number of suppliers (one or two) included in the supply base and the capacity to be invested in each supplier. The pricing mechanism determines the timing of the price decisions, with the buyer making price commitments before suppliers exert cost-reduction efforts that may be renegotiated afterward. We find that symmetric capacity investment in suppliers and low price commitments (more likely to be renegotiated) are effective at fostering supplier competition, whereas asymmetric investment and high price commitments (less likely to be renegotiated) are better at motivating supplier effort. A complementary relationship exists between the supply base design and pricing mechanism: A more symmetric supply base should be combined with lower price commitments, leading to more renegotiation opportunities. This results in three possible sourcing structures: sole sourcing (investing capacity in a single supplier and forming price with ex ante commitments), symmetric dual sourcing (investing equal capacity in both suppliers and forming price with ex post negotiations), and asymmetric dual sourcing (investing positive but unequal capacities in two (ex ante identical) suppliers and forming price using both ex ante commitments and ex post (re)negotiations). We characterize the conditions for each structure and identify a strategic role of capacity investment.."
1404,"On Implications of Demand Censoring in the Newsvendor Problem","Besbes, Omar and Muharremoglu, Alp","MANAGEMENT SCIENCE","59","6","1407-1424","2013","JUN","Demand Censoring;Inventory Management;Newsvendor;Estimation;Nonparametric","","We consider a repeated newsvendor problem in which the decision maker (DM) does not have access to the underlying demand distribution. The goal of this paper is to characterize the implications of demand censoring on performance. To that end, we compare the benchmark setting in which the DM has access to demand observations to a setting in which the DM may only rely on sales data. We measure performance in terms of regret: the difference between the cumulative costs of a policy and the optimal cumulative costs with knowledge of the demand distribution. Through upper and lower bounds, we characterize the optimal magnitude of the worst-case regret for the two settings, enabling one to isolate the implications of demand censoring. In particular, the results imply that the exploration-exploitation trade-off introduced by demand censoring is fundamentally different in the continuous and discrete demand cases, and that active exploration plays a much stronger role in the latter case. We further establish that in the discrete demand case, the need for active exploration almost disappears as soon as a lost sales indicator (that records whether demand was censored or not) becomes available, in addition to the censored demand samples."
1405,"Social Ties and User-Generated Content: Evidence from an Online Social Network","Shriver, Scott K. and Nair, Harikesh S. and Hofstetter, Reto","MANAGEMENT SCIENCE","59","6","1425-1443","2013","JUN","Marketing;User-Generated Content;Social Networks;Monotone Treatment Response;Monotone Treatment Selection;Monotone Instrumental Variables;Homophily;Endogenous Group Formation;Correlated Unobservables;Endogeneity","","We exploit changes in wind speeds at surfing locations in Switzerland as a source of variation in users' propensity to post content about their surfing activity on an online social network. We exploit this variation to test whether users' online content-generation activity is codetermined with their social ties. Economically significant effects of this type can produce positive feedback that generates local network effects in content generation. When quantitatively significant, the increased content and tie density arising from the network effect induces more visitation and browsing on the site, which fuels growth by generating advertising revenue. We find evidence consistent with such network effects."
1406,"Social Networks, Information Acquisition, and Asset Prices","Han, Bing and Yang, Liyan","MANAGEMENT SCIENCE","59","6","1444-1457","2013","JUN","Social Communication;Price Informativeness;Information Acquisition;Asset Prices;Liquidity;Volume;Welfare","","We analyze a rational expectations equilibrium model to explore the implications of information networks for the financial market. When information is exogenous, social communication improves market efficiency. However, social communication crowds out information production due to traders' incentives to free ride on informed friends and on a more informative price system. Overall, social communication hurts market efficiency when information is endogenous. The network effects on the cost of capital, liquidity, trading volume, and welfare are also sensitive to whether information is endogenous. Our analysis highlights the importance of information acquisition in examining the implications of information networks for financial markets."
1407,"Tiers in One-Sided Matching Markets: Theory and Experimental Investigation","Wang, Yu and Haruvy, Ernan","MANAGEMENT SCIENCE","59","6","1458-1477","2013","JUN","One-Sided Matching;Mechanism Design;Fractional Ownership;State-Dependant Utility;Economics Experiments;Risk Aversion","","The design of a matching market may affect behavior in prematch stages. In some settings, forward-looking agents might purchase low-priced properties with the intention of trading up. From a design standpoint, such behavior is undesirable. We investigate a tiered structure as a potential solution. Using a model that endogenizes prematch acquisition decisions, we show that tiers promote exchange while protecting the primary market. In the laboratory, we find that both firm revenue and total social surplus are improved by tiered matching, and the amount of improvement depends on the exchange mechanism the firm uses. We focus on two popular mechanisms deposit first and request first. We find that subjects are less likely to take advantage of the match under tier-free deposit first mechanism, possibly because of risk aversion. Thus, a tiered approach is more critical under the request first mechanism. We confirm that risk aversion partly explains deviations from theory."
1408,"Information Acquisition During Online Decision Making: A Model-Based Exploration Using Eye-Tracking Data","Shi, Savannah Wei and Wedel, Michel and Pieters, F. G. M. (Rik)","MANAGEMENT SCIENCE","59","5","1009-1026","2013","MAY","Process Data;Online Choice;Hierarchical Hidden Markov Model;Eye Tracking;Information Acquisition;Gaze Cascade;Comparison Websites","","We propose a model of eye-tracking data to understand information acquisition patterns on attribute-by-product matrices, which are common in online choice environments such as comparison websites. The objective is to investigate how consumers gather product and attribute information from moment to moment. We propose a hierarchical hidden Markov model that consists of three connected layers: a lower layer that describes the eye movements, a middle layer that identifies information acquisition processes, and an upper layer that captures strategy switching. The proposed model accounts for the data better than several alternative models. The results show that consumers switch frequently between acquisition strategies, and they obtain information on only two or three attributes or products in a particular acquisition strategy before switching. Horizontal and contiguous eye movements play an important role in information acquisition. Furthermore, our results shed new light on the phenomenon of gaze cascades during choice. We discuss the implications for Web design, online retailing, and new directions for research on online choice."
1409,"On Hospice Operations Under Medicare Reimbursement Policies","Ata, Baris and Killaly, Bradley L. and Olsen, Tava Lennon and Parker, Rodney P.","MANAGEMENT SCIENCE","59","5","1027-1044","2013","MAY","Healthcare;Government: Regulations;Fluid Analysis;Simulation","","This paper analyzes the United States Medicare hospice reimbursement policy. The existing policy consists of a daily payment for each patient under care with a global cap of revenues accrued during the Medicare year, which increases with each newly admitted patient. We investigate the hospice's expected profit and provide reasons for a spate of recent provider bankruptcies related to the reimbursement policy; recommendations to alleviate these problems are given. We also analyze a hospice's incentives for patient management, finding several unintended consequences of the Medicare reimbursement policy. Specifically, a hospice may seek short-lived patients (such as cancer patients) over patients with longer expected lengths of stay. The effort with which hospices seek out, or recruit, such patients will vary during the year. Furthermore, the effort they apply to actively discharge a patient whose condition has stabilized may also depend on the time of year. These phenomena are unintended and undesirable but are a direct consequence of the Medicare reimbursement policy. We propose an alternative reimbursement policy to ameliorate these shortcomings."
1410,"The Impact of Corporate Social Responsibility on Firm Value: The Role of Customer Awareness","Servaes, Henri and Tamayo, Ane","MANAGEMENT SCIENCE","59","5","1045-1061","2013","MAY","Corporate Social Responsibiliy;Firm Value;Customer Awareness;Reputation","","This paper shows that corporate social responsibility (CSR) and firm value are positively related for firms with high customer awareness, as proxied by advertising expenditures. For firms with low customer awareness, the relation is either negative or insignificant. In addition, we find that the effect of awareness on the CSR-value relation is reversed for firms with a poor prior reputation as corporate citizens. This evidence is consistent with the view that CSR activities can add value to the firm but only under certain conditions."
1411,"The Stock Selection and Performance of Buy-Side Analysts","Groysberg, Boris and Healy, Paul and Serafeim, George and Shanthikumar, Devin","MANAGEMENT SCIENCE","59","5","1062-1075","2013","MAY","Buy-Side Analysts;Sell-Side Analysts;Stock Recommendations;Recommendation Optimism;Recommendation Performance","","Prior research on equity analysts focuses almost exclusively on those employed by sell-side investment banks and brokerage houses. Yet investment firms undertake their own buy-side research, and their analysts face different stock selection and recommendation incentives than their sell-side peers. We examine the selection and performance of stocks recommended by analysts at a large investment firm relative to those of sell-side analysts from mid-1997 to 2004. We find that the buy-side firm's analysts issue less optimistic recommendations for stocks with larger market capitalizations and lower return volatility than their sell-side peers, consistent with their facing fewer conflicts of interest and having a preference for liquid stocks. Tests with no controls for these effects indicate that annualized buy-side strong buy/buy recommendations underperform those for sell-side peers by 5.9% using market-adjusted returns and by 3.8% using four-factor model abnormal returns. However, these findings are driven by differences in the stocks recommended and their market capitalization. After controlling for these selection effects, we find no difference in the performance of the buy- and sell-side analysts' strong buy/buy recommendations."
1412,"Investor Sentiment, Disagreement, and the Breadth-Return Relationship","Cen, Ling and Lu, Hai and Yang, Liyan","MANAGEMENT SCIENCE","59","5","1076-1091","2013","MAY","Investor Sentiment;Disagreement;Breadth Of Ownership;Cross-Sectional Stock Returns","","We study the cross-sectional breadth-return relation by assuming that investors subject to market sentiment hold a biased belief in the aggregate. With a dynamic multiasset model, we predict that the breadth-return relationship can be either positive or negative depending on the relative strength of two offsetting forces-disagreement and sentiment. We find evidence consistent with our predictions. The breadth-return relationship is positive when the sentiment effect is small. However, the relationship becomes negative when (i) the time-series variation of market-wide sentiment is high and (ii) the cross-sectional dispersion of firm-specific exposure to market-wide sentiment variation is large. Our unified framework reconciles a few seemingly inconsistent empirical studies in this literature and explains puzzling cross-sectional return patterns observed during the Internet bubble and the subprime crisis periods."
1413,"Managing Licensing in a Market for Technology","Arora, Ashish and Fosfuri, Andrea and Ronde, Thomas","MANAGEMENT SCIENCE","59","5","1092-1106","2013","MAY","Technology Licensing;Markets For Technology;Strategic Organization Design;Centralization","","Technology licensing is an important means for companies to extract more value from their intellectual assets. We build a model that helps understand how licensing activity should be organized within large corporations. More specifically, we compare decentralization-where the business unit using the technology makes licensing decisions-to centralized licensing. The business unit has superior information about licensing opportunities but may not have the appropriate incentives because its rewards depend on product market performance. If licensing is decentralized, the business unit forgoes valuable licensing opportunities because the rewards for licensing are (optimally) weaker than those for product market profits. This distortion is stronger when production-based incentives, especially private benefits, of business unit managers are more powerful, making centralization more attractive. Surprisingly, we find that interdependency across business units may result in more, not less, decentralization. Furthermore, even though centralization results in less information, centralized licensing deals are larger. Our model conforms to the existing evidence that reports heterogeneity across firms in both licensing propensity and organization of licensing."
1414,"Control of Dividends, Capital Subscriptions, and Physical Inventories","Li, Lode and Shubik, Martin and Sobel, Matthew J.","MANAGEMENT SCIENCE","59","5","1107-1124","2013","MAY","Inventory;Production;Stochastic;Finance;Corporate Finance;Dynamic Programming;Applications","","Manufacturers manage interrelated flows of material and cash. Material needs capital, and sales contribute cash. Therefore, it may be beneficial to coordinate operational and financial decisions. We study a dynamic model of coordination in an equity-financed firm in which inventory and financial decisions interact in the presence of demand uncertainty, financial constraints, and a risk of default. The criterion is to maximize the expected present value of dividends net of capital subscriptions. The optimal target inventory level and financial decision variables are nondecreasing functions of the levels of inventory and retained earnings. Some important attributes of an optimal policy remain the same regardless of whether default precipitates Chapter 7 or Chapter 11 bankruptcy. The optimal policy is myopic, and if pertinent cost functions are piecewise linear, it is characterized with simple formulas. We show that the methods of inventory theory are useful in analyzing models of operational and financial coordination."
1415,"Optimal Workflow Decisions for Investigators in Systems with Interruptions","Dobson, Gregory and Tezcan, Tolga and Tilson, Vera","MANAGEMENT SCIENCE","59","5","1125-1141","2013","MAY","Dynamic Programming;Optimal Control;Markov;Healthcare;Hospitals;Probability;Markov Processes;Stochastic;Queues;Limit Theorems","","We model a system that consists of a stream of customers processed through three steps by two resources. The first resource, an investigator, handles the first step, in which she collects information from the customer and decides what work will be done in the second step by the second resource, the back office. In the third step, the investigator returns to the customer armed with the additional information or analysis done by the back office and provides the customer with a conclusion, solution, or diagnosis. The investigator has to prioritize either seeing a new customer or completing the work with a customer already in the system. While serving one customer, the investigator may be interrupted by requests from the other customers in the system. Our main objective is to understand the impact of the investigator's choices on system throughput. In addition, we are interested in the occupancy of the system (and thus the flow time of customers). We create a stylized queueing model to examine the investigator's decisions and show that, when interruptions are not an issue, the investigator should prioritize new customers to maximize throughput, keeping the system as full as possible. If customers who have been in the system for a long time generate interruptions and thus additional work for the investigator, we show that it is asymptotically optimal for the investigator to keep the system occupancy low and prioritize discharging customers. Our conclusions are based on a model of a re-entrant queue with dedicated servers serving multiple stations, with two novel features: a buffer that is shared between stations, and jobs in the system generating additional work for the servers."
1416,"The Evolving Impact of Combinatorial Opportunities and Exhaustion on Innovation by Business Groups as Market Development Increases: The Case of Taiwan","Mahmood, Ishtiaq and Chung, Chi-Nien and Mitchell, Will","MANAGEMENT SCIENCE","59","5","1142-1161","2013","MAY","Strategy;Effectiveness;Generalized Networks;Research And Development;Innovation;Business Groups;Market Development","","Business groups are key sources of innovation in emerging market economies, but we understand little about why innovativeness differs across groups and over time. Variation in the density of intragroup buyer-supplier ties, which are common structural linkages among group affiliates, can help explain both cross-sectional and temporal heterogeneity of group innovativeness. We argue that greater buyer-supplier density within a group initially creates combinatorial opportunities that contribute to group innovativeness but ultimately generates combinatorial exhaustion that constrains innovation. Combinatorial exhaustion will set in at lower levels of density as the market environment becomes more developed because the opportunity costs of local search increase. The research introduces a dynamic argument to studies of business-group innovation."
1417,"Consumer Heterogeneity, Product Quality, and Distribution Channels","Shi, Hongyan and Liu, Yunchuan and Petruzzi, Nicholas C.","MANAGEMENT SCIENCE","59","5","1162-1176","2013","MAY","Product Quality;Consumer Heterogeneity;Consumer Transaction Cost;Distribution Channel;Retail-Level Competition;Game Theory","","This paper shows that the effect of different distribution channel structures on product quality depends on the type of consumer heterogeneity and its distribution in a market. When consumer heterogeneity is uniformly distributed either vertically on willingness to pay or horizontally on transaction costs, a manufacturer may provide the same or lower product quality in a decentralized channel than in a centralized channel. In contrast, when consumer heterogeneity follows a more general distribution on willingness to pay, under certain conditions, the manufacturer may provide higher product quality in a decentralized channel than in a centralized channel. Decentralization also may lead to a higher product quality if consumer heterogeneity is uniformly distributed both vertically and horizontally, but not if consumer heterogeneity is uniformly distributed vertically on each of two product-quality attributes. Additionally, competition at the retail level may amplify these findings."
1418,"Revenue Sharing in Airline Alliances","Hu, Xing and Caldentey, Rene and Vulcano, Gustavo","MANAGEMENT SCIENCE","59","5","1177-1195","2013","MAY","Revenue Management;Capacity Control;Contract Design;Cooperative Game Theory;Nash Equilibrium","","We propose a two-stage game-theoretic approach to study the operations of an airline alliance in which independent carriers, managing different reservation and information systems, can collaboratively market and operate codeshare and interline itineraries. In the first-stage game, airlines negotiate fixed proration rates to share the revenues generated by such itineraries. In the second-stage game, airlines operate independent inventory control systems to maximize their own expected revenues. We derive a revenue-sharing rule that is (i) an admissible outcome of the first-stage negotiation, in the sense that no airline coalition has enough incentives to secede from the grand alliance, and (ii) efficient for the second-stage game, in the sense that the decentralized system can achieve the same revenues as a central planner managing the global alliance network. Our numerical study shows that the proposed proration rates can lead to a significant increase in revenues with respect to other rules commonly used in practice. Finally, because our proposal requires the disclosure of private demand information, we introduce a simple alternative rule that is based on public information. This heuristic performs remarkably well, becoming an interesting candidate to be pursued in practice."
1419,"Facilitating Fit Revelation in the Competitive Market","Gu, Zheyin (Jane) and Xie, Ying","MANAGEMENT SCIENCE","59","5","1196-1212","2013","MAY","Consumer Fit Uncertainty;Fit Revelation;Competitive Strategies;Game Theory","","This study examines firms' strategic decisions in the competitive market regarding whether to engage in marketing activities to assist consumers in finding the fit between their personal tastes and products' horizontal attributes. We find that competitive firms' strategies to facilitate fit revelation critically depend on the product qualities they offer. In particular, a firm offering a high-quality product is more likely to facilitate fit revelation in the competitive market than it would as a market monopolist, whereas a firm offering a low-quality product is less likely to do so. In addition, the firm offering the high-quality product implements fit-revealing activities in a greater intensity than its rival that offers the low-quality product, if the quality difference between the two products is small and both products' qualities are sufficiently high."
1420,"Multistage Capital Budgeting for Shared Investments","Johnson, Nicole Bastian and Pfeiffer, Thomas and Schneider, Georg","MANAGEMENT SCIENCE","59","5","1213-1228","2013","MAY","Capital Budgeting;Cooperative Investments;Two-Stage Investment Decisions;Abandonment Options;Cost Allocation","","This paper studies the performance of delegated decision-making schemes in a two-stage, multidivision capital budgeting problem for a shared investment with an inherent abandonment option. Applying both robust goal congruence and sequential adverse selection frameworks, we show that the optimal capital budgeting mechanism entails a capital charge rate above the firm's cost of capital in the first stage but below the cost of capital in the second stage. Further, the first-stage asset cost-sharing rule depends only on the relative divisional growth profiles, and equal cost sharing can be optimal even when the divisions receive significantly different benefits from the shared investment project. In the presence of an adverse selection problem, all agency costs are incorporated into the second-stage budgeting mechanism, leaving the first-stage capital charge rate and asset-sharing rule unaffected even though the agency problem induces capital rationing at both stages."
1421,"Dynamics of Contract Design with Screening","Cvitanic, Jaksa and Wan, Xuhu and Yang, Huali","MANAGEMENT SCIENCE","59","5","1229-1244","2013","MAY","Adverse Selection;Constant Private Shock;Principal-Agent Model;Continuous Time;Continuation Value;Temptation Value;Dynamic Moral Hazard","","We analyze a novel principal-agent problem of moral hazard and adverse selection in continuous time. The constant private shock revealed at time 0 when the agent selects the contract has a long-term impact on the optimal contract. The latter is based not only on the continuation value of the agent who truthfully reports but is also contingent upon the continuation value of the agent who misreports, called the temptation value. The good agent is retired when the temptation value of the bad agent becomes large, because then it is expensive to motivate the good agent. The bad agent is retired when the temptation value of the good agent becomes small, because then the future payment does not provide sufficient incentives. We also compare the efficiency of the shutdown contract and the screening contract and find that the screening contract can bring more profit to the principal only when the agent's reservation utility is sufficiently small."
1422,"Newsvendor Demand Chasing Revisited","Lau, Nelson and Bearden, J. Neil","MANAGEMENT SCIENCE","59","5","1245-1249","2013","MAY","Behavioral Operations;Econometric Analysis;Experiments;Newsvendor;Demand Chasing","","Existing research. on newsvendor behavior asserts that individuals engage in demand chasing adjusting their order quantities towards prior demand. Several metrics have been used to identify this heuristic. By simulation, current metrics are shown to yield excessive false positives, indicating demand chasing when the true order generating process is independent of prior demand. A simple correlation measure does not suffer from this problem and is proposed here as an alternative to some of the more commonly used measures."
1423,"Revisiting Almost Second-Degree Stochastic Dominance","Tzeng, Larry Y. and Huang, Rachel J. and Shih, Pai-Ta","MANAGEMENT SCIENCE","59","5","1250-1254","2013","MAY","Stochastic Dominance;Almost Stochastic Dominance;Risk Aversion","","Leshno and Levy [Leshno M, Levy H (2002) Preferred by all and preferred by most decision makers: Almost stochastic dominance. Management Sci. 48(8):1074-1085] established almost stochastic dominance to reveal preferences for most rather than all decision makers with an increasing and concave utility function. In this paper, we first provide a counterexample to the main theorem of Leshno and Levy related to almost second-degree stochastic dominance. We then redefine this dominance condition and show that the newly defined almost second-degree stochastic dominance is the necessary and sufficient condition to rank distributions for all decision makers excluding the pathological concave preferences. We further extend our results to almost higher-degree stochastic dominance."
1424,"Competitive Incentives: Working Harder or Working Smarter?","Bracha, Anat and Fershtman, Chaim","MANAGEMENT SCIENCE","59","4","771-781","2013","APR","Behavioral Economics;Individual Decision Making;Lab Experiment;Competitive Incentives;Work Effort","","Almost all jobs require a combination of cognitive effort and labor effort. This paper focuses on the effect that competitive incentive schemes have on the chosen combination of these two types of efforts. We use an experimental approach to show that competitive incentives may induce agents to work harder but not necessarily smarter. This effect was stronger for women."
1425,"Analyzing Screening Policies for Childhood Obesity","Yang, Yan and Goldhaber-Fiebert, Jeremy D. and Wein, Lawrence M.","MANAGEMENT SCIENCE","59","4","782-795","2013","APR","Dynamic Programming;Applications;Healthcare;Statistics","","Because of the health and economic costs of childhood obesity, coupled with studies suggesting the benefits of comprehensive (dietary, physical activity, and behavioral counseling) intervention, the U. S. Preventive Services Task Force recently recommended childhood screening and intervention for obesity beginning at age 6. Using a longitudinal data set consisting of the body mass index of 3,164 children up to age 18 and another longitudinal data set containing the body mass index at ages 18 and 40 and the presence or absence of disease (hypertension and diabetes) at age 40 for 747 people, we formulate and numerically solve-separately for boys and girls-a dynamic programming problem for the optimal biennial (i.e., at ages 2, 4, ... , 16) obesity screening thresholds. Unlike most screening problem formulations, we take a societal viewpoint, where the state of the system at each age is the population-wide probability density function of the body mass index. Compared to the biennial version of the task force's recommendation, the screening thresholds derived from the dynamic program achieve a relative reduction in disease prevalence of 3% at the same screening (and treatment) cost, or-because of the flatness of the disease versus screening trade-off curve-achieves the same disease prevalence at a 28% relative reduction in cost. Compared to the task force's policy, which uses the 95th percentile of body mass index (from cross-sectional growth charts tabulated by the Centers for Disease Control and Prevention) as the screening threshold for each age, the dynamic programming policy treats mostly 16-year-olds (including many who are not obese) and very few males under 14 years old. Although our results suggest that adult hypertension and diabetes are minimized by focusing childhood obesity screening and treatment on older adolescents, the shortcomings in the available data and the narrowness of the medical outcomes considered prevent us from making a recommendation about childhood obesity screening policies."
1426,"Class-Restricted Clustering and Microperturbation for Data Privacy","Li, Xiao-Bai and Sarkar, Sumit","MANAGEMENT SCIENCE","59","4","796-812","2013","APR","Confidentiality;Minimum Spanning Tree;Microaggregation;Data Perturbation;Information Theory","","T he extensive use of information technologies by organizations to collect and share personal data has raised strong privacy concerns. To respond to the public's demand for data privacy, a class of clustering-based data masking techniques is increasingly being used for privacy-preserving data sharing and analytics. Although they address reidentification risks, traditional clustering-based approaches for masking numeric attributes typically do not consider the disclosure risk of categorical confidential attributes. We propose a new approach to deal with this problem. The proposed method clusters data such that the data points within a group are similar in the nonconfidential attribute values, whereas the confidential attribute values within a group are well distributed. To accomplish this, the clustering method, which is based on a minimum spanning tree (MST) technique, uses two risk-utility trade-off measures in the growing and pruning stages of the MST technique, respectively. As part of our approach we also propose a novel cluster-level microperturbation method for masking data that overcomes a common problem of traditional clustering-based methods for data masking, which is their inability to preserve important statistical properties such as the variance of attributes and the covariance across attributes. We show that the mean vector and the covariance matrix of the masked data generated using the microperturbation method are unbiased estimates of the original mean vector and covariance matrix. An experimental study on several real-world data sets demonstrates the effectiveness of the proposed approach."
1427,"Managing Strategic Inventories via Manufacturer-to-Consumer Rebates","Arya, Anil and Mittendorf, Brian","MANAGEMENT SCIENCE","59","4","813-818","2013","APR","Inventory;Rebates;Supply Chains","","Manufacturer-to-consumer rebates are a staple of modern supply chains. Such rebates are typically viewed as a means of price discrimination because of partial redemption by consumers. However, the proliferation of universally redeemed instant rebates suggests the practice may be motivated by additional considerations, an issue we tackle in this paper. Our results demonstrate that consumer rebates can be particularly useful when a supply chain encounters inefficiencies stemming from strategic inventory buildup by retailers. Wary of high wholesale prices, a retailer may hold excess inventory to convey a lower willingness to pay in future interactions and thereby strategically undercut future wholesale prices. As a retaliatory consequence, the manufacturer sets high near-term wholesale prices. The pull promotion from consumer rebates encourages more timely retail sales and in doing so undercuts (but does not eliminate) the retailer's strategic inventories. In other words, the introduction of consumer rebates can serve as an enticement for retailers to sell, not just for consumers to buy. Perhaps surprisingly, we find that the manufacturer, retailer, and consumers alike all benefit from the use of rebates, this despite the fact that the manufacturer uses the rebates in self interest and as a strategic weapon."
1428,"Overcoming Resistance to Organizational Change: Strong Ties and Affective Cooptation","Battilana, Julie and Casciaro, Tiziana","MANAGEMENT SCIENCE","59","4","819-836","2013","APR","Organizational Studies;Behavior;Effectiveness;Performance;Networks;Organizational Change;Institutional Theory","","We propose a relational theory of how change agents in organizations use the strength of ties in their network to overcome resistance to change. We argue that strong ties to potentially influential organization members who are ambivalent about a change (fence-sitters) provide the change agent with an affective basis to coopt them. This cooptation increases the probability that the organization will adopt the change. By contrast, strong ties to potentially influential organization members who disapprove of a change outright (resistors) are an effective means of affective cooptation only when a change diverges little from institutionalized practices. With more divergent changes, the advantages of strong ties to resistors accruing to the change agent are weaker, and may turn into liabilities that reduce the likelihood of change adoption. Analyses of longitudinal data from 68 multimethod case studies of organizational change initiatives conducted at the National Health Service in the United Kingdom support these predictions and advance a relational view of organizational change in which social networks operate as tools of political influence through affective mechanisms."
1429,"Knowledge Recombination Across Technological Boundaries: Scientists vs. Engineers","Gruber, Marc and Harhoff, Dietmar and Hoisl, Karin","MANAGEMENT SCIENCE","59","4","837-851","2013","APR","Inventors;Scientists;Engineers;Recombinant Search;Technological Breadth;Patent Classes;Innovation","","Building on the seminal work of Thomas J. Allen, we contribute to the emerging microlevel theory of knowledge recombination by examining how individual-level characteristics of inventors affect the breadth of their technological recombinations. Our data set combines information from 30,550 European patents with matched survey data obtained from 1,880 inventors. The analysis supports the view that inventors with a scientific education are more likely to generate patents that span technological boundaries (in our case, 30 broad, top-level technological domains) than inventors with an engineering degree. A doctoral degree is associated with increased recombination breadth for all groups of inventors. The breadth of an inventor's technological recombinations diminishes with increasing temporal distance to his education, but the differences between scientists and engineers persist over time. Our findings provide several new insights for research on inventors, the literature on organizational learning and innovation, and strategy research."
1430,"Momentum and Organizational Risk Taking: Evidence from the National Football League","Lehman, David W. and Hahn, Jungpil","MANAGEMENT SCIENCE","59","4","852-868","2013","APR","Momentum;Risk;Performance Feedback;Attention;Variable Focus Of Attention Model","","This study examines how momentum shapes organizational risk taking. We define momentum as a sustained and systematic trajectory in performance over time, and we argue that such trends impact interpretations of current performance as well as expectations of future performance. Drawing on the variable focus of attention model, we posit that momentum therefore directs the focus of organizational attention between concerns of aspirations, survival, and slack. Our conceptual model accounts for momentum that occurs within a performance period as well as that which occurs across periods. We propose that within- and across-period momentums are unique in terms of when and how each type impacts risk taking. We tested and found support for our hypotheses in the context of 22,603 play-by-play decisions made by the 32 teams of the National Football League during the 2000-2005 regular season games. Theoretical and practical implications are discussed."
1431,"Multistage Capital Budgeting with Delayed Consumption of Slack","Baiman, Stanley and Heinle, Mirko S. and Saouma, Richard","MANAGEMENT SCIENCE","59","4","869-881","2013","APR","Accounting;Capital Budgeting;Resource Allocation;Multistaged Financing;Abandonment Options;Milestone-Contingent Investments","","Capital budgeting frequently involves multiple stages at which firms can continue or abandon ongoing projects. In this paper, we study a project requiring two stages of investment. Failure to fund Stage 1 of the investment precludes investment in Stage 2, whereas failure to fund Stage 2 results in early termination. In contrast to the existing literature, we assume that the firm can limit the manager's informational rents with the early termination of the project. In this setting, we find that the firm optimally commits to a capital allocation scheme whereby it forgoes positive net present value (NPV) projects at Stage 1 (capital rationing), whereas at Stage 2, depending on the manager's previous report, it sometimes implements projects with a negative continuation NPV but in other situations forgoes implementing projects with positive continuation NPVs."
1432,"Failure and Rescue in an Interbank Network","Rogers, L. C. G. and Veraart, L. A. M.","MANAGEMENT SCIENCE","59","4","882-898","2013","APR","Contagion;Interbank Network;Bank Failure;Merger","","This paper is concerned with systemic risk in an interbank market, modelled as a directed graph of interbank obligations. This builds on the modelling paradigm of Eisenberg and Noe [Eisenberg L, Noe TH (2001) Systemic risk in financial systems. Management Sci. 47(2):236-249] by introducing costs of default if loans have to be called in by a failing bank. This immediately introduces novel and realistic effects. We find that, in general, many different clearing vectors can arise, among which there is a greatest clearing vector, arrived at by letting banks fail in succession until only solvent banks remain. Such a collapse should be prevented if at all possible. We then study situations in which consortia of banks may have the means and incentives to rescue failing banks. This again departs from the conclusions of the earlier work of Eisenberg and Noe, where in the absence of default losses there would be no incentive for solvent banks to rescue failing banks. We conclude with some remarks about how a rescue consortium might be constructed."
1433,"Add-on Pricing by Asymmetric Firms","Shulman, Jeffrey D. and Geng, Xianjun","MANAGEMENT SCIENCE","59","4","899-917","2013","APR","Game Theory;Add-On Pricing;Vertical Differentiation;Bounded Rationality","","This paper uses an analytical model to examine the consequences of add-on pricing when firms are both horizontally and vertically differentiated and there is a segment of boundedly rational consumers who are unaware of the add-on fees at the time of initial purchase. We find that consumers who know the add-on fees can be penalized-and increasingly so-by the existence of boundedly rational consumers. Our consideration of quality asymmetries on base goods and add-ons, plus the inclusion of boundedly rational consumers, leads to several novel findings regarding firm profits. When quality asymmetry is on base goods only and with boundedly rational consumers, add-on pricing can diminish profit for a qualitatively superior firm and increase profit for an inferior firm (i.e., a lose-win result), compared to when add-on pricing is prohibited or infeasible. When quality asymmetries exist on both base goods and add-ons and without boundedly rational consumers, the opposite win-lose result prevails. When quality asymmetries exist on both base goods and add-ons and with boundedly rational consumers, the result can be win-win, win-lose, or lose-win, depending on the magnitude of quality differentiation on add-ons."
1434,"Publicizing Performance","Strobl, Guenter and Van Wesep, Edward D.","MANAGEMENT SCIENCE","59","4","918-932","2013","APR","Publicizing Performance;Compensation;Hidden Information;Matching","","In most employment relationships, the employee's performance at the firm is privately, not publicly, observed. Firms can reward successful employees by publicizing their abilities, for example, via a job title, a glowing letter of recommendation, or a resume-worthy award. Firms that establish reputations for hiring young workers and promoting those who succeed lose good workers to competitors but can pay less to young, inexperienced workers in exchange. We find in a general equilibrium setting that firms with reputations for publicizing performance are able to pay less to employees at every level of tenure and thus earn economic profit, but that these firms will never be the most productive in the economy. For such equilibria to exist, the worker-firm match must be important, suggesting that this practice takes place only in human-capital-intensive industries."
1435,"First-Party Content and Coordination in Two-Sided Markets","Hagiu, Andrei and Spulber, Daniel","MANAGEMENT SCIENCE","59","4","933-949","2013","APR","Two-Sided Platforms;Platform Strategy;Technology;First-Party Content","","The strategic use of first-party content by two-sided platforms is driven by two key factors: the nature of buyer and seller expectations (favorable versus unfavorable) and the nature of the relationship between first-party content and third-party content (complements or substitutes). Platforms facing unfavorable expectations face an additional constraint: their prices and first-party content investment need to be such that low (zero) participation equilibria are eliminated. This additional constraint typically leads them to invest more (less) in first-party content relative to platforms facing favorable expectations when first-and third-party content are substitutes (complements). These results hold with both simultaneous and sequential entry of the two sides. With two competing platforms-incumbent facing favorable expectations and entrant facing unfavorable expectations-and multi-homing on one side of the market, the incumbent always invests (weakly) more in first-party content relative to the case in which it is a monopolist."
1436,"Industry or Academia, Basic or Applied? Career Choices and Earnings Trajectories of Scientists","Agarwal, Rajshree and Ohyama, Atsushi","MANAGEMENT SCIENCE","59","4","950-970","2013","APR","Human Capital;Matching;Scientists And Engineers;Earnings Profile","","We extend life cycle models of human capital investments by incorporating matching theory to examine the sorting pattern of heterogeneous scientists into different career trajectories. We link differences in physical capital investments and complementarities between basic and applied scientists across industry and academic settings to individual differences in scientist ability and preferences to predict an equilibrium matching of scientists to careers and to their earnings evolution. Our empirical analysis, using the National Science Foundation's Scientists and Engineers Statistical Data System database, is consistent with theoretical predictions of (i) sorting by ability into basic versus applied science among academic scientists, but not among industry scientists; and (ii) sorting by higher taste for nonmonetary returns into academia over industry. The evolution of an earnings profile is consistent with these sorting patterns: the earnings trajectories of basic and applied scientists are distinct from each other in academia but are similar in industry."
1437,"Competitive Price-Matching Guarantees: Equilibrium Analysis of the Availability Verification Clause Under Demand Uncertainty","Nalca, Arcan and Boyaci, Tamer and Ray, Saibal","MANAGEMENT SCIENCE","59","4","971-986","2013","APR","Price-Matching Guarantees;Inventory;Availability;Stochastic Demand;Pricing;Verification Of Availability","","Price-matching guarantees involve a retailer matching the lower price of a competitor for an identical product. In reality, retailers often make such guarantees contingent on the verification of product availability at the competitor's location, and decline a price-match request if the product is not available there. This creates certain consternation on the part of customers. In this paper, we investigate the availability contingency strategy from the perspectives of both the retailers and the customers. Our analysis shows that availability contingency clauses intensify inventory competition between retailers and reinstitutes price competition, which is otherwise eliminated by unconditional price-matching guarantees. Consequently, despite what customers may think about the availability verification, it actually increases their surplus. On the other hand, such a clause reduces profits and, hence, is not the equilibrium strategy for retailers. Subsequently, we discuss how a likely customer behaviour pattern may be a plausible explanation regarding the use of the clause by the retailers in practice."
1438,"Dynamic Forecasting and Control Algorithms of Glaucoma Progression for Clinician Decision Support","Helm, Jonathan E. and Lavieri, Mariel S. and Van Oyen, Mark P. and Stein, Joshua D. and Musch, David C.","OPERATIONS RESEARCH","63","5","979-999","2015","SEP-OCT","Linear Gaussian Systems Modeling;Controlled Observations;Stochastic Control;Disease Monitoring;Medical Decision Making;Glaucoma;Visual Field","","In managing chronic diseases such as glaucoma, the timing of periodic examinations is crucial, as it may significantly impact patients' outcomes. We address the question of when to monitor a glaucoma patient by integrating a dynamic, stochastic state space system model of disease evolution with novel optimization approaches to predict the likelihood of progression at any future time. Information about each patient's disease state is learned sequentially through a series of noisy medical tests. This information is used to determine the best time to next test based on each patient's individual disease trajectory as well as population information. We develop closed-form solutions and study structural properties of our algorithm. While some have proposed that fixed-interval monitoring can be improved upon, our methodology validates a sophisticated model-based approach to doing so. Based on data from two large-scale, 10+ years clinical trials, we show that our methods significantly outperform fixed-interval schedules and age-based threshold policies by achieving greater accuracy of identifying progression with fewer examinations. Although this work is motivated by our collaboration with glaucoma specialists, the methodology developed is applicable to a variety of chronic diseases."
1439,"Automated Design of Revenue-Maximizing Combinatorial Auctions","Sandholm, Tuomas and Likhodedov, Anton","OPERATIONS RESEARCH","63","5","1000-1025","2015","SEP-OCT","Combinatorial Auction;Optimal Auction;Revenue Maximization;Automated Mechanism Design (Amd);Parametric Mechanism Design","","Designing optimal-that is, revenue-maximizing-combinatorial auctions (CAs) is an important elusive problem. It is unsolved even for two bidders and two items for sale. Rather than pursuing the manual approach of attempting to characterize the optimal CA, we introduce a family of CAs and then seek a high-revenue auction within that family. The family is based on bidder weighting and allocation boosting; we coin such CAs virtual valuations combinatorial auctions (VVCAs). VVCAs are the Vickrey-Clarke-Groves (VCG) mechanism executed on virtual valuations that are affine transformations of the bidders' valuations. The auction family is parameterized by the coefficients in the transformations. The problem of designing a CA is thereby reduced to search in the parameter space of VVCA-or the more general space of affine maximizer auctions. We first construct VVCAs with logarithmic approximation guarantees in canonical special settings: (1) limited supply with additive valuations and (2) unlimited supply. In the main part of the paper, we develop algorithms that design high-revenue CAs for general valuations using samples from the prior distribution over bidders' valuations. (Priors turn out to be necessary for achieving high revenue.) We prove properties of the problem that guide our design of algorithms. We then introduce a series of algorithms that use economic insights to guide the search and thus reduce the computational complexity. Experiments show that our algorithms create mechanisms that yield significantly higher revenue than the VCG and scale dramatically better than prior automated mechanism design algorithms. The algorithms yielded deterministic mechanisms with the highest known revenues for the settings tested, including the canonical setting with two bidders, two items, and uniform additive valuations."
1440,"Unbiased Estimation with Square Root Convergence for SDE Models","Rhee, Chang-Han and Glynn, Peter W.","OPERATIONS RESEARCH","63","5","1026-1043","2015","SEP-OCT","Unbiased Estimation;Exact Estimation;Square Root Convergence Rate;Stochastic Differential Equations","","In many settings in which Monte Carlo methods are applied, there may be no known algorithm for exactly generating the random object for which an expectation is to be computed. Frequently, however, one can generate arbitrarily close approximations to the random object. We introduce a simple randomization idea for creating unbiased estimators in such a setting based on a sequence of approximations. Applying this idea to computing expectations of path functionals associated with stochastic differential equations (SDEs), we construct finite variance unbiased estimators with a square root convergence rate for a general class of multidimensional SDEs. We then identify the optimal randomization distribution. Numerical experiments with various path functionals of continuous-time processes that often arise in finance illustrate the effectiveness of our new approach."
1441,"Government Debt Control: Optimal Currency Portfolio and Payments","Huaman-Aguilar, Ricardo and Cadenillas, Abel","OPERATIONS RESEARCH","63","5","1044-1057","2015","SEP-OCT","Debt Control;Optimal Currency Debt Portfolio;Optimal Debt Payments;Stochastic Control","","Motivated by empirical facts, we develop a theoretical model for optimal currency government debt portfolio and debt payments, which allows both government debt aversion and jumps in the exchange rates. We obtain first a realistic stochastic differential equation for public debt and then solve explicitly the optimal currency debt problem. We show that higher debt aversion and jumps in the exchange rates lead to a lower proportion of optimal debt in foreign currencies. Furthermore, we show that for a government with extreme debt aversion it is optimal not to issue debt in foreign currencies. To the best of our knowledge, this is the first theoretical model that provides a rigorous explanation of why developing countries have reduced consistently their proportion of foreign debt in their debt portfolios."
1442,"Adaptive Execution: Exploration and Learning of Price Impact","Park, Beomsoo and Van Roy, Benjamin","OPERATIONS RESEARCH","63","5","1058-1076","2015","SEP-OCT","Adaptive Execution;Price Impact;Reinforcement Learning;Regret Bound","","We consider a model in which a trader aims to maximize expected risk-adjusted profit while trading a single security. In our model, each price change is a linear combination of observed factors, impact resulting from the trader's current and prior activity, and unpredictable random effects. The trader must learn coefficients of a price impact model while trading. We propose a new method for simultaneous execution and learning-the confidence-triggered regularized adaptive certainty equivalent (CTRACE) policy-and establish a poly-logarithmic finite-time expected regret bound. In addition, we demonstrate via Monte Carlo simulation that CTRACE outperforms the certainty equivalent policy and a recently proposed reinforcement learning algorithm that is designed to explore efficiently in linear-quadratic control problems."
1443,"Risk Estimation via Regression","Broadie, Mark and Du, Yiping and Moallemi, Ciamac C.","OPERATIONS RESEARCH","63","5","1077-1097","2015","SEP-OCT","","","We introduce a regression-based nested Monte Carlo simulation method for the estimation of financial risk. An outer simulation level is used to generate financial risk factors and an inner simulation level is used to price securities and compute portfolio losses given risk factor outcomes. The mean squared error (MSE) of standard nested simulation converges at the rate k(-2/3), where k measures computational effort. The proposed regression method combines information from different risk factor realizations to provide a better estimate of the portfolio loss function. The MSE of the regression method converges at the rate k(-1) until reaching an asymptotic bias level which depends on the magnitude of the regression error. Numerical results consistent with our theoretical analysis are provided and numerical comparisons with other methods are also given."
1444,"Joint Inventory and Cash Management for Multidivisional Supply Chains","Luo, Wei and Shang, Kevin","OPERATIONS RESEARCH","63","5","1098-1116","2015","SEP-OCT","Multi-Echelon;Cash Pooling;Supply Chain Integration;Financial Flows","","This paper develops a centralized supply chain model that integrates material flows with cash flows. The supply chain is owned by a single firm with two divisions. The downstream division (headquarters), facing random customer demand, replenishes materials from the upstream division. The firm installs a financial services platform that pools the divisions' cash into a master account managed by the headquarters. In each period, cash is received from customers and paid to the outside vendor after materials are delivered. The headquarters determines how much cash to retain for inventory replenishment. The objective is to determine an optimal joint inventory replenishment and cash retention policy for the entire supply chain. We prove that the optimal policy has a surprisingly simple structure-both divisions implement a base-stock policy for inventory replenishment; the headquarters monitors the corporate working capital and implements a two-threshold policy for cash retention. This result is obtained by extending the well-known Clark-Scarf decomposition with newly derived cash-related penalty functions. The optimal policy enables us to investigate the interaction between cash and inventory decisions. We show that in the presence of transaction costs, a firm may stock more even if the inventory holding cost increases. To quantify the value of financial integration, we compare the cash pooling model with systems under different levels of financial integration. Our study suggests that the value of cash pooling can be significant when demand is increasing (respectively, stationary) and the internal transfer price is low (respectively, high). Nevertheless, a significant amount of cash pooling benefit may be recovered if the headquarters can optimize the internal transfer price."
1445,"On Dynamic Decision Making to Meet Consumption Targets","Chen, Lucy Gongtao and Long, Daniel Zhuoyu and Sim, Melvyn","OPERATIONS RESEARCH","63","5","1117-1130","2015","SEP-OCT","Dynamic Programming;Targets;Riskiness Index","","We investigate a dynamic decision model that facilitates a target-oriented decision maker in regulating her risky consumption based on her desired target consumption level in every period in a finite planning horizon. We focus on dynamic operational decision problems of a firm where risky cash flows are being resolved over time. The firm can finance consumption by borrowing or saving to attain prescribed consumption targets over time. To evaluate the ability of the consumption in meeting respective targets, we propose the consumption shortfall risk (CSR) criterion, which has salient properties of attainment content, starvation aversion, subadditivity, and positive homogeneity. We show that if borrowing and saving are unrestricted and their interest rates are common, the optimal policy that minimizes the CSR criterion is to finance consumption at the target level for all periods except the last. For general convex dynamic decision problems, the optimal policies correspond to those that maximize an additive expected utility, in which the underlying utility functions are concave and increasing. Despite the interesting properties, this approach violates the principle of normative utility theory and we discuss the limitations of our target-oriented decision model."
1446,"Merchant Commodity Storage Practice Revisited","Secomandi, Nicola","OPERATIONS RESEARCH","63","5","1131-1143","2015","SEP-OCT","Commodity And Energy Storage;Dual Bounds;Heuristics;Linear Programming;Monte Carlo Simulation;Natural Gas;Real Options;Reoptimization","","Commodity merchants use various heuristics to value leasing contracts on storage facilities as real options and make inventory trading decisions. Two prominent heuristics sequentially reoptimize simple models, leading to the so-called rolling intrinsic (RI) policy and rolling basket of spread options (RSO) policy. The extant literature numerically demonstrates that these two policies are nearly optimal in many realistic settings and can be used with Monte Carlo simulation to obtain fairly accurate estimates of the value of storage contracts. This paper provides a theoretical basis for the observed benefit of reoptimization with these heuristics and additional numerical evidence for the near optimal performance of the RI and RSO policies in several practical cases, but shows that the RI policy significantly outperforms the RSO policy in some of these cases. This research also proves that the RSO policy has a double basestock target structure, a known property of an optimal policy that is trivially true for the RI policy. Moreover, this work develops efficient and effective dual bounds to assess the performance of merchant commodity storage heuristics. In particular, these bounds are immediately relevant to the developers and users of the two considered heuristics."
1447,"Creating More and Better Alternatives for Decisions Using Objectives","Siebert, Johannes and Keeney, Ralph L.","OPERATIONS RESEARCH","63","5","1144-1158","2015","SEP-OCT","Decision Analysis: Creating Alternatives","","The quality of alternatives is crucial for making good decisions. This research, based on five empirical studies of important personally relevant decisions, examines the ability of decision makers to create alternatives for their important decisions and the effectiveness of different stimuli for improving this ability. For decisions for which the full set of potentially desirable alternatives is not readily apparent, our first study indicates that decision makers identify less than half of their alternatives and that the average quality of the overlooked alternatives is the same as those identified. Four other studies provide insight about how to use objectives to stimulate the alternative-creation process of decision makers and confirm with high significance that such use enhances both the number and quality of created alternatives. Using results of the studies, practical guidelines to create alternatives for important decisions are presented."
1448,"Optimal Sparse Designs for Process Flexibility via Probabilistic Expanders","Chen, Xi and Zhang, Jiawei and Zhou, Yuan","OPERATIONS RESEARCH","63","5","1159-1176","2015","SEP-OCT","Flexible Manufacturing;Graph Expanders;Probabilistic Expanders","","We study the problem of how to design a sparse flexible process structure in a balanced and symmetrical production system to match supply with random demand more effectively. Our goal is to provide a sparsest design to achieve (1 - epsilon)-optimality relative to the fully flexible system. In a balanced system with n plants and n products, Chou et al. (2011) proved that there exists a graph expander with Omicron(n/epsilon) arcs to achieve (1 - epsilon)-optimality for every demand realization. Wang and Zhang (2015) showed that the simple k-chain design with Omicron(n/epsilon) arcs can achieve (1 - epsilon)-optimality in expectation. In this paper, we introduce a new concept called probabilistic graph expanders. We prove that a probabilistic expander with O(n ln (1/epsilon) ) arcs guarantees (1 - epsilon) -optimality with high probability (w.h.p.), which is a stronger notion of optimality as compared to the expected performance. Easy-to-implement randomized and deterministic constructions of probabilistic expanders are provided. We show our bound is best possible in the sense that any structure should need at least Omega(n ln (1/epsilon)) arcs to achieve (1 - epsilon)-optimality in expectation (and hence w.h.p.). We also show that in order to achieve (1 - epsilon)-optimality in the worst case, any design would need at least Omega(n/epsilon) arcs; and in order to achieve (1 - epsilon)-optimality in expectation, k-chain needs at least Omega(n/epsilon) arcs."
1449,"Fully Sequential Procedures for Large-Scale Ranking-and-Selection Problems in Parallel Computing Environments","Luo, Jun and Hong, L. Jeff and Nelson, Barry L. and Wu, Yang","OPERATIONS RESEARCH","63","5","1177-1194","2015","SEP-OCT","Fully Sequential Procedures;Parallel Computing;Statistical Issues;Asymptotic Validity","","Fully sequential ranking-and-selection (R&S) procedures to find the best from a finite set of simulated alternatives are often designed to be implemented on a single processor. However, parallel computing environments, such as multi-core personal computers and many-core servers, are becoming ubiquitous and easily accessible for ordinary users. In this paper, we propose two types of fully sequential procedures that can be used in parallel computing environments. We call them vector-filling procedures and asymptotic parallel selection procedures, respectively. Extensive numerical experiments show that the proposed procedures can take advantage of multiple parallel processors and solve large-scale R&S problems."
1450,"Penalty Function with Memory for Discrete Optimization via Simulation with Stochastic Constraints","Park, Chuljin and Kim, Seong-Hee","OPERATIONS RESEARCH","63","5","1195-1212","2015","SEP-OCT","Discrete Optimization Via Simulation;Stochastic Constraints;Penalty Function With Memory","","We consider a discrete optimization via simulation (DOvS) problem with stochastic constraints on secondary performance measures in which both objective and secondary performance measures need to be estimated by stochastic simulation. To solve the problem, we develop a new method called the Penalty Function with Memory (PFM). It is similar to an existing penalty-type method-which consists of a penalty parameter and a measure of violation of constraints-in a sense that it converts a DOvS problem with constraints into a series of unconstrained problems. However, PFM uses a different penalty parameter, called a penalty sequence, determined by the past history of feasibility checks on a solution. Specifically, assuming a minimization problem, a penalty sequence diverges to infinity for any infeasible solution but converges to zero for any feasible solution under certain conditions. As a result, a DOvS algorithm combined with PFM performs well even when an optimal feasible solution is a boundary solution with one or more active constraints. We prove convergence properties and discuss parameter selection for the implementation of PFM. Experimental results on a number of numerical examples show that a DOvS algorithm combined with PFM works well."
1451,"Necessity of Future Information in Admission Control","Xu, Kuang","OPERATIONS RESEARCH","63","5","1213-1226","2015","SEP-OCT","Admission Control;Queueing;Algorithm;Future Information;Predictive Model;Heavy-Traffic Asymptotics","","We study the necessity of predictive information in a class of queueing admission control problems, where a system manager is allowed to divert incoming jobs up to a fixed rate, in order to minimize the queueing delay experienced by the admitted jobs. Spencer et al. (2014) [Spencer J, Sudan M, Xu K (2014) Queuing with future information. Ann. Appl. Probab. 24(5): 2091-2142.] show that the system's delay performance can be significantly improved by having access to future information in the form of a lookahead window, during which the times of future arrivals and services are revealed. They prove that, while delay under an optimal online policy diverges to infinity in the heavy-traffic regime, it can stay bounded by making use of future information. However, the diversion polices of Spencer et al. (2014) require the length of the lookahead window to grow to infinity at a nontrivial rate in the heavy-traffic regime, and it remained open whether substantial performance improvement could still be achieved with less future information. We resolve this question to a large extent by establishing an asymptotically tight lower bound on how much future information is necessary to achieve superior performance, which matches the upper bound of Spencer et al. (2014) up to a constant multiplicative factor. Our result hence demonstrates that the system's heavy-traffic delay performance is highly sensitive to the amount of future information available. Our proof is based on analyzing certain excursion probabilities of the input sample paths, and exploiting a connection between a policy's diversion decisions and subsequent server idling, which may be of independent interest for related dynamic resource allocation problems."
1452,"Non-Stationary Stochastic Optimization","Besbes, Omar and Gur, Yonatan and Zeevi, Assaf","OPERATIONS RESEARCH","63","5","1227-1244","2015","SEP-OCT","Stochastic Approximation;Non-Stationary;Minimax Regret;Online Convex Optimization","","We consider a non-stationary variant of a sequential stochastic optimization problem, in which the underlying cost functions may change along the horizon. We propose a measure, termed variation budget, that controls the extent of said change, and study how restrictions on this budget impact achievable performance. We identify sharp conditions under which it is possible to achieve long-run average optimality and more refined performance measures such as rate optimality that fully characterize the complexity of such problems. In doing so, we also establish a strong connection between two rather disparate strands of literature: (1) adversarial online convex optimization and (2) the more traditional stochastic approximation paradigm (couched in a non-stationary setting). This connection is the key to deriving well-performing policies in the latter, by leveraging structure of optimal policies in the former. Finally, tight bounds on the minimax regret allow us to quantify the price of non-stationarity, which mathematically captures the added complexity embedded in a temporally changing environment versus a stationary one."
1453,"Iterative Auction Design for Tree Valuations","Candogan, Ozan and Ozdaglar, Asuman and Parrilo, Pablo A.","OPERATIONS RESEARCH","63","4","751-771","2015","JUL-AUG","","","We study a special class of multi-item valuations (tree valuations) that exhibit both value complementarity and substitutability. We provide a linear programming formulation of the efficient allocation problem that is of polynomial size in the number of agents and items. This reveals a new class of valuations for which a Walrasian equilibrium exists in the presence of value complementarities. An iterative algorithm for this linear program, in conjunction with an appropriate payment rule, yields an iterative auction that implements the efficient outcome (at an ex post perfect equilibrium). This auction relies on a simple pricing rule, compact demand reports, and uses a novel (interleaved) price update structure to assign final payments to bidders that guarantee truthful bidding."
1454,"Bundled Payments For Healthcare Services: Proposer Selection and Information Sharing","Gupta, Diwakar and Mehrotra, Mili","OPERATIONS RESEARCH","63","4","772-788","2015","JUL-AUG","","","The Centers for Medicare and Medicaid Services (CMS) has introduced a bundled payments for care improvement (BPCI) initiative. Each bundle pertains to a specific medical condition, a set of linked services, and a length of time referred to as an episode of care. Proposers choose bundles, design service chains, and propose target values of quality metrics and payments per episode. Expert panels evaluate proposals based on CMS-announced relative weights, but there is no limit on the number of proposers that may be selected. Moreover, there is no minimum score that will guarantee selection, which makes selection uncertain for proposers. We develop normative models for the parameter selection problems faced by potential proposers within the CMS' proposal selection process. Proposers have private information about their costs of achieving different quality targets, which determine their equilibrium responses. We show that an optimal strategy for CMS, under its current approach, may be to either announce a fixed threshold or keep the selection process uncertain, depending on market characteristics. We also formulate and solve the proposer selection problem as a constrained mechanism design problem, which reveals that CMS' current approach is not optimal. We present policy guidelines for government agencies pursuing bundled payment innovations."
1455,"Dynamic Trading with Reference Point Adaptation and Loss Aversion","Shi, Yun and Cui, Xiangyu and Yao, Jing and Li, Duan","OPERATIONS RESEARCH","63","4","789-806","2015","JUL-AUG","","","We formalize the reference point adaptation process by relating it to a way people perceive prior gains and losses. We then develop a dynamic trading model with reference point adaptation and loss aversion, and derive its semi-analytical solution. The derived optimal stock holding has an asymmetric V-shaped form with respect to prior outcomes, and the related sensitivities are directly determined by the sensitivities of reference point shifts with respect to the outcomes. We also find that the effects of reference point adaptation can be used to shed light on some well documented trading patterns, e.g., house money, break even, and disposition effects."
1456,"Technical Note-Price-Setting Newsvendor Problems with Uncertain Supply and Risk Aversion","Kazaz, Burak and Webster, Scott","OPERATIONS RESEARCH","63","4","807-811","2015","JUL-AUG","","","The price-setting newsvendor problem, which models the economic trade-offs associated with uncertain demand of a perishable product, is fundamental to supply chain analysis. However, in settings such as agriculture, there is significant economic risk associated with supply uncertainty. We analyze how risk aversion and the source of uncertainty-demand and/or supply-affect tractability and optimal decisions. We find that concavity of the objective function is preserved under the introduction of risk aversion if the source of uncertainty is demand, but it is not necessarily preserved if the source of uncertainty is supply. We identify a structural difference that explains this result, and show that this difference can lead to opposing directional effects of risk aversion on optimal decisions."
1457,"Capacity Constraints Across Nests in Assortment Optimization Under the Nested Logit Model","Feldman, Jacob B. and Topaloglu, Huseyin","OPERATIONS RESEARCH","63","4","812-822","2015","JUL-AUG","","","We consider assortment optimization problems when customers choose according to the nested logit model and there is a capacity constraint limiting the total capacity consumption of all products offered in all nests. When each product consumes one unit of capacity, our capacity constraint limits the cardinality of the offered assortment. For the cardinality constrained case, we develop an efficient algorithm to compute the optimal assortment. When the capacity consumption of each product is arbitrary, we give an algorithm to obtain a 4-approximate solution. We show that we can compute an upper bound on the optimal expected revenue for an individual problem instance by solving a linear program. In our numerical experiments, we consider problem instances involving products with arbitrary capacity consumptions. Comparing the expected revenues from the assortments obtained by our 4-approximation algorithm with the upper bounds on the optimal expected revenues, our numerical results indicate that the 4-approximation algorithm performs quite well, yielding less than 2% optimality gap on average."
1458,"Production and Inventory Control for a Make-to-Stock/Calibrate-to-Order System with Dedicated and Shared Resources","Demirel, Sueleyman and Duenyas, Izak and Kapuscinski, Roman","OPERATIONS RESEARCH","63","4","823-839","2015","JUL-AUG","","","Consider a firm that produces multiple products on dedicated production lines (stage 1), which are further customized/calibrated on a shared resource (stage 2), common to all products. The dedicated production lines and the shared resource for calibration face capacity uncertainties. The firm holds inventory of products that are not yet calibrated and carries out calibration when an order is received. We analyze a multiperiod inventory model for two products and derive the optimal production policy at stage 1 as well as the optimal allocation of the shared resource to demands at stage 2. For the shared resource, because of its capacity uncertainty, not only the total planned production quantities matter, but also the sequence in which the products are processed. We characterize the optimal allocation of the shared resource and show that the optimal policy keeps the ending inventories of products as close to a so-called target path as possible. For the dedicated production lines, because of their capacity uncertainty, the optimal production policy depends on the initial inventories. We identify and characterize the structural properties of the optimal production policy. Through a numerical study, we explore how the presence of finite shared capacity influences the inventory targets. We find that the behavior may be counterintuitive: when multiple products share a finite capacity in stage 2, the inventory target for the product having a larger dedicated production capacity or less capacity variability in stage 1 can be higher than the other product. We finally provide sensitivity analysis for the optimal policy and test the performance of simple heuristic policies."
1459,"Technical Note-Pricing Under the Nested Attraction Model with a Multistage Choice Structure","Huh, Woonghee Tim and Li, Hongmin","OPERATIONS RESEARCH","63","4","840-850","2015","JUL-AUG","","","We develop a solution approach to the centralized pricing problem of a nested attraction model with a multistage tree structure. We identify conditions under which the optimal solution can be uniquely determined, and we characterize the optimal solution as a fixed point of a single variable. In the special case of a multistage nested logit model, we show the impact of asymmetry in price sensitivity and adjustment index (also known as the dissimilarity index) and we derive a closed-form solution when the tree structure is symmetric. Many existing results in the literature regarding the single or two-stage nested attraction model are shown to be special cases of the results we have derived. We show that the equal markup property, which holds for the single-stage logit model with symmetric price sensitivity, in general does not hold for products that do not share the same immediate parent node in the nested choice structure even when price sensitivities are the same for all products."
1460,"Benders Decomposition for Production Routing Under Demand Uncertainty","Adulyasak, Yossiri and Cordeau, Jean-Francois and Jans, Raf","OPERATIONS RESEARCH","63","4","851-867","2015","JUL-AUG","","","The production routing problem (PRP) is a generalization of the inventory routing problem and concerns the production and distribution of a single product from a production plant to multiple customers using capacitated vehicles in a discrete- and finite-time horizon. In this study, we consider the stochastic PRP with demand uncertainty in two-stage and multistage decision processes. The decisions in the first stage include production setups and customer visit schedules, while the production and delivery quantities are determined in the subsequent stages. We introduce formulations for the two problems, which can be solved by a branch-and-cut algorithm. To handle a large number of scenarios, we propose a Benders decomposition approach, which is implemented in a single branch-and-bound tree and enhanced through lower-bound lifting inequalities, scenario group cuts, and Pareto-optimal cuts. For the multistage problem, we also use a warm start procedure that relies on the solution of the simpler two-stage problem. Finally, we exploit the reoptimization capabilities of Benders decomposition in a sample average approximation method for the two-stage problem and in a rollout algorithm for the multistage problem. Computational experiments show that instances of realistic size can be solved to optimality for the two-stage and multistage problems, and that Benders decomposition provides significant speedups compared to a classical branch-and-cut algorithm."
1461,"The Power of Optimization Over Randomization in Designing Experiments Involving Small Samples","Bertsimas, Dimitris and Johnson, Mac and Kallus, Nathan","OPERATIONS RESEARCH","63","4","868-876","2015","JUL-AUG","","","Random assignment, typically seen as the standard in controlled trials, aims to make experimental groups statistically equivalent before treatment. However, with a small sample, which is a practical reality in many disciplines, randomized groups are often too dissimilar to be useful. We propose an approach based on discrete linear optimization to create groups whose discrepancy in their means and variances is several orders of magnitude smaller than with randomization. We provide theoretical and computational evidence that groups created by optimization have exponentially lower discrepancy than those created by randomization and that this allows for more powerful statistical inference."
1462,"K-Adaptability in Two-Stage Robust Binary Programming","Hanasusanto, Grani A. and Kuhn, Daniel and Wiesemann, Wolfram","OPERATIONS RESEARCH","63","4","877-891","2015","JUL-AUG","","","Over the last two decades, robust optimization has emerged as a computationally attractive approach to formulate and solve single-stage decision problems affected by uncertainty. More recently, robust optimization has been successfully applied to multistage problems with continuous recourse. This paper takes a step toward extending the robust optimization methodology to problems with integer recourse, which have largely resisted solution so far. To this end, we approximate two-stage robust binary programs by their corresponding K-adaptability problems, in which the decision maker precommits to K second-stage policies, here -and-now, and implements the best of these policies once the uncertain parameters are observed. We study the approximation quality and the computational complexity of the K-adaptability problem, and we propose two mixed-integer linear programming reformulations that can be solved with off-the-shelf software. We demonstrate the effectiveness of our reformulations for stylized instances of supply chain design, route planning, and capital budgeting problems."
1463,"Control of Patient Flow in Emergency Departments, or Multiclass Queues with Deadlines and Feedback","Huang, Junfei and Carmeli, Boaz and Mandelbaum, Avishai","OPERATIONS RESEARCH","63","4","892-908","2015","JUL-AUG","","","We consider the control of patient flow through physicians in emergency departments (EDs). The physicians must choose between catering to patients right after triage, who are yet to be checked, and those who are in process (IP) and are occasionally returning to be checked. Physician capacity is thus modeled as a queueing system with multiclass customers, where some of the classes face deadline constraints on their time-till-first-service, whereas the other classes feedback through service while incurring congestion costs. We consider two types of such costs: first, costs that are incurred at queue-dependent rates and second, costs that are functions of IP sojourn time. The former is our base model, which paves the way for the latter (perhaps more ED realistic). In both cases, we propose and analyze scheduling policies that, asymptotically in conventional heavy traffic, minimize congestion costs while adhering to all deadline constraints. Our policies have two parts: the first chooses between triage and IP patients; assuming triage patients are chosen, the physicians serve the one who is closest to violating the deadline; alternatively, IP patients are served according to a Gc mu rule, in which mu is simply modified to account for feedbacks. For our proposed policies, we establish asymptotic optimality, and develop some congestion laws (snapshot principles) that support forecasting of waiting and sojourn times. Simulation then shows that these policies outperform some commonly used ones. It also validates our laws and demonstrates that some ED features, the complexity of which reaches beyond our model (e.g., time-varying arrival rates, leave without being seen (LWBS) or leave against medical advice (LAMA)), do not lead to significant performance degradation."
1464,"Performance of an LP-Based Control for Revenue Management with Unknown Demand Parameters","Jasin, Stefanus","OPERATIONS RESEARCH","63","4","909-915","2015","JUL-AUG","","","We consider a standard network revenue management (RM) problem and study the performance of a linear program (LP)-based control, the Probabilistic Allocation Control (PAC), in the presence of unknown demand parameters. We show that frequent re-optimizations of PAC without re-estimation suffice to shrink the asymptotic impact of estimation error on revenue loss. If, in addition to re-optimizations, we also frequently re-estimate the parameters, we prove that the performance of PAC in the unknown parameters setting is almost as good as the performance of PAC in the known parameters setting. Our numerical experiments show that PAC yields a revenue improvement of order 0.5%-1.5% relative to LP-based Booking Limit and Bid Price in most cases. Given the small margin in RM industries, such as the airline industry (about 2%), this level of improvement can easily translate into a significant increase in profit."
1465,"Appointment Capacity Planning in Specialty Clinics: A Queueing Approach","Izady, Navid","OPERATIONS RESEARCH","63","4","916-930","2015","JUL-AUG","","","Specialty clinics provide specialized care for patients referred by primary care physicians, emergency departments, or other specialists. Urgent patients must often be seen on the referral day, whereas nonurgent referrals are typically booked an appointment for the future. To deliver a balanced performance, the clinics must know how much appointment capacity is needed for achieving a reasonably quick access for nonurgent patients. To help identify the capacity that leads to the desired performance, we model the dynamics of appointment backlog as novel discrete-time bulk service queues and develop numerical methods for efficient computation of corresponding performance metrics. Realistic features such as arbitrary referral and clinic appointment cancellation distributions, delay-dependent no-show behaviour, and rescheduling of no-shows are explicitly captured in our models. The accuracy of the models in predicting performance as well as their usefulness in appointment capacity planning is demonstrated using real data. We also show the application of our models in capacity planning in clinics where patient panel size, rather than appointment capacity, is the major decision variable."
1466,"Sequential Selection with Unknown Correlation Structures","Qu, Huashuai and Ryzhov, Ilya O. and Fu, Michael C. and Ding, Zi","OPERATIONS RESEARCH","63","4","931-948","2015","JUL-AUG","","","We create the first computationally tractable Bayesian statistical model for learning unknown correlation structures in fully sequential simulation selection. Correlations represent similarities or differences between various design alternatives and can be exploited to extract much more information from each individual simulation. However, in most applications, the correlation structure is unknown, thus creating the additional challenge of simultaneously learning unknown mean performance values and unknown correlations. Based on our new statistical model, we derive a Bayesian procedure that seeks to optimize the expected opportunity cost of the final selection based on the value of information, thus anticipating future changes to our beliefs about the correlations. Our approach outperforms existing methods for known correlation structures in numerical experiments, including one motivated by the problem of optimal wind farm placement, where real data are used to calibrate the simulation model."
1467,"Multistate Bayesian Control Chart Over a Finite Horizon","Wang, Jue and Lee, Chi-Guhn","OPERATIONS RESEARCH","63","4","949-964","2015","JUL-AUG","","","We study a multistate partially observable process control model with a general state transition structure. The process is initially in control and subject to Markovian deterioration that can bring it to out-of-control states. The process may continue making transitions among the out-of-control states, or even back to the in-control state until it reaches an absorbing state. We assume that at least one out-of-control state is absorbing. The objective is to minimize the expected total cost over a finite horizon. By transforming the standard Cartesian belief space into the spherical coordinate system, we show that the optimal policy has a simple control-limit structure. We also examine two specialized models. The first is the phase-type transition time model, in which we develop an algorithm whose complexity is not affected by the number of phases. The second is a model with multiple absorbing out-of-control states, by which we show that certain out-of-control states may incur less total cost than the in-control state, a phenomenon never occurs in the two-state models. We conclude that there are fundamental differences between multistate models and two-state models, and that the spherical coordinate transformation offers significant analytical and computational benefits."
1468,"Dynamic Pricing and Learning with Finite Inventories","den Boer, Arnoud V. and Zwart, Bert","OPERATIONS RESEARCH","63","4","965-978","2015","JUL-AUG","","","We study a dynamic pricing problem with finite inventory and parametric uncertainty on the demand distribution. Products are sold during selling seasons of finite length, and inventory that is unsold at the end of a selling season perishes. The goal of the seller is to determine a pricing strategy that maximizes the expected revenue. Inference on the unknown parameters is made by maximum-likelihood estimation. We show that this problem satisfies an endogenous learning property, which means that the unknown parameters are learned on the fly if the chosen selling prices are sufficiently close to the optimal ones. We show that a small modification to the certainty equivalent pricing strategy-which always chooses the optimal price w.r.t. current parameter estimates-satisfies Regret (T) = O(log(2) (T)), where Regret (T) measures the expected cumulative revenue loss w.r.t. a clairvoyant who knows the demand distribution. We complement this upper bound by showing an instance for which the regret of any pricing policy satisfies Omega (log T)."
1469,"Optimal Coordination Mechanisms for Unrelated Machine Scheduling","Azar, Yossi and Fleischer, Lisa and Jain, Kamal and Mirrokni, Vahab and Svitkina, Zoya","OPERATIONS RESEARCH","63","3","489-500","2015","MAY-JUN","","","We investigate the influence of different algorithmic choices on the approximation ratio in selfish scheduling. Our goal is to design local policies that minimize the inefficiency of resulting equilibria. In particular, we design optimal coordination mechanisms for unrelated machine scheduling, and improve the known approximation ratio from Theta(m) to Theta(log m), where m is the number of machines. A local policy for each machine orders the set of jobs assigned to it only based on parameters of those jobs. A strongly local policy only uses the processing time of jobs on the same machine. We prove that the approximation ratio of any set of strongly local ordering policies in equilibria is at least Omega(m). In particular, it implies that the approximation ratio of a greedy shortest-first algorithm for machine scheduling is at least Omega(m). This closes the gap between the known lower and upper bounds for this problem and answers an open question raised by Ibarra and Kim (1977) [Ibarra OH, Kim CE (1977) Heuristic algorithms for scheduling independent tasks on nonidentical processors. J. ACM 24(2):280-289.], and Davis and Jaffe (1981) [Davis E, Jaffe JM (1981) Algorithms for scheduling tasks on unrelated processors. J. ACM 28(4):721-736.]. We then design a local ordering policy with the approximation ratio of Theta(log m) in equilibria, and prove that this policy is optimal among all local ordering policies. This policy orders the jobs in the nondecreasing order of their inefficiency, i.e., the ratio between the processing time on that machine over the minimum processing time. Finally, we show that best responses of players for the inefficiency-based policy may not converge to a pure Nash equilibrium, and present a Theta(log(2) m) policy for which we can prove fast convergence of best responses to pure Nash equilibria."
1470,"Coalitional Bargaining in Networks","Thanh Nguyen","OPERATIONS RESEARCH","63","3","501-511","2015","MAY-JUN","","","We analyze a noncooperative bargaining game with a general coalition structure. In each period an opportunity for a feasible coalition to form arises according to a stochastic process, and a randomly selected agent in the coalition makes a take-it-or-leave-it offer to the other agents in the coalition. We develop a new technique based on convex programming to characterize the unique stationary equilibrium payoff of the game. We apply the framework to various settings including trading networks with middlemen and cooperation networks with overlapping communities. In these applications, feasible coalitions are determined by an underlying network structure. We study the effect of the underlying network on the pattern of trade and show how an agent's payoff is related to her position in the network."
1471,"Error Theory for Elimination by Aspects","Kohli, Rajeev and Jedidi, Kamel","OPERATIONS RESEARCH","63","3","512-526","2015","MAY-JUN","","","Elimination by aspects (EBA) is a random utility model that is considered to represent the choice process used by consumers more faithfully than logit and probit models. One limitation of the model is that it does not have a known error theory. We show that EBA can be derived by assuming that aspects have random utilities with independent, extreme value distributions. Multinomial logit and rank-ordered logit models are special cases of EBA."
1472,"An Excursion-Theoretic Approach to Regulator's Bank Reorganization Problem","Egami, Masahiko and Oryu, Tadao","OPERATIONS RESEARCH","63","3","527-539","2015","MAY-JUN","","","The importance of the global financial system cannot be exaggerated. When a large financial institution becomes problematic and is bailed out, that bank is often claimed as too big to fail. On the other hand, to prevent bank's failure, regulatory authorities adopt the Prompt Corrective Action (PCA) against a bank that violates certain criteria, often measured by its leverage ratio. In this article, we provide a framework where one can analyze the cost and effect of PCAs. We model a large bank that has deteriorating assets and regulatory actions attempting to prevent the bank's failure. The model uses the excursion theory of Levy processes and finds an optimal leverage ratio that triggers a PCA. A nice feature includes that it incorporates the fact that social cost associated with PCAs are greatly affected by the size of banks subject to PCAs. In other words, one can see the cost of rescuing a bank that is too big to fail."
1473,"A General Framework for Pricing Asian Options Under Markov Processes","Cai, Ning and Song, Yingda and Kou, Steven","OPERATIONS RESEARCH","63","3","540-554","2015","MAY-JUN","","","A general framework is proposed for pricing both continuously and discretely monitored Asian options under one-dimensional Markov processes. For each type (continuously monitored or discretely monitored), we derive the double transform of the Asian option price in terms of the unique bounded solution to a related functional equation. In the special case of continuous-time Markov chain (CTMC), the functional equation reduces to a linear system that can be solved analytically via matrix inversion. Thus the Asian option prices under a one-dimensional Markov process can be obtained by first constructing a CTMC to approximate the targeted Markov process model, and then computing the Asian option prices under the approximate CTMC by numerically inverting the double transforms. Numerical experiments indicate that our pricing method is accurate and fast under popular Markov process models, including the CIR model, the CEV model, Merton's jump diffusion model, the double-exponential jump diffusion model, the variance gamma model, and the CGMY model."
1474,"Process Flexibility: A Distribution-Free Bound on the Performance of k-Chain","Wang, Xuan and Zhang, Jiawei","OPERATIONS RESEARCH","63","3","555-571","2015","MAY-JUN","","","Process flexibility has been widely applied in many industries as a competitive strategy to improve responsiveness to demand uncertainty. An important flexibility concept is the long chain proposed by Jordan and Graves (1995) [Jordan WC, Graves SC (1995) Principles on the benefits of manufacturing process flexibility. Management Sci. 41(4):577-594.]. The effectiveness of the long chain has been investigated via numerical as well as theoretical analysis for specific probability distributions of the random demand. In this paper, we obtain in closed form a distribution-free bound on the ratio of the expected sales of the long chain relative to that of full flexibility. Our bound depends only on the mean and standard deviation of the random demand, but compares very well with the ratio that uses complete information of the demand distribution. This suggests the robustness of the performance of the long chain under different distributions. We also prove a similar result for k-chain, a more general flexibility structure. We further tighten the bounds by incorporating more distributional information of the random demand."
1475,"Multi-Product Price and Assortment Competition","Federgruen, Awi and Hu, Ming","OPERATIONS RESEARCH","63","3","572-584","2015","MAY-JUN","","","We address a generic price competition model in an industry with an arbitrary number of competitors, each offering all or a subset of a given line of N products. The products are substitutes in the sense that the demand volume of each product weakly increases whenever the price of another product increases. The cost structure is linear, with arbitrary cost rates. Our demand model is the unique regular extension of a set of demand functions that are affine in a limited polyhedral subset of the price space. A set of demand functions is regular if it satisfies the following conditions: Under any given price vector, when some product is priced out of the market, i.e., has zero demand, any increase of its price has no impact on the demand volumes. Depending on the set of prices selected by the competing firms, a different product assortment is offered in the market. We characterize the equilibrium prices, product assortment, and sales volumes in the price competition model, under this demand model. Under minimal conditions, we show that a pure Nash equilibrium always exists; while multiple price equilibria may arise, they are equivalent in the sense of generating an identical product assortment and sales volumes."
1476,"Approximation Algorithms for Perishable Inventory Systems","Chao, Xiuli and Gong, Xiting and Shi, Cong and Zhang, Huanan","OPERATIONS RESEARCH","63","3","585-601","2015","MAY-JUN","","","We develop the first approximation algorithms with worst-case performance guarantees for periodic-review perishable inventory systems with general product lifetime, for both backlogging and lost-sales models. The demand process can be nonstationary and correlated over time, capturing such features as demand seasonality and forecast updates. The optimal control policy for such systems is notoriously complicated, thus finding effective heuristic policies is of practical importance. In this paper, we construct a computationally efficient inventory control policy, called the proportional-balancing policy, for systems with an arbitrarily correlated demand process and show that it has a worst-case performance guarantee less than 3. In addition, when the demands are independent and stochastically nondecreasing over time, we propose another policy, called the dual-balancing policy, which admits a worst-case performance guarantee of 2. We demonstrate through an extensive numerical study that both policies perform consistently close to optimal."
1477,"Technical Note-Managing Nonperishable Inventories with Learning About Demand Arrival Rate Through Stockout Times","Bensoussan, Alain and Guo, Pengfei","OPERATIONS RESEARCH","63","3","602-609","2015","MAY-JUN","","","We study a periodic review inventory model with a nonperishable product over an infinite planning horizon. The demand for the nonperishable product arrives according to a Poisson process. Lost sales are unobservable but the stockout times are observable. We formulate the problem as a dynamic programming model with learning on arrival rate according to stockout times and further simplify it by using unnormalized probabilities. We then compare the system performance with those under other two information scenarios where lost sales are observable or both lost sales and stockout times are unobservable. We show that the optimal inventory order-up-to level with observable stockout times is larger than the one with observable lost sales. We also show that more information improves the system performance."
1478,"Design of Near Optimal Decision Rules in Multistage Adaptive Mixed-Integer Optimization","Bertsimas, Dimitris and Georghiou, Angelos","OPERATIONS RESEARCH","63","3","610-627","2015","MAY-JUN","","","In recent years, decision rules have been established as the preferred solution method for addressing computationally demanding, multistage adaptive optimization problems. Despite their success, existing decision rules (a) are typically constrained by their a priori design and (b) do not incorporate in their modeling adaptive binary decisions. To address these problems, we first derive the structure for optimal decision rules involving continuous and binary variables as piecewise linear and piecewise constant functions, respectively. We then propose a methodology for the optimal design of such decision rules that have a finite number of pieces and solve the problem robustly using mixed-integer optimization. We demonstrate the effectiveness of the proposed methods in the context of two multistage inventory control problems. We provide global lower bounds and show that our approach is (i) practically tractable and (ii) provides high quality solutions that outperform alternative methods."
1479,"Oracle-Based Robust Optimization via Online Learning","Ben-Tal, Aharon and Hazan, Elad and Koren, Tomer and Mannor, Shie","OPERATIONS RESEARCH","63","3","628-638","2015","MAY-JUN","","","Robust optimization is a common optimization framework under uncertainty when problem parameters are unknown, but it is known that they belong to some given uncertainty set. In the robust optimization framework, a min-max problem is solved wherein a solution is evaluated according to its performance on the worst possible realization of the parameters. In many cases, a straightforward solution to a robust optimization problem of a certain type requires solving an optimization problem of a more complicated type, which might be NP-hard in some cases. For example, solving a robust conic quadratic program, such as those arising in a robust support vector machine (SVM) with an ellipsoidal uncertainty set, leads in general to a semidefinite program. In this paper, we develop a method for approximately solving a robust optimization problem using tools from online convex optimization, where at every stage a standard (nonrobust) optimization program is solved. Our algorithms find an approximate robust solution using a number of calls to an oracle that solves the original (nonrobust) problem that is inversely proportional to the square of the target accuracy."
1480,"A Constructive Approach to Estimating Pure Characteristics Demand Models with Pricing","Pang, Jong-Shi and Su, Che-Lin and Lee, Yu-Ching","OPERATIONS RESEARCH","63","3","639-659","2015","MAY-JUN","","","Discrete-choice demand models are important and fundamental tools for understanding consumers' choice behavior and for analyzing firms' operations and pricing strategies. In these models, products are often described as a vector of observed characteristics. A consumer chooses the product that maximizes her utility, assumed to be a function of the observed product characteristics and the consumer's preference over these product characteristics. One central task in the demand estimation literature is to infer, based on observed data, consumers' preferences on product characteristics. We consider such an estimation problem for pure characteristics models, a class of random coefficients demand models without the idiosyncratic logit error term in a consumer's utility function. The absence of the logit error term and the use of numerical integration to approximate the integral in aggregate market shares lead to a nonsmooth formulation of approximated market share equations. As a result, solving the approximated market share equations and estimating the model by using existing methods proposed in the econometrics literature remain computationally intractable. To overcome this difficulty, we first characterize consumers' purchase decisions by a system of complementarity constraints. This new characterization leads to smooth approximated market share equations and allows us to cast the corresponding generalized method of moments (GMM) estimation problem essentially as a quadratic program with linear complementarity constraints, parameterized by an exponential, thus nonlinear, function of the structural parameter on price. We also extend this estimation framework to incorporate an endogenous pricing mechanism that captures the competitive profit maximization behavior of the producing firms. We provide existence results of a solution for the GMM estimator and present numerical results to demonstrate the computational effectiveness of our approach."
1481,"Managing Underperformance Risk in Project Portfolio Selection","Hall, Nicholas G. and Long, Daniel Zhuoyu and Qi, Jin and Sim, Melvyn","OPERATIONS RESEARCH","63","3","660-675","2015","MAY-JUN","","","We consider a project selection problem where each project has an uncertain return with partially characterized probability distribution. The decision maker selects a feasible subset of projects so that the risk of the portfolio return not meeting a specified target is minimized. To model and evaluate this risk, we propose and justify a general performance measure, the underperformance riskiness index (URI). We define a special case of the URI, the entropic underperformance riskiness index (EURI), for the project selection problem. We minimize the EURI of the project portfolio, which is the reciprocal of the absolute risk aversion (ARA) of an ambiguity-averse individual with constant ARA who is indifferent between the target return with certainty and the uncertain portfolio return. The EURI extends the riskiness index of Aumann and Serrano (2008) by incorporating the target and distributional ambiguity, and controls the underperformance probability (UP) for any target level. Our model includes correlation and interaction effects such as synergies. Since the model is a discrete nonlinear optimization problem, we derive the optimal solution using Benders decomposition techniques. We show that computationally efficient solution of the model is possible. Furthermore, the project portfolios generated by minimizing the underperformance risk are more than competitive in achieving the target with those found by benchmark approaches, including maximization of expected return, minimization of UP, mean-variance analysis, and maximization of Roy's safetyfirst ratio (1952). When there is only a single constraint for the budget, we describe a heuristic which routinely provides project portfolios with near-optimal underperformance risk."
1482,"Robust Queueing Theory","Bandi, Chaithanya and Bertsimas, Dimitris and Youssef, Nataly","OPERATIONS RESEARCH","63","3","676-700","2015","MAY-JUN","","","We propose an alternative approach for studying queues based on robust optimization. We model the uncertainty in the arrivals and services via polyhedral uncertainty sets, which are inspired from the limit laws of probability. Using the generalized central limit theorem, this framework allows us to model heavy-tailed behavior characterized by bursts of rapidly occurring arrivals and long service times. We take a worst-case approach and obtain closed-form upper bounds on the system time in a multi-server queue. These expressions provide qualitative insights that mirror the conclusions obtained in the probabilistic setting for light-tailed arrivals and services and generalize them to the case of heavy-tailed behavior. We also develop a calculus for analyzing a network of queues based on the following key principles: (a) the departure from a queue, (b) the superposition, and (c) the thinning of arrival processes have the same uncertainty set representation as the original arrival processes. The proposed approach (a) yields results with error percentages in single digits relative to simulation, and (b) is to a large extent insensitive to the number of servers per queue, network size, degree of feedback, and traffic intensity; it is somewhat sensitive to the degree of diversity of external arrival distributions in the network."
1483,"Inventory Models with Shelf-Age and Delay-Dependent Inventory Costs","Federgruen, Awi and Wang, Min","OPERATIONS RESEARCH","63","3","701-715","2015","MAY-JUN","","","In this paper, we show how any model with a general shelf-age-dependent holding cost and delay-dependent backlogging cost structure may be transformed into an equivalent model in which all expected inventory costs are level dependent. We develop our equivalency results, first, for periodic review models with full backlogging of stockouts. These equivalency results permit us to characterize the optimal procurement strategy in various settings and to adopt known algorithms to compute such strategies. For models in which all or part of stockouts are lost, we show that the addition of any shelfage and delay-dependent cost structure does not complicate the structure of the model beyond what is required under the simplest, i. e., linear, holding and backlogging costs. We proceed to show that our results carry over to continuous review models, with demands generated by compound renewal processes; the continuous review models with shelf-age and delay-dependent carrying and backlogging costs are shown to be equivalent to periodic review models with convex level-dependent inventory cost functions."
1484,"Asymptotically Optimal Inventory Control for Assemble-to-Order Systems with Identical Lead Times","Reiman, Martin I. and Wang, Qiong","OPERATIONS RESEARCH","63","3","716-732","2015","MAY-JUN","","","Optimizing multiproduct assemble-to-order (ATO) inventory systems is a long-standing difficult problem. We consider ATO systems with identical component lead times and a general  bill of materials. We use a related two-stage stochastic program (SP) to set a lower bound on the average inventory cost and develop inventory control policies for the dynamic ATO system using this SP. We apply the first-stage SP optimal solution to specify a base-stock replenishment policy, and the second-stage SP recourse linear program to make allocation decisions. We prove that our policies are asymptotically optimal on the diffusion scale, so the percentage gap between the average cost from its lower bound diminishes to zero as the lead time grows."
1485,"M/M/c Queue with Two Priority Classes","Wang, Jianfu and Baron, Opher and Scheller-Wolf, Alan","OPERATIONS RESEARCH","63","3","733-749","2015","MAY-JUN","","","This paper provides the first exact analysis of a preemptive M/M/c queue with two priority classes having different service rates. To perform our analysis, we introduce a new technique to reduce the two-dimensionally infinite Markov chain (MC), representing the two class state space, into a one-dimensionally infinite MC, from which the generating function (GF) of the number of low-priority jobs can be derived in closed form. (The high-priority jobs form a simple M/M/c system and are thus easy to solve.) We demonstrate our methodology for the c = 1, 2 cases; when c > 2, the closed-form expression of the GF becomes cumbersome. We thus develop an exact algorithm to calculate the moments of the number of low-priority jobs for any c >= 2. Numerical examples demonstrate the accuracy of our algorithm and generate insights on (i) the relative effect of improving the service rate of either priority class on the mean sojourn time of low-priority jobs; (ii) the performance of a system having many slow servers compared with one having fewer fast servers; and (iii) the validity of the square root staffing rule in maintaining a fixed service level for the low-priority class. Finally, we demonstrate the potential of our methodology to solve other problems using the M/M/c queue with two priority classes, where the high-priority class is completely impatient."
1486,"OR Forum-A Glimpse at an Operation Analyst's World War II: Report on the Combat Performance of the Remote Control Turrets of B-29 Aircraft","Green, Alex E. S. and Green, Deborah S. and Francis, Richard L.","OPERATIONS RESEARCH","63","2","262-268","2015","MAR-APR","","","Alex Green was a pioneering operations analyst/researcher for the U.S. Army Air Force during World War II. His February 1945 operations analysis Report on the Combat Performance of the Remote Control Turrets of B-29 Aircraft was classified and buried for 70 years. Stationed in the China-Burma-India theatre and addressing a problem of combat losses posed by General Curtis LeMay, Green used written reports and interviews to draw conclusions regarding direction of enemy attack on the B-29s, opposite those of a large stateside simulation study. Resulting in LeMay's changes in B-29 flight formations and frontal armaments, his report also addressed B-29 gun dispersion adjustments and modifications to the analog computer in the plane's nose. This paper examines how Green drew his conclusions under wartime conditions before digital computers. Apart from the extraordinary advances in computer technology, much of his methodology is still relevant today and a part of operations research (OR). This paper offers a window into the origins of OR and remarkable efforts of its pioneers."
1487,"Accounting for Parameter Uncertainty in Large-Scale Stochastic Simulations with Correlated Inputs","Biller, Bahar and Corlu, Canan G.","OPERATIONS RESEARCH","59","3","661-673","2011","MAY-JUN","","","This paper considers large-scale stochastic simulations with correlated inputs having normal-to-anything (NORTA) distributions with arbitrary continuous marginal distributions. Examples of correlated inputs include processing times of workpieces across several workcenters in manufacturing facilities and product demands and exchange rates in global supply chains. Our goal is to obtain mean performance measures and confidence intervals for simulations with such correlated inputs by accounting for the uncertainty around the NORTA distribution parameters estimated from finite historical input data. This type of uncertainty is known as the parameter uncertainty in the discrete-event stochastic simulation literature. We demonstrate how to capture parameter uncertainty with a Bayesian model that uses Sklar's marginal-copula representation and Cooke's copula-vine specification for sampling the parameters of the NORTA distribution. The development of such a Bayesian model well suited for handling many correlated inputs is the primary contribution of this paper. We incorporate the Bayesian model into the simulation replication algorithm for the joint representation of stochastic uncertainty and parameter uncertainty in the mean performance estimate and the confidence interval. We show that our model improves both the consistency of the mean line-item fill-rate estimates and the coverage of the confidence intervals in multiproduct inventory simulations with correlated demands."
1488,"Charlemagne's Challenge: The Periodic Latency Problem","Coene, Sofie and Spieksma, Frits C. R. and Woeginger, Gerhard J.","OPERATIONS RESEARCH","59","3","674-683","2011","MAY-JUN","","","Latency problems are characterized by their focus on minimizing the waiting time for all clients. We study periodic latency problems, a nontrivial extension of standard latency problems. In a periodic latency problem each client has to be visited regularly: there is a server traveling at unit speed, and there is a set of n clients with given positions. The server must visit the clients over and over again, subject to the constraint that successive visits to client i are at most q(i) time units away from each other. We investigate two main problems. In problem PLPP the goal is to find a repeatable route for the server visiting as many clients as possible without violating their q(i)(s). In problem PLP the goal is to minimize the number of servers needed to serve all clients. Depending on the topology of the underlying network, we derive polynomial-time algorithms or hardness results for these two problems. Our results draw sharp separation lines between easy and hard cases."
1489,"Structured Replacement Policies for Components with Complex Degradation Processes and Dedicated Sensors","Elwany, Alaa H. and Gebraeel, Nagi Z. and Maillart, Lisa M.","OPERATIONS RESEARCH","59","3","684-695","2011","MAY-JUN","","","Failure of many engineering systems usually results from a gradual and irreversible accumulation of damage, a degradation process. Most degradation processes can be monitored using sensor technology. The resulting degradation signals are usually correlated with the degradation process. A system is considered to have failed once its degradation signal reaches a prespecified failure threshold. This paper considers a replacement problem for components whose degradation process can be monitored using dedicated sensors. First, we present a stochastic degradation modeling framework that characterizes, in real time, the path of a component's degradation signal. These signals are used to predict the evolution of the component's degradation state. Next, we formulate a single-unit replacement problem as a Markov decision process and utilize the real-time signal observations to determine a replacement policy. We focus on exponentially increasing degradation signals and show that the optimal replacement policy for this class of problems is a monotonically nondecreasing control limit policy. Finally, the model is used to determine an optimal replacement policy by utilizing vibration-based degradation signals from a rotating machinery application."
1490,"Economic and Emissions Implications of Load-Based, Source-Based, and First-Seller Emissions Trading Programs Under California AB32","Chen, Yihsu and Liu, Andrew L. and Hobbs, Benjamin F.","OPERATIONS RESEARCH","59","3","696-712","2011","MAY-JUN","","","In response to Assembly Bill 32, the state of California considered three types of carbon emissions trading programs for the electric power sector: load-based, source-based, and first-seller. They differed in terms of their point of regulation and in whether in-state-to-out-of-state and out-of-state-to-in-state electricity sales are regulated. In this paper, we formulate a market equilibrium model for each of the three approaches, considering power markets, transmission limitations, and emissions trading, and making the simplifying assumption of pure bilateral markets. We analyze the properties of their solutions and show the equivalence of load-based, first-seller, and source-based approaches when in-state-to-out-of-state sales are regulated under the cap. A numeric example illustrates the emissions and economic implications of the models. In the simulated cases, leakage eliminates most of the emissions reductions that the regulations attempt to impose. Furthermore, contract reshuffling occurs to such an extent that all the apparent emissions reductions resulting from changes in sources of imported power are illusory. In reality, the three systems would not be equivalent because there will also be pool-type markets, and the three systems provide different incentives for participating in those markets. However, the equivalence results under our simplifying assumptions show that load-based trading has no inherent advantage compared to other systems in terms of costs to consumers, contrary to claims elsewhere."
1491,"Mixed 0-1 Linear Programs Under Objective Uncertainty: A Completely Positive Representation","Natarajan, Karthik and Teo, Chung Piaw and Zheng, Zhichao","OPERATIONS RESEARCH","59","3","713-728","2011","MAY-JUN","","","In this paper, we analyze mixed 0-1 linear programs under objective uncertainty. The mean vector and the second-moment matrix of the nonnegative objective coefficients are assumed to be known, but the exact form of the distribution is unknown. Our main result shows that computing a tight upper bound on the expected value of a mixed 0-1 linear program in maximization form with random objective is a completely positive program. This naturally leads to semidefinite programming relaxations that are solvable in polynomial time but provide weaker bounds. The result can be extended to deal with uncertainty in the moments and more complicated objective functions. Examples from order statistics and project networks highlight the applications of the model. Our belief is that the model will open an interesting direction for future research in discrete and linear optimization under uncertainty."
1492,"Efficient Resource Allocation via Efficiency Bootstraps: An Application to R&D Project Budgeting","Chen, Chien-Ming and Zhu, Joe","OPERATIONS RESEARCH","59","3","729-741","2011","MAY-JUN","","","Resource allocation decisions are crucial for the success of an organization. This paper proposes an integrated approach to resource allocation problems, in which decision makers have one observation of the multiple input-output criteria of candidates. We offer important improvements over existing approaches based on the widely used data envelopment analysis (DEA), which has two major limitations in its application to resource allocation. First, traditional DEA models compute efficiency scores by optimizing firm-specific shadow prices of inputs and outputs. This could be problematic, because in practice stakeholders would usually require unanimously agreed-upon trade-offs among evaluation criteria. Second, previous allocation approaches based on DEA do not allow for controlling the risk exposure of allocation portfolios. To tackle these problems, we propose an efficiency measure based on equilibrium shadow prices of different criteria, and we use the bootstrap efficiency distributions to gather information regarding efficiency variations and correlations. Through our methodology, decision makers can obtain the risk-minimizing allocation portfolio. We illustrate the proposed approach through an empirical R&D project budgeting problem in which we allocate funding according to the projects efficiency distributions."
1493,"Fault Reporting in Partially Known Networks and Folk Theorems","Tomala, Tristan","OPERATIONS RESEARCH","59","3","754-763","2011","MAY-JUN","","","We consider a group of players who perform tasks repeatedly. The players are nodes of a communication network and observe their neighbors' actions. Players have partial knowledge of the network and only know their set of neighbors. We study the existence of protocols for fault reporting: whenever a player chooses a faulty action, the communication protocol starts and the output publicly reveals the identity of the faulty player. We consider two setups. In the first one, players do not share authentication keys. We show that existence of a protocol for fault reporting is equivalent to the 2-vertex-connectedness of the network: no single vertex deletion disconnects the graph. In the second setup, we allow players to share authentication keys. We show that existence of a distribution of the keys and of a protocol for fault reporting is equivalent to the 2-edge-connectedness of the network: no single edge deletion disconnects the graph. We give applications to the implementation of socially optimal outcomes in repeated games."
1494,"One-Switch Independence for Multiattribute Utility Functions","Abbas, Ali E. and Bell, David E.","OPERATIONS RESEARCH","59","3","764-771","2011","MAY-JUN","","","Assessment of multiattribute utility functions is significantly simplified if it is possible to decompose the function into more manageable pieces. Utility independence is a powerful property that serves well for this purpose, but if it is not appropriate in a given situation, what options does the analyst have? We review some possibilities and propose a new independence assumption based on the one-switch property. We argue that it is a natural generalization of utility independence and show how it leads to tractable multiattribute utility functions."
1495,"Queueing Systems with Synergistic Servers","Andradottir, Sigrun and Ayhan, Hayriye and Down, Douglas G.","OPERATIONS RESEARCH","59","3","772-780","2011","MAY-JUN","","","We consider tandem lines with finite buffers and flexible, heterogeneous servers that are synergistic in that they work more effectively in teams than on their own. Our objective is to determine how the servers should be assigned dynamically to tasks in order to maximize the long-run average throughput. In particular, we investigate when it is better to take advantage of synergy among servers, rather than exploiting the servers' special skills, to achieve the best possible system throughput. We show that when there is no trade-off between server synergy and servers' special skills (because the servers are generalists who are equally skilled at all tasks), the optimal policy has servers working in teams of two or more at all times. Moreover, for Markovian systems with two stations and two servers, we provide a complete characterization of the optimal policy and show that, depending on how well the servers work together, the optimal policy either takes full advantage of servers' special skills, or full advantage of server synergy (and hence there is no middle ground in this case). Finally, for a class of larger Markovian systems, we provide sufficient conditions that guarantee that the optimal policy should take full advantage of server synergy at all times."
1496,"Optimizing Strategic Safety Stock Placement in General Acyclic Networks","Humair, Salal and Willems, Sean P.","OPERATIONS RESEARCH","59","3","781-787","2011","MAY-JUN","","","We present two significant enhancements to the guaranteed-service (GS) model for multiechelon safety stock placement. First, we let each stage's expected inventory cost be a generalized nonconcave non-closed-form function of its incoming and outgoing service time. This allows the GS model to incorporate important phenomena such as variable stage times and nonnested review periods, which previous GS literature has not allowed. Second, we optimize the generalized cost GS model for directed acyclic networks, rather than assembly/distribution networks or trees. For the resulting NP-hard optimization problem, we present a provably optimal algorithm that runs within minutes for 29 chains from a data set of 38 real-world supply chains ranging from 8 to 2,025 stages. We also present two significantly faster yet near-optimal heuristics. One heuristic is motivated by the structure of the formulation's dual space, whereas the other heuristic simply terminates the optimization algorithm after a fixed number of iterations. As a performance benchmark, on the 38 chains, the first heuristic has an average optimality gap of approximately 1.1% and average run time of 88 seconds, whereas the second heuristic has an average optimality gap of 2.8% and an average run time of 5.9 seconds."
1497,"Production Planning with Patterns: A Problem from Processed Food Manufacturing","Mehrotra, Mili and Dawande, Milind and Gavirneni, Srinagesh and Demirci, Mehmet and Tayur, Sridhar","OPERATIONS RESEARCH","59","2","267-282","2011","MAR-APR","","","Based on our work with ConAgra Foods (http://www.conagrafoods.com), a leading U. S. food manufacturer, we study a large-scale production-planning problem. The problem incorporates several distinguishing characteristics of production in the processed-food industry, including (i) production patterns that define specific combinations of weeks in which products can be produced, (ii) food groups that classify products based on the allergens they contain, (iii) sequence-dependent setup times, and (iv) manufacture of a large number of products (typically, around 200-250) on multiple production lines (typically, around 15-20) in the presence of significant inventory holding costs and production setup costs. The objective is to obtain a minimum-cost four-week cyclic schedule to resolve three basic decisions: (a) the assignment of products to each line, (b) the partitioning of the demand of each product over the lines to which it is assigned, and (c) the sequence of production on each line. We show that the general problem is strongly NP-hard. To develop intuition via theoretical analysis, we first obtain a polynomially solvable special case by sacrificing as little of its structure as possible and then analyzing the impact of imposing production patterns. A mixed-integer programming model of the general problem allows us to assess the average impact of production patterns and production capacities on the cost of an optimal schedule. Next, to solve practical instances of the problem, we develop an easy-to-implement heuristic. We first demonstrate the effectiveness of the heuristic on a comprehensive test bed of instances; the average percentage gap of the heuristic solution from the optimum is about 3%. Then, we show savings of about 28% on a real-world instance (283 products, 17 production lines) by comparing the schedule obtained from the heuristic to one that was in use (at ConAgra) based on an earlier consultant's work. Finally, we discuss the IT infrastructure implemented to enable the incorporation of optimized (or near-optimized) solutions for ongoing use."
1498,"An Elasticity Approach to the Newsvendor with Price-Sensitive Demand","Kocabiyikoglu, Ayse and Popescu, Ioana","OPERATIONS RESEARCH","59","2","301-312","2011","MAR-APR","","","We introduce a measure of elasticity of stochastic demand, called the elasticity of the lost-sales rate, which offers a unifying perspective on the well-known newsvendor with pricing problem. This new concept provides a framework to characterize structural results for coordinated and uncoordinated pricing and inventory strategies. Concavity and submodularity of the profit function, as well as sensitivity properties of the optimal inventory and price policies, are characterized by monotonicity conditions, or bounds, on the elasticity of the lost-sales rate. These elasticity conditions are satisfied by most relevant demand models in the marketing and operations literature. Our results unify and complement previous work on price-setting newsvendor models and provide a new tool for researchers modeling stochastic price-sensitive demand in other contexts."
1499,"Multidimensional Approximation Algorithms for Capacity-Expansion Problems","Truong, Van-Anh and Roundy, Robin O.","OPERATIONS RESEARCH","59","2","313-327","2011","MAR-APR","","","We develop multidimensional balancing algorithms to compute provably near-optimal capacity-expansion policies. Our approach is computationally efficient and guaranteed to produce a policy with total expected cost of no more than twice that of an optimal policy. We overcome the curse of dimensionality by introducing novel cost-separation schemes to separate the lost-sales cost of the system into exact monotonic subparts. This is the first approximation technique for multimachine, multiproduct systems facing stochastic, nonstationary, and correlated demands. To show the generality of this separation technique, we apply it to the capacity-expansion problem under two different production planning models: monotone production and revenue-maximizing production. We make the assumptions of minimal inventory and lost sales."
1500,"Fixed-Point Approaches to Computing Bertrand-Nash Equilibrium Prices Under Mixed-Logit Demand","Morrow, W. Ross and Skerlos, Steven J.","OPERATIONS RESEARCH","59","2","328-345","2011","MAR-APR","","","This article describes numerical methods that exploit fixed-point equations equivalent to the first-order condition for Bertrand-Nash equilibrium prices in a class of differentiated product market models based on the mixed-logit model of demand. One fixed-point equation is already prevalent in the literature, and one is novel. Equilibrium prices are computed for the calendar year 2005 new-vehicle market under two mixed-logit models using (i) a state-of-the-art variant of Newton's method applied to the first-order conditions as well as the two fixed-point equations and (ii) a fixed-point iteration generated by our novel fixed-point equation. A comparison of the performance of these methods for a simple model with multiple equilibria is also provided. The analysis and trials illustrate the importance of using fixed-point forms of the first-order conditions for efficient and reliable computations of equilibrium prices."
1501,"A Multiproduct Risk-Averse Newsvendor with Law-Invariant Coherent Measures of Risk","Choi, Sungyong and Ruszczynski, Andrzej and Zhao, Yao","OPERATIONS RESEARCH","59","2","346-364","2011","MAR-APR","","","We consider a multiproduct risk-averse newsvendor under the law-invariant coherent measures of risk. We first establish several fundamental properties of the model regarding the convexity of the problem, the symmetry of the solution, and the impact of risk aversion. Specifically, we show that for identical products with independent demands, increased risk aversion leads to decreased orders. For a large but finite number of heterogeneous products with independent demands, we derive closed-form approximations for the optimal order quantities. The approximations are as simple to compute as the classical risk-neutral solutions. We also show that the risk-neutral solution is asymptotically optimal as the number of products tends to be infinity, and thus risk aversion has no impact in the limit. For a risk-averse newsvendor with dependent demands, we show that positively (negatively) dependent demands lead to lower (higher) optimal order quantities than independent demands. Using a numerical study, we examine the convergence rates of the approximations and develop additional insights into the interplay between dependent demands and risk aversion."
1502,"Discounted Robust Stochastic Games and an Application to Queueing Control","Kardes, Erim and Ordonez, Fernando and Hall, Randolph W.","OPERATIONS RESEARCH","59","2","365-382","2011","MAR-APR","","","This paper presents a robust optimization model for n-person finite state/action stochastic games with incomplete information. We consider nonzero sum discounted stochastic games in which none of the players knows the true data of a game, and each player adopts a robust optimization approach to address the uncertainty. We call these games discounted robust stochastic games. Such games allow us to use simple uncertainty sets for the unknown data and eliminate the need to have an a-priori probability distribution over a set of games. We prove the existence of equilibrium points and propose an explicit mathematical programming formulation for an equilibrium calculation. We illustrate the use of discounted robust stochastic games in a single server queueing control problem."
1503,"The Irrevocable Multiarmed Bandit Problem","Farias, Vivek F. and Madan, Ritesh","OPERATIONS RESEARCH","59","2","383-399","2011","MAR-APR","","","This paper considers the multiarmed bandit problem with multiple simultaneous arm pulls and the additional restriction that we do not allow recourse to arms that were pulled at some point in the past but then discarded. This additional restriction is highly desirable from an operational perspective, and we refer to this problem as the irrevocable multiarmed bandit problem. We observe that natural modifications to well-known heuristics for multiarmed bandit problems that satisfy this irrevocability constraint have unsatisfactory performance and, thus motivated, introduce a new heuristic: the packing heuristic. We establish through numerical experiments that the packing heuristic offers excellent performance, even relative to heuristics that are not constrained to be irrevocable. We also provide a theoretical analysis that studies the price of irrevocability, i.e., the performance loss incurred in imposing the constraint we propose on the multiarmed bandit model. We show that this performance loss is uniformly bounded for a general class of multiarmed bandit problems and indicate its dependence on various problem parameters. Finally, we obtain a computationally fast algorithm to implement the packing heuristic; the algorithm renders the packing heuristic computationally cheaper than methods that rely on the computation of Gittins indices."
1504,"An Ascending Vickrey Auction for Selling Bases of a Matroid","Bikhchandani, Sushil and de Vries, Sven and Schummer, James and Vohra, Rakesh V.","OPERATIONS RESEARCH","59","2","400-413","2011","MAR-APR","","","Consider selling bundles of indivisible goods to buyers with concave utilities that are additively separable in money and goods. We propose an ascending auction for the case when the seller is constrained to sell bundles whose elements form a basis of a matroid. It extends easily to polymatroids. Applications include scheduling, allocation of homogeneous goods, and spatially distributed markets, among others. Our ascending auction induces buyers to bid truthfully and returns the economically efficient basis. Unlike other ascending auctions for this environment, ours runs in pseudopolynomial or polynomial time. Furthermore, we prove the impossibility of an ascending auction for nonmatroidal independence set-systems."
1505,"An Exact Algorithm for the Pickup and Delivery Problem with Time Windows","Baldacci, Roberto and Bartolini, Enrico and Mingozzi, Aristide","OPERATIONS RESEARCH","59","2","414-426","2011","MAR-APR","","","The pickup and delivery problem with time windows (PDPTW) is a generalization of the vehicle routing problem with time windows. In the PDPTW, a set of identical vehicles located at a central depot must be optimally routed to service a set of transportation requests subject to capacity, time window, pairing, and precedence constraints. In this paper, we present a new exact algorithm for the PDPTW based on a set-partitioning-like integer formulation, and we describe a bounding procedure that finds a near-optimal dual solution of the LP-relaxation of the formulation by combining two dual ascent heuristics and a cut-and-column generation procedure. The final dual solution is used to generate a reduced problem containing only the routes whose reduced costs are smaller than the gap between a known upper bound and the lower bound achieved. If the resulting problem has moderate size, it is solved by an integer programming solver; otherwise, a branch-and-cut-and-price algorithm is used to close the integrality gap. Extensive computational results over the main instances from the literature show the effectiveness of the proposed exact method."
1506,"Drift Control with Changeover Costs","Matoglu, Melda Ormeci and Vande Vate, John","OPERATIONS RESEARCH","59","2","427-439","2011","MAR-APR","","","We model the problem of managing capacity in a build-to-order environment as a Brownian drift control problem and seek a policy that minimizes the long-term average cost. We assume the controller can, at some cost, shift the processing rate among a finite set of alternatives, for example by adding or removing staff, increasing or reducing the number of shifts, or opening or closing production lines. The controller incurs a cost for capacity per unit time and a delay cost that reflects the opportunity cost of revenue waiting to be recognized or the customer service impacts of delaying delivery of orders. Furthermore, he incurs a cost per unit to reject orders or idle resources as necessary to keep the workload of waiting orders within a prescribed range. We introduce a practical restriction on this problem, called the S-restricted Brownian control problem, and show how to model it via a structured linear program. We demonstrate that an optimal solution to the S-restricted problem can be found among a special class of policies called deterministic nonoverlapping control band policies. These results exploit apparently new relationships between complementary dual solutions and relative value functions that allow us to obtain a lower bound on the average cost of any nonanticipating policy for the problem, even without the S restriction. Under mild assumptions on the cost parameters, we show that our linear programming approach is asymptotically optimal for the unrestricted Brownian control problem in the sense that by appropriately selecting the S-restricted problem, we can ensure its solution is within an arbitrary finite tolerance of a lower bound on the average cost of any nonanticipating policy for the unrestricted Brownian control problem."
1507,"Quantifying the Impact of Layout on Productivity: An Analysis from Robotic-Cell Manufacturing","Rajapakshe, Tharanga and Dawande, Milind and Sriskandarajah, Chelliah","OPERATIONS RESEARCH","59","2","440-454","2011","MAR-APR","","","Although the impact of layout on the productivity of manufacturing systems is well recognized, a quantification of this impact is an issue that is often ignored or crudely approximated in practice. When evaluating competing layouts for a manufacturing system, the trade-off between their relative benefits and their relative costs underlines the need for a reasonably accurate comparison of the productivity offered by these potential layouts. In this paper, we argue for this approach by comparing the productivity of two well-known layouts in robotic-cell manufacturing: circular and linear. We consider the problem of optimizing throughput in single-gripper, bufferless robotic cells that produce identical parts under the free-pickup criterion and the additive-travel-time metric. For cells with a circular layout, we show that the problem of finding an optimal 1-unit cycle is NP-hard. Our main algorithmic result is a polynomial-time 5/3-approximation algorithm for this problem. We then demonstrate that our algorithm provides near-optimal solutions by compiling its performance on an extensive test bed of practically-relevant instances. Finally, we use the algorithm to assess the increase in throughput for cells with a circular layout over those with a linear layout. We show that a circular layout offers a significant improvement in productivity and demonstrate the robustness of this improvement by examining the sensitivity with respect to changes in the design parameters of the robotic cell. Thus, our work provides operations managers with a tool to trade off the resulting increase in revenue with the additional cost of acquiring and maintaining a robot that can exploit a circular layout."
1508,"Performance Analysis of Queueing Networks via Robust Optimization","Bertsimas, Dimitris and Gamarnik, David and Rikun, Alexander Anatoliy","OPERATIONS RESEARCH","59","2","455-466","2011","MAR-APR","","","Performance analysis of queueing networks is one of the most challenging areas of queueing theory. Barring very specialized models such as product-form type queueing networks, there exist very few results that provide provable nonasymptotic upper and lower bounds on key performance measures. In this paper we propose a new performance analysis method, which is based on the robust optimization. The basic premise of our approach is as follows: rather than assuming that the stochastic primitives of a queueing model satisfy certain probability laws-such as i.i.d. interarrival and service times distributions-we assume that the underlying primitives are deterministic and satisfy the implications of such probability laws. These implications take the form of simple linear constraints, namely, those motivated by the law of the iterated logarithm (LIL). Using this approach we are able to obtain performance bounds on some key performance measures. Furthermore, these performance bounds imply similar bounds in the underlying stochastic queueing models. We demonstrate our approach on two types of queueing networks: (a) tandem single-class queueing network and (b) multiclass single-server queueing network. In both cases, using the proposed robust optimization approach, we are able to obtain explicit upper bounds on some steady-state performance measures. For example, for the case of TSC system we obtain a bound of the form C(1 - rho)(-1) ln ln (1 - rho)(-1)) on the expected steady-state sojourn time, where C is an explicit constant and rho is the bottleneck traffic intensity. This qualitatively agrees with the correct heavy traffic scaling of this performance measure up to the ln ln((1 - rho)(-1)) correction factor."
1509,"Support Vector Machines with the Ramp Loss and the Hard Margin Loss","Brooks, J. Paul","OPERATIONS RESEARCH","59","2","467-479","2011","MAR-APR","","","In the interest of deriving classifiers that are robust to outlier observations, we present integer programming formulations of Vapnik's support vector machine (SVM) with the ramp loss and hard margin loss. The ramp loss allows a maximum error of 2 for each training observation, while the hard margin loss calculates error by counting the number of training observations that are in the margin or misclassified outside of the margin. SVM with these loss functions is shown to be a consistent estimator when used with certain kernel functions. In computational studies with simulated and real-world data, SVM with the robust loss functions ignores outlier observations effectively, providing an advantage over SVM with the traditional hinge loss when using the linear kernel. Despite the fact that training SVM with the robust loss functions requires the solution of a quadratic mixed-integer program (QMIP) and is NP-hard, while traditional SVM requires only the solution of a continuous quadratic program (QP), we are able to find good solutions and prove optimality for instances with up to 500 observations. Solution methods are presented for the new formulations that improve computational performance over industry-standard integer programming solvers alone."
1510,"Revenue Management with Bargaining","Bhandari, Atul and Secomandi, Nicola","OPERATIONS RESEARCH","59","2","498-506","2011","MAR-APR","","","Static game-theoretic models of bilateral bargaining assume that the seller knows his valuation for the item that is up for sale; that is, how the seller may determine this quantity is exogenous to these models. In this paper, we develop and analyze a stylized Markov decision process that endogenizes the seller's computation of his marginal inventory valuation in an infinite-horizon revenue management setting when each sale occurs according to a given bilateral bargaining mechanism. We use this model to compare, both analytically and numerically, the seller's performance under four basic bilateral bargaining mechanisms with a tractable information structure. These comparisons provide insights into the seller's performance under the following trading arrangements: buyer and seller posted pricing, negotiated pricing, and rule-based pricing."
1511,"A Comparison of Bertrand and Cournot Profits in Oligopolies with Differentiated Products","Farahat, Amr and Perakis, Georgia","OPERATIONS RESEARCH","59","2","507-513","2011","MAR-APR","","","We compare equilibrium profits of Bertrand (price) and Cournot (quantity) competition in oligopolies with an arbitrary number of nonsymmetric firms offering differentiated substitutable products under an affine demand function. We provide a precise characterization of the profit relationship in terms of (1) the number of firms, (2) their relative quality and cost differences, and (3) the competition intensity, defined as the maxiumum absolute value of total change in competitors' demand over change in own demand due to a unit change in own price. We first examine the case where firms have the same demand sensitivity to own price and the same demand sensitivity to competitor prices but different cost and quality parameters. For this case, we prove that the total profit of the industry under Cournot competition is at least as high as the total profit under Bertrand competition if the number of firms is less than 28 or if the competition intensity is less than 0.909 or if the differences in quality and cost competitiveness between firms are small. We also prove that for each firm, the profit achieved under Cournot competition is at least as high as the profit achieved under Bertrand competition if the number of firms is less than eight or if the competition intensity is less than 0.739. We then provide numerical and analytical results that qualitatively support the same conclusions for general affine demand functions with variable demand sensitivities to prices."
1512,"Optimal Product Acquisition, Pricing, and Inventory Management for Systems with Remanufacturing","Zhou, Sean X. and Yu, Yikun","OPERATIONS RESEARCH","59","2","514-521","2011","MAR-APR","","","Acquisition of used products ( cores) is central to the success of remanufacturing programs for companies. At the same time, dynamic pricing strategies have been adopted in various industries to better balance supply and customer demand. In this paper, we study the integration of these two aspects of operations together with inventory management for a production/remanufacturing firm. We develop a periodic-review single-product inventory system with price-dependent customer demand. The product return in each period is random but can be actively controlled by the firm's acquisition effort. The firm aims to maximize its total discounted profit over a finite planning horizon by implementing optimal production, remanufacturing, product acquisition, and pricing strategies. We first show that with an exogenous selling price, the optimal production-remanufacturing-disposal policy is simple and characterized by three state-independent parameters. The optimal acquisition effort is decreasing in the aggregate inventory level of serviceable product and cores. Nevertheless, when pricing is an endogenous decision, we find that the optimal policy becomes much more complicated, and its control parameters are state dependent. The optimal selling price is decreasing, whereas the optimal acquisition effort is increasing in the serviceable product inventory level, and both decisions decrease with the aggregate inventory level."
1513,"Optimal Control of an Assembly System with Multiple Stages and Multiple Demand Classes","Benjaafar, Saif and ElHafsi, Mohsen and Lee, Chung-Yee and Zhou, Weihua","OPERATIONS RESEARCH","59","2","522-529","2011","MAR-APR","","","We consider an assembly system with multiple stages, multiple items, and multiple customer classes. The system consists of m production facilities, each producing a different item. Items are produced in variable batch sizes, one batch at a time, with exponentially distributed batch production times. Demand from each class takes place continuously over time according to a compound Poisson process. At each decision epoch, we must determine whether or not to produce an item and, should demand from a particular class arise, whether or not to satisfy it from existing inventory, if any is available. We formulate the problem as a Markov decision process and use it to characterize the structure of the optimal policy. In contrast to systems with exogenous and deterministic production lead times, we show that the optimal production policy for each item is a state-dependent base-stock policy with the base-stock level nonincreasing in the inventory level of items that are downstream and nondecreasing in the inventory level of all other items. For inventory allocation, we show that the optimal policy is a multilevel state-dependent rationing policy with the rationing level for each demand class nonincreasing in the inventory level of all nonend items. We also show how the optimal control problem can be reformulated in terms of echelon inventory and how the essential features of the optimal policy can be reinterpreted in terms of echelon inventory."
1514,"A Top-Down Approach to Multiname Credit","Giesecke, Kay and Goldberg, Lisa R. and Ding, Xiaowei","OPERATIONS RESEARCH","59","2","283-300","2011","MAR-APR","","","A multiname credit derivative is a security that is tied to an underlying portfolio of corporate bonds and has payoffs that depend on the loss due to default in the portfolio. The value of a multiname derivative depends on the distribution of portfolio loss at multiple horizons. Intensity-based models of the loss point process that are specified without reference to the portfolio constituents determine this distribution in terms of few economically meaningful parameters and lead to computationally tractable derivatives valuation problems. However, these models are silent about the portfolio constituent risks. They cannot be used to address applications that are based on the relationship between portfolio and component risks, for example, constituent risk hedging. This paper develops a method that extends these models to the constituents. We use random thinning to decompose the portfolio intensity into a sum of constituent intensities. We show that a thinning process, which allocates the portfolio intensity to constituents, uniquely exists, and is a probabilistic model for the next-to-default. We derive a formula for the constituent default probability in terms of the thinning process and the portfolio intensity, and develop a semi-analytical transform approach to evaluate it. The formula leads to a calibration scheme for the thinning processes and an estimation scheme for constituent hedge sensitivities. An empirical analysis for September 2008 shows that the constituent hedges generated by our method outperform the hedges prescribed by the Gaussian copula model, which is widely used in practice."
1515,"Modeling Cross Correlation in Three-Moment Four-Parameter Decomposition Approximation of Queueing Networks","Kim, Sunkyo","OPERATIONS RESEARCH","59","2","480-497","2011","MAR-APR","","","In two-moment decomposition approximations of queueing networks, the arrival process is modeled as a renewal process, and each station is approximated as a GI/G/1 queue whose mean waiting time is approximated based on the first two moments of the interarrival times and the service times. The departure process is also approximated as a renewal process even though the autocorrelation of this process may significantly affect the performance of the subsequent queue depending on the traffic intensity. When the departure process is split into substreams by Markovian random routing, the split processes typically are modeled as independent renewal processes even though they are correlated with each other. This cross correlation might also have a serious impact on the queueing performance. In this paper, we propose an approach for modeling both the cross correlation and the autocorrelation by a three-moment four-parameter decomposition approximation of queueing networks. The arrival process is modeled as a nonrenewal process by a two-state Markov-modulated Poisson process, viz., MMPP(2). The cross correlation between randomly split streams is accounted for in the second and third moments of the merged process by the innovations method. The main contribution of the present research is that both the cross correlation and the autocorrelation can be modeled in parametric decomposition approximations of queueing networks by integrating the MMPP(2) approximation of the arrival/departure process and the innovations method. We also present numerical results that strongly support our refinements."
1516,"Scheduling of Dynamic In-Game Advertising","Turner, John and Scheller-Wolf, Alan and Tayur, Sridhar","OPERATIONS RESEARCH","59","1","1-16","2011","JAN-FEB","","","Dynamic in-game advertising is a new form of advertising in which ads are served to video game consoles in real time over the Internet. We present a model for the in-game ad-scheduling problem faced by Massive Inc., a wholly owned subsidiary of Microsoft, and a leading global network provider of in-game ad space. Our model has two components: (1) a linear program (solved periodically) establishes target service rates, and (2) a real-time packing heuristic (run whenever a player enters a new level) tracks these service rates. We benchmark our model against Massive's legacy algorithm: When tested on historical data, we observe (1) an 80%-87% reduction in make-good costs (depending on forecast accuracy), and (2) a shift in the age distribution of served ad space, leaving more premium inventory open for future sales. As a result of our work, Massive has increased the number of unique individuals that see each campaign by, on average, 26% per week and achieved 33% smoother campaign delivery as measured by standard deviation of hourly impressions served."
1517,"The Price of Fairness","Bertsimas, Dimitris and Farias, Vivek F. and Trichakis, Nikolaos","OPERATIONS RESEARCH","59","1","17-31","2011","JAN-FEB","","","In this paper we study resource allocation problems that involve multiple self-interested parties or players and a central decision maker. We introduce and study the price of fairness, which is the relative system efficiency loss under a fair allocation assuming that a fully efficient allocation is one that maximizes the sum of player utilities. We focus on two well-accepted, axiomatically justified notions of fairness, viz., proportional fairness and max-min fairness. For these notions we provide a tight characterization of the price of fairness for a broad family of problems."
1518,"Risk Analysis of Collateralized Debt Obligations","Giesecke, Kay and Kim, Baeho","OPERATIONS RESEARCH","59","1","32-49","2011","JAN-FEB","","","Collateralized debt obligations, which are securities with payoffs that are tied to the cash flows in a portfolio of defaultable assets such as corporate bonds, play a significant role in the financial crisis that has spread throughout the world. Insufficient capital provisioning due to flawed and overly optimistic risk assessments is at the center of the problem. This paper develops stochastic methods to measure the risk of positions in collateralized debt obligations and related instruments tied to an underlying portfolio of defaultable assets. It proposes an adaptive point process model of portfolio default timing, a maximum likelihood method for estimating point process models that is based on an acceptance/rejection resampling scheme, and statistical tests for model validation. To illustrate these tools, they are used to estimate the distribution of the profit or loss generated by positions in multiple tranches of a collateralized debt obligation that references the CDX High Yield portfolio and the risk capital required to support these positions."
1519,"Routing and Staffing in Large-Scale Service Systems: The Case of Homogeneous Impatient Customers and Heterogeneous Servers","Armony, Mor and Mandelbaum, Avishai","OPERATIONS RESEARCH","59","1","50-65","2011","JAN-FEB","","","Motivated by call centers, we study large-scale service systems with homogeneous impatient customers and heterogeneous servers; the servers differ with respect to their speed of service. For this model, we propose staffing and routing rules that are jointly asymptotically optimal in the heavy-traffic many-server QED, ED, and ED + QED regimes, respectively. For the QED regime, our proposed routing rule is FSF, that assigns customers to the fastest server available first. In the ED and ED + QED regimes, all work-conserving policies perform (asymptotically) equally well. In all these regimes, the form of the asymptotically optimal staffing is consistent with the asymptotically optimal staffing in the same regimes in the single-pool case, respectively. In particular, the total service capacity is (asymptotically) equal to a term that is proportional to the arrival rate plus, possibly, a term that is proportional to the square-root of the arrival rate, with both terms being regime dependent. Our specific proposed approximation for the optimal staffing vector is obtained via a straightforward solution to a deterministic optimization problem subject to a linear feasible region."
1520,"On the Minimax Complexity of Pricing in a Changing Environment","Besbes, Omar and Zeevi, Assaf","OPERATIONS RESEARCH","59","1","66-79","2011","JAN-FEB","","","We consider a pricing problem in an environment where the customers' willingness-to-pay (WtP) distribution may change at some point over the selling horizon. Customers arrive sequentially and make purchase decisions based on a quoted price and their private reservation price. The seller knows the WtP distribution pre- and postchange but does not know the time at which this change occurs. The performance of a pricing policy is measured in terms of regret: the loss in revenues relative to an oracle that knows the time of change prior to the start of the selling season. We derive lower bounds on the worst-case regret and develop pricing strategies that achieve the order of these bounds, thus establishing the complexity of the pricing problem. Our results shed light on the role of price experimentation and its necessity for optimal detection of changes in market response/WtP. Our formulation allows for essentially arbitrary consumer WtP distributions and purchase request patterns."
1521,"Quasi-Monte Carlo Methods in Financial Engineering: An Equivalence Principle and Dimension Reduction","Wang, Xiaoqun and Sloan, Ian H.","OPERATIONS RESEARCH","59","1","80-95","2011","JAN-FEB","","","Quasi-Monte Carlo (QMC) methods are playing an increasingly important role in the pricing of complex financial derivatives. For models in which the prices of the underlying assets are driven by Brownian motions, the performance of QMC methods is known to depend crucially on the construction of Brownian motions. This paper focuses on the impact of various constructions. Although the Brownian bridge (BB) construction often yields very good results, as Papageorgiou pointed out, there are financial derivatives for which the BB construction performs badly [Papageorgiou, A. 2002. The Brownian bridge does not offer a consistent advantage in quasi-Monte Carlo integration. J. Complexity 18(1) 171-186]. In this paper we first extend Papageorgiou's analysis to establish an equivalence principle: if the BB construction (or any other construction) is the preferred construction for a particular financial derivative, then for any other construction, there is another financial derivative for which the latter construction is the preferred one. In this sense, all methods of construction are equivalent and no method is consistently superior to others; it all depends on the particular financial derivative. We then show how to find a good construction for a particular class of financial derivatives. In practice, our strategy is to find a good construction for an easy problem and then apply it to more complicated problems related to the easy one. This strategy is applied to the arithmetic Asian options (including Bermudan Asian options) based on the weighted average of the stock prices. We do this by studying a simpler problem, namely, the geometric Asian option, for which the best construction is easily available, and applying it to the arithmetic Asian option. Numerical experiments confirm the success of this strategy: whereas in QMC all the common methods (the standard method, BB, and principal component analysis) may lose their power in some situations, the new method behaves very well in all cases. Further large variance reduction can be achieved in combination with a control variate. The new method can be interpreted as a practical way of reducing the effective dimension for some class of functions."
1522,"Kernel Estimation of the Greeks for Options with Discontinuous Payoffs","Liu, Guangwu and Hong, L. Jeff","OPERATIONS RESEARCH","59","1","96-108","2011","JAN-FEB","","","The Greeks are the derivatives (also known as sensitivities) of the option prices with respect to market parameters. They play an important role in financial risk management. Among many Monte Carlo methods of estimating the Greeks, the classical pathwise method requires only the pathwise information that is directly observable from simulation and is generally easier to implement than many other methods. However, the classical pathwise method is generally not applicable to the Greeks of options with discontinuous payoffs and the second-order Greeks. In this paper, we generalize the classical pathwise method to allow discontinuity in the payoffs. We show how to apply the new pathwise method to the first- and second-order Greeks and propose kernel estimators that require little analytical efforts and are very easy to implement. The numerical results show that our estimators work well for practical problems."
1523,"Optimal Inventory Policies when Purchase Price and Demand Are Stochastic","Berling, Peter and Martinez-de-Albeniz, Victor","OPERATIONS RESEARCH","59","1","109-124","2011","JAN-FEB","","","In this paper we consider the problem of a firm that faces a stochastic (Poisson) demand and must replenish from a market in which prices fluctuate, such as a commodity market. We describe the price evolution as a continuous stochastic process and we focus on commonly used processes suggested by the financial literature, such as the geometric Brownian motion and the Ornstein-Uhlenbeck process. It is well known that under variable purchase price, a price-dependent base-stock policy is optimal. Using the single-unit decomposition approach, we explicitly characterize the optimal base-stock level using a series of threshold prices. We show that the base-stock level is first increasing and then decreasing in the current purchase price. We provide a procedure for calculating the thresholds, which yields closed-form solutions when price follows a geometric Brownian motion and implicit solutions under the Ornstein-Uhlenbeck price model. In addition, our numerical study shows that the optimal policy performs much better than inventory policies that ignore future price evolution, because it tends to place larger orders when prices are expected to increase."
1524,"Risk-Averse Two-Stage Stochastic Linear Programming: Modeling and Decomposition","Miller, Naomi and Ruszczynski, Andrzej","OPERATIONS RESEARCH","59","1","125-132","2011","JAN-FEB","","","We formulate a risk-averse two-stage stochastic linear programming problem in which unresolved uncertainty remains after the second stage. The objective function is formulated as a composition of conditional risk measures. We analyze properties of the problem and derive necessary and sufficient optimality conditions. Next, we construct a new decomposition method for solving the problem that exploits the composite structure of the objective function. We illustrate its performance on a portfolio optimization problem."
1525,"Average Cost Single-Stage Inventory Models: An Analysis Using a Vanishing Discount Approach","Huh, Woonghee Tim and Janakiraman, Ganesh and Nagarajan, Mahesh","OPERATIONS RESEARCH","59","1","143-155","2011","JAN-FEB","","","An important problem in the theory of dynamic programming is that of characterizing sufficient conditions under which the optimal policies for Markov decision processes (MDPs) under the infinite-horizon discounted cost criterion converge to an optimal policy under the average cost criterion as the discount factor approaches 1. In this paper, we provide, for stochastic inventory models, a set of such sufficient conditions. These conditions, unlike many others in the dynamic programming literature, hold when the action space is noncompact and the underlying transition law is weakly continuous. Moreover, we verify that these conditions hold for almost all conceivable single-stage inventory models with few assumptions on cost and demand parameters. As a consequence of our analysis, we partially characterize, for the first time, optimal policies for the following inventory systems under the infinite-horizon average-cost criterion, which have thus far been a challenge: (a) capacitated systems with setup costs, (b) uncapacitated systems with convex ordering costs plus a setup cost, and (c) systems with lost sales and lead times."
1526,"Supply Chain Competition with Multiple Manufacturers and Retailers","Adida, Elodie and DeMiguel, Victor","OPERATIONS RESEARCH","59","1","156-172","2011","JAN-FEB","","","We study competition in a supply chain where multiple manufacturers compete in quantities to supply a set of products to multiple risk-averse retailers who compete in quantities to satisfy the uncertain consumer demand. For the symmetric supply chain, we give closed-form expressions for the unique equilibrium. We find that, provided there is a sufficiently large number of manufacturers and retailers, the supply chain efficiency (the ratio of the aggregate utility in the decentralized and centralized chains) can be raised to 1 by inducing the right degree of retailer differentiation. Also, risk aversion results in triple marginalization: retailers require a strictly positive margin to distribute even when they are perfectly competitive, because otherwise they are unwilling to undertake the risk associated with the uncertainty in demand. For the asymmetric supply chain, we show how numerical optimization can be used to compute the equilibria, and we find that the supply chain efficiency may drop sharply with the asymmetry of either manufacturers or retailers. We also find that the introduction of asymmetric product assortment reduces the degree of competition among retailers and thus has an effect similar to that of reducing the number of retailers. We show that, unlike in the symmetric chain, the asymmetric chain efficiency depends on product differentiation and risk aversion because of the interaction between these features and the asymmetry of manufacturers and retailers."
1527,"Solving Nonlinear Covering Problems Arising in WLAN Design","Amaldi, Edoardo and Bosio, Sandro and Malucelli, Federico and Yuan, Di","OPERATIONS RESEARCH","59","1","173-187","2011","JAN-FEB","","","Wireless local area networks (WLANs) are widely used for cable replacement and wireless Internet access. Because the medium access control (MAC) scheme of WLANs has a strong influence on network performance, it should be accounted for in WLAN design. This paper presents AP location models that optimize a network performance measure specifically for the MAC scheme of WLANs that represents the efficiency in sharing the wireless medium. For these models, we propose a solution framework based on an effective integer-linear programming Dantzig-Wolfe reformulation. This framework is applicable to any nonlinear covering problem where the objective function is a sum of contributions over the groundset elements (users in WLANs). Extensive computational results show that our solution strategy quickly yields optimal or near-optimal solutions for WLAN design instances of realistic size."
1528,"Information Collection on a Graph","Ryzhov, Ilya O. and Powell, Warren B.","OPERATIONS RESEARCH","59","1","188-201","2011","JAN-FEB","","","We derive a knowledge gradient policy for an optimal learning problem on a graph, in which we use sequential measurements to refine Bayesian estimates of individual edge values in order to learn about the best path. This problem differs from traditional ranking and selection in that the implementation decision (the path we choose) is distinct from the measurement decision (the edge we measure). Our decision rule is easy to compute and performs competitively against other learning policies, including a Monte Carlo adaptation of the knowledge gradient policy for ranking and selection."
1529,"Finite Disjunctive Programming Characterizations for General Mixed-Integer Linear Programs","Chen, Binyuan and Kuecuekyavuz, Simge and Sen, Suvrajeet","OPERATIONS RESEARCH","59","1","202-210","2011","JAN-FEB","","","In this paper, we give a finite disjunctive programming procedure to obtain the convex hull of general mixed-integer linear programs (MILP) with bounded integer variables. We propose a finitely convergent convex hull tree algorithm that constructs a linear program that has the same optimal solution as the associated MILP. In addition, we combine the standard notion of sequential cutting planes with ideas underlying the convex hull tree algorithm to help guide the choice of disjunctions to use within a cutting plane method. This algorithm, which we refer to as the cutting plane tree algorithm, is shown to converge to an integral optimal solution in finitely many iterations. Finally, we illustrate the proposed algorithm on three well-known examples in the literature that require an infinite number of elementary or split disjunctions in a rudimentary cutting plane algorithm."
1530,"An Exact Algorithm for the Period Routing Problem","Baldacci, Roberto and Bartolini, Enrico and Mingozzi, Aristide and Valletta, Andrea","OPERATIONS RESEARCH","59","1","228-241","2011","JAN-FEB","","","This paper presents an exact algorithm for solving strategic and tactical multiperiod vehicle routing problems that can be modeled as period vehicle routing problems (PVRPs). The PVRP is defined on a time horizon of several days and consists of assigning appropriate combinations of delivery to customers and designing a set of delivery routes for every day of the planning period. The objective is to service all customers assigned to each day minimizing the overall routing cost. This paper describes an integer programming formulation of the PVRP that is used to derive different lower bounds and an exact solution method. Computational results on test instances from the literature and on new sets of test instances show the effectiveness of the proposed method."
1531,"The Adaptive Knapsack Problem with Stochastic Rewards","Ilhan, Taylan and Iravani, Seyed M. R. and Daskin, Mark S.","OPERATIONS RESEARCH","59","1","242-248","2011","JAN-FEB","","","Given a set of items with associated deterministic weights and random rewards, the adaptive stochastic knapsack problem (adaptive SKP) maximizes the probability of reaching a predetermined target reward level when items are inserted sequentially into a capacitated knapsack before the reward of each item is realized. This model arises in resource allocation problems that permit or require sequential allocation decisions in a probabilistic setting. One particular application is in obsolescence inventory management. In this paper, the adaptive SKP is formulated as a dynamic programming (DP) problem for discrete random rewards. The paper also presents a heuristic that mixes adaptive and static policies to overcome the curse of dimensionality in the DP. The proposed heuristic is extended to problems with normally distributed random rewards. The heuristic can solve large problems quickly, and its solution always outperforms a static policy. The numerical study indicates that a near-optimal solution can be obtained by using an algorithm with limited look-ahead capabilities."
1532,"Exact Analysis of a Lost Sales Model Under Stuttering Poisson Demand","Chen, Jie and Jackson, Peter L. and Muckstadt, John A.","OPERATIONS RESEARCH","59","1","249-253","2011","JAN-FEB","","","We investigate the (S - 1, S) inventory policy under stuttering Poisson demand and generally distributed lead time when the excess demand is lost. We correct results presented in Feeney and Sherbrooke's seminal paper [Feeney, G. J., C. C. Sherbrooke. 1966. The (S - 1, S) inventory policy under compound Poisson demand. Management Sci. 12(5) 391-411] and note that the stationary distribution of units on order for the general compound Poisson demand case is still an open question."
1533,"Robust Newsvendor Competition Under Asymmetric Information","Jiang, Houyuan and Netessine, Serguei and Savin, Sergei","OPERATIONS RESEARCH","59","1","254-261","2011","JAN-FEB","","","We generalize analysis of competition among newsvendors to a setting in which competitors possess asymmetric information about future demand realizations, and this information is limited to knowledge of the support of demand distribution. In such a setting, traditional expectation-based optimization criteria are not adequate, and therefore we focus on the alternative criterion used in the robust optimization literature: the absolute regret minimization. We show existence and derive closed-form expressions for the robust optimization Nash equilibrium solution for a game with an arbitrary number of players. This solution allows us to gain insight into the nature of robust asymmetric newsvendor competition. We show that the competitive solution in the presence of information asymmetry is an intuitive extension of the robust solution for the monopolistic newsvendor problem, which allows us to distill the impact of both competition and information asymmetry. In addition, we show that, contrary to the intuition, a competing newsvendor does not necessarily benefit from having better information about its own demand distribution than its competitor has."
1534,"Clique Relaxations in Social Network Analysis: The Maximum k-Plex Problem","Balasundaram, Balabhaskar and Butenko, Sergiy and Hicks, Illya V.","OPERATIONS RESEARCH","59","1","133-142","2011","JAN-FEB","","","This paper introduces and studies the maximum k-plex problem, which arises in social network analysis and has wider applicability in several important areas employing graph-based data mining. After establishing NP-completeness of the decision version of the problem on arbitrary graphs, an integer programming formulation is presented, followed by a polyhedral study to identify combinatorial valid inequalities and facets. A branch-and-cut algorithm is implemented and tested on proposed benchmark instances. An algorithmic approach is developed exploiting the graph-theoretic properties of a k-plex that is effective in solving the problem to optimality on very large, sparse graphs such as the power law graphs frequently encountered in the applications of interest."
1535,"An Integer Optimization Approach to Large-Scale Air Traffic Flow Management","Bertsimas, Dimitris and Lulli, Guglielmo and Odoni, Amedeo","OPERATIONS RESEARCH","59","1","211-227","2011","JAN-FEB","","","This paper presents a new integer programming (IP) model for large-scale instances of the air traffic flow management (ATFM) problem. The model covers all the phases of each flight-i.e., takeoff, en route cruising, and landing-and solves for an optimal combination of flow management actions, including ground-holding, rerouting, speed control, and airborne holding on a flight-by-flight basis. A distinguishing feature of the model is that it allows for rerouting decisions. This is achieved through the imposition of sets of local conditions that make it possible to represent rerouting options in a compact way by only introducing some new constraints. Moreover, three classes of valid inequalities are incorporated into the model to strengthen the polyhedral structure of the underlying relaxation. Computational times are short and reasonable for practical application on problem instances of size comparable to that of the entire U. S. air traffic management system. Thus, the proposed model has the potential of serving as the main engine for the preliminary identification, on a daily basis, of promising air traffic flow management interventions on a national scale in the United States or on a continental scale in Europe."
1536,"Initial Shipment Decisions for New Products at Zara","Gallien, Jeremie and Mersereau, Adam J. and Garro, Andres and Dapena Mora, Alberte and Novoa Vidal, Martin","OPERATIONS RESEARCH","63","2","269-286","2015","MAR-APR","","","Given uncertain popularity of new products by location, fast fashion retailer Zara faces a trade-off. Large initial shipments to stores reduce lost sales in the critical first days of the product life cycle, but maintaining stock at the warehouse allows restocking flexibility once initial sales are observed. In collaboration with Zara, we develop and test a decision support system featuring a data-driven model of forecast updating and a dynamic optimization formulation for allocating limited stock by location over time. A controlled field experiment run worldwide with 34 articles during the 2012 season showed an increase in total average season sales by approximately 2% and a reduction in the number of unsold units at the end of the regular selling season by approximately 4%."
1537,"Planning for HIV Screening, Testing, and Care at the Veterans Health Administration","Deo, Sarang and Rajaram, Kumar and Rath, Sandeep and Karmarkar, Uday S. and Goetz, Matthew B.","OPERATIONS RESEARCH","63","2","287-304","2015","MAR-APR","","","We analyzed the planning problem for HIV screening, testing, and care. This problem consists of determining the optimal fraction of patients to be screened in every period as well as the optimum staffing level at each part of the healthcare system to maximize the total health benefits to the patients measured by quality-adjusted life-years (QALYs) gained. We modeled this problem as a nonlinear mixed integer programming program comprising disease progression (the transition of the patients across health states), system dynamics (the flow of patients in different health states across various parts of the healthcare delivery system), and budgetary and capacity constraints. We applied the model to the Greater Los Angeles (GLA) station in the Veterans Health Administration system. We found that a Centers for Disease Control and Prevention recommended routine screening policy in which all patients visiting the system are screened for HIV irrespective of risk factors may not be feasible because of budgetary constraints. Consequently, we used the model to develop and evaluate managerially relevant policies within existent capacity and budgetary constraints to improve upon the current risk based screening policy of screening only high risk patients. Our computational analysis showed that the GLA station can achieve substantial increase (20% to 300%) in the QALYs gained by using these policies over risk based screening. The GLA station has already adapted two of these policies that could yield better patient health outcomes over the next few years. In addition, our model insights have influenced the decision making process at this station."
1538,"Service Systems with Slowdowns: Potential Failures and Proposed Solutions","Dong, Jing and Feldman, Pnina and Yom-Tov, Galit B.","OPERATIONS RESEARCH","63","2","305-324","2015","MAR-APR","","","Many service systems exhibit service slowdowns when the system is congested. Our goal in this paper is to investigate this phenomenon and its effect on system performance. We modify the Erlang-A model to account for service slowdowns and carry out the performance analysis in the quality-and efficiencydriven (QED) regime. We find that when the load sensitivity is low, the system can achieve QED performance, but the square-root staffing parameter requires an adjustment to achieve the same performance as an ordinary Erlang-A queue. When the load sensitivity is high, the system alternates randomly between a QED and an efficiency-driven (ED) regime performance levels, a phenomenon that we refer to as bistability. We analyze how the system scale and model parameters affect the bistability phenomenon and propose an admission control policy to avoid ED performance."
1539,"The d-Level Nested Logit Model: Assortment and Price Optimization Problems","Li, Guang and Rusmevichientong, Paat and Topaloglu, Huseyin","OPERATIONS RESEARCH","63","2","325-341","2015","MAR-APR","","","We consider assortment and price optimization problems under the d-level nested logit model. In the assortment optimization problem, the goal is to find the revenue-maximizing assortment of products to offer, when the prices of the products are fixed. Using a novel formulation of the d-level nested logit model as a tree of depth d, we provide an efficient algorithm to find the optimal assortment. For a d-level nested logit model with n products, the algorithm runs in O(dn log n) time. In the price optimization problem, the goal is to find the revenue-maximizing prices for the products, when the assortment of offered products is fixed. Although the expected revenue is not concave in the product prices, we develop an iterative algorithm that generates a sequence of prices converging to a stationary point. Numerical experiments show that our method converges faster than gradient-based methods, by many orders of magnitude. In addition to providing solutions for the assortment and price optimization problems, we give support for the d-level nested logit model by demonstrating that it is consistent with the random utility maximization principle and equivalent to the elimination by aspects model."
1540,"Optimal Joint Replenishment and Transshipment Policies in a Multi-Period Inventory System with Lost Sales","Abouee-Mehrizi, Hossein and Berman, Oded and Sharma, Shrutivandana","OPERATIONS RESEARCH","63","2","342-350","2015","MAR-APR","","","Mismatch between supply and demand when the uncertainty of the demand is high and the supply lead time is relatively long, such as seasonal good markets, can result in high overstocking and understocking costs. In this paper we propose transshipment as a powerful mechanism to mitigate the mismatch between the supply and demand. We consider a finite horizon multi-period inventory system where in each period two retailers have the option to replenish their inventory from a supplier (if there is any supply) or via transshipment from the other retailer. Each retailer observes nonnegative stochastic demand with general distribution in each period and incurs overstocking/understocking costs as well as costs for replenishment and transshipment that may be time dependent. We study a stochastic control problem where the objective is to determine the optimal joint replenishment and transshipment policies so as to minimize the total expected cost over the season. We characterize the structure of the optimal policy and show that unlike the known order-up-to level inventory policy, the optimal ordering policy in each period is determined based on two switching curves. Similarly, the optimal transshipment policy is also identified by two switching curves. These four curves together partition the optimal joint ordering and transshipment polices to eight regions where in each region the optimal policy is an order-up-to-curve policy. We demonstrate that the structure of the optimal policy holds for any known sequence and combination of ordering and transshipment over time."
1541,"Technical Note-Trading Off Quick versus Slow Actions in Optimal Search","Shechter, Steven M. and Ghassemi, Farhad and Gocgun, Yasin and Puterman, Martin L.","OPERATIONS RESEARCH","63","2","353-362","2015","MAR-APR","","","We consider the search for a target whose precise location is uncertain. The search region is divided into grid cells, and the searcher decides which cell to visit next and whether to search it quickly or slowly. A quick search of a cell containing the target may damage it, resulting in a failed search, or it may locate the target safely. If the target is not in the cell, the search continues over the remaining cells. If a slow search is performed on a cell, then the search ends in failure with a fixed probability regardless of whether or not the target is in that cell (e.g., because of enemy fire while performing the slow search). If the slow search survives this failure possibility, then the search ends in success if the target is in that cell; otherwise, the search continues over the remaining cells. We seek to minimize the probability of the search ending in failure and consider two types of rules for visiting cells: the unconstrained search, in which the searcher may visit cells in any order, and the constrained search, in which the searcher may only visit adjacent cells (e.g., up, down, left, or right of cells already visited). We prove that the optimal policy for the unconstrained search is to search quickly some initial set of cells with the lowest probabilities of containing the target before slowly searching the remaining cells in decreasing order of probabilities. For the special case in which a quick search on a cell containing the target damages it with certainty, the optimal policy is to search all cells slowly, in decreasing order of probabilities. We use the optimal solution of the unconstrained search in a branch-and-bound optimal solution algorithm for the constrained search. For larger instances, we evaluate heuristics and approximate dynamic programming approaches for finding good solutions."
1542,"Generalized Almost Stochastic Dominance","Tsetlin, Ilia and Winkler, Robert L. and Huang, Rachel J. and Tzeng, Larry Y.","OPERATIONS RESEARCH","63","2","363-377","2015","MAR-APR","","","Almost stochastic dominance allows small violations of stochastic dominance rules to avoid situations where most decision makers prefer one alternative to another but stochastic dominance cannot rank them. While the idea behind almost stochastic dominance is quite promising, it has not caught on in practice. Implementation issues and inconsistencies between integral conditions and their associated utility classes contribute to this situation. We develop generalized almost second-degree stochastic dominance and almost second-degree risk in terms of the appropriate utility classes and their corresponding integral conditions, and extend these concepts to higher degrees. We address implementation issues and show that generalized almost stochastic dominance inherits the appealing properties of stochastic dominance. Finally, we define convex generalized almost stochastic dominance to deal with risk-prone preferences. Generalized almost stochastic dominance could be useful in decision analysis, empirical research (e.g., in finance), and theoretical analyses of applied situations."
1543,"Multiattribute Utility Functions Satisfying Mutual Preferential Independence","Abbas, Ali E. and Sun, Zhengwei","OPERATIONS RESEARCH","63","2","378-393","2015","MAR-APR","","","The construction of a multiattribute utility function is an important step in decision analysis. One of the most widely used conditions for constructing the utility function is the assumption of mutual preferential independence where trade-offs among any subset of the attributes do not depend on the instantiations of the remaining attributes. Mutual preferential independence asserts that ordinal preferences can be represented by an additive function of the attributes. This paper derives the most general form of a multiattribute utility function that (i) exhibits mutual preferential independence and (ii) is strictly increasing with each argument at the maximum value of the complement attributes. We show that a multiattribute utility function satisfies these two conditions if and only if it is an Archimedean combination of univariate utility assessments. This result enables the construction of multiattribute utility functions that satisfy additive ordinal preferences using univariate utility assessments and a single generating function. We also provide a nonparametric approach for estimating the generating function of the Archimedean form by iteration."
1544,"Structural Properties of Voronoi Diagrams in Facility Location Problems with Continuous Demand","Averbakh, Igor and Berman, Oded and Kalcsics, Joerg and Krass, Dmitry","OPERATIONS RESEARCH","63","2","394-411","2015","MAR-APR","","","We consider facility location problems where the demand is continuously and uniformly distributed over a convex polygon with m vertices in the rectilinear plane, n facilities are already present, and the goal is to find an optimal location for an additional facility. Based on an analysis of structural properties of incremental Voronoi diagrams, we develop polynomial exact algorithms for five conditional location problems. The developed methodology is applicable to a variety of other facility location problems with continuous demand. Moreover, we briefly discuss the Euclidean case."
1545,"Analysis of MILP Techniques for the Pooling Problem","Dey, Santanu S. and Gupte, Akshay","OPERATIONS RESEARCH","63","2","412-427","2015","MAR-APR","","","The pq-relaxation for the pooling problem can be constructed by applying McCormick envelopes for each of the bilinear terms appearing in the so-called pq-formulation of the pooling problem. This relaxation can be strengthened by using piecewise-linear functions that over-and under-estimate each bilinear term. Although there is a significant amount of empirical evidence to show that such piecewise-linear relaxations, which can be written as mixed-integer linear programs (MILPs), yield good bounds for the pooling problem, to the best of our knowledge, no formal result regarding the quality of these relaxations is known. In this paper, we prove that the ratio of the upper bound obtained by solving piecewise-linear relaxations (objective function is maximization) to the optimal objective function value of the pooling problem is at most n, where n is the number of output nodes. Furthermore for any epsilon > 0 and for any piecewise-linear relaxation, there exists an instance where the ratio of the relaxation value to the optimal value is at least n - epsilon. This analysis naturally yields a polynomial-time n-approximation algorithm for the pooling problem. We also show that if there exists a polynomial-time approximation algorithm for the pooling problem with guarantee better than n(1-epsilon). for any epsilon > 0, then NP-complete problems have randomized polynomial-time algorithms. Finally, motivated by the approximation algorithm, we design a heuristic that involves solving an MILP-based restriction of the pooling problem. This heuristic is guaranteed to provide solutions within a factor of n. On large-scale test instances and in significantly lesser time, this heuristic provides solutions that are often orders of magnitude better than those given by commercial local and global optimization solvers."
1546,"Myopic Bounds for Optimal Policy of POMDPs: An Extension of Lovejoy's Structural Results","Krishnamurthy, Vikram and Pareek, Udit","OPERATIONS RESEARCH","63","2","428-434","2015","MAR-APR","","","This paper provides a relaxation of the sufficient conditions and an extension of the structural results for partially observed Markov decision processes (POMDPs) obtained by Lovejoy in 1987. Sufficient conditions are provided so that the optimal policy can be upper and lower bounded by judiciously chosen myopic policies. These myopic policy bounds are constructed to maximize the volume of belief states where they coincide with the optimal policy. Numerical examples illustrate these myopic bounds for both continuous and discrete observation sets."
1547,"Technical Note-On Estimating Quantile Sensitivities via Infinitesimal Perturbation Analysis","Jiang, Guangxin and Fu, Michael C.","OPERATIONS RESEARCH","63","2","435-441","2015","MAR-APR","","","Hong (2009) [Hong LJ (2009) Estimating quantile sensitivities. Oper. Res. 57(1):118-130.] introduced a general framework based on probability sensitivities and a conditional expectation relationship for estimating quantile sensitivities by infinitesimal perturbation analysis (IPA). We present an alternative more direct derivation of the IPA estimators that leads to simplified proofs for strong consistency and convergence rate of the unbatched estimator, and strong consistency and a central limit theorem for the batched estimator."
1548,"Investment Timing with Incomplete Information and Multiple Means of Learning","Harrison, J. Michael and Sunar, Nur","OPERATIONS RESEARCH","63","2","442-457","2015","MAR-APR","","","We consider a firm that can use one of several costly learning modes to dynamically reduce uncertainty about the unknown value of a project. Each learning mode incurs cost at a particular rate and provides information of a particular quality. In addition to dynamic decisions about its learning mode, the firm must decide when to stop learning and either invest or abandon the project. Using a continuous-time Bayesian framework, and assuming a binary prior distribution for the project's unknown value, we solve both the discounted and undiscounted versions of this problem. In the undiscounted case, the optimal learning policy is to choose the mode that has the smallest cost per signal quality. When the discount rate is strictly positive, we prove that an optimal learning and investment policy can be summarized by a small number of critical values, and the firm only uses learning modes that lie on a certain convex envelope in cost-rate-versus-signal-quality space. We extend our analysis to consider a firm that can choose multiple learning modes simultaneously, which requires the analysis of both investment timing and dynamic subset selection decisions. We solve both the discounted and undiscounted versions of this problem and explicitly identify sets of learning modes that are used under the optimal policy."
1549,"Optimizing Reorder Intervals for Two-Echelon Distribution Systems with Stochastic Demand","Shang, Kevin H. and Tao, Zhijie and Zhou, Sean X.","OPERATIONS RESEARCH","63","2","458-475","2015","MAR-APR","","","We consider a periodic-review inventory system in which N non-identical retailers replenish from a warehouse, which further replenishes from an outside vendor with ample supply. Each facility faces Poisson demand and replenishes according to a base-stock policy in a fixed time interval. Fixed costs are incurred for placing an order. The warehouse fills the retailers' orders in the same sequence as the occurrence of the demand at the retailers. The objective is to minimize the average system cost per period. This paper develops an evaluation scheme and provides a method to obtain the optimal base-stock levels and reorder intervals. Specifically, with fixed reorder intervals, we show that the optimal base-stock levels can be obtained by generalizing the result in the literature. To find the optimal reorder intervals, we first allocate the total system cost to each facility and then construct a lower bound to the allocated facility cost. These lower bound functions, which are separable functions of reorder intervals, can be used to derive bounds for the optimal reorder intervals. The key to tightening the bounds is to obtain a near-optimal total cost. Thus, we propose a simple heuristic that modifies the algorithm that solves the deterministic counterpart. The results of numerical studies suggest that the optimal reorder intervals tend to satisfy integer-ratio relationships and that the suggested heuristic can generate effective integer-ratio policies for large systems."
1550,"Resource Pooling and Cost Allocation Among Independent Service Providers","Karsten, Frank and Slikker, Marco and van Houtum, Geert-Jan","OPERATIONS RESEARCH","63","2","476-488","2015","MAR-APR","","","We study a situation where several independent service providers collaborate by complete pooling of their resources and customer streams into a joint service system. These service providers may represent such diverse organizations as hospitals that pool beds or maintenance firms that pool repairmen. We model the service systems as Erlang delay systems (M / M / s queues) that face a fixed cost rate per server and homogeneous delay costs for waiting customers. We examine rules to fairly allocate the collective costs of the pooled system amongst the participants by applying concepts from cooperative game theory. We consider both the case where players' numbers of servers are exogenously given and the scenario where any coalition picks an optimal number of servers. By exploiting new analytical properties of the continuous extension of the classic Erlang delay function, we provide sufficient conditions for the games under consideration to possess a core allocation (i.e., an allocation that gives no group of players an incentive to split off and form a separate pool) and to admit a population monotonic allocation scheme (whereby adding extra players does not make anyone worse off). This is not guaranteed in general, as illustrated via examples."
1551,"Time to Come Clean? Disclosure and Inspection Policies for Green Production","Kim, Sang-Hyun","OPERATIONS RESEARCH","63","1","1-20","2015","JAN-FEB","","","We examine the interplay between two important decisions that impact environmental performance in a production setting: inspections performed by a regulator and noncompliance disclosure by a production firm. To preempt the penalty that will be levied once a compliance violation is discovered in an inspection, the firm dynamically decides whether it should disclose a random occurrence of noncompliance. Anticipating this, the regulator determines inspection frequency and penalty amounts to minimize environmental and social costs, performing either random inspections or periodic inspections. We study this problem by developing a novel analytical framework that combines features from reliability theory and law enforcement economics. We find that, contrary to common belief, surprising the firm with random inspections is not always preferred to inspecting the firm periodically according to a set schedule. We also find that the firm's opportunistic disclosure timing behavior may lead to a partial disclosure equilibrium in which the substitutable relationship between inspection intensity and penalty is reversed; a threat of increased penalty is accompanied by more frequent inspections."
1552,"Dynamic Equilibria in Fluid Queueing Networks","Cominetti, Roberto and Correa, Jose and Larre, Omar","OPERATIONS RESEARCH","63","1","21-34","2015","JAN-FEB","","","Flows over time provide a natural and convenient description for the dynamics of a continuous stream of particles traveling from a source to a sink in a network, allowing to track the progress of each infinitesimal particle along time. A basic model for the propagation of flow is the so-called fluid queue model in which the time to traverse an edge is composed of a flow-dependent waiting time in a queue at the entrance of the edge plus a constant travel time after leaving the queue. In a dynamic network routing game each infinitesimal particle is interpreted as a player that seeks to complete its journey in the least possible time. Players are forward looking and anticipate the congestion and queuing delays induced by others upon arrival to any edge in the network. Equilibrium occurs when each particle travels along a shortest path. This paper is concerned with the study of equilibria in the fluid queue model and provides a constructive proof of existence and uniqueness of equilibria in single origin-destination networks with piecewise constant inflow rate. This is done through a detailed analysis of the underlying static flows obtained as derivatives of a dynamic equilibrium. Furthermore, for multicommodity networks, we give a general nonconstructive proof of existence of equilibria when the inflow rates belong to L-p."
1553,"Understanding the Memory Effects in Pulsing Advertising","Aravindakshan, Ashwin and Naik, Prasad A.","OPERATIONS RESEARCH","63","1","35-47","2015","JAN-FEB","","","Extant models assume that awareness decline commences instantly. In contrast, we incorporate the possibility that awareness declines with a delay due to the memory for advertisements. To this end, we use delay differential equations to understand the evolution of awareness in the presence of ad memorability. This extended model generates optimal advertising policies that include the even spending policy, blitz policy, and various cyclic pulsing policies, depending on whether ad memorability exceeds a critical threshold. The extended model not only unifies the various patterns of advertising spending over time, but also augments the prior research by furnishing the optimality of pulsing advertising. Thus ad memorability could drive pulsing. We discuss the implications for practicing managers and identify avenues for future researchers."
1554,"An Exact Decomposition Approach for the Real-Time Train Dispatching Problem","Lamorgese, Leonardo and Mannino, Carlo","OPERATIONS RESEARCH","63","1","48-64","2015","JAN-FEB","","","Trains' movements on a railway network are regulated by official timetables. Deviations and delays occur quite often in practice, demanding fast rescheduling and rerouting decisions in order to avoid conflicts and minimize overall delay. This is the real-time train dispatching problem. In contrast with the classic holistic approach, we show how to decompose the problem into smaller subproblems associated with the line and the stations. This decomposition is the basis for a master-slave solution algorithm, in which the master problem is associated with the line and the slave problem is associated with the stations. The two subproblems are modeled as mixed integer linear programs, with specific sets of variables and constraints. Similarly to the classical Benders' decomposition approach, slave and master communicate through suitable feasibility cuts in the variables of the master. Extensive tests on real-life instances from single and double-track lines in Italy showed significant improvements over current dispatching performances. A decision support system based on this exact approach has been in operation in Norway since February 2014 and represents one of the first operative applications of mathematical optimization to train dispatching."
1555,"The Post-Disaster Debris Clearance Problem Under Incomplete Information","Celik, Melih and Ergun, Ozlem and Keskinocak, Pinar","OPERATIONS RESEARCH","63","1","65-85","2015","JAN-FEB","","","Debris management is one of the most time consuming and complicated activities among post-disaster operations. Debris clearance is aimed at pushing the debris to the sides of the roads so that relief distribution and search-and-rescue operations can be maintained in a timely manner. Given the limited resources, uncertainty, and urgency during disaster response, efficient and effective planning of debris clearance to achieve connectivity between relief demand and supply is important. In this paper, we define the stochastic debris clearance problem (SDCP), which captures post-disaster situations where the limited information on the debris amounts along the roads is updated as clearance activities proceed. The main decision in SDCP is to determine a sequence of roads to clear in each period such that benefit accrued by satisfying relief demand is maximized. To solve SDCP to optimality, we develop a partially observable Markov decision process model. We then propose a heuristic based on a continuous-time approximation, and we further reduce the computational burden by applying a limited look ahead on the search tree and heuristic pruning. The performance of these approaches is tested on randomly generated instances that reflect various geographical and information settings, and instances based on a real-world earthquake scenario. The results of these experiments underline the importance of applying a stochastic approach and indicate significant improvements over heuristics that mimic the current practice for debris clearance."
1556,"Learning and Pricing with Models That Do Not Explicitly Incorporate Competition","Cooper, William L. and Homem-de-Mello, Tito and Kleywegt, Anton J.","OPERATIONS RESEARCH","63","1","86-103","2015","JAN-FEB","","","In revenue management research and practice, demand models are used that describe how demand for a seller's products depends on the decisions, such as prices, of that seller. Even in settings where the demand for a seller's products also depends on decisions of other sellers, the models often do not explicitly account for such decisions. It has been conjectured in the revenue management literature that such monopoly models may incorporate the effects of competition, because the parameter estimates of the monopoly models are based on data collected in the presence of competition. In this paper we take a closer look at such a setting to investigate the behavior of parameter estimates and decisions if monopoly models are used in the presence of competition. We consider repeated pricing games in which two competing sellers use mathematical models to choose the prices of their products. Over the sequence of games, each seller attempts to estimate the values of the parameters of a demand model that expresses demand as a function only of its own price using data comprised only of its own past prices and demand realizations. We analyze the behavior of the sellers' parameter estimates and prices under various assumptions regarding the sellers' knowledge and estimation procedures, and we identify situations in which (a) the sellers' prices converge to the Nash equilibrium associated with knowledge of the correct demand model, (b) the sellers' prices converge to the cooperative solution, and (c) the sellers' prices have many potential limit points that are neither the Nash equilibrium nor the cooperative solution and that depend on the initial conditions. We compare the sellers' revenues at potential limit prices with their revenues at the Nash equilibrium and the cooperative solution, and we show that it is possible for sellers to be better off when using a monopoly model than at the Nash equilibrium."
1557,"Simulating Risk Contributions of Credit Portfolios","Liu, Guangwu","OPERATIONS RESEARCH","63","1","104-121","2015","JAN-FEB","","","The 2007-2009 financial turmoil highlighted the need for more active management of credit portfolios. After measuring portfolio credit risk, an important step toward active risk management is to measure risk contributions of individual obligors to the overall risk of the portfolio. In practice, value-at-risk is often used as a risk measure for credit portfolios, and it can be decomposed into a sum of the risk contributions of individual obligors. Estimation of these risk contributions is computationally challenging, mainly because they are expectations conditioned on a rare event. In this paper, we tackle this computational problem by developing a restricted importance sampling (RIS) method for a class of conditional-independence credit risk models, where defaults of obligors are conditionally independent given an appropriately chosen random vector. We propose fast estimators for risk contributions and their confidence intervals. Furthermore, we study the incorporation of traditional importance sampling methods into the RIS method to further improve its efficiency for the widely used Gaussian copula model. Numerical examples show that the proposed method works well."
1558,"Optimal Trade-Off Between Speed and Acuity When Searching for a Small Object","Alpern, Steve A and Lidbetter, Thomas","OPERATIONS RESEARCH","63","1","122-133","2015","JAN-FEB","","","A Searcher seeks to find a stationary Hider located at some point H (not necessarily a node) on a given network Q. The Searcher can move along the network from a given starting point at unit speed, but to actually find the Hider she must pass it while moving at a fixed slower speed (which may depend on the arc). In this bimodal search game, the payoff is the first time the Searcher passes the Hider while moving at her slow speed. This game models the search for a small or well hidden object (e.g., a contact lens, improvised explosive device, predator search for camouflaged prey). We define a bimodal Chinese postman tour as a tour of minimum time, which traverses every point of every arc at least once in the slow mode. For trees and weakly Eulerian networks (networks containing a number of disjoint Eulerian cycles connected in a tree-like fashion) the value of the bimodal search game is, delta/2. For trees, the optimal Hider strategy has full support on the network. This differs from traditional search games, where it is optimal for him to hide only at leaf nodes. We then consider the notion of a lucky Searcher who can also detect the Hider with a positive probability q even when passing him at her fast speed. This paper has particular importance for demining problems."
1559,"Demand Estimation and Ordering Under Censoring: Stock-Out Timing Is (Almost) All You Need","Jain, Aditya and Rudi, Nils and Wang, Tong","OPERATIONS RESEARCH","63","1","134-150","2015","JAN-FEB","","","Retailers facing uncertain demand can use observed sales to update demand estimates. However, such learning is limited by the amount of inventory carried; when demand exceeds inventory (i.e., when a stock-out event occurs), a retailer in general cannot observe actual demand. We propose using observations on the timing of sales occurrences in a Bayesian fashion to learn about demand, and we analyze this learning method for a multiperiod newsvendor setting. We find that, as previously shown with the use of only stock-out event observations, the optimal order quantity with timing observations is greater than the optimal order quantity with full demand observations. We prove this result using a novel methodology from the statistics literature on comparison of experiments. Although the optimal over-ordering with timing observations tends to be less than that with only stock-out event observations in most cases, we do observe cases where the opposite is true. Such cases correspond to high demand uncertainty and low margins, where marginal learning from timing observations is significantly higher than using only a stock-out event. In an extensive numerical study we find that, on average and with respect to uncensored demand observations, the use of timing observations eliminates 76.1% of the loss in expected profit from using only stock-out event observations. We show that, for Poisson and normal demand with unknown mean, the proposed learning method is tractable as well as intuitively appealing: the information contained in the timing of sales occurrences is fully captured by a single number-the timing of stock-out. We also investigate checkpoint models in which the newsvendor can make observations only at predetermined times in a period, and illustrate its convergence to the models with timing and stock-out event observations."
1560,"Auction Design for the Efficient Allocation of Service Capacity Under Congestion","Barrera, Jorge and Garcia, Alfredo","OPERATIONS RESEARCH","63","1","151-165","2015","JAN-FEB","","","We consider the problem of efficiently allocating the capacity of a number of service facilities (prone to congestion) to a set of users with private information regarding their willingness to pay for different combinations of throughput versus latency. Auction mechanisms can be used to schedule the service capacity of available facilities. However, the interdependency of users' valuations implies that simple uniform price adjustment processes (e.g., tatonnement) either fail to effectively clear or are subject to strategic manipulation. In this paper, we propose an iterative auction design and show that (i) it is efficient (i.e., the auction closes with the allocation of service that maximizes the social welfare) and (ii) it is strategy-proof, that is, it is a dominant strategy for users to truthfully reveal their demand for service capacity throughout the auction."
1561,"Worst-Case Analysis of Process Flexibility Designs","Simchi-Levi, David and Wei, Yehua","OPERATIONS RESEARCH","63","1","166-185","2015","JAN-FEB","","","Theoretical studies of process flexibility designs have mostly focused on expected sales. In this paper, we take a different approach by studying process flexibility designs from the worst-case point of view. To study the worst-case performances, we introduce the plant cover indices (PCIs), defined by bottlenecks in flexibility designs containing a fixed number of products. We prove that given a flexibility design, a general class of worst-case performance measures can be expressed as functions of the design's PCIs and the given uncertainty set. This result has several major implications. First, it suggests a method to compare the worst-case performances of different flexibility designs without the need to know the specifics of the uncertainty sets. Second, we prove that under symmetric uncertainty sets and a large class of worst-case performance measures, the long chain, a celebrated sparse design, is superior to a large class of sparse flexibility designs, including any design that has a degree of two on each of its product nodes. Third, we show that under stochastic demand, the classical Jordan and Graves (JG) index can be expressed as a function of the PCIs. Furthermore, the PCIs motivate a modified JG index that is shown to be more effective in our numerical study. Finally, the PCIs lead to a heuristic for finding sparse flexibility designs that perform well under expected sales and have lower risk measures in our computational study."
1562,"Technical Note-New Sufficient Conditions for (s, S) Policies to be Optimal in Systems with Multiple Uncertainties","Chen, Lucy Gongtao and Robinson, Lawrence W. and Roundy, Robin O. and Zhang, Rachel Q.","OPERATIONS RESEARCH","63","1","186-197","2015","JAN-FEB","","","In today's business environment, unpredictable economic and noneconomic forces can affect firms' operational costs and discount factors, as well as demand. In this paper, we incorporate these uncertainties into a single-product, periodic-review, finite-horizon stochastic inventory system by modeling operational costs, discount factors, and demands as stochastic processes that evolve over time. We study three stockout protocols and establish conditions under which (s, S) inventory policies are optimal when discount factors, operational costs, and demands are stochastic and correlated both to one another and over time. Examples are provided to demonstrate nontrivial optimal policies in the absence of these sufficient conditions."
1563,"A Tailor-Made Test of Intransitive Choice","Baillon, Aurelien and Bleichrodt, Han and Cillo, Alessandra","OPERATIONS RESEARCH","63","1","198-211","2015","JAN-FEB","","","This paper reports a new test of intransitive choice using individual measurements of regret-and similarity-based intransitive models of choice under uncertainty. Our test is tailor-made and uses subject-specific stimuli. Despite these features, we observed only a few intransitivities. A possible explanation for the poor predictive performance of intransitive choice models is that they only allow for interactions between acts. They exclude within-act interactions by retaining the assumption that preferences are separable over states of nature. Prospect theory, which relaxes separability but retains transitivity, predicted choices better. Our data suggest that descriptively realistic models must allow for within-act interactions but may retain transitivity."
1564,"A General Attraction Model and Sales-Based Linear Program for Network Revenue Management Under Customer Choice","Gallego, Guillermo and Ratliff, Richard and Shebalov, Sergey","OPERATIONS RESEARCH","63","1","212-232","2015","JAN-FEB","","","This paper addresses two concerns with the state of the art in network revenue management with dependent demands. The first concern is that the basic attraction model (BAM), of which the multinomial logit (MNL) model is a special case, tends to overestimate demand recapture in practice. The second concern is that the choice-based deterministic linear program, currently in use to derive heuristics for the stochastic network revenue management problem, has an exponential number of variables. We introduce a generalized attraction model (GAM) that allows for partial demand dependencies ranging from the BAM to the independent demand model (IDM). We also provide an axiomatic justification for the GAM and a method to estimate its parameters. As a choice model, the GAM is of practical interest because of its flexibility to adjust product-specific recapture. Our second contribution is a new formulation called the sales-based linear program (SBLP) that works for the GAM. This formulation avoids the exponential number of variables in the earlier choice-based network RM (revenue management) approaches and is essentially the same size as the well-known LP formulation for the IDM. The SBLP should be of interest to revenue managers because it makes choice-based network RM problems tractable to solve. In addition, the SBLP formulation yields new insights into the assortment problem that arises when capacities are infinite. Together these contributions move forward the state of the art for network revenue management under customer choice and competition."
1565,"The Benefit of Introducing Variability in Single-Server Queues with Application to Quality-Based Service Domains","Xu, Ying and Scheller-Wolf, Alan and Sycara, Katia","OPERATIONS RESEARCH","63","1","233-246","2015","JAN-FEB","","","We propose a static service differentiation policy for a single-server queueing system serving homogeneous customers. We show that by randomly assigning customers different service grades with different service rates, the average waiting time can be reduced without affecting the mean service time. Such differentiation introduces more service time variability, but it also creates information that enables the implementation of service rate-based scheduling, which mitigates the increased variance and may even reduce the total waiting time. We provide conditions under which our static service differentiation reduces waiting, and further derive closed-form expressions for the optimal differentiation policy, which shows that both optimal service rates and allocation probabilities form geometric sequences. We illustrate our policy in the context of quality-based service domains, in which customers value service time but dislike waiting. Numerically, we find that providing differentiated service can improve system performance by 5% without any additional capacity."
1566,"Strategic Arrivals into Queueing Networks: The Network Concert Queueing Game","Honnappa, Harsha and Jain, Rahul","OPERATIONS RESEARCH","63","1","247-259","2015","JAN-FEB","","","Queueing networks models typically assume that the arrival process is exogenous and unaffected by admission control, scheduling policies, etc. In many situations, however, users choose the time of their arrival strategically, taking delay and other metrics into account. In this paper, we develop a framework to study such strategic arrivals into queueing networks. We study the population game wherein users strategically choose when to arrive at a parallel queueing network and upon arrival, which of the queues to join. The queues start service at given times, which can potentially be different. We characterize the (strategic) arrival process at each of the queues and the price of anarchy of the ensuing strategic arrival game. We then extend the analysis to multiple populations of users, each with a different cost metric. The equilibrium arrival profile and price of anarchy are derived. Finally, we extend this to general feedforward network architectures by modeling the arrival timing game as a two-stage extensive form game. We prove the existence and essential uniqueness of equilibria. We also study more specific network topologies, like tandem and trellis networks, and we derive the equilibrium arrival and routing profiles. We show that there exists an equivalent parallel queueing network that has the same equilibrium arrival profile. Thus, the price of anarchy of the arrival game is then implied by that of the parallel queueing network."
1567,"OR Forum-Design of Risk Weights","Glasserman, Paul and Kang, Wanmo","OPERATIONS RESEARCH","62","6","1204-1220","2014","NOV-DEC","","","Banking regulations set minimum levels of capital for banks. These requirements are generally formulated through a ratio of capital to risk-weighted assets. A risk-weighting scheme assigns a weight to each asset or category of assets and effectively functions as a linear constraint on a bank's portfolio choice; it also changes the incentives for banks to hold various kinds of assets. In this paper, we investigate the design of risk weights to align regulatory and private objectives in a simple mean-variance framework for portfolio selection. By setting risk weights proportional to profitability rather than risk, the regulator can induce a bank to reduce its overall level of risk without distorting its asset mix. Because the regulator is unlikely to know the true profitability of assets, we introduce an adaptive formulation in which the regulator sets weights by observing a bank's portfolio. The adaptive scheme converges to the same combination of weights and portfolio choice that would hold if the regulator knew the asset profitability. We also investigate other objectives, including steering banks to a target mix of assets, adding robustness, mitigating procyclicality, and reducing system-wide risk in a setting with multiple heterogeneous banks."
1568,"Nash Codes for Noisy Channels","Hernandez, Penelope and von Stengel, Bernhard","OPERATIONS RESEARCH","62","6","1221-1235","2014","NOV-DEC","","","This paper studies the stability of communication protocols that deal with transmission errors. We consider a coordination game between an informed sender and an uninformed receiver, who communicate over a noisy channel. The sender's strategy, called a code, maps states of nature to signals. The receiver's best response is to decode the received channel output as the state with highest expected receiver payoff. Given this decoding, an equilibrium or Nash code results if the sender encodes every state as prescribed. We show two theorems that give sufficient conditions for Nash codes. First, a receiver-optimal code defines a Nash code. A second, more surprising observation holds for communication over a binary channel, which is used independently a number of times, a basic model of information transmission: under a minimal monotonicity requirement for breaking ties when decoding, which holds generically, every code is a Nash code."
1569,"Improving Community Cohesion in School Choice via Correlated-Lottery Implementation","Ashlagi, Itai and Shi, Peng","OPERATIONS RESEARCH","62","6","1247-1264","2014","NOV-DEC","","","In school choice, children submit a preference ranking over schools to a centralized assignment algorithm, which takes into account schools' priorities over children and uses randomization to break ties. One criticism of existing school choice mechanisms is that they tend to disperse communities, so children do not go to school with others from their neighborhood. We suggest improving community cohesion by implementing a correlated lottery in a given school choice mechanism: we find a convex combination of deterministic assignments that maintains the original assignment probabilities, thus maintaining choice but improving community cohesion. To analyze the gain in cohesion for a wide class of mechanisms, we first prove the following characterization, which may be of independent interest: any mechanism that, in the large market limit, is nonatomic, Bayesian incentive compatible, symmetric, and efficient within each priority class is a lottery-plus-cutoff mechanism. This means that the large market limit can be described as follows: given the distribution of preferences, every student receives an identically distributed lottery number, every school sets a lottery cutoff for each priority class, and a student is assigned to her most preferred school for which she meets the cutoff. This generalizes Liu and Pycia (2012) to allow arbitrary priorities. Using this, we derive analytic expressions for maximum cohesion under a large market approximation. We show that the benefit of lottery-correlation is greater when students' preferences are more correlated. In practice, although the correlated-lottery implementation problem is NP-hard, we present a heuristic that does well. We apply this to real data from Boston elementary school choice 2012 and find that we can increase cohesion by 79% for kindergarten 1 (K1) and 37% for kindergarten 2 (K2) new families. Greater cohesion gain is possible (tripling cohesion for K1 and doubling for K2) if we reduce the choice menus on top of applying lottery correlation."
1570,"Design and Optimization Methods for Elective Hospital Admissions","Helm, Jonathan E. and Van Oyen, Mark P.","OPERATIONS RESEARCH","62","6","1265-1282","2014","NOV-DEC","","","Hospitals typically lack effective enterprise level strategic planning of bed and care resources, contributing to bed census levels that are statistically out of control. This system dysfunction manifests itself in bed block, surgical cancelation, ambulance diversions, and operational chaos. This is the classic hospital admission scheduling and control (HASC) problem, which has been addressed in its entirety only through inexact simulation-based search heuristics. This paper develops new analytical models of controlled hospital census that can, for the first time, be incorporated into a mixed-integer programming model to optimally solve the strategic planning/scheduling portion of the HASC. Our new solution method coordinates elective admissions with other hospital subsystems to reduce system congestion. We formulate a new Poisson-arrival-location model (PALM) based on an innovative stochastic location process that we developed and call the patient temporal resource needs model. We further extend the PALM approach to the class of deterministic controlled-arrival-location models (d-CALM) and develop linearizing approximations to stochastic blocking metrics. This work provides the theoretical foundations for an efficient scheduled admissions planning system as well as a practical decision support methodology to stabilize hospital census."
1571,"Fairness and Efficiency in Multiportfolio Optimization","Iancu, Dan A. and Trichakis, Nikolaos","OPERATIONS RESEARCH","62","6","1283-1301","2014","NOV-DEC","","","We deal with the problem faced by a portfolio manager in charge of multiple accounts. We argue that because of market impact costs, this setting differs in several subtle ways from the classical (single account) case, with the key distinction being that the performance of each individual account typically depends on the trading strategies of other accounts, as well. We propose a novel, tractable approach for jointly optimizing the trading activities of all accounts and also splitting the associated market impact costs between the accounts. Our approach allows the manager to balance the conflicting objectives of maximizing the aggregate gains from joint optimization and distributing them across the accounts in an equitable way. We perform numerical studies that suggest that our approach outperforms existing methods employed in the industry or discussed in the literature."
1572,"Robustifying Convex Risk Measures for Linear Portfolios: A Nonparametric Approach","Wozabal, David","OPERATIONS RESEARCH","62","6","1302-1315","2014","NOV-DEC","","","This paper introduces a framework for robustifying convex, law invariant risk measures. The robustified risk measures are defined as the worst case portfolio risk over neighborhoods of a reference probability measure, which represent the investors' beliefs about the distribution of future asset losses. It is shown that under mild conditions, the infinite dimensional optimization problem of finding the worst-case risk can be solved analytically and closed-form expressions for the robust risk measures are obtained. Using these results, robust versions of several risk measures including the standard deviation, the Conditional Value-at-Risk, and the general class of distortion functionals are derived. The resulting robust risk measures are convex and can be easily incorporated into portfolio optimization problems, and a numerical study shows that in most cases they perform significantly better out-of-sample than their nonrobust variants in terms of risk, expected losses, and turnover."
1573,"Stability and Endogenous Formation of Inventory Transshipment Networks","Fang, Xin and Cho, Soo-Haeng","OPERATIONS RESEARCH","62","6","1316-1334","2014","NOV-DEC","","","This paper studies a cooperative game of inventory transshipment among multiple firms. In this game, firms first make their inventory decisions independently and then decide collectively how to transship excess inventories to satisfy unmet demands. In modeling transshipment, we use networks of firms as the primitive, which offer a richer representation of relationships among firms by taking the coalitions used in all previous studies as special cases. For any given cooperative network, we construct a dual price allocation under which the network is stable for any residual demands and supplies in the sense that no firms find it more profitable to form subnetworks. Under the allocation based on the marginal contribution of each firm to its network (called the MJW value), we show that various network structures such as complete, hub-spoke, and chain networks are stable only under certain conditions on residual amounts. Moreover, these conditions differ across network structures, implying that a network structure plays an important role in establishing the stability of a decentralized transshipment system. Finally, we consider the case when firms establish networks endogenously, and show that pairwise Nash stable networks underperform the corresponding networks in centralized systems."
1574,"Technical Note-Joint Inventory and Pricing Control with General Additive Demand","Chen, Hong and Zhang, Zhan","OPERATIONS RESEARCH","62","6","1335-1343","2014","NOV-DEC","","","This paper analyzes a periodic-review, joint inventory and pricing control problem for a firm that faces stochastic, price-sensitive demand under a nonstationary environment with fixed ordering costs. Any unsatisfied demand is backlogged. The objective is to maximize expected profit over a finite selling horizon by coordinating the inventory and pricing decisions in each period. We show that for an additive demand model, an (s, S, p) policy is optimal when the expected revenue is quasi-concave in price, the inventory cost (of holding and/or backlogging) is quasi-convex, and the nonnegative random demand has a Polya or uniform density function. For the special case with no fixed ordering cost, the optimality of a base stock list price policy is demonstrated for more general demand distributions and convex inventory cost. These sets of sufficient conditions generalize the existing conditions in the literature that require, for example, the demand and/or revenue functions to be concave or the model parameters to be stationary in time. Our generalization makes the structural results applicable to models broadly supported by economic theory and empirical data. In addition, our proof uses a distinct sequential optimization technique for iteratively establishing the quasi-K-concavity of dynamic optimal value functions."
1575,"Simulating the Dynamic Escape Process in Large Public Places","Gao, Ziyou and Qu, Yunchao and Li, Xingang and Long, Jiancheng and Huang, Hai-Jun","OPERATIONS RESEARCH","62","6","1344-1357","2014","NOV-DEC","","","Pedestrian dynamics plays an important role in public facility design and evacuation management. During an escape process from a large public space, crowd behavior is a collection of pedestrian exit/route choice behavior, and movement behavior. Modelling such an escape process is an extremely complex challenge. In this paper, an integrated macro-micro approach is developed to simulate the escape process. An analysis of the simulation reveals the mechanisms of the formation of crowd congestion and flow distribution. At the macroscopic level, a mathematical model, based on the concept of the dynamic user optimal (DUO) criterion, is formulated to describe the pedestrian exit/route choice behavior. A method based on the fundamental diagram and point-queuing theory is developed to estimate the pedestrian escape time. At the microscopic level, a modified social force model is adopted to formulate pedestrians' dynamic movements during the escape process. A solution algorithm is proposed to solve the macro-micro integrated model and a series of experiments are carried out to validate the proposed model. The simulation results agree with the extracted experimental data. Finally, the integrated model and algorithm are used to simulate the escape process in a large public place. The proposed approach is able to generate the bandwagon effect, bottleneck effect, and route choice patterns."
1576,"Distributionally Robust Convex Optimization","Wiesemann, Wolfram and Kuhn, Daniel and Sim, Melvyn","OPERATIONS RESEARCH","62","6","1358-1376","2014","NOV-DEC","","","Distributionally robust optimization is a paradigm for decision making under uncertainty where the uncertain problem data are governed by a probability distribution that is itself subject to uncertainty. The distribution is then assumed to belong to an ambiguity set comprising all distributions that are compatible with the decision maker's prior information. In this paper, we propose a unifying framework for modeling and solving distributionally robust optimization problems. We introduce standardized ambiguity sets that contain all distributions with prescribed conic representable confidence sets and with mean values residing on an affine manifold. These ambiguity sets are highly expressive and encompass many ambiguity sets from the recent literature as special cases. They also allow us to characterize distributional families in terms of several classical and/or robust statistical indicators that have not yet been studied in the context of robust optimization. We determine conditions under which distributionally robust optimization problems based on our standardized ambiguity sets are computationally tractable. We also provide tractable conservative approximations for problems that violate these conditions."
1577,"The Value of Stochastic Modeling in Two-Stage Stochastic Programs with Cost Uncertainty","Delage, Erick and Arroyo, Sharon and Ye, Yinyu","OPERATIONS RESEARCH","62","6","1377-1393","2014","NOV-DEC","","","Although stochastic programming is probably the most effective framework for handling decision problems that involve uncertain variables, it is always a costly task to formulate the stochastic model that accurately embodies our knowledge of these variables. In practice, this might require one to collect a large amount of observations, to consult with experts of the specialized field of practice, or to make simplifying assumptions about the underlying system. When none of these options seem feasible, a common heuristic has been to simply seek the solution of a version of the problem where each uncertain variable takes on its expected value (otherwise known as the solution of the mean value problem). In this paper, we show that when (1) the stochastic program takes the form of a two-stage mixed-integer stochastic linear programs, and (2) the uncertainty is limited to the objective function, the solution of the mean value problem is in fact robust with respect to the selection of a stochastic model. We also propose tractable methods that will bound the actual value of stochastic modeling: i.e., how much improvement can be achieved by investing more efforts in the resolution of the stochastic model. Our framework is applied to an airline fleet composition problem. In the three cases that are considered, our results indicate that resolving the stochastic model can not lead to more than a 7% improvement of expected profits, thus providing arguments against the need to develop these more sophisticated models."
1578,"Information Relaxations, Duality, and Convex Stochastic Dynamic Programs","Brown, David B. and Smith, James E.","OPERATIONS RESEARCH","62","6","1394-1415","2014","NOV-DEC","","","We consider the information relaxation approach for calculating performance bounds for stochastic dynamic programs (DPs). This approach generates performance bounds by solving problems with relaxed nonanticipativity constraints and a penalty that punishes violations of these nonanticipativity constraints. In this paper, we study DPs that have a convex structure and consider gradient penalties that are based on first-order linear approximations of approximate value functions. When used with perfect information relaxations, these penalties lead to subproblems that are deterministic convex optimization problems. We show that these gradient penalties can, in theory, provide tight bounds for convex DPs and can be used to improve on bounds provided by other relaxations, such as Lagrangian relaxation bounds. Finally, we apply these results in two example applications: first, a network revenue management problem that describes an airline trying to manage seat capacity on its flights; and second, an inventory management problem with lead times and lost sales. These are challenging problems of significant practical interest. In both examples, we compute performance bounds using information relaxations with gradient penalties and find that some relatively easy-to-compute heuristic policies are nearly optimal."
1579,"Balancing Exploitation and Exploration in Discrete Optimization via Simulation Through a Gaussian Process-Based Search","Sun, Lihua and Hong, L. Jeff and Hu, Zhaolin","OPERATIONS RESEARCH","62","6","1416-1438","2014","NOV-DEC","","","Random search algorithms are often used to solve discrete optimization-via-simulation (DOvS) problems. The most critical component of a random search algorithm is the sampling distribution that is used to guide the allocation of the search effort. A good sampling distribution can balance the trade-off between the effort used in searching around the current best solution (which is called exploitation) and the effort used in searching largely unknown regions (which is called exploration). However, most of the random search algorithms for DOvS problems have difficulties in balancing this trade-off in a seamless way. In this paper we propose a new scheme that derives a sampling distribution from a fast fitted Gaussian process based on previously evaluated solutions. We show that the sampling distribution has the desired properties and can automatically balance the exploitation and exploration trade-off. Furthermore, we integrate this sampling distribution into a random research algorithm, called a Gaussian process-based search (GPS) and show that the GPS algorithm has the desired global convergence as the simulation effort goes to infinity. We illustrate the properties of the algorithm through a number of numerical experiments."
1580,"A Bayesian Framework for Quantifying Uncertainty in Stochastic Simulation","Xie, Wei and Nelson, Barry L. and Barton, Russell R.","OPERATIONS RESEARCH","62","6","1439-1452","2014","NOV-DEC","","","When we use simulation to estimate the performance of a stochastic system, the simulation often contains input models that were estimated from real-world data; therefore, there is both simulation and input uncertainty in the performance estimates. In this paper, we provide a method to measure the overall uncertainty while simultaneously reducing the influence of simulation estimation error due to output variability. To reach this goal, a Bayesian framework is introduced. We use a Bayesian posterior for the input-model parameters, conditional on the real-world data, to quantify the input-parameter uncertainty; we propagate this uncertainty to the output mean using a Gaussian process posterior distribution for the simulation response as a function of the input-model parameters, conditional on a set of simulation experiments. We summarize overall uncertainty via a credible interval for the mean. Our framework is fully Bayesian, makes more effective use of the simulation budget than other Bayesian approaches in the stochastic simulation literature, and is supported with both theoretical analysis and an empirical study. We also make clear how to interpret our credible interval and why it is distinctly different from the confidence intervals for input uncertainty obtained in other papers."
1581,"Limit Theorems for Markovian Bandwidth-Sharing Networks with Rate Constraints","Reed, Josh and Zwart, Bert","OPERATIONS RESEARCH","62","6","1453-1466","2014","NOV-DEC","","","Bandwidth-sharing networks provide a natural modeling framework for describing the dynamic flow-level interaction among elastic data transfers in computer and communication systems, and can be used to develop traffic pricing/charging mechanisms. At the same time, such models are exciting from an operations research perspective because their analysis requires techniques from stochastic modeling and optimization. In this paper, we develop a framework to approximate bandwidth-sharing networks under the assumption that the number of users as well as the capacities of the system are large, and the assumption that the traffic that each user is allowed to submit is bounded above by some rate, which is standard in practice. We also assume that customers on each route in the network abandon according to exponential patience times. Under Markovian assumptions, we develop fluid and diffusion approximations, which are quite tractable: for most parameter combinations, the invariant distribution is multivariate normal, with mean and diffusion coefficients that can be computed in polynomial time as a function of the size of the network."
1582,"Choice-Based Recommender Systems: A Unified Approach to Achieving Relevancy and Diversity","Jiang, Hai and Qi, Xin and Sun, He","OPERATIONS RESEARCH","62","5","973-993","2014","SEP-OCT","","","Recommender systems have been widely used by online stores to suggest items of interest to users. These systems often identify a subset of items from a much larger set that best matches the user's interest. A key concern with existing approaches is overspecialization, which results in returning items that are too similar to each other. Unlike existing solutions that rely on diversity metrics to reduce similarity among recommended items, we propose using choice probability to measure the overall quality of a recommendation list, which unifies the desire to achieve both relevancy and diversity in recommendation. We first define the recommendation problem from the discrete choice perspective. We then model the problem under the multilevel nested logit model, which is capable of handling similarities between alternatives along multiple dimensions. We formulate the problem as a nonlinear binary integer programming problem and develop an efficient dynamic programming algorithm that solves the problem to optimum in O(nKSR(2)) time, where n is the number of levels and K is the maximum number of children nests a nest can have in the multilevel nested logit model, S is the total number of items in the item pool, and R is the number of items wanted in recommendation."
1583,"Supporting New Product or Service Introductions: Location, Marketing, and Word of Mouth","Abedi, Vahideh Sadat and Berman, Oded and Krass, Dmitry","OPERATIONS RESEARCH","62","5","994-1013","2014","SEP-OCT","","","Introduction of a new, innovative product or service is a fundamental problem that managers face regularly. The temporal sales pattern of such a product is often dynamically influenced by word of mouth as well as by marketing and distribution support. Appropriate marketing support strategies must be specified to induce the best sales pattern; however, the success of these strategies is heavily tied to the accessibility of the retail facilities, whether physical stores or virtual ones such as the Internet or phone. Managing the relation between accessibility and marketing support becomes more challenging when the firm faces a limited time, often due to short product life cycle. In this work, we present a general model for the joint design of the network of retail facilities and marketing strategies in the presence of word-of-mouth effects and limited time horizon. We develop exact and heuristic solution methods and provide insights on the structure of the optimal solution. Our solution methods identify the number and location of retail facilities to carry the product, as well as the proper mix of marketing channels and expenditures in them over time. Our results demonstrate that significant profit improvement can be achievable by jointly optimizing the design of the network of retail facilities with the choice of marketing strategies. Results of numerical experiments and an illustrative case study on opening Nespresso boutiques are also reported."
1584,"A Bound on the Performance of an Optimal Ambulance Redeployment Policy","Maxwell, Matthew S. and Ni, Eric Cao and Tong, Chaoxu and Henderson, Shane G. and Topaloglu, Huseyin and Hunter, Susan R.","OPERATIONS RESEARCH","62","5","1014-1027","2014","SEP-OCT","","","Ambulance redeployment is the practice of repositioning ambulance fleets in real time in an attempt to reduce response times to future calls. When redeployment decisions are based on real-time information on the status and location of ambulances, the process is called system-status management. An important performance measure is the long-run fraction of calls with response times over some time threshold. We construct a lower bound on this performance measure that holds for nearly any ambulance redeployment policy through comparison methods for queues. The computation of the bound involves solving a number of integer programs and then simulating a multiserver queue. This work originated when one of the authors was asked to analyze a response to a request-for-proposals (RFP) for ambulance services in a county in North America."
1585,"Modeling Short-Range Ballistic Missile Defense and Israel's Iron Dome System","Armstrong, Michael J.","OPERATIONS RESEARCH","62","5","1028-1039","2014","SEP-OCT","","","This paper develops a model of short-range ballistic missile defense and uses it to study the performance of Israel's Iron Dome system. The deterministic base model allows for inaccurate missiles, unsuccessful interceptions, and civil defense. Model enhancements consider the trade-offs in attacking the interception system, the difficulties faced by militants in assembling large salvos, and the effects of imperfect missile classification by the defender. A stochastic model is also developed. Analysis shows that system performance can be highly sensitive to the missile salvo size, and that systems with higher interception rates are more fragile when overloaded. The model is calibrated using publically available data about Iron Dome's use during Operation Pillar of Defense in November 2012. If the systems performed as claimed, they saved Israel an estimated 1,778 casualties and $80 million in property damage, and thereby made preemptive strikes on Gaza about eight times less valuable to Israel. Gaza militants could have inflicted far more damage by grouping their rockets into large salvos, but this may have been difficult given Israel's suppression efforts. Counter-battery fire by the militants is unlikely to be worthwhile unless they can obtain much more accurate missiles."
1586,"Robustness of Order-Up-to Policies in Lost-Sales Inventory Systems","Bijvank, Marco and Huh, Woonghee Tim and Janakiraman, Ganesh and Kang, Wanmo","OPERATIONS RESEARCH","62","5","1040-1047","2014","SEP-OCT","","","We study an inventory system under periodic review when excess demand is lost. It is known (Huh et al. 2009) that the best base-stock policy is asymptotically optimal as the lost-sales penalty cost parameter grows. We now show that this result is robust in the following sense: Consider the base-stock level which is optimal in a backordering system (with a per-unit-per-period backordering cost) in which the backorder cost parameter is a function of the lost-sales parameter in the original system. Then there is a large family of functions (mapping the lost-sales cost parameter to the backorder cost parameter) such that the resulting base-stock policy is asymptotically optimal. We also demonstrate the robustness phenomenon through a second result. We consider the base-stock level which is optimal in a backordering system in which a unit of backorder is charged a penalty cost only once (such a system has been studied by Rosling). We show that this base-stock policy is also asymptotically optimal. Furthermore, we show that a modification suggested by Archibald of this base-stock level also results in an asymptotically optimal policy. Finally, we numerically test the performance of this heuristic policy for a wide spectrum of values for the lost-sales penalty cost parameter and illustrate the superior performance of Archibald's method."
1587,"Production-Inventory Systems with Lost Sales and Compound Poisson Demands","Shi, Jim (Junmin) and Katehakis, Michael N. and Melamed, Benjamin and Xia, Yusen","OPERATIONS RESEARCH","62","5","1048-1063","2014","SEP-OCT","","","This paper considers a continuous-review, single-product, production-inventory system with a constant replenishment rate, compound Poisson demands, and lost sales. Two objective functions that represent metrics of operational costs are considered: (1) the sum of the expected discounted inventory holding costs and lost-sales penalties, both over an infinite time horizon, given an initial inventory level; and (2) the long-run time average of the same costs. The goal is to minimize these cost metrics with respect to the replenishment rate. It is, however, not possible to obtain closed-form expressions for the aforementioned cost functions directly in terms of positive replenishment rate (PRR). To overcome this difficulty, we construct a bijection from the PRR space to the space of positive roots of Lundberg's fundamental equation, to be referred to as the Lundberg positive root (LPR) space. This transformation allows us to derive closed-form expressions for the aforementioned cost metrics with respect to the LPR variable, in lieu of the PRR variable. We then proceed to solve the optimization problem in the LPR space and, finally, recover the optimal replenishment rate from the optimal LPR variable via the inverse bijection. For the special cases of constant or loss-proportional penalty and exponentially distributed demand sizes, we obtain simpler explicit formulas for the optimal replenishment rate."
1588,"Statistical Learning of Service-Dependent Demand in a Multiperiod Newsvendor Setting","Deng, Tianhu and Shen, Zuo-Jun Max and Shanthikumar, J. George","OPERATIONS RESEARCH","62","5","1064-1076","2014","SEP-OCT","","","We study an inventory system wherein a customer may leave the seller's market after experiencing an inventory stockout. Traditionally, researchers and practitioners assume a single penalty cost to model this customer behavior of stockout aversion. Recently, a stream of researchers explicitly model this customer behavior and support the traditional penalty cost approach. We enrich this literature by studying the statistical learning of service-dependent demand. We build and solve four models: a baseline model, where the seller can observe the demand distribution; a second model, where the seller cannot observe the demand distribution but statistically learns the demand distribution; a third model, where the seller can learn or pay to obtain the exact information of the demand distribution; and a fourth model, where demand in excess of available inventory is lost and unobserved. Interestingly, we find that all four models support the traditional penalty cost approach. This result confirms the use of a state-independent stockout penalty cost in the presence of demand learning. More strikingly, the first three models imply the same stockout penalty cost, which is larger than the stockout penalty cost implied by the last model."
1589,"Dynamic Pricing and Inventory Management Under Inventory-Dependent Demand","Yang, Nan and Zhang, Renyu","OPERATIONS RESEARCH","62","5","1077-1094","2014","SEP-OCT","","","We analyze a finite horizon periodic review joint pricing and inventory management model for a firm that replenishes and sells a product under the scarcity effect of inventory. The demand distribution in each period depends negatively on the sales price and customer-accessible inventory level at the beginning of the period. The firm can withhold or dispose of its on-hand inventory to deal with the scarcity effect. We show that a customer-accessible-inventory-dependent order-upto/dispose-down-to/display-up-to list-price policy is optimal. Moreover, the optimal order-up-to/display-up-to and list-price levels are decreasing in the customer-accessible inventory level. When the scarcity effect of inventory is sufficiently strong, the firm should display no positive inventory and deliberately make every customer wait. The analysis of two important special cases wherein the firm cannot withhold (or dispose of) inventory delivers sharper insights showing that the inventory-dependent demand drives both optimal prices and order-up-to levels down. In addition, we demonstrate that an increase in the operational flexibility (e.g., a higher salvage value or the inventory withholding opportunity) mitigates the demand loss caused by high excess inventory and increases the optimal order-up-to levels and sales prices. We also generalize our model by incorporating responsive inventory reallocation after demand realizes. Finally, we perform extensive numerical studies to demonstrate that both the profit loss of ignoring the scarcity effect and the value of dynamic pricing under the scarcity effect are significant."
1590,"A Reduced-Cost Iterated Local Search Heuristic for the Fixed-Charge Transportation Problem","Buson, Erika and Roberti, Roberto and Toth, Paolo","OPERATIONS RESEARCH","62","5","1095-1106","2014","SEP-OCT","","","The fixed-charge transportation problem (FCTP) is a generalization of the transportation problem where an additional fixed cost is paid for sending a flow from an origin to a destination. We propose an iterated local search heuristic based on the utilization of reduced costs for guiding the restart phase. The reduced costs are obtained by applying a lower bounding procedure that computes a sequence of nondecreasing lower bounds by solving a three-index mathematical formulation of the problem strengthened with valid inequalities. The proposed method was tested on two sets of benchmark instances from the literature. The first set was used to evaluate the state-of-the-art heuristics for the problem; the proposed heuristic was able to provide new best-knownupper bounds on all 124 open instances. On the second set of instances, which was recently introduced for testing the currently best exact method for the problem, the new heuristic was able to provide provably good upper bounds within short computing times."
1591,"A Dynamic Traveling Salesman Problem with Stochastic Arc Costs","Toriello, Alejandro and Haskell, William B. and Poremba, Michael","OPERATIONS RESEARCH","62","5","1107-1125","2014","SEP-OCT","","","We propose a dynamic traveling salesman problem (TSP) with stochastic arc costs motivated by applications, such as dynamic vehicle routing, in which the cost of a decision is known only probabilistically beforehand but is revealed dynamically before the decision is executed. We formulate this as a dynamic program (DP) and compare it to static counterparts to demonstrate the advantage of the dynamic paradigm over an a priori approach. We then apply approximate linear programming (ALP) to overcome the DP's curse of dimensionality, obtain a semi-infinite linear programming lower bound, and discuss its tractability. We also analyze a rollout version of the price-directed policy implied by our ALP and derive worst-case guarantees for its performance. Our computational study demonstrates the quality of a heuristically modified rollout policy using a computationally effective a posteriori bound."
1592,"An Exact Algorithm for the Two-Dimensional Orthogonal Packing Problem with Unloading Constraints","Cote, Jean-Francois and Gendreau, Michel and Potvin, Jean-Yves","OPERATIONS RESEARCH","62","5","1126-1141","2014","SEP-OCT","","","This paper describes an exact algorithm for solving a two-dimensional orthogonal packing problem with unloading constraints, which occurs as a subproblem of mixed vehicle routing and loading problems. The packing considered in this work is basically a feasibility problem involving a single bin. The problem is addressed through a decomposition approach wherein a branch-and-cut algorithm is designed for solving a one-dimensional relaxation of the original problem. When an integer solution is found in the branching tree, a subsidiary problem is solved to identify a two-dimensional packing that does not lead to any overlap and satisfies the unloading constraints. Cuts are added when the subsidiary problem proves to be infeasible. Several preprocessing techniques aimed at reducing the size of the solution space and uncovering infeasibility are also described. A numerical comparison with the best known exact method is reported at the end based on benchmark instances."
1593,"Dynamic Pricing with an Unknown Demand Model: Asymptotically Optimal Semi-Myopic Policies","Keskin, N. Bora and Zeevi, Assaf","OPERATIONS RESEARCH","62","5","1142-1167","2014","SEP-OCT","","","We consider a monopolist who sells a set of products over a time horizon of T periods. The seller initially does not know the parameters of the products' linear demand curve, but can estimate them based on demand observations. We first assume that the seller knows nothing about the parameters of the demand curve, and then consider the case where the seller knows the expected demand under an incumbent price. It is shown that the smallest achievable revenue loss in T periods, relative to a clairvoyant who knows the underlying demand model, is of order root T in the former case and of order log T in the latter case. To derive pricing policies that are practically implementable, we take as our point of departure the widely used policy called greedy iterated least squares (ILS), which combines sequential estimation and myopic price optimization. It is known that the greedy ILS policy itself suffers from incomplete learning, but we show that certain variants of greedy ILS achieve the minimum asymptotic loss rate. To highlight the essential features of well-performing pricing policies, we derive sufficient conditions for asymptotic optimality."
1594,"Reoptimization and Self-Adjusting Price Control for Network Revenue Management","Jasin, Stefanus","OPERATIONS RESEARCH","62","5","1168-1178","2014","SEP-OCT","","","We consider a standard dynamic pricing problem with finite inventories, finite selling horizon, and stochastic demands, where the objective of the seller is to maximize total expected revenue. We introduce a simple improvement of the popular static price control known in the literature. The proposed heuristic only requires a single optimization at the beginning of the selling horizon and does not require any reoptimization at all. This provides an advantage over the potentially heavy computational burden of reoptimization, especially for very large applications with frequent price adjustments. In addition, our heuristic can be implemented in combination with a few reoptimizations to achieve a high-level revenue performance. This hybrid of real-time adjustment and reoptimization allows the seller to enjoy the benefit of reoptimization without overdoing it."
1595,"Double-Sided Batch Queues with Abandonment: Modeling Crossing Networks","Afeche, Philipp and Diamant, Adam and Milner, Joseph","OPERATIONS RESEARCH","62","5","1179-1201","2014","SEP-OCT","","","We study a double-sided queue with batch arrivals and abandonment. There are two types of customers, patient ones who queue but may later abandon, and impatient ones who depart immediately if their order is not filled. The system matches units from opposite sides of the queue based on a first-come first-served policy. The model is particularly applicable to a class of alternative trading systems called crossing networks that are increasingly important in the operation of modern financial markets. We characterize, in closed form, the steady-state queue length distribution and the system-level average system time and fill rate. These appear to be the first closed-form results for a double-sided queuing model with batch arrivals and abandonment. For a customer who arrives to the system in steady state, we derive formulae for the expected fill rate and system time as a function of her order size and deadline. We compare these system-and customer-level results for our model that captures abandonment in aggregate, to simulation results for a system in which customers abandon after some random deadline. We find close correspondence between the predicted performance based on our analytical results and the performance observed in the simulation. Our model is particularly accurate in approximating the performance in systems with low fill rates, which are representative of crossing networks."
1596,"Stability in Large Matching Markets with Complementarities","Ashlagi, Itai and Braverman, Mark and Hassidim, Avinatan","OPERATIONS RESEARCH","62","4","713-732","2014","JUL-AUG","","","Labor markets can often be viewed as many-to-one matching markets. It is well known that if complementarities are present in such markets, a stable matching may not exist. We study large random matching markets with couples. We introduce a new matching algorithm and show that if the number of couples grows slower than the size of the market, a stable matching will be found with high probability. If however, the number of couples grows at a linear rate, with constant probability (not depending on the market size), no stable matching exists. Our results explain data from the market for psychology interns."
1597,"Opaque Distribution Channels for Competing Service Providers: Posted Price vs. Name-Your-Own-Price Mechanisms","Chen, Rachel R. and Gal-Or, Esther and Roma, Paolo","OPERATIONS RESEARCH","62","4","733-750","2014","JUL-AUG","","","Opaque selling has been widely adopted by service providers in the travel industry to sell off leftover capacity under stochastic demand. We consider a two-stage model to study the impact of different selling mechanisms, posted price (PP) versus name-your-own-price (NYOP), of an opaque reseller on competing service providers who face forward-looking customers. We find that in this environment, providers prefer that the opaque reseller uses a posted price instead of a bidding model. This is because the ability to set retail prices is critical for extracting surplus from customers who wait to purchase from the reseller. Such surplus extraction enables providers to set high prices for advance sales and obtain high profits. The dominance of PP over NYOP disappears, however, when competition between sellers is minimal or absent. We extend our model to multiple opaque resellers who compete in selling off last-minute capacity for service providers and find that our main insights continue to hold with differentiated resellers. Despite providers' preference in favor of PP, there are circumstances under which the opaque reseller earns higher profits under NYOP. Leisure customers might also prefer the bidding mechanism, which allows them to retain some surplus. This can help explain the rapid growth of the NYOP model over the last decade. Our findings are consistent with the evolution of opaque selling in the travel industry, and in particular, the recent trend towards more published price sales for opaque products."
1598,"Simultaneous Location of Trauma Centers and Helicopters for Emergency Medical Service Planning","Cho, Soo-Haeng and Jang, Hoon and Lee, Taesik and Turner, John","OPERATIONS RESEARCH","62","4","751-771","2014","JUL-AUG","","","This paper studies the problem of simultaneously locating trauma centers and helicopters. The standard approach to locating helicopters involves the use of helicopter busy fractions to model the random availability of helicopters. However, busy fractions cannot be estimated a priori in our problem because the demand for each helicopter cannot be determined until the trauma center locations are selected. To overcome this challenge, we endogenize the computation of busy fractions within an optimization problem. The resulting formulation has nonconvex bilinear terms in the objective, for which we develop an integrated method that iteratively solves a sequence of problem relaxations and restrictions. Specifically, we devise a specialized algorithm, called the shifting quadratic envelopes algorithm, that (1) generates tighter outer approximations than linear McCormick envelopes and (2) outperforms a Benders-like cut generation scheme. We apply our integrated method to the design of a nationwide trauma care system in Korea. By running a trace-based simulation on a full year of patient data, we find that the solutions generated by our model outperform several benchmark heuristics by up to 20%, as measured by an industry-standard metric: the proportion of patients successfully transported to a care facility within one hour. Our results have helped the Korean government to plan its nationwide trauma care system. More generally, our method can be applied to a class of optimization problems that aim to find the locations of both fixed and mobile servers when service needs to be carried out within a certain time threshold."
1599,"Integrated Charge Batching and Casting Width Selection at Baosteel","Tang, Lixin and Wang, Gongshu and Chen, Zhi-Long","OPERATIONS RESEARCH","62","4","772-787","2014","JUL-AUG","","","We study an integrated charge batching and casting width selection problem arising in the continuous casting operation of the steelmaking process at Shanghai, China based Baosteel. This decision-making problem is not unique to Baosteel; it exists in every large iron and steel company in the world. We collaborated with Baosteel on this problem from 2006 to 2008 by developing and implementing a decision support system (DSS) that replaced their manual planning method. The DSS is still in active use at Baosteel. This paper describes the solution algorithms we developed and imbedded in the DSS. For the general problem that is strongly NP-hard, a column generation-based branch-and-price (B&P) solution approach is developed to obtain optimal solutions. By exploiting the problem structure, efficient dynamic programming algorithms are designed to solve the subproblems involved in the column generation procedure. Branching strategies are designed in a way that ensures that after every stage of branching the structure of the subproblems is preserved such that they can still be solved efficiently. We also consider a frequently occurring case of the problem where each steel grade is incompatible with any other grade. For this special case, a two-level polynomial-time algorithm is developed to obtain optimal solutions. Computational tests on a set of real production data as well as on a more diverse set of randomly generated problem instances show that our algorithms outperform the manual planning method that Baosteel used to use by a significant margin both in terms of tundish utilization for almost every case, and in terms of total cost for most cases. Consequently, by replacing their manual method with our DSS, the estimated benefits to Baosteel include an annual cost saving of about US $1.6 million and an annual revenue increase of about US $3.25 million."
1600,"Subadditive and Homogeneous of Degree One Games Are Totally Balanced","Anily, Shoshana and Haviv, Moshe","OPERATIONS RESEARCH","62","4","788-793","2014","JUL-AUG","","","A cooperative game with transferable utility is said to be homogeneous of degree one if for any integer m, the value of cloning m times all players at any given coalition, leads to m times the value of the original coalition. We show that this property coupled with subadditivity, guarantees the nonemptyness of the core of the game and of all its subgames, namely, the game is totally balanced. Examples for games stemming from the areas of retailing and of facility location are given."
1601,"Appointment Scheduling Under Patient Preference and No-Show Behavior","Feldman, Jacob and Liu, Nan and Topaloglu, Huseyin and Ziya, Serhan","OPERATIONS RESEARCH","62","4","794-811","2014","JUL-AUG","","","Motivated by the rising popularity of electronic appointment booking systems, we develop appointment scheduling models that take into account the patient preferences regarding when they would like to be seen. The service provider dynamically decides which appointment days to make available for the patients. Patients arriving with appointment requests may choose one of the days offered to them or leave without an appointment. Patients with scheduled appointments may cancel or not show up for the service. The service provider collects a revenue from each patient who shows up and incurs a service cost that depends on the number of scheduled appointments. The objective is to maximize the expected net profit per day. We begin by developing a static model that does not consider the current state of the scheduled appointments. We give a characterization of the optimal policy under the static model and bound its optimality gap. Building on the static model, we develop a dynamic model that considers the current state of the scheduled appointments, and we propose a heuristic solution procedure. In our computational experiments, we test the performance of our models under the patient preferences estimated through a discrete choice experiment that we conduct in a large community health center. Our computational experiments reveal that the policies we propose perform well under a variety of conditions."
1602,"Modified Echelon (r, Q) Policies with Guaranteed Performance Bounds for Stochastic Serial Inventory Systems","Hu, Ming and Yang, Yi","OPERATIONS RESEARCH","62","4","812-828","2014","JUL-AUG","","","We consider the classic continuous-review N stage serial inventory system with a homogeneous Poisson demand arrival process at the most downstream stage (Stage 1). Any shipment to each stage, regardless of its size, incurs a positive fixed setup cost and takes a positive constant lead time. The optimal policy for this system under the long-run average cost criterion is unknown. Finding a good worst-case performance guarantee remains an open problem. We tackle this problem by introducing a class of modified echelon (r, Q) policies that do not require Q(i+1)/Q(i) to be a positive integer: Stage i +1 ships to Stage i based on its observation of the echelon inventory position at Stage i; if it is at or below r(i) and Stage i +1 has positive on-hand inventory, then a shipment is sent to Stage i to raise its echelon inventory position to r(i) + Q(i) as close as possible. We construct a heuristic policy within this class of policies, which has the following features: First, it has provably primitive-dependent performance bounds. In a two-stage system, the performance of the heuristic policy is guaranteed to be within (1 + K-1/K-2) times the optimal cost, where K-1 is the downstream fixed cost and K-2 is the upstream fixed cost. We also provide an alternative performance bound, which depends on efficiently computable optimal (r, Q) solutions to N single-stage systems but tends to be tighter. Second, the heuristic is simple, it is efficiently computable and it performs well numerically; it is even likely to outperform the optimal integer-ratio echelon (r, Q) policies when K-1 is dominated by K-2. Third, the heuristic is asymptotically optimal when we take some dominant relationships between the setup or holding cost primitives at an upstream stage and its immediate downstream stage to the extreme, for example, when h(2)/h(1) -> 0, where h(1) is the downstream holding cost parameter and h(2) is the upstream holding cost parameter."
1603,"Aircraft Rescheduling with Cruise Speed Control","Akturk, M. Selim and Atamturk, Alper and Gurel, Sinan","OPERATIONS RESEARCH","62","4","829-845","2014","JUL-AUG","","","Airline operations are subject to frequent disruptions typically due to unexpected aircraft maintenance requirements and undesirable weather conditions. Recovery from a disruption often involves propagating delays in downstream flights and increasing cruise stage speed when possible in an effort to contain the delays. However, there is a critical trade-off between fuel consumption (and its adverse impact on air quality and greenhouse gas emissions) and cruise speed. Here we consider delays caused by such disruptions and propose a flight rescheduling model that includes adjusting cruise stage speed on a set of affected and unaffected flights as well as swapping aircraft optimally. To the best of our knowledge, this is the first study in which the cruise speed is explicitly included as a decision variable into an airline recovery optimization model along with the environmental constraints and costs. The proposed model allows one to investigate the trade-off between flight delays and the cost of recovery. We show that the optimization approach leads to significant cost savings compared to the popular recovery method delay propagation. Flight time controllability, nonlinear delay, fuel burn and CO2 emission cost functions, and binary aircraft swapping decisions complicate the aircraft recovery problem significantly. In order to mitigate the computational difficulty we utilize the recent advances in conic mixed integer programming and propose a strengthened formulation so that the nonlinear mixed integer recovery optimization model can be solved efficiently. Our computational tests on realistic cases indicate that the proposed model may be used by operations controllers to manage disruptions in real time in an optimal manner instead of relying on ad-hoc heuristic approaches."
1604,"Quantity Premiums and Discounts in Dynamic Pricing","Levin, Yuri and Nediak, Mikhail and Bazhanov, Andrei","OPERATIONS RESEARCH","62","4","846-863","2014","JUL-AUG","","","We consider a dynamic pricing problem for a monopolistic company selling a perishable product when customer demand is both uncertain and occurs in batches that must be fulfilled as a whole. The seller can price-discriminate between different sized batches by setting different unit prices. The problem is modeled as a stochastic optimal control problem to find an inventory-contingent dynamic pricing policy that maximizes the expected total revenues. We find the optimal pricing policy and prove several monotonicity results. First, we establish stochastic order conditions on the unit willingness-to-pay distributions that determine when quantity discounts or premiums take place for a batch purchase compared to a rapid sequence of purchases with the same total size. Second, we give sufficient conditions for prices to be monotonically decreasing or increasing in inventory. Third, we characterize the conditions for the perceived quantity discounts and premiums that result from comparing unit prices for different batch sizes under a particular inventory level."
1605,"Markov Decision Problems Where Means Bound Variances","Arlotto, Alessandro and Gans, Noah and Steele, J. Michael","OPERATIONS RESEARCH","62","4","864-875","2014","JUL-AUG","","","We identify a rich class of finite-horizon Markov decision problems (MDPs) for which the variance of the optimal total reward can be bounded by a simple linear function of its expected value. The class is characterized by three natural properties: reward nonnegativity and boundedness, existence of a do-nothing action, and optimal action monotonicity. These properties are commonly present and typically easy to check. Implications of the class properties and of the variance bound are illustrated by examples of MDPs from operations research, operations management, financial engineering, and combinatorial optimization."
1606,"A Dynamic Near-Optimal Algorithm for Online Linear Programming","Agrawal, Shipra and Wang, Zizhuo and Ye, Yinyu","OPERATIONS RESEARCH","62","4","876-890","2014","JUL-AUG","","","A natural optimization model that formulates many online resource allocation problems is the online linear programming ( LP) problem in which the constraint matrix is revealed column by column along with the corresponding objective coefficient. In such a model, a decision variable has to be set each time a column is revealed without observing the future inputs, and the goal is to maximize the overall objective function. In this paper, we propose a near-optimal algorithm for this general class of online problems under the assumptions of random order of arrival and some mild conditions on the size of the LP right-hand-side input. Specifically, our learning-based algorithm works by dynamically updating a threshold price vector at geometric time intervals, where the dual prices learned from the revealed columns in the previous period are used to determine the sequential decisions in the current period. Through dynamic learning, the competitiveness of our algorithm improves over the past study of the same problem. We also present a worst case example showing that the performance of our algorithm is near optimal."
1607,"Perspective Reformulations of the CTA Problem with L-2 Distances","Castro, Jordi and Frangioni, Antonio and Gentile, Claudio","OPERATIONS RESEARCH","62","4","891-909","2014","JUL-AUG","","","Any institution that disseminates data in aggregated form has the duty to ensure that individual confidential information is not disclosed, either by not releasing data or by perturbing the released data while maintaining data utility. Controlled tabular adjustment (CTA) is a promising technique of the second type where a protected table that is close to the original one in some chosen distance is constructed. The choice of the specific distance shows a trade-off: although the Euclidean distance has been shown (and is confirmed here) to produce tables with greater utility, it gives rise to mixed integer quadratic problems (MIQPs) with pairs of linked semi-continuous variables that are more difficult to solve than the mixed integer linear problems corresponding to linear norms. We provide a novel analysis of perspective reformulations (PRs) for this special structure; in particular, we devise a projected PR ((PR)-R-2), which is piecewise-conic but simplifies to a (nonseparable) MIQP when the instance is symmetric. We then compare different formulations of the CTA problem, showing that the ones based on (PR)-R-2 most often obtain better computational results."
1608,"Strategic Customers in a Transportation Station: When Is It Optimal to Wait?","Manou, Athanasia and Economou, Antonis and Karaesmen, Fikri","OPERATIONS RESEARCH","62","4","910-925","2014","JUL-AUG","","","We consider a transportation station, where customers arrive according to a Poisson process. A transportation facility visits the station according to a renewal process and serves at each visit a random number of customers according to its capacity. We assume that the arriving customers decide whether to join the station or balk, based on a natural reward-cost structure. We study the strategic behavior of the customers and determine their symmetric Nash equilibrium strategies under two levels of information."
1609,"A Fully Sequential Elimination Procedure for Indifference-Zone Ranking and Selection with Tight Bounds on Probability of Correct Selection","Frazier, Peter I.","OPERATIONS RESEARCH","62","4","926-942","2014","JUL-AUG","","","We consider the indifference-zone (IZ) formulation of the ranking and selection problem with independent normal samples. In this problem, we must use stochastic simulation to select the best among several noisy simulated systems, with a statistical guarantee on solution quality. Existing IZ procedures sample excessively in problems with many alternatives, in part because loose bounds on probability of correct selection lead them to deliver solution quality much higher than requested. Consequently, existing IZ procedures are seldom considered practical for problems with more than a few hundred alternatives. To overcome this, we present a new sequential elimination IZ procedure, called BIZ (Bayes-inspired indifference zone), whose lower bound on worst-case probability of correct selection in the preference zone is tight in continuous time, and nearly tight in discrete time. To the author's knowledge, this is the first sequential elimination procedure with tight bounds on worst-case preference-zone probability of correct selection for more than two alternatives. Theoretical results for the discrete-time case assume that variances are known and have an integer multiple structure, but the BIZ procedure itself can be used when these assumptions are not met. In numerical experiments, the sampling effort used by BIZ is significantly smaller than that of another leading IZ procedure, the KN procedure, especially on the largest problems tested (2(14) = 16 1 384 alternatives)."
1610,"Routing and Staffing in Customer Service Chat Systems with Impatient Customers","Tezcan, Tolga and Zhang, Jiheng","OPERATIONS RESEARCH","62","4","943-956","2014","JUL-AUG","","","We consider customer service chat (CSC) systems where customers can receive real time service from agents using an instant messaging (IM) application over the Internet. A unique feature of these systems is that agents can serve multiple customers simultaneously. The number of customers that an agent is serving determines the rate at which each customer assigned to that agent receives service. We consider the staffing problem in CSC systems with impatient customers where the objective is to minimize the number of agents while providing a certain service level. The service level is measured in terms of the proportion of customers who abandon the system in the long run. First we propose effective routing policies based on a static planning LP, both for the cases when the arrival rate is observable and for when the rate is unobservable. We show that these routing policies minimize the proportion of abandoning customers in the long run asymptotically for large systems. We also prove that the staffing solution obtained from a staffing LP, when used with the proposed routing policies, is asymptotically optimal. We illustrate the effectiveness of our solution procedure in systems with small to large sizes via numerical and simulation experiments."
1611,"Directed Principal Component Analysis","Kao, Yi-Hao and Van Roy, Benjamin","OPERATIONS RESEARCH","62","4","957-972","2014","JUL-AUG","","","We consider a problem involving estimation of a high-dimensional covariance matrix that is the sum of a diagonal matrix and a low-rank matrix, and making a decision based on the resulting estimate. Such problems arise, for example, in portfolio management, where a common approach employs principal component analysis (PCA) to estimate factors used in constructing the low-rank term of the covariance matrix. The decision problem is typically treated separately, with the estimated covariance matrix taken to be an input to an optimization problem. We propose directed PCA, an efficient algorithm that takes the decision objective into account when estimating the covariance matrix. Directed PCA effectively adjusts factors that would be produced by PCA so that they better guide the specific decision at hand. We demonstrate through computational studies that directed PCA yields significant benefit, and we prove theoretical results establishing that the degree of improvement over conventional PCA can be arbitrarily large."
1612,"Judge: Don't Vote!","Balinski, Michel and Laraki, Rida","OPERATIONS RESEARCH","62","3","483-511","2014","MAY-JUN","","","This article argues that the traditional model of the theory of social choice is not a good model and does not lead to acceptable methods of ranking and electing. It presents a more meaningful and realistic model that leads naturally to a method of ranking and electing-majority judgment-that better meets the traditional criteria of what constitutes a good method. It gives descriptions of its successful use in several different practical situations and compares it with other methods including Condorcet's, Borda's, first-past-the-post, and approval voting."
1613,"Optimal Pricing and Inventory Control Policy with Quantity-Based Price Differentiation","Lu, Ye and Chen, Youhua (Frank) and Song, Miao and Yan, Xiaoming","OPERATIONS RESEARCH","62","3","512-523","2014","MAY-JUN","","","A firm facing price dependent stochastic demand aims to maximize its total expected profit over a planning horizon. In addition to the regular unit selling price, the firm can utilize quantity discounts to increase sales. We refer to this dual-pricing strategy as quantity-based price differentiation. At the beginning of each period, the firm needs to make three decisions: replenish the inventory, set the unit selling price if the unit sales mode is deployed, and set the quantity-discount price if the quantity-sales mode is deployed (or the combination of the two modes of sales). We identify conditions under which the optimal inventory control policy and selling/pricing strategy is well structured. Remarkably, under a utility-based demand framework, these conditions can be unified by a simple regularity assumption that has long been used in the auction and mechanism design literature. Moreover, sharper structural results are yielded for the optimal selling strategy. We also examine the comparative advantage of quantity-based price differentiation with respect to model parameters. Our numerical study shows that substantial profit improvement can be gained as a result of shifting from uniform pricing to quantity-based pricing, especially when the product has a low unit ordering cost and high utility."
1614,"Analyzing Scrip Systems","Johnson, Kris and Simchi-Levi, David and Sun, Peng","OPERATIONS RESEARCH","62","3","524-534","2014","MAY-JUN","","","Scrip systems provide a nonmonetary trade economy for exchange of resources. We model a scrip system as a stochastic game and study system design issues on selection rules to match potential trade partners over time. We show the optimality of one particular rule in terms of maximizing social welfare for a given scrip system that guarantees players' incentives to participate. We also investigate the optimal number of scrips to issue under this rule. In particular, if the time discount factor is close enough to one, or trade benefits one partner much more than it costs the other, the maximum social welfare is always achieved no matter how many scrips are in the system. When the benefit of trade and time discount are not sufficiently large, on the other hand, injecting more scrips in the system hurts most participants; as a result, there is an upper bound on the number of scrips allowed in the system, above which some players may default. We show that this upper bound increases with the discount factor as well as the ratio between the benefit and cost of service. Finally, we demonstrate similar properties for a different service provider selection rule that has been analyzed in previous literature."
1615,"Technical Note-A Risk- and Ambiguity-Averse Extension of the Max-Min Newsvendor Order Formula","Han, Qiaoming and Du, Donglei and Zuluaga, Luis F.","OPERATIONS RESEARCH","62","3","535-542","2014","MAY-JUN","","","Scarf's max-min order formula for the risk-neutral and ambiguity-averse newsvendor problem is a classical result in the field of inventory management. In this article, we extend Scarf's formula by deriving an analogous closed-form order formula for the risk-and ambiguity-averse newsvendor problem. Specifically, we provide and analyze the newsvendor order quantity that maximizes the worst-case expected profit versus risk trade-off (risk-averse) when only the mean and standard deviation of the product's demand distribution are known (ambiguity-averse), and the risk is measured by the standard deviation of the newsvendor's profit. We provide both analytical and numerical results to illustrate the combined effect of considering risk aversion and ambiguity aversion in computing the newsvendor order."
1616,"On the Estimation of Marginal Cost","Delis, Manthos and Iosifidi, Maria and Tsionas, Efthymios G.","OPERATIONS RESEARCH","62","3","543-556","2014","MAY-JUN","","","This article proposes the estimation of the marginal cost of individual firms using semiparametric and nonparametric methods. These methods have a number of appealing features when applied to cost functions. The empirical analysis uses data from a unique sample of the California electricity industry for which we observe the actual marginal cost and estimate the marginal cost from these data. We compare the actual values of marginal cost with the estimates from semiparametric and nonparametric methods, as well as with the estimates obtained through conventional parametric methods. We show that the semiparametric and nonparametric methods produce marginal cost estimates that very closely approximate the actual. In contrast, the results from conventional parametric methods are significantly biased and provide invalid inference."
1617,"Hub Location as the Minimization of a Supermodular Set Function","Contreras, Ivan and Fernandez, Elena","OPERATIONS RESEARCH","62","3","557-570","2014","MAY-JUN","","","This paper highlights how a general class of hub location problems can be modeled as the minimization of a real-valued supermodular set function. Well-known problems such as uncapacitated hub location, p-hub median, and hub arc location, among others, are shown to be particular cases of this class. Two integer programming formulations are introduced and compared. One uses path-based variables, frequently employed in hub location, whereas the other exploits properties of supermodular functions. In addition, several worst case bounds for a greedy and a local improvement heuristic are obtained for the general class and for some particular cases in which sharper bounds can be devised. Computational experiments are performed to compare both formulations when used with a general purpose solver. Computational results obtained on benchmark instances confirm the superiority of the supermodular formulation."
1618,"Technical Note-Optimal Structural Results for Assemble-to-Order Generalized M-Systems","Nadar, Emre and Akan, Mustafa and Scheller-Wolf, Alan","OPERATIONS RESEARCH","62","3","571-579","2014","MAY-JUN","","","We consider an assemble-to-order generalized M -system with multiple components and multiple products, batch ordering of components, random lead times, and lost sales. We model the system as an infinite-horizon Markov decision process and seek an optimal policy that specifies when a batch of components should be produced (i.e., inventory replenishment) and whether an arriving demand for each product should be satisfied (i. e., inventory allocation). We characterize optimal inventory replenishment and allocation policies under a mild condition on component batch sizes via a new type of policy: lattice-dependent base stock and lattice-dependent rationing."
1619,"Modeling Passenger Travel and Delays in the National Air Transportation System","Barnhart, Cynthia and Fearing, Douglas and Vaze, Vikrant","OPERATIONS RESEARCH","62","3","580-601","2014","MAY-JUN","","","Many of the existing methods for evaluating an airline's on-time performance are based on flight-centric measures of delay. However, recent research has demonstrated that passenger delays depend on many factors in addition to flight delays. For instance, significant passenger delays result from flight cancellations and missed connections, which themselves depend on a significant number of factors. Unfortunately, lack of publicly available passenger travel data has made it difficult for researchers to explore the nature of these relationships. In this paper, we develop methodologies to model historical travel and delays for U. S. domestic passengers. We develop a multinomial logit model for estimating historical passenger travel and extend a previously developed greedy reaccommodation heuristic for estimating the resulting passenger delays. We report and analyze the estimated passenger delays for calendar year 2007, developing insights into factors that affect the performance of the National Air Transportation System in the United States."
1620,"Impulse Control of Interest Rates","Mitchell, Daniel and Feng, Haolin and Muthuraman, Kumar","OPERATIONS RESEARCH","62","3","602-615","2014","MAY-JUN","","","This paper examines the effect that a central bank's interventions have on longer term interest rate securities by examining a stochastic short rate process that can be controlled by the central bank. Rather than investigate the motivations for the intervention, we assume that the bank is able to quantify its preferences and tolerances for various rates. We allow for a very general class of stochastic processes for the short rate, and most of the popular models in literature fall within this class. Interventions are best modeled as impulse controls, which are very difficult to handle, even computationally, except in very special cases. Allowing interventions to be modeled by impulse controls, we develop a computational method and provide relevant convergence results. We also derive error bounds for intermediate iterations. Using this method, we solve for the central bank's optimal control policy and also study the effect of this on longer term interest rate securities using a change of measure. The method developed here can easily be applied to a very wide range of impulse control problems beyond the realm of interest rate models."
1621,"American Option Sensitivities Estimation via a Generalized Infinitesimal Perturbation Analysis Approach","Chen, Nan and Liu, Yanchu","OPERATIONS RESEARCH","62","3","616-632","2014","MAY-JUN","","","In this paper, we develop efficient Monte Carlo methods for estimating American option sensitivities. The problem can be reformulated as how to perform sensitivity analysis for a stochastic optimization problem with model uncertainty. We introduce a generalized infinitesimal perturbation analysis (IPA) approach to resolve the difficulty caused by discontinuity of the optimal decision with respect to the underlying parameter. The IPA estimators are unbiased if the optimal decisions are explicitly known. To quantify the estimation bias caused by intractable exercising policies in the case of pricing American options, we also provide an approximation guarantee that relates the sensitivity under the optimal exercise policy to that computed under a suboptimal policy. The price-sensitivity estimators yielded from this approach demonstrate significant advantages numerically in both high-dimensional environments and various process settings. We can easily embed them into many of the most popular pricing algorithms without extra simulation effort to obtain sensitivities as a by-product of the option price. Our generalized approach also casts new insights on how to perform sensitivity analysis using IPA: we do not need path-wise continuity to apply it."
1622,"CUT: A Multicriteria Approach for Concavifiable Preferences","Argyris, Nikolaos and Morton, Alec and Figueira, Jose Rui","OPERATIONS RESEARCH","62","3","633-642","2014","MAY-JUN","","","We consider the problem of helping a decision maker (DM) choose from a set of multiattributed objects when her preferences are concavifiable, i.e. representable by a concave value function. We establish conditions under which preferences or preference intensities are concavifiable. We also derive a characterization for the family of concave value functions compatible with a set of such preference statements expressed by the DM. This can be used to validate dominance relations over discrete sets of alternatives and forms the basis of an interactive procedure. We report on the practical use of this procedure with several DMs for a flat-choice problem and its computational performance on a set of project-portfolio selection problem instances. The use of preference intensities is found to provide significant improvements to the performance of the procedure."
1623,"Combinatorial Benders' Cuts for the Strip Packing Problem","Cote, Jean-Francois and Dell'Amico, Mauro and Iori, Manuel","OPERATIONS RESEARCH","62","3","643-661","2014","MAY-JUN","","","We study the strip packing problem, in which a set of two-dimensional rectangular items has to be packed in a rectangular strip of fixed width and infinite height, with the aim of minimizing the height used. The problem is important because it models a large number of real-world applications, including cutting operations where stocks of materials such as paper or wood come in large rolls and have to be cut with minimum waste, scheduling problems in which tasks require a contiguous subset of identical resources, and container loading problems arising in the transportation of items that cannot be stacked one over the other. The strip packing problem has been attacked in the literature with several heuristic and exact algorithms, nevertheless, benchmark instances of small size remain unsolved to proven optimality. In this paper we propose a new exact method that solves a large number of the open benchmark instances within a limited computational effort. Our method is based on a Benders' decomposition, in which in the master we cut items into unit-width slices and pack them contiguously in the strip, and in the slave we attempt to reconstruct the rectangular items by fixing the vertical positions of their unit-width slices. If the slave proves that the reconstruction of the items is not possible, then a cut is added to the master, and the algorithm is reiterated. We show that both the master and the slave are strongly N P-hard problems and solve them with tailored preprocessing, lower and upper bounding techniques, and exact algorithms. We also propose several new techniques to improve the standard Benders' cuts, using the so-called combinatorial Benders' cuts, and an additional lifting procedure. Extensive computational tests show that the proposed algorithm provides a substantial breakthrough with respect to previously published algorithms."
1624,"FAST-Fast Algorithm for the Scenario Technique","Care, Algo and Garatti, Simone and Campi, Marco C.","OPERATIONS RESEARCH","62","3","662-671","2014","MAY-JUN","","","The scenario approach is a recently introduced method to obtain feasible solutions to chance-constrained optimization problems based on random sampling. It has been noted that the sample complexity of the scenario approach rapidly increases with the number of optimization variables and this may pose a hurdle to its applicability to medium-and large-scale problems. We here introduce the Fast Algorithm for the Scenario Technique, a variant of the scenario optimization algorithm with reduced sample complexity."
1625,"Technical Note-Deriving Robust and Globalized Robust Solutions of Uncertain Linear Programs with General Convex Uncertainty Sets","Gorissen, Bram L. and Blanc, Hans and den Hertog, Dick and Ben-Tal, Aharon","OPERATIONS RESEARCH","62","3","672-679","2014","MAY-JUN","","","We propose a new way to derive tractable robust counterparts of a linear program based on the duality between the robust (pessimistic) primal problem and its optimistic dual. First we obtain a new convex reformulation of the dual problem of a robust linear program, and then show how to construct the primal robust solution from the dual optimal solution. Our result allows many new uncertainty regions to be considered. We give examples of tractable uncertainty regions that were previously intractable. The results are illustrated by solving a multi-item newsvendor problem. We also apply the new method to the globalized robust counterpart scheme and show its tractability."
1626,"Generalized Inverse Multiobjective Optimization with Application to Cancer Therapy","Chan, Timothy C. Y. and Craig, Tim and Lee, Taewoo and Sharpe, Michael B.","OPERATIONS RESEARCH","62","3","680-695","2014","MAY-JUN","","","We generalize the standard method of solving inverse optimization problems to allow for the solution of inverse problems that would otherwise be ill posed or infeasible. In multiobjective linear optimization, given a solution that is not a weakly efficient solution to the forward problem, our method generates objective function weights that make the given solution a near-weakly efficient solution. Our generalized inverse optimization model specializes to the standard model when the given solution is weakly efficient and retains the complexity of the underlying forward problem. We provide a novel interpretation of our inverse formulation as the dual of the well-known Benson's method and by doing so develop a new connection between inverse optimization and Pareto surface approximation techniques. We apply our method to prostate cancer data obtained from Princess Margaret Cancer Centre in Toronto, Canada. We demonstrate that clinically acceptable treatments can be generated using a small number of objective functions and inversely optimized weights-current treatments are designed using a complex formulation with a large parameter space in a trial-and-error reoptimization process. We also show that our method can identify objective functions that are most influential in treatment plan optimization."
1627,"Generalized Restless Bandits and the Knapsack Problem for Perishable Inventories","Graczova, Darina and Jacko, Peter","OPERATIONS RESEARCH","62","3","696-711","2014","MAY-JUN","","","In this paper we introduce the knapsack problem for perishable inventories concerning the optimal dynamic allocation of a collection of products to a limited knapsack. The motivation for designing such a problem comes from retail revenue management, where different products often have an associated lifetime during which they can only be sold, and the managers can regularly select some products to be allocated to a limited promotion space that is expected to attract more customers than the standard shelves. Another motivation comes from scheduling of requests in modern multiserver data centers so that quality-of-service requirements given by completion deadlines are satisfied. Using the Lagrangian approach we derive an optimal index policy for the Whittle relaxation of the problem in which the knapsack capacity is used only on average. Assuming a certain structure of the optimal policy for the single-inventory control, we prove indexability and derive an efficient, linear-time algorithm for computing the index values. To the best of our knowledge, our paper is the first to provide indexability analysis of a restless bandit with bi-dimensional state (lifetime and inventory level). We illustrate that these index values are numerically close to the true index values when such a structure is not present. We test two index-based heuristics for the original, nonrelaxed problem: (1) a conventional index rule, which prescribes to order the products according to their current index values and promotes as many products as fit in the knapsack, and (2) a recently proposed index-knapsack heuristic, which employs the index values as a proxy for the price of promotion and proposes to solve a deterministic knapsack problem to select the products. By a systematic computational study we show that the performance of both heuristics is nearly optimal, and that the index-knapsack heuristic outperforms the conventional index rule."
1628,"Optimal Allocation of Resources in Airport Security: Profiling vs. Screening","Bagchi, Aniruddha and Paul, Jomon Aliyas","OPERATIONS RESEARCH","62","2","219-233","2014","MAR-APR","","","This model examines the role of intelligence gathering and screening in providing airport security. We analyze this problem using a game between the government and a terrorist. By investing in intelligence gathering, the government can improve the precision of its information. In contrast, screening can be used to search a passenger and thereby deter terrorist attacks. We determine the optimal allocation of resources between these two strategies wherein we model the role of intelligence using the concept of supermodular precision. One striking result is that under certain circumstances, an increase in the investment in intelligence can induce a more devious terrorist to attack with a higher probability. We also find that when there is a cost-reducing innovation in the screening technology, then the optimal investment in intelligence gathering can go either way. However, such an innovation unambiguously improves social welfare. Another interesting implication is that a developed economy would value intelligence inputs more than a developing economy. We also examine the efficacy of a program such as PreCheck that allows some select passengers expedited screening in exchange for voluntarily revealing information about themselves. Our analysis shows that such a program can be used to cushion the adverse effect of budgetary shortages. Finally, we also examine the role of enhanced punishment on the optimal level of intelligence. We find that the result can go both ways. If the initial level of punishment is high, then any further enhancement reduces the optimal level of intelligence gathering. However, this result is reversed if the initial level of punishment is low."
1629,"Market-Consistent Modeling for Cap-and-Trade Schemes and Application to Option Pricing","Barrieu, Pauline and Fehr, Max","OPERATIONS RESEARCH","62","2","234-249","2014","MAR-APR","","","In this paper we refer to the requirement for industrialized countries to reach a domestic target for greenhouse emissions, as ratified in the Kyoto Protocol, and propose a market-consistent model of futures price dynamics for cap-and-trade schemes designed in the spirit of the European Union Emissions Trading Scheme (EU ETS). Historical price dynamics for the EU ETS suggest that both European emission allowance (EUA) and certified emission reduction (CER) certificates, generated by a nondomestic offset mechanism, are significantly related. We use an equilibrium framework to demonstrate that compliance regulation singles out special price dynamics. Based on this result, we propose an arbitrage-free model and apply it to the pricing of spread options between EUAs and CERs."
1630,"Assortment Optimization Under Variants of the Nested Logit Model","Davis, James M. and Gallego, Guillermo and Topaloglu, Huseyin","OPERATIONS RESEARCH","62","2","250-273","2014","MAR-APR","","","We study a class of assortment optimization problems where customers choose among the offered products according to the nested logit model. There is a fixed revenue associated with each product. The objective is to find an assortment of products to offer so as to maximize the expected revenue per customer. We show that the problem is polynomially solvable when the nest dissimilarity parameters of the choice model are less than one and the customers always make a purchase within the selected nest. Relaxing either of these assumptions renders the problem NP-hard. To deal with the NP-hard cases, we develop parsimonious collections of candidate assortments with worst-case performance guarantees. We also formulate a convex program whose optimal objective value is an upper bound on the optimal expected revenue. Thus, we can compare the expected revenue provided by an assortment with the upper bound on the optimal expected revenue to get a feel for the optimality gap of the assortment. By using this approach, our computational experiments test the performance of the parsimonious collections of candidate assortments that we develop."
1631,"Delay-Robust Event Scheduling","Caprara, Alberto and Galli, Laura and Stiller, Sebastian and Toth, Paolo","OPERATIONS RESEARCH","62","2","274-283","2014","MAR-APR","","","Robust optimisation is a well-established concept to deal with uncertainty. In particular, recovery-robust models are suitable for real-world contexts, where a certain amount of recovery-although limited-is often available. In this paper we describe a general framework to optimise event-based problems against delay propagation. We also present a real-world application to train platforming in the Italian railways in order to show the practical effectiveness of our framework."
1632,"Coordinating Inventory Control and Pricing Strategies for Perishable Products","Chen, Xin and Pang, Zhan and Pan, Limeng","OPERATIONS RESEARCH","62","2","284-300","2014","MAR-APR","","","We analyze a joint pricing and inventory control problem for a perishable product with a fixed lifetime over a finite horizon. In each period, demand depends on the price of the current period plus an additive random term. Inventories can be intentionally disposed of, and those that reach their lifetime have to be disposed of. The objective is to find a joint pricing, ordering, and disposal policy to maximize the total expected discounted profit over the planning horizon taking into account linear ordering cost, inventory holding and backlogging or lost-sales penalty cost, and disposal cost. Employing the concept of L-(sic)-concavity, we show some monotonicity properties of the optimal policies. Our results shed new light on perishable inventory management, and our approach provides a significantly simpler proof of a classical structural result in the literature. Moreover, we identify bounds on the optimal order-up-to levels and develop an effective heuristic policy. Numerical results show that our heuristic policy performs well in both stationary and nonstationary settings. Finally, we show that our approach also applies to models with random lifetimes and inventory rationing models with multiple demand classes."
1633,"Sequential Resource Allocation for Nonprofit Operations","Lien, Robert W. and Iravani, Seyed M. R. and Smilowitz, Karen R.","OPERATIONS RESEARCH","62","2","301-317","2014","MAR-APR","","","This paper studies a sequential resource allocation problem motivated by distribution operations of a nonprofit organization. The alternate objectives that arise in nonprofit (as opposed to commercial) operations lead to new variations on traditional problems in operations research and inventory management. Specifically, we consider the problem of distributing a scarce resource to meet customers' demands that are observed sequentially. An allocation policy that seeks to maximize profit may lead to inequitable distributions among customers. Our work in a nonprofit setting solves the sequential resource allocation problem with an objective function aimed at equitable and effective service. We define service in terms of fill rate (the ratio of the allocated amount to observed demand) and develop an objective function to maximize the expected minimum fill rate among customers, which balances equity in fill rates with effectiveness in the use of resources (low waste). Through a dynamic programming framework, we characterize the structure of the optimal allocation policy for a given sequence of customers when demand follows continuous probability distributions. We use that optimal structure to develop a heuristic allocation policy for instances with discrete demand distribution. In addition, we identify customer demand properties to consider when sequencing customer visits to optimize the fill rate objective. For both inventory allocation and customer sequencing decisions, the proposed heuristic methods yield near-optimal solutions."
1634,"Close the Gaps: A Learning-While-Doing Algorithm for Single-Product Revenue Management Problems","Wang, Zizhuo and Deng, Shiming and Ye, Yinyu","OPERATIONS RESEARCH","62","2","318-331","2014","MAR-APR","","","We consider a retailer selling a single product with limited on-hand inventory over a finite selling season. Customer demand arrives according to a Poisson process, the rate of which is influenced by a single action taken by the retailer (such as price adjustment, sales commission, advertisement intensity, etc.). The relationship between the action and the demand rate is not known in advance. However, the retailer is able to learn the optimal action on the fly as she maximizes her total expected revenue based on the observed demand reactions. Using the pricing problem as an example, we propose a dynamic learning-while-doing algorithm that only involves function value estimation to achieve a near-optimal performance. Our algorithm employs a series of shrinking price intervals and iteratively tests prices within that interval using a set of carefully chosen parameters. We prove that the performance of our algorithm is among the best of all possible algorithms in terms of the asymptotic regret (the relative loss compared to the full information optimal solution). Our result closes the performance gaps between parametric and nonparametric learning and between the post-price mechanism and the customer-bidding mechanism. Important managerial insight from this research is that the values of information on both the parametric form of the demand function as well as each customer's exact reservation price are less important than prior literature suggests. Our results also suggest that firms would be better off to perform dynamic learning and action concurrently rather than sequentially."
1635,"On Markov Equilibria in Dynamic Inventory Competition","Olsen, Tava Lennon and Parker, Rodney P.","OPERATIONS RESEARCH","62","2","332-344","2014","MAR-APR","","","We provide a review of the types of equilibria typically found in operations management inventory papers and a discussion on when the commonly used stationary infinite-horizon (open-loop) equilibrium may be sufficient for study. We focus particularly on order-up-to and basestock equilibria in the context of inventory duopolies. We give conditions under which the stationary infinite-horizon equilibrium is also a Markov perfect (closed-loop) equilibrium. These conditions are then applied to three specific duopolies. The first application is one with stockout-based substitution, where the firms face independent direct demand but some fraction of a firm's lost sales will switch to the other firm. The second application is one where shelf-space display stimulates primary demand and reduces demand for the other firm's product. The final application is one where the state variables represent goodwill rather than inventory. These specific problems have been previously studied in both the single period and/or stationary infinite-horizon (open-loop) settings but not in Markov perfect (closed-loop) settings. Under the Markov perfect setting, a variety of interesting dynamics may occur, including that there may be a so-called commitment value to inventory."
1636,"One-Machine Sequencing to Minimize Total Tardiness: A Fourth Theorem for Emmons","Kanet, John J.","OPERATIONS RESEARCH","62","2","345-347","2014","MAR-APR","","","In 1969 H. Emmons provided three theorems (Emmons 1-3) for determining precedence relations between pairs of jobs for the single-machine tardiness problem. We show here a fourth straightforward theorem that uses the information when the jobs in the pair are both known to precede a third job in an optimum sequence. The new theorem augments the three Emmons theorems and is shown to be a generalization of a theorem by Elmaghraby."
1637,"On the Performance of Sparse Process Structures in Partial Postponement Production Systems","Chou, Mabel C. and Chua, Geoffrey A. and Zheng, Huan","OPERATIONS RESEARCH","62","2","348-365","2014","MAR-APR","","","Production postponement, the strategy to hold reserved production capacity that can be deployed based on actual demand signals, is often used to mitigate supply-demand mismatch risk. The effectiveness of this strategy depends crucially on the ease, or flexibility, in deploying the reserved capacity to meet product demands. Existing literature assumes that the reserved capacity is fully flexible, i.e., capable of being deployed to meet the demand of any item in a multiproduct system. Little is known if reserved capacity is held at many different locations, with each location having only a limited range of flexibility on production options. This paper examines how effective the production postponement strategy is in this environment. When the amount of reserved capacity is small (i.e., postponement level near 0%), no amount of flexibility can reap significant benefits. When the reserved capacity is high (i.e., postponement level near 100%), it is well known that a sparse structure such as a 2-chain can perform nearly as well as a fully flexible structure. Hence, process flexibility beyond 2-chain has little impact on the effectiveness of production postponement strategy in these two extreme environments. Interestingly, in a symmetric system, we prove that the performance of 2-chain, vis-a-vis the full flexibility structure, has a wider gap when postponement level (i.e., amount of reserved capacity) is moderate, and thus process flexibility beyond 2-chain matters and affects appreciably the performance of the production postponement strategy. Fortunately, adding a little more flexibility, say turning a 2-chain into a 3-chain, the system can perform almost as well as a full flexibility structure for all postponement levels. This is important as first stage production capacity can be allocated as if the reserve capacity is fully flexible. Our analysis hinges on an exact analytical expression for the performance of d-chain, obtained from solving a related class of random walk problems. To the best of our knowledge, this is the first paper with analytical results on the performance of d-chain for d > 2."
1638,"A Mean-Risk Model for the Traffic Assignment Problem with Stochastic Travel Times","Nikolova, E. and Stier-Moses, N. E.","OPERATIONS RESEARCH","62","2","366-382","2014","MAR-APR","","","Heavy and uncertain traffic conditions exacerbate the commuting experience of millions of people across the globe. When planning important trips, commuters typically add an extra buffer to the expected trip duration to ensure on-time arrival. Motivated by this, we propose a new traffic assignment model that takes into account the stochastic nature of travel times. Our model extends the traditional model of Wardrop competition when uncertainty is present in the network. The focus is on strategic risk-averse users who capture the trade-off between travel times and their variability in a mean-standard deviation objective, defined as the mean travel time plus a risk-aversion factor times the standard deviation of travel time along a path. We consider both infinitesimal users, leading to a nonatomic game, and atomic users, leading to a discrete finite game. We establish conditions that characterize an equilibrium traffic assignment and find when it exists. The main challenge is posed by the users' risk aversion, since the mean-standard deviation objective is nonconvex and nonseparable, meaning that a path cannot be split as a sum of edge costs. As a result, even an individual user's subproblem-a stochastic shortest path problem-is a nonconvex optimization problem for which no polynomial time algorithms are known. In turn, the mathematical structure of the traffic assignment model with stochastic travel times is fundamentally different from the deterministic counterpart. In particular, an equilibrium characterization requires exponentially many variables, one for each path in the network, since an edge flow has multiple possible path-flow decompositions that are not equivalent. Because of this, characterizing the equilibrium and the socially optimal assignment, which minimizes the total user cost, is more challenging than in the traditional deterministic setting. Nevertheless, we prove that both can be encoded by a representation with just polynomially many paths. Finally, under the assumption that the standard deviations of travel times are independent from edge loads, we show that the worst-case ratio between the social cost of an equilibrium and that of an optimal solution is not higher than the analogous ratio in the deterministic setting. In other words, uncertainty does not further degrade the system performance in addition to strategic user behavior alone."
1639,"Scheduled Service Network Design for Freight Rail Transportation","Zhu, Endong and Crainic, Teodor Gabriel and Gendreau, Michel","OPERATIONS RESEARCH","62","2","383-400","2014","MAR-APR","","","This paper addresses the scheduled service network design problem for freight rail transportation. The proposed model integrates service selection and scheduling, car classification and blocking, train makeup, and routing of time-dependent customer shipments based on a cyclic three-layer space-time network representation of the associated operations and decisions and their relations and time dimensions. This paper also proposes a matheuristic solution methodology integrating slope scaling, a dynamic block-generation mechanism, long-term-memory-based perturbation strategies, and ellipsoidal search, a new intensification mechanism to thoroughly explore very large neighborhoods of elite solutions restricted using information from the history of the search. Experimental results show that the proposed solution method is efficient and robust, yielding high-quality solutions for realistically sized problem instances."
1640,"Computational Methods for Risk-Averse Undiscounted Transient Markov Models","Cavus, Ozlem and Ruszczynski, Andrzej","OPERATIONS RESEARCH","62","2","401-417","2014","MAR-APR","","","The total cost problem for discrete-time controlled transient Markov models is considered. The objective functional is a Markov dynamic risk measure of the total cost. Two solution methods, value and policy iteration, are proposed, and their convergence is analyzed. In the policy iteration method, we propose two algorithms for policy evaluation: the nonsmooth Newton method and convex programming, and we prove their convergence. The results are illustrated on a credit limit control problem."
1641,"Fabrication-Adaptive Optimization with an Application to Photonic Crystal Design","Men, Han and Freund, Robert M. and Nguyen, Ngoc C. and Saa-Seoane, Joel and Peraire, Jaime","OPERATIONS RESEARCH","62","2","418-434","2014","MAR-APR","","","It is often the case that the computed optimal solution of an optimization problem cannot be implemented directly, irrespective of data accuracy, because of either (i) technological limitations (such as physical tolerances of machines or processes), (ii) the deliberate simplification of a model to keep it tractable (by ignoring certain types of constraints that pose computational difficulties), and/or (iii) human factors (getting people to do the optimal solution). Motivated by this observation, we present a modeling paradigm called fabrication-adaptive optimization for treating issues of implementation/fabrication. We develop computationally focused theory and algorithms, and we present computational results for incorporating considerations of implementation/fabrication into constrained optimization problems that arise in photonic crystal design. The fabrication-adaptive optimization framework stems from the robust regularization of a function. When the feasible region is not a normed space (as typically encountered in application settings), the fabrication-adaptive optimization framework typically yields a nonconvex optimization problem. (In the special case where the feasible region is a finite-dimensional normed space, we show that fabrication-adaptive optimization can be recast as an instance of modern robust optimization.) We study a variety of problems with special structures on functions, feasible regions, and norms for which computation is tractable and develop an algorithmic scheme for solving these problems in spite of the challenges of nonconvexity. We apply our methodology to compute fabrication-adaptive designs of two-dimensional photonic crystals with a variety of prescribed features."
1642,"Integral Simplex Using Decomposition for the Set Partitioning Problem","Zaghrouti, Abdelouahab and Soumis, Francois and El Hallaoui, Issmail","OPERATIONS RESEARCH","62","2","435-449","2014","MAR-APR","","","Since the 1970s, several authors have studied the structure of the set partitioning polytope and proposed adaptations of the simplex algorithm that find an optimal solution via a sequence of basic integer solutions. Balas and Padberg in 1972 proved the existence of such a sequence with nonincreasing costs, but degeneracy makes it difficult to find the terms of the sequence. This paper uses ideas from the improved primal simplex to deal efficiently with degeneracy and find subsequent terms in the sequence. When there is no entering variable that leads to a better integer solution, the algorithm referred to as the integral simplex using decomposition algorithm uses a subproblem to find a group of variables to enter into the basis in order to obtain such a solution. We improve the Balas and Padberg results by introducing a constructive method that finds this sequence by only using normal pivots on positive coefficients. We present results for large-scale problems (with up to 500,000 variables) for which optimal integer solutions are often obtained without any branching."
1643,"Multiproduct Price Optimization and Competition Under the Nested Logit Model with Product-Differentiated Price Sensitivities","Gallego, Guillermo and Wang, Ruxian","OPERATIONS RESEARCH","62","2","450-461","2014","MAR-APR","","","We study firms that sell multiple substitutable products and customers whose purchase behavior follows a nested logit model, of which the multinomial logit model is a special case. Customers make purchasing decisions sequentially under the nested logit model: they first select a nest of products and subsequently purchase one within the selected nest. We consider the multiproduct pricing problem under the general nested logit model with product-differentiated price sensitivities and arbitrary nest coefficients. We show that the adjusted markup, defined as price minus cost minus the reciprocal of price sensitivity, is constant for all the products within a nest at optimality. This reduces the problem's dimension to a single variable per nest. We also show that the adjusted nest-level markup is nest invariant for all the nests, which further reduces the problem to maximizing a single-variable unimodal function under mild conditions. We also use this result to simplify the oligopolistic multiproduct price competition and characterize the Nash equilibrium. We also consider more general attraction functions that include the linear utility and the multiplicative competitive interaction models as special cases, and we show that similar techniques can be used to significantly simplify the corresponding pricing problems."
1644,"When to Use Speedup: An Examination of Service Systems with Returns","Chan, Carri W. and Yom-Tov, Galit and Escobar, Gabriel","OPERATIONS RESEARCH","62","2","462-482","2014","MAR-APR","","","In a number of service systems, there can be substantial latitude to vary service rates. However, although speeding up service rate during periods of congestion may address a present congestion issue, it may actually exacerbate the problem by increasing the need for rework. We introduce a state-dependent queuing network where service times and return probabilities depend on the overloaded and underloaded state of the system. We use a fluid model to examine how different definitions of overload affect the long-term behavior of the system and provide insight into the impact of using speedup. We identify scenarios where speedup can be helpful to temporarily alleviate congestion and increase access to service. For such scenarios, we provide approximations for the likelihood of speedup to service. We also identify scenarios where speedup should never be used; moreover, in such a situation, an interesting bi-stability arises, such that the system shifts randomly between two equilibria states. Hence, our analysis sheds light on the potential benefits and pitfalls of using speedup when the subsequent returns may be unavoidable."
1645,"Budget-Optimal Task Allocation for Reliable Crowdsourcing Systems","Karger, David R. and Oh, Sewoong and Shah, Devavrat","OPERATIONS RESEARCH","62","1","1-24","2014","JAN-FEB","","","Crowdsourcing systems, in which numerous tasks are electronically distributed to numerous information pieceworkers, have emerged as an effective paradigm for human-powered solving of large-scale problems in domains such as image classification, data entry, optical character recognition, recommendation, and proofreading. Because these low-paid workers can be unreliable, nearly all such systems must devise schemes to increase confidence in their answers, typically by assigning each task multiple times and combining the answers in an appropriate manner, e.g., majority voting. In this paper, we consider a general model of such crowdsourcing tasks and pose the problem of minimizing the total price (i.e., number of task assignments) that must be paid to achieve a target overall reliability. We give a new algorithm for deciding which tasks to assign to which workers and for inferring correct answers from the workers' answers. We show that our algorithm, inspired by belief propagation and low-rank matrix approximation, significantly outperforms majority voting and, in fact, is optimal through comparison to an oracle that knows the reliability of every worker. Further, we compare our approach with a more general class of algorithms that can dynamically assign tasks. By adaptively deciding which questions to ask to the next set of arriving workers, one might hope to reduce uncertainty more efficiently. We show that, perhaps surprisingly, the minimum price necessary to achieve a target reliability scales in the same manner under both adaptive and nonadaptive scenarios. Hence, our nonadaptive approach is order optimal under both scenarios. This strongly relies on the fact that workers are fleeting and cannot be exploited. Therefore, architecturally, our results suggest that building a reliable worker-reputation system is essential to fully harnessing the potential of adaptive designs."
1646,"Coordinating Inventory Control and Pricing Strategies Under Batch Ordering","Yang, Yi and Chen, Youhua (Frank) and Zhou, Yun","OPERATIONS RESEARCH","62","1","25-37","2014","JAN-FEB","","","In this paper we investigate joint pricing and inventory control problems in a finite-horizon, single-product, periodic-review setting with certain/uncertain supply capacities. The demands in different periods are random variables whose distributions depend on the posted price exhibiting the additive form. The order quantity in each period is required to be of integral multiples of a given specific batch size (denoted by Q). Inventory replenishment incurs a linear ordering cost. Referred to as the cost-rate function, the sum of holding and backorder costs can either be convex or quasi-convex. The objective is to determine a joint ordering and pricing decision that can maximize the total expected profit over the planning horizon. We first consider the case in which the cost-rate function is convex and show that the modified (r, Q) list-price policy is optimal for the system with certain and limited capacities, a special case of which is the (r, Q) list-price policy when capacities become unlimited. As supply capacities become random, the optimal policy follows a new structure wherein the optimal order-up-to level and posted price must be coordinated to make the optimal safety stock level follow the (r, Q) policy. We further consider the case of a quasi-convex cost-rate function, which may arise when a service level constraint is used as a surrogate for the shortage cost. We demonstrate that the (r, Q) list-price policy is optimal for the system without supply capacity constraints. In addition, extensions to several other models are discussed. The enabling technique is based on the notion of Q-jump convexity and its variants."
1647,"Equilibrium in Queues Under Unknown Service Times and Service Value","Debo, Laurens and Veeraraghavan, Senthil","OPERATIONS RESEARCH","62","1","38-57","2014","JAN-FEB","","","In the operations research literature, the queue joining probability is monotonic decreasing in the queue length; the longer the queue, the fewer consumers join. Recent academic and empirical evidence indicates that queue-joining probabilities may not always be decreasing in the queue length. We provide a simple explanation for these nonmonotonic queue-joining strategies by relaxing the informational assumptions in Naor's model. Instead of imposing that the expected service time and service value are common knowledge, we assume that they are unknown to consumers, but positively correlated. Under such informational assumptions, the posterior expected waiting cost and service value increase in the observed queue length. As a consequence, we show that queue-joining equilibria may emerge for which the joining probability increases locally in the queue length. We refer to these as sputtering equilibria. We discuss when and why such sputtering equilibria exist for discrete as well as continuously distributed priors on the expected service time (with positively correlated service value)."
1648,"Exact Algorithms for the Clustered Vehicle Routing Problem","Battarra, Maria and Erdogan, Guenes and Vigo, Daniele","OPERATIONS RESEARCH","62","1","58-71","2014","JAN-FEB","","","This study presents new exact algorithms for the clustered vehicle routing problem (CluVRP). The CluVRP is a generalization of the capacitated vehicle routing problem (CVRP), in which the customers are grouped into clusters. As in the CVRP, all the customers must be visited exactly once, but a vehicle visiting one customer in a cluster must visit all the remaining customers therein before leaving it. Based on an exponential time preprocessing scheme, an integer programming formulation for the CluVRP is presented. The formulation is enhanced by a polynomial time graph reduction scheme. Two exact algorithms for the CluVRP, a branch and cut as well as a branch and cut and price, are presented. The computational performances of the algorithms are tested on benchmark instances adapted from the vehicle routing problem literature as well as real-world instances from a solid waste collection application."
1649,"Technical Note-Capacity Allocation Under Retail Competition: Uniform and Competitive Allocations","Cho, Soo-Haeng and Tang, Christopher S.","OPERATIONS RESEARCH","62","1","72-80","2014","JAN-FEB","","","When retailers' orders exceed the supplier's available capacity, the supplier allocates his capacity according to some allocation rule. When retailers are local monopolists, uniform allocation eliminates the gaming effect so that each retailer orders her ideal allocation. However, when two retailers engage in Cournot competition under complete information, a recent study has shown that uniform allocation fails to eliminate the gaming effect so that some retailer may inflate her order strategically. By examining a more general situation in which two or more retailers engage in Cournot competition under complete information, we establish exact conditions under which uniform allocation fails to eliminate the gaming effect. These exact conditions enable us to construct a new rule called competitive allocation that can eliminate the gaming effect. Without inflated orders from the retailers, the supplier's profit could be lower under competitive allocation than under uniform allocation when certain restrictive conditions hold. In contrast, competitive allocation generates higher average profits for the retailers and for the supply chain; hence, it reduces the inefficiency of the decentralized supply chain."
1650,"Fixed-Dimensional Stochastic Dynamic Programs: An Approximation Scheme and an Inventory Application","Chen, Wei and Dawande, Milind and Janakiraman, Ganesh","OPERATIONS RESEARCH","62","1","81-103","2014","JAN-FEB","","","We study fixed-dimensional stochastic dynamic programs in a discrete setting over a finite horizon. Under the primary assumption that the cost-to-go functions are discrete L-textbackslash{}tau-convex, we propose a pseudo-polynomial time approximation scheme that solves this problem to within an arbitrary prespecified additive error of epsilon > 0. The proposed approximation algorithm is a generalization of the explicit-enumeration algorithm and offers us full control in the trade-off between accuracy and running time. The main technique we develop for obtaining our scheme is approximation of a fixed-dimensional L-textbackslash{}tau-convex function on a bounded rectangular set, using only a selected number of points in its domain. Furthermore, we prove that the approximation function preserves L-textbackslash{}tau-convexity. Finally, to apply the approximate functions in a dynamic program, we bound the error propagation of the approximation. Our approximation scheme is illustrated on a well-known problem in inventory theory, the single-product problem with lost sales and lead times. We demonstrate the practical value of our scheme by implementing our approximation scheme and the explicit-enumeration algorithm on instances of this inventory problem."
1651,"Effects of Competition in a Secretary Problem","Cownden, Daniel and Steinsaltz, David","OPERATIONS RESEARCH","62","1","104-113","2014","JAN-FEB","","","In a novel multiplayer extension of the famous secretary problem, multiple players seek to employ secretaries from a common labour pool. Secretaries do not accept being put on hold, always accept job offers immediately, and leave the labour pool once rejected by a single player. All players have an identical preference for secretaries, and all players seek to optimize the probability of obtaining the best of all n secretaries. We find that in the Nash equilibrium, as the number, N, of players searching the labour pool grows, the optimal strategy converges to a simple function of N. For the two-player case we also compute how much players can gain through cooperation and how the optimal strategy changes under a payoff structure that promotes spite."
1652,"Exploiting Erraticism in Search","Fischetti, Matteo and Monaci, Michele","OPERATIONS RESEARCH","62","1","114-122","2014","JAN-FEB","","","High sensitivity to initial conditions is generally viewed as a drawback of tree search methods because it leads to erratic behavior to be mitigated somehow. In this paper we investigate the opposite viewpoint and consider this behavior as an opportunity to exploit. Our working hypothesis is that erraticism is in fact just a consequence of the exponential nature of tree search that acts as a chaotic amplifier, so it is largely unavoidable. We propose a bet-and-run approach to actually turn erraticism to one's advantage. The idea is to make a number of short sample runs with randomized initial conditions, to bet on the most promising run selected according to certain simple criteria, and to bring it to completion. Computational results on a large testbed of mixed integer linear programs from the literature are presented, showing the potential of this approach even when embedded in a proof-of-concept implementation."
1653,"Using Strategic Idleness to Improve Customer Service Experience in Service Networks","Baron, Opher and Berman, Oded and Krass, Dmitry and Wang, Jianfu","OPERATIONS RESEARCH","62","1","123-140","2014","JAN-FEB","","","The most common measure of waiting time is the overall expected waiting time for service. However, in service networks the perception of waiting may also depend on how it is distributed among different stations. Therefore, reducing the probability of a long wait at any station may be important in improving customers' perception of service quality. In a single-station queue it is known that the policy that minimizes the waiting time and the probability of long waits is nonidling. However, this is not necessarily the case for queueing networks with several stations. We present a family of threshold-based policies (TBPs) that strategically idle some stations. We demonstrate the advantage of strategically idling by applying TBP in a network with two single-server queues in tandem. We provide closed form results for the special case where the first station has infinite capacity and develop efficient algorithms when this is not the case. We compare TBPs with the nonidling and Kanban policies, and we discuss when a TBP is advantageous. Using simulation, we demonstrate that the analytical insights for the two-station case hold for a three-station serial queue as well."
1654,"Infinite Horizon Strategies for Replenishment Systems with a General Pool of Suppliers","Federgruen, Awi and Yang, Nan","OPERATIONS RESEARCH","62","1","141-159","2014","JAN-FEB","","","We consider a general infinite horizon inventory control model that combines demand and supply risks and the firm's ability to mitigate the supply risks by diversifying its procurement orders among a set of N potential suppliers. Supply risks arise because only a random percentage of any given replenishment order is delivered as useable units. The suppliers are characterized by the price they charge and the distribution of their yield factor. Assuming unsatisfied demand is backlogged, the firm incurs, as in standard inventory models, three types of costs: (i) procurement costs, (ii) inventory carrying costs for units carried over from one period to the next, and (iii) backlogging costs. We establish the existence of an optimal stationary policy, under both the long-run discounted and average cost criteria, and characterize its structure. Assuming each period's inventory level distribution can be approximated as a normal, we develop an efficient solution method identifying additional structural properties. Finally, we identify a simple class of heuristic policies that come close to being optimal."
1655,"A Probabilistic Model for Minmax Regret in Combinatorial Optimization","Natarajan, Karthik and Shi, Dongjian and Toh, Kim-Chuan","OPERATIONS RESEARCH","62","1","160-181","2014","JAN-FEB","","","In this paper, we propose a new probabilistic model for minimizing the anticipated regret in combinatorial optimization problems with distributional uncertainty in the objective coefficients. The interval uncertainty representation of data is supplemented with information on the marginal distributions. As a decision criterion, we minimize the worst-case conditional value at risk of regret. The proposed model includes the interval data minmax regret model as a special case. For the class of combinatorial optimization problems with a compact convex hull representation, a polynomial sized mixed-integer linear program is formulated when (a) the range and mean are known, and (b) the range, mean, and mean absolute deviation are known; and a mixed-integer second order cone program is formulated when (c) the range, mean, and standard deviation are known. For the subset selection problem of choosing K elements of maximum total weight out of a set of N elements, the probabilistic regret model is shown to be solvable in polynomial time in the instances (a) and (b) above. This extends the current known polynomial complexity result for minmax regret subset selection with range information only."
1656,"Decision Analysis with Geographically Varying Outcomes: Preference Models and Illustrative Applications","Simon, Jay and Kirkwood, Craig W. and Keller, L. Robin","OPERATIONS RESEARCH","62","1","182-194","2014","JAN-FEB","","","This paper presents decision analysis methodology for decisions based on data from geographic information systems. The consequences of a decision alternative are modeled as distributions of outcomes across a geographic region. We discuss conditions that may conform with the decision maker's preferences over a specified set of alternatives; then we present specific forms for value or utility functions that are implied by these conditions. Decisions in which there is certainty about the consequences resulting from each alternative are considered first; then probabilistic uncertainty about the consequences is included as an extension. The methodology is applied to two hypothetical urban planning decisions involving water use and temperature reduction in regional urban development, and fire coverage across a city. These examples illustrate the applicability of the approach and the insights that can be gained from using it."
1657,"Analytical Results and Efficient Algorithm for Optimal Portfolio Deleveraging with Market Impact","Chen, Jingnan and Feng, Liming and Peng, Jiming and Ye, Yinyu","OPERATIONS RESEARCH","62","1","195-206","2014","JAN-FEB","","","In this paper, we consider an optimal portfolio deleveraging problem, where the objective is to meet specified debt/equity requirements at the minimal execution cost. Permanent and temporary price impact is taken into account. With no restrictions on the relative magnitudes of permanent and temporary price impact, the optimal deleveraging problem reduces to a nonconvex quadratic program with quadratic and box constraints. Analytical results on the optimal deleveraging strategy are obtained. They provide guidance on how we liquidate a portfolio according to endogenous and exogenous factors. A Lagrangian method is proposed to solve the nonconvex quadratic program numerically. By studying the breakpoints of the Lagrangian problem, we obtain conditions under which the Lagrangian method returns an optimal solution of the deleveraging problem. When the Lagrangian algorithm returns a suboptimal approximation, we present upper bounds on the loss in equity caused by using such an approximation."
1658,"Average Utility Maximization: A Preference Foundation","Kothiyal, Amit and Spinu, Vitalie and Wakker, Peter P.","OPERATIONS RESEARCH","62","1","207-218","2014","JAN-FEB","","","This paper provides necessary and sufficient preference conditions for average utility maximization over sequences of variable length. We obtain full generality by using a new algebraic technique that exploits the richness structure naturally provided by the variable length of the sequences. Thus we generalize many preceding results in the literature. For example, continuity in outcomes, a condition needed in other approaches, now is an option rather than a requirement. Applications to expected utility, decisions under ambiguity, welfare evaluations for variable population size, discounted utility, and quasilinear means in functional analysis are presented."
1659,"Determining the Optimal Configuration of Hospital Inpatient Rooms in the Presence of Isolation Patients","Pinker, Edieal and Tezcan, Tolga","OPERATIONS RESEARCH","61","6","1259-1276","2013","NOV-DEC","","","We study the optimal configuration of hospital inpatient rooms with private and semiprivate rooms when some of the patients have infectious diseases and need to be isolated. We assume that the demand is random and seasonal. We propose a computationally efficient solution procedure that is based on a stochastic program that uses asymptotic approximations for the system performance under different admission policies and show its accuracy for large systems. Using our model, we study the appropriateness of the recent trends in hospital design calling for 100% private rooms. We show that even with isolation patients such an extreme approach could result in a significant degradation in the access of patients to hospital beds."
1660,"Improving Health Outcomes Through Better Capacity Allocation in a Community-Based Chronic Care Model","Deo, Sarang and Iravani, Seyed and Jiang, Tingting and Smilowitz, Karen and Samuelson, Stephen","OPERATIONS RESEARCH","61","6","1277-1294","2013","NOV-DEC","","","This paper studies a model of community-based healthcare delivery for a chronic disease. In this setting, patients periodically visit the healthcare delivery system, which influences their disease progression and consequently their health outcomes. We investigate how the provider can maximize community-level health outcome's through better operational decisions pertaining to capacity allocation across different patients. To do so, we develop an integrated capacity allocation model that incorporates clinical (disease progression) and operational (capacity constraint) aspects. Specifically, we model the provider's problem as a finite horizon stochastic dynamic program, where the provider decides which patients to schedule at the beginning of each period. Therapy is provided to scheduled patients, which may improve their health states. Patients that are not seen follow their natural disease progression. We derive a quantitative measure for comparison of patients' health states and use it to design an easy-to-implement myopic heuristic that is provably optimal in special cases of the problem. We employ the myopic heuristic in a more general setting and test its performance using operational and clinical data obtained from Mobile C.A.R.E. Foundation, a community-based provider of pediatric asthma care in Chicago. Our extensive computational experiments suggest that the myopic heuristic can improve the health gains at the community level by up to 15% over the current policy. The benefit is driven by the ability of our myopic heuristic to alter the duration between visits for patients with different health states depending on the tightness of the capacity and the health states of the entire patient population."
1661,"Optimal Contracts for Outsourcing of Repair and Restoration Services","Jain, Nitish and Hasija, Sameer and Popescu, Dana G.","OPERATIONS RESEARCH","61","6","1295-1311","2013","NOV-DEC","","","Outsourcing of equipment repair and restoration is commonly practiced by firms in many industries. The operational performance of equipment is determined by joint decisions of the firm (client) and the service provider (vendor). Although some decisions are verifiable and thus directly contractible, many decisions are not. The result is a double-sided moral hazard environment in which each party has incentives to free ride on the other's effort. A performance-based contract allows the client to align the incentives of the vendor, but it also exposes the vendor to stochastic earnings and thereby creates disincentives to make first-best decisions. To capture these issues, we develop a novel principal-agent model by integrating elements of the machine repairman model and a stochastic financial distress model within the double-sided moral hazard framework. We apply our model to solve the client's problem of designing the optimal performance-based contract. We find that the client can attain the first-best profit by restricting the search space to only two classes of performance-based contract structures: linear and tiered. We show that the linear contract structure has limited ability in attaining the first-best outcome, contingent on the vendor's exogenous characteristics. In contrast, the tiered contract structure enables the client to attain the first-best outcome regardless of vendor characteristics. Our results provide normative insights on the role of contract structures in eliminating any loss due to double-sided moral hazard or to the vendor's financial concerns. These results also provide theoretical support for the extensive use of tiered contracts observed in practice."
1662,"Analysis of Deterministic LP-Based Booking Limit and Bid Price Controls for Revenue Management","Jasin, Stefanus and Kumar, Sunil","OPERATIONS RESEARCH","61","6","1312-1320","2013","NOV-DEC","","","We study the performance of two popular and widely used heuristics for revenue management known as the booking limit and bid price controls. In contrast to a recent result in the literature where frequent re-solvings of a certain heuristic are shown to significantly reduce revenue loss, we show that the asymptotic revenue loss of either booking limit or bid price control cannot be reduced regardless of the choice of re-solving times and the frequency of re-solving. Moreover, we also show that further variations within the policy classes, such as nested instead, of partition booking limit, or certainty equivalent instead of additive bid price, are simply indistinguishable in terms of their order of revenue loss under frequent re-solvings. This negative result highlights the limitation of re-solving deterministic linear programs when the solution is interpreted as either a booking limit or a bid price. Finally, we briefly discuss how to modify the traditional booking limit control to make it more responsive to frequent re-solvings and test its performance using numerical experiments."
1663,"Saving Seats for Strategic Customers","Cil, Eren B. and Lariviere, Martin A.","OPERATIONS RESEARCH","61","6","1321-1332","2013","NOV-DEC","","","We consider a service provider in a market with two segments. Members of the first request a reservation ahead of service and will not patronize the firm Without one. Members of the second walk in and demand service immediately. These customers have a fixed cost of reaching the firm and may behave strategically. In equilibrium, they randomize between walking in and staying home. The service provider must decide how much of a limited capacity to make available to advance customers. When the advance demand segment offers a higher per customer margin, the firm may opt to decline some reservation requests in order to bolster walk-in demand. When walk-in customers are more valuable, classical revenue management models would dictate that at least some capacity be set aside for high-value later arrivals. Here it is possible that the optimal policy saves no capacity for walk-ins. Thus, it may be better to ignore rather than pamper walk-in customers. This outcome is robust to changes in the model."
1664,"A Simulation-Based Optimization Framework for Urban Transportation Problems","Osorio, Carolina and Bierlaire, Michel","OPERATIONS RESEARCH","61","6","1333-1345","2013","NOV-DEC","","","This paper proposes a simulation-based optimization (SO) method that enables the efficient use of complex stochastic urban traffic simulators to address various transportation problems. It presents a metamodel that integrates information from a simulator with an analytical queueing network model. The proposed metamodel combines a general-purpose component (a quadratic polynomial), which provides a detailed local approximation, with a physical component (the analytical queueing network model), which provides tractable analytical and global information. This combination leads to an SO framework that is computationally efficient and suitable for complex problems with very tight computational budgets. We integrate this metamodel within a derivative-free trust region algorithm. We evaluate the performance of this method considering a traffic signal control problem for the Swiss city of Lausanne, different demand scenarios, and tight computational budgets. The method leads to well-performing signal plans. It leads to reduced, as well as more reliable, average travel times."
1665,"Models for Effective Deployment and Redistribution of Bicycles Within Public Bicycle-Sharing Systems","Shu, Jia and Chou, Mabel C. and Liu, Qizhang and Teo, Chung-Piaw and Wang, I-Lin","OPERATIONS RESEARCH","61","6","1346-1359","2013","NOV-DEC","","","We develop practical operations research models to support decision making in the design and management of public bicycle-sharing systems. We develop a network flow model with proportionality constraints to estimate the flow of bicycles within the network and the number of trips supported, given an initial allocation of bicycles at each station. We also examine the effectiveness of periodic redistribution of bicycles in the network to support greater flow, and the impact on the number of docks needed. We conduct our numerical analysis using transit data from train operators in Singapore. Given that a substantial proportion of passengers in the train system commute a short distance more than 16% of passengers alight within two stops from the origin-this forms a latent segment of demand for a bicycle-sharing program. We argue that for a bicycle-sharing system to be most effective for this customer segment, the system must deploy the right number of bicycles at the right places, because this affects the utilization rate of the bicycles and how bicycles circulate within the system. We also identify the appropriate operational environments in which periodic redistribution of bicycles will be most effective for improving system performance."
1666,"Euclidean Hub-and-Spoke Networks","Carlsson, John Gunnar and Jia, Fan","OPERATIONS RESEARCH","61","6","1360-1382","2013","NOV-DEC","","","The hub-and-spoke distribution paradigm has been a fundamental principle in geographic network design for more than 40 years. One of the primary advantages that such networks possess is their ability to exploit economies of scale in transportation by aggregating network flows through common sources. In this paper, we consider the problem of designing an optimal hub-and-spoke network in continuous Euclidean space: the spokes of the network are distributed uniformly over a service region, and our objective is to determine the optimal number of hub nodes and their locations. We consider seven different backbone network topologies for connecting the hub nodes, namely, the Steiner and minimum spanning trees, a travelling salesman tour, a star network, a capacitated vehicle routing tour, a complete bipartite graph, and a complete graph. We also perform an additional analysis on a multilevel network in which network flows move through multiple levels of transshipment before reaching the service region. We describe the asymptotically optimal (or near-optimal) configurations that minimize the total network costs as the demand in the region becomes large and give an approximation algorithm that solves our problem on a convex planar region for any values of the relevant input parameters."
1667,"The Wisdom of Competitive Crowds","Lichtendahl, Jr., Kenneth C. and Grushka-Cockayne, Yael and Pfeifer, Phillip E.","OPERATIONS RESEARCH","61","6","1383-1398","2013","NOV-DEC","","","When several individuals are asked to forecast an uncertain quantity, they often face implicit or explicit incentives to be the most accurate. Despite the desire to elicit honest forecasts, such competition induces forecasters to report strategically and nontruthfully. The question we address is whether the competitive crowd's forecast (the average of strategic forecasts) is more accurate than the truthful crowd's forecast (the average of truthful forecasts from the same forecasters). We analyze a forecasting competition in which a prize is awarded to the forecaster whose point forecast is closest to the actual outcome: Before reporting a forecast, we assume each forecaster receives two signals: one common and one private. These signals represent the forecasters' past shared and personal experiences relevant for forecasting the uncertain quantity of interest. In a set of equilibrium results, we characterize the nature of the strategic forecasts in this game. As the correlation among the forecasters' private signals increases, the forecasters switch from using a pure to a mixed strategy. In both cases, forecasters exaggerate their private information and thereby make the competitive crowd's forecast more accurate than the truthful crowd's forecast."
1668,"On the Axiomatization of the Satiation and Habit Formation Utility Models","He, Ying and Dyer, James S. and Butler, John C.","OPERATIONS RESEARCH","61","6","1399-1410","2013","NOV-DEC","","","We propose a preference condition called shifted difference independence to axiomatize a general habit formation and satiation model (GHS). This model allows for a general habit formation and satiation function that contain many functional forms in the literature as special cases. Since the GHS model can be reduced to either a general satiation model (GSa) or a general habit formation model (GHa), our theory also provides approaches to axiomatize both the GSa model and the GHa model. Furthermore, by adding extra preference conditions into our axiomatization framework, we obtain a GHS model with a linear habit formation function and a recursively defined linear satiation function."
1669,"Multivalued Decision Diagrams for Sequencing Problems","Cire, Andre A. and van Hoeve, Willem-Jan","OPERATIONS RESEARCH","61","6","1411-1428","2013","NOV-DEC","","","Sequencing problems are among the most prominent problems studied in operations research, with primary application in, e.g., scheduling and routing. We propose a novel approach to solving generic sequencing problems using multivalued decision diagrams (MDDs). Because an MDD representation may grow exponentially large, we apply MDDs of limited size as a discrete relaxation to the problem. We show that MDDs can be used to represent a wide range of sequencing problems with various side constraints and objective functions, and we demonstrate how MDDs can be added to existing constraint-based scheduling systems. Our computational results indicate that the additional inference obtained by our MDDs can speed up a state-of-the art solver by several orders of magnitude, for a range of different problem classes."
1670,"Technical Note-On Traveling Salesman Games with Asymmetric Costs","Toriello, Alejandro and Uhan, Nelson A.","OPERATIONS RESEARCH","61","6","1429-1434","2013","NOV-DEC","","","We consider cooperative traveling salesman games with nonnegative asymmetric costs satisfying the triangle inequality. We construct a stable cost allocation with budget balance guarantee equal to the Held-Karp integrality gap for the asymmetric traveling salesman problem, using the parsimonious property and a previously unknown connection to linear production games. We also show that our techniques extend to larger classes of network design games. We then provide a simple example showing that our cost allocation does not necessarily achieve the best possible budget balance guarantee, even among cost allocations stable for the game defined by the Held-Karp relaxation, and discuss its implications on future work on traveling salesman games."
1671,"Worst-Case-Expectation Approach to Optimization Under Uncertainty","Shapiro, Alexander and Tekaya, Wajdi and Soares, Murilo Pereira and da Costa, Joari Paulo","OPERATIONS RESEARCH","61","6","1435-1449","2013","NOV-DEC","","","In this paper we discuss multistage programming with the data process subject to uncertainty. We consider a situation where the data process can be naturally separated into two components: one can be modeled as a random process, with a specified probability distribution, and the other one can be treated from a robust (worst-case) point of view. We formulate this in a time consistent way and derive the corresponding dynamic programming equations. To solve the obtained multistage problem, we develop a variant of the stochastic dual dynamic programming method. We give a general description of the algorithm and present computational studies related to planning of the Brazilian interconnected power system."
1672,"Optimal Rate Scheduling via Utility-Maximization for J-User MIMO Markov Fading Wireless Channels with Cooperation","Dai, Wanyang","OPERATIONS RESEARCH","61","6","1450-1462","2013","NOV-DEC","","","We design a dynamic rate scheduling policy of Markov type by using the solution (a social optimal Nash equilibrium point) to a utility-maximization problem over a randomly evolving capacity set for a stochastic system of generalized processor-sharing queues in a random environment whose job arrivals to each queue follow a doubly stochastic renewal process (DSRP). Both the random environment and the random arrival rate of each DSRP are driven by a finite state continuous time Markov chain. The scheduling policy optimizes in a greedy fashion with respect to each queue and environmental state. Since the closed-form solution for the performance of such a queuing system under the policy is difficult to obtain, we establish a reflecting diffusion with regime-switching model for its measures of performance. Furthermore, we justify its asymptotic optimality by deriving the stochastic fluid and diffusion limits for the corresponding system under heavy traffic. In addition, we identify a cost function related to the utility function, which is minimized by minimizing the workload process in the diffusion limit. More importantly, our queuing model includes typical systems in the future wireless networks, such as the J-user multi-input multioutput multiple access channel and the broadcast channel under Markov fading with cooperation and admission control as special cases."
1673,"OR Forum - The Cost of Latency in High-Frequency Trading","Moallemi, Ciamac C. and Saglam, Mehmet","OPERATIONS RESEARCH","61","5","1070-1086","2013","SEP-OCT","","","Modern electronic markets have been characterized by a relentless drive toward faster decision making. Significant technological investments have led to dramatic improvements in latency, the delay between a trading decision and the resulting trade execution. We describe a theoretical model for the quantitative valuation of latency. Our model measures the trading frictions created by the presence of latency, by considering the optimal execution problem of a representative investor. Via a dynamic programming analysis, our model provides a closed-form expression for the cost of latency in terms of well-known parameters of the underlying asset. We implement our model by estimating the latency cost incurred by trading on a human time scale. Examining NYSE common stocks from 1995 to 2005 shows that median latency cost across our sample roughly tripled during this time period. Furthermore, using the same data set, we compute a measure of implied latency and conclude that the median implied latency decreased by approximately two orders of magnitude. Empirically calibrated, our model suggests that the reduction in cost achieved by going from trading on a human time scale to a low latency time scale is comparable with other execution costs faced by the most cost efficient institutional investors, and it is consistent with the rents that are extracted by ultra-low latency agents, such as providers of automated execution services or high frequency traders."
1674,"The Bipartite Rationing Problem","Moulin, Herve and Sethuraman, Jay","OPERATIONS RESEARCH","61","5","1087-1100","2013","SEP-OCT","","","In the bipartite rationing problem, a set of agents share a single resource available in different types, each agent has a claim over only a subset of the resource types, and these claims overlap in arbitrary fashion The goal is to divide fairly the various types of resources between the claimants when resources are in short supply. With a single type of resource, this is the standard rationing problem [O'Neill B (1982) A problem of rights arbitration from the Talmud. Math. Soc. Sci. 2(4):345-371], of which the three benchmark solutions are the proportional, uniform gains, and uniform losses methods. We extend these methods to the bipartite context, imposing the familiar consistency requirement: the division is unchanged if we remove an agent (respectively, a resource), and take away at the same time his share of the various resources (respectively, reduce the claims of the relevant agents). The uniform gains and uniform losses methods have infinitely many consistent extensions, but the proportional method has only one.. In contrast, we find that most parametric rationing methods [Young HP (1987a) On dividing an amount according to individual claims or liabilities. Math. Oper. Res. 12(3):397-414], [Thomson W (2003) Axiomatic and game-theoretic analysis of bankruptcy and taxation problems. Math. Soc. Sci. 45(3):249-297] cannot be consistently extended."
1675,"The Modern Science of Multicriteria Decision Making and Its Practical Applications: The AHP/ANP Approach","Saaty, Thomas L.","OPERATIONS RESEARCH","61","5","1101-1118","2013","SEP-OCT","","","This paper presents a summary of the discrete mathematical part of my work, the Analytic Hierarchy Process (AHP) and its generalization to dependence and feedback, the Analytic Network Process (ANP), for measuring tangible and intangible factors, particularly as applied to decision making. The factors of the decision are arranged in hierarchical or network structures and judgments are then made by the decision maker, or by an expert, about the dominant element for each pair with respect to a common property. From simple judgments on two elements at a time with respect to a common property, priority vectors are obtained that are combined throughout the structure to give the best outcome for a decision. The judgments may be inconsistent, and there is a mathematical way to measure inconsistency so that the outlying judgments may be revised by the decision maker in an acceptable way or a decision may be delayed until more consistent information is obtained. In practical applications using either hierarchical or network structures, decisions are often analyzed in separate parts for their benefits, opportunities, costs, and risks, and the results are then combined in an appropriate way into an overall synthesis of those priorities. The mathematics hai been generalized in the literature to the Neural Network Process (NNP), the continuous case for modeling how the brain synthesizes signals. There has been a diversity of applications over the past 30 to 40 years, and some of these are reported here. A brief mention is made of other methods of decision making and how AHP/ANP may compare with them."
1676,"Product-Generation Transition Decision Making for Bayer's Hemophilia Drugs: Global Capacity Expansion Under Uncertainty with Supply-Demand Imbalances","Stonebraker, Jeffrey S.","OPERATIONS RESEARCH","61","5","1119-1133","2013","SEP-OCT","","","We present an application of decision analysis to global production capacity expansion under uncertainty for Bayer Group's proposed new biotechnology drug to treat hemophilia A. This decision analysis developed an improved approach to Bayer's decision for product-generation transition and global production capacity expansion that more realistically addresses potential regional supply shortages and overages due to demand and supply uncertainties that can result in supply-demand imbalances. With the added confidence provided by this more realistic approach, Bayer's executive leadership team acted on the recommendation from the decision analysis in contrast to an earlier analysis that had not resulted in management action. The paper makes two major contributions: First, it describes the details of what is involved in conducting applied decision analysis in a real-world setting in more detail than what is typically in textbooks on decision analysis. Second, the paper illustrates the important role of economic modeling in a large-scale applied decision analysis. The approach is applicable to other product-generation transition decision making for expanding global production capacity under uncertainty in a supply-constrained environment, especially for new product introductions and new product development decisions when supply is limited."
1677,"An Intersection-Movement-Based Dynamic User Optimal Route Choice Problem","Long, Jiancheng and Huang, Hai-Jun and Gao, Ziyou and Szeto, W. Y.","OPERATIONS RESEARCH","61","5","1134-1147","2013","SEP-OCT","","","In this paper a novel variational inequality (VI) formulation of the dynamic user optimal (DUO) route choice problem is proposed using the concept of approach proportion. An approach proportion represents the proportion of travelers that select a turning or through movement when leaving a node. Approach proportions contain travelers' route information so that the realistic effects of physical queues can be captured in a formulation when a physical-queue traffic flow model is adopted, and so that route enumeration and path-set generation can be avoided in the solution procedure. In addition, the simple structure of the approach proportion representation allows us to decompose the constraint set for solving large-scale DUO route choice problems. This paper also discusses the existence and uniqueness of the solutions to the VI problem and develops a solution algorithm based on the extragradient method to solve the proposed VI problem. This solution algorithm makes use of the decomposition property of the constraint set and is convergent if the travel time functions are pseudomonotone and Lipschitz continuous. It is not necessary to know the Lipschitz constant of the travel time functions in advance. Finally, numerical examples are given to demonstrate the properties of the proposed model and the performance of the solution algorithm."
1678,"Opening the Black Box of Efficiency Measurement: Input Allocation in Multioutput Settings","Cherchye, Laurens and De Rock, Bram and Dierynck, Bart and Roodhooft, Filip and Sabbe, Jeroen","OPERATIONS RESEARCH","61","5","1148-1165","2013","SEP-OCT","","","We develop a new data envelopment analysis (DEA)-based methodology for measuring the efficiency of decision-making units (DMUs) characterized by multiple inputs and multiple outputs. The distinguishing feature of our method is that it explicitly includes information about output-specific inputs and joint inputs in the efficiency evaluation. This method contributes to.opening the black box of efficiency measurement in two different ways. First, including information on the input allocation substantially increases the discriminatory power of the efficiency measurement. Second, it allows us to decompose the efficiency value of a DMU into output-specific efficiency values, which facilitates the identification of the outputs the manager should focus on to remedy the observed inefficiency. We demonstrate the usefulness and managerial implications of our methodology by means of a unique data set collected from the activity-based costing (ABC) system of a large service company with 290 DMUs."
1679,"Technical Note-Preservation of Supermodularity in Parametric Optimization Problems with Nonlattice Structures","Chen, Xin and Hu, Peng and He, Simai","OPERATIONS RESEARCH","61","5","1166-1173","2013","SEP-OCT","","","This paper establishes a new preservation property of supermodularity in a class of two-dimensional parametric optimization problems, where the constraint sets may not be lattices. This property and its extensions unify several results in the literature and provide powerful tools to analyze a variety of operations models including a two-product coordinated pricing and inventory control problem with cross-price effects that we use as an illustrative example."
1680,"Sequential Bayes-Optimal Policies for Multiple Comparisons with a Known Standard","Xie, Jing and Frazier, Peter I.","OPERATIONS RESEARCH","61","5","1174-1189","2013","SEP-OCT","","","We consider the problem of efficiently allocating simulation effort to determine which of several simulated systems have mean performance exceeding a threshold of known value. Within a Bayesian formulation of this problem, the optimal fully sequential policy for allocating simulation effort is the solution to a dynamic program. When sampling is limited by probabilistic termination or sampling costs, we show that this dynamic program can be solved efficiently, providing a tractable way to compute the Bayes-optimal policy. The solution uses techniques from optimal stopping and multiarmed bandits. We then present further theoretical results characterizing this Bayes-optimal policy, compare it numerically to several approximate policies, and apply it to applications in emergency services and manufacturing."
1681,"Learning Preferences Under Noise and Loss Aversion: An Optimization Approach","Bertsimas, Dimitris and O'Hair, Allison","OPERATIONS RESEARCH","61","5","1190-1199","2013","SEP-OCT","","","Preference learning has been a topic of research in many fields, including operations research, marketing, machine learning, and behavioral economics. In this work, we strive to combine the ideas from these different fields into a single methodology to learn preferences and make decisions. We use robust and integer optimization in an adaptive and dynamic way to determine preferences from data that are consistent with human behavior. We use integer optimization to address human inconsistency, robust optimization and conditional value at risk (CVaR) to address loss aversion, and adaptive conjoint analysis and linear optimization to frame the questions to learn preferences. The paper makes the following methodological contributions: to the robust optimization literature by proposing a method to derive undertainty sets from adaptive questionnaires, to the marketing literature by using the analytic center of discrete sets (as opposed to polyhedra) to capture errors and inconsistencies, and to the risk modeling literature by using efficient methods from computer science for sampling to optimize CVaR. We have implemented an online goftware that uses the proposed approach and report empirical evidence of its strength."
1682,"An Infinite Server System with General Packing Constraints","Stolyar, Alexander L.","OPERATIONS RESEARCH","61","5","1200-1217","2013","SEP-OCT","","","We consider a service system model primarily motivated by the problem of efficient assignment of virtual machines to physical host machines in a network cloud, so that the number of occupied hosts is minimized. There are multiple input flows of different type customers, with a customer mean service time depending on its type. There is an infinite number of servers. A server-packing configuration is the vector k = {k(i)}, where k(i) is the number of type i customers the server contains. Packing constraints must be observed; namely, there is a fixed finite set of configurations k that are allowed. Service times of different customers are independent; after a service completion, each customer leaves its server and the system. Each new arriving customer is placed for service immediately; it can be placed into a server already serving other customers (as long as packing constraints are not violated), or into an idle server. We consider a simple parsimonious real-time algorithm, called Greedy, that attempts to minimize the increment of the objective function Sigma(k)Sigma(l+d)(k), alpha > 0, caused by each new assignment; here X-k is the number of servers in configuration k. (When a is small, Sigma X-k(k)l+alpha approximates the total number Sigma X-k(k) of occupied servers.) Our main results show that certain versions of the Greedy algorithm are asymptotically optimal, in the sense of minimizing Sigma X-k(k)l+alpha in stationary regime as the input flow rates grow to infinity. We also show that in the special case when the set of allowed configurations is determined by vector-packing.constraints, the Greedy algorithm can work with aggregate configurations as opposed to exact configurations k, thus reducing computational complexity while preserving the asymptotic optimality."
1683,"Robust and Adaptive Network Flows","Bertsimas, Dimitris and Nasrabadi, Ebrahim and Stiller, Sebastian","OPERATIONS RESEARCH","61","5","1218-1242","2013","SEP-OCT","","","We study network flow problems in an uncertain environment from the viewpoint of robust optimization. In contrast to previous work, we consider the case that the network parameters (e.g., capacities) are known and deterministic, but the network structure (e.g., nodes and arcs) is subject to uncertainty. In this paper, we study the robust and adaptive versions of the maximum flow problem and minimum cut problems in networks with node and arc failures, and establish structural and computational results. The adaptive two-stage model adjusts the solution after the realization of the failures in the network. This leads to a more flexible model and yields less conservative solutions compared to the robust model. We show that the robust maximum flow problem can be solved in polynomial time, but the robust minimum cut problem is NP-hard. We also prove that the adaptive versions are NP-hard. We further characterize the adaptive model as a twoperson zero-sum game and prove the existence of an equilibrium in such games. Moreover, we consider a path-based formulation of flows in contrast to the more commonly used arc-based version of flows. This leads to a different model of robustness for maximum flows. We analyze this problem as well and develop a simple linear optimization model to obtain approximate solutions. Furthermore, we introduce the concept of adaptive maximum flows over time in networks with transit times on the arcs. Unlike the deterministic case, we show that this problem is NP-hard on series-parallel graphs even for the case that only one arc is allowed to fail. Finally, we propose heuristics based on linear optimization models that exhibit strong computational performance for large-scale instances."
1684,"Parallel Machine Scheduling: Impact of Adding Extra Machines","Rustogi, Kabir and Strusevich, Vitaly A.","OPERATIONS RESEARCH","61","5","1243-1257","2013","SEP-OCT","","","We consider the classical scheduling problems of processing jobs on identical parallel machines to minimize (i) the makespan (the maximum completion time) or (ii) the total flow time (the sum of the completion times). The focus of this study is on the impact that additional machines may have, if added to the system. We measure such a machine impact by the ratio of the value of the objective function computed with the original number of machines to the one computed with extra machines. We give tight bounds on the machine impact for the problem of minimizing the makespan, for both the preemptive and non-preemptive versions, as well as for the problem of minimizing the total flow time. We also present polynomial-time exact and approximation algorithms to make a cost-effective choice of the number of machines, provided that each machine incurs a cost and the objective function captures the trade-off between the cost of the used machines and a scheduling objective."
1685,"Optimal Economic Dispatch and Risk Management of Thermal Power Plants in Deregulated Markets","Thompson, Matt","OPERATIONS RESEARCH","61","4","791-809","2013","JUL-AUG","","","This paper presents a methodology for the valuation, optimization, market, margin and credit risk management of gas-fired power plants and associated tolling contracts. Term structure models for the power and gas forward curves are employed to facilitate hedging and risk adjustment and for improved forecasting of short-term prices. The model for the power forward curve is capable of reproducing the important phenomena often observed in power markets, including spot price spikes and spike clustering, negative prices, and the empirically observed volatility term structures of power and gas forward prices as well as the correlation term structure between these forward curves. The method solves the stochastic dynamic optimization problem that arises from the inclusion of the various operational constraints of gas-fired power plants including minimum uptime and downtime requirements, ramp rate restrictions and costs, variable output and efficiency rates, and minimum generation levels. The model involves the solution of a system of partial differential equations (PDEs), which are solved using the radial basis function (RBF) method. At each time step and operational configuration the model produces an analytic function (RBF expansion) for the value of the power plant as a function of the independent risk factors. These functions can be used for determining optimal operating strategies and can be differentiated analytically to obtain the relevant hedging statistics for the dynamic management of market risk. In addition, these value functions facilitate the calculation of the credit value adjustment (CVA) and potential future exposure (PFE) measurement of tolling contracts. The analytic differentiability of these value functions also facilitates the pricing and risk management of commodity contingent revolvers (CCRs), credit vehicles used to manage margin requirements that result from hedging market risk on an exchange."
1686,"Optimizing Trading Decisions for Hydro Storage Systems Using Approximate Dual Dynamic Programming","Loehndorf, Nils and Wozabal, David and Minner, Stefan","OPERATIONS RESEARCH","61","4","810-823","2013","JUL-AUG","","","We propose a new approach to optimize operations of hydro storage systems with multiple connected reservoirs whose operators participate in wholesale electricity markets. Our formulation integrates short-term intraday with long-term interday decisions. The intraday problem considers bidding decisions as well as storage operation during the day and is formulated as a stochastic program. The interday problem is modeled as a Markov decision process of managing storage operation over time, for which we propose integrating stochastic dual dynamic programming with approximate dynamic programming. We show that the approximate solution converges toward an upper bound of the optimal solution. To demonstrate the efficiency of the solution approach, we fit an econometric model to actual price and inflow data and apply the approach to a case study of an existing hydro storage system. Our results indicate that the approach is tractable for a real-world application and that the gap between theoretical upper and a simulated lower bound decreases sufficiently fast."
1687,"Imposing Connectivity Constraints in Forest Planning Models","Carvajal, Rodolfo and Constantino, Miguel and Goycoolea, Marcos and Vielma, Juan Pablo and Weintraub, Andres","OPERATIONS RESEARCH","61","4","824-836","2013","JUL-AUG","","","Connectivity requirements are a common component of forest planning models, with important examples arising in wildlife habitat protection. In harvest scheduling models, one way of addressing preservation concerns consists of requiring that large contiguous patches of mature forest are maintained. In the context of nature reserve design, it is common practice to select a connected region of forest, as a reserve, in such a way as to maximize the number of species and habitats protected. Although a number of integer programming formulations have been proposed for these forest planning problems, most are impractical in that they fail to solve reasonably sized scheduling instances. We present a new integer programming methodology and test an implementation of it on five medium-sized forest instances publicly available in the Forest Management Optimization Site repository. Our approach allows us to obtain near-optimal solutions for multiple time-period instances in fewer than four hours."
1688,"Optimal Dynamic Mechanism Design and the Virtual-Pivot Mechanism","Kakade, Sham M. and Lobel, Ilan and Nazerzadeh, Hamid","OPERATIONS RESEARCH","61","4","837-854","2013","JUL-AUG","","","We consider the problem of designing optimal mechanisms for settings where agents have dynamic private information. We present the virtual-pivot mechanism, which is optimal in a large class of environments that satisfy a separability condition. The mechanism satisfies a rather strong equilibrium notion (it is periodic ex post incentive compatible and individually rational). We provide both necessary and sufficient conditions for immediate incentive compatibility for mechanisms that satisfy periodic ex post incentive compatibility in future periods. The result also yields a strikingly simple mechanism for selling a sequence of items to a single buyer. We also show that the allocation rule of the virtual-pivot mechanism has a very simple structure (a virtual index) in multiarmed bandit settings. Finally, we show through examples that the relaxation technique we use does not produce optimal dynamic mechanisms in general nonseparable environments."
1689,"Optimal Bidding in Multi-Item Multislot Sponsored Search Auctions","Abhishek, Vibhanshu and Hosanagar, Kartik","OPERATIONS RESEARCH","61","4","855-873","2013","JUL-AUG","","","We study optimal bidding strategies for advertisers in sponsored search auctions. In general, these auctions are run as variants of second-price auctions but have been shown to be incentive incompatible. Thus, advertisers have to be strategic about bidding. Uncertainty in the decision-making environment, budget constraints, and the presence of a large portfolio of keywords makes the bid optimization problem nontrivial. We present an analytical model to compute the optimal bids for keywords in an advertiser's portfolio. To validate our approach, we estimate the parameters of the model using data from an advertiser's sponsored search campaign and use the bids proposed by the model in a field experiment. The results of the field implementation show that the proposed bidding technique is very effective in practice. We extend our model to account for interactions between keywords, in the form of positive spillovers from generic keywords into branded keywords. The spillovers are estimated using a dynamic linear model framework and are used to jointly optimize the bids of the keywords using an approximate dynamic programming approach. Accounting for the interaction between keywords leads to an additional improvement in the campaign performance."
1690,"Robust Portfolio Control with Stochastic Factor Dynamics","Glasserman, Paul and Xu, Xingbo","OPERATIONS RESEARCH","61","4","874-893","2013","JUL-AUG","","","Portfolio selection is vulnerable to the error-amplifying effects of combining optimization with statistical estimation and model error. For dynamic portfolio control, sources of model error include the evolution of market factors and the influence of these factors on asset returns. We develop portfolio control rules that are robust to this type of uncertainty, applying a stochastic notion of robustness to uncertainty in model dynamics. In this stochastic formulation, robustness reflects uncertainty about the probability law generating market data, and not just uncertainty about model parameters. We analyze both finite-and infinite-horizon problems in a model in which returns are driven by factors that evolve stochastically. The model incorporates transaction costs and leads to simple and tractable optimal robust controls for multiple assets. We illustrate the performance of the controls on historical data. As one would expect, in-sample tests show no evidence of improved performance through robustness-evaluating performance on the same data used to estimate a model leaves no room to capture model uncertainty. However, robustness does improve performance in out-of-sample tests in which the model is estimated on a rolling window of data and then applied over a subsequent time period. By acknowledging uncertainty in the estimated model, the robust rules lead to less aggressive trading and are less sensitive to sharp moves in underlying prices."
1691,"Exact Sampling of Jump Diffusions","Giesecke, Kay and Smelov, Dmitry","OPERATIONS RESEARCH","61","4","894-907","2013","JUL-AUG","","","This paper develops a method for the exact simulation of a skeleton, a hitting time, and other functionals of a one-dimensional jump diffusion with state-dependent drift, volatility, jump intensity, and jump size. The method requires the drift function to be C-1, the volatility function to be C-2, and the jump intensity function to be locally bounded. No further structure is imposed on these functions. The method leads to unbiased simulation estimators of security prices, transition densities, hitting probabilities, and other quantities. Numerical results illustrate its features."
1692,"Optimal Production Planning with Emissions Trading","Gong, Xiting and Zhou, Sean X.","OPERATIONS RESEARCH","61","4","908-924","2013","JUL-AUG","","","Emissions trading is a market-based mechanism for curbing emissions, and it has been implemented in Europe, North America, and several other parts of the world. To study its impact on production planning, we develop a dynamic production model, where a manufacturer produces a single product to satisfy random market demands. The manufacturer has access to both a green and a regular production technology, of which the former is more costly but yields fewer emissions. To comply with the emissions regulations, the manufacturer can buy or sell the allowances in each period via forward contracts in an outside market with stochastic trading prices while needing to keep a nonnegative allowance account balance at the end of the planning horizon. We first derive several important structural properties of the model, and based upon them, we characterize the optimal emissions trading and production policies that minimize the manufacturer's expected total discounted cost. In particular, the optimal emissions trading policy is a target interval policy with two thresholds that decrease with the starting inventory level. The optimal production policy is established by first determining the optimal technology choice and then showing the optimality of a base-stock type of production policy. We show that the optimal base-stock level is independent of the starting inventory level and the allowance level when the manufacturer trades the allowance or uses both technologies simultaneously. A numerical study using representative data from the cement industry is conducted to illustrate the analytical results and to examine the value of green technology for the manufacturer."
1693,"Technical Note-New Results Concerning Probability Distributions with Increasing Generalized Failure Rates","Banciu, Mihai and Mirchandani, Prakash","OPERATIONS RESEARCH","61","4","925-931","2013","JUL-AUG","","","The generalized failure rate of a continuous random variable has demonstrable importance in operations management. If the valuation distribution of a product has an increasing generalized failure rate (that is, the distribution is IGFR), then the associated revenue function is unimodal, and when the generalized failure rate is strictly increasing, the global maximum is uniquely specified. The assumption that the distribution is IGFR is thus useful and frequently held in recent pricing, revenue, and supply chain management literature. This note contributes to the IGFR literature in several ways. First, it investigates the prevalence of the IGFR property for the left and right truncations of valuation distributions. Second, we extend the IGFR notion to discrete distributions and contrast it with the continuous distribution case. The note also addresses two errors in the previous IGFR literature. Finally, for future reference, we analyze all common (continuous and discrete) distributions for the prevalence of the IGFR property, and derive and tabulate their generalized failure rates."
1694,"A Simple Behavioral Characterization of Subjective Expected Utility","Blavatskyy, Pavlo","OPERATIONS RESEARCH","61","4","932-940","2013","JUL-AUG","","","Subjective expected utility is the most widely used model to represent preferences under uncertainty (when objective probabilities of events may not be known). This paper presents a new behavioral characterization (preference axiomatization) of subjective expected utility. The latter is derived from a behavioral assumption of cardinal independence, also known as standard sequence invariance. This axiom requires that a standard sequence of outcomes (equally spaced in terms of utility) is independent of the conditional event. This axiom is a weaker version of the trade-off consistency condition of Wakker [Wakker PP (1984) Cardinal coordinate independence for expected utility. J. Math. Psych. 28: 110-117]. The main representation theorem is derived both in the connected topology approach and the algebraic approach (when step-continuity is replaced with solvability and Archimedean axioms)."
1695,"Supermodularity and Affine Policies in Dynamic Robust Optimization","Iancu, Dan A. and Sharma, Mayank and Sviridenko, Maxim","OPERATIONS RESEARCH","61","4","941-956","2013","JUL-AUG","","","This paper considers a particular class of dynamic robust optimization problems, where a large number of decisions must be made in the first stage, which consequently fix the constraints and cost structure underlying a one-dimensional, linear dynamical system. We seek to bridge two classical paradigms for solving such problems, namely, (1) dynamic programming (DP), and (2) policies parameterized in model uncertainties (also known as decision rules), obtained by solving tractable convex optimization problems. We show that if the uncertainty sets are integer sublattices of the unit hypercube, the DP value functions are convex and supermodular in the uncertain parameters, and a certain technical condition is satisfied, then decision rules that are affine in the uncertain parameters are optimal. We also derive conditions under which such rules can be obtained by optimizing simple (i.e., linear) objective functions over the uncertainty sets. Our results suggest new modeling paradigms for dynamic robust optimization, and our proofs, which bring together ideas from three areas of optimization typically studied separately-robust optimization, combinatorial optimization (the theory of lattice programming and supermodularity), and global optimization (the theory of concave envelopes)-may be of independent interest. We exemplify our findings in a class of applications concerning the design of flexible production processes, where a retailer seeks to optimally compute a set of strategic decisions (before the start of a selling season), as well as in-season replenishment policies. We show that, when the costs incurred are jointly convex, replenishment policies that depend linearly on the realized demands are optimal. When the costs are also piecewise affine, all the optimal decisions can be found by solving a single linear program of small size (when all decisions are continuous) or a mixed-integer, linear program of the same size (when some strategic decisions are discrete)."
1696,"On Solving Multistage Stochastic Programs with Coherent Risk Measures","Philpott, Andy and de Matos, Vitor and Finardi, Erlon","OPERATIONS RESEARCH","61","4","957-970","2013","JUL-AUG","","","We consider a class of multistage stochastic linear programs in which at each stage a coherent risk measure of future costs is to be minimized. A general computational approach based on dynamic programming is derived that can be shown to converge to an optimal policy. By computing an inner approximation to future cost functions, we can evaluate an upper bound on the cost of an optimal policy, and an outer approximation delivers a lower bound. The approach we describe is particularly useful in sampling-based algorithms, and a numerical example is provided to show the efficacy of the methodology when used in conjunction with stochastic dual dynamic programming."
1697,"Mean Field Equilibrium in Dynamic Games with Strategic Complementarities","Adlakha, Sachin and Johari, Ramesh","OPERATIONS RESEARCH","61","4","971-989","2013","JUL-AUG","","","We study a class of stochastic dynamic games that exhibit strategic complementarities between players; formally, in the games we consider, the payoff of a player has increasing differences between her own state and the empirical distribution of the states of other players. Such games can be used to model a diverse set of applications, including network security models, recommender systems, and dynamic search in markets. Stochastic games are generally difficult to analyze, and these difficulties are only exacerbated when the number of players is large (as might be the case in the preceding examples). We consider an approximation methodology called mean field equilibrium to study these games. In such an equilibrium, each player reacts to only the long-run average state of other players. We find necessary conditions for the existence of a mean field equilibrium in such games. Furthermore, as a simple consequence of this existence theorem, we obtain several natural monotonicity properties. We show that there exist a largest and a smallest equilibrium among all those where the equilibrium strategy used by a player is nondecreasing, and we also show that players converge to each of these equilibria via natural myopic learning dynamics; as we argue, these dynamics are more reasonable than the standard best-response dynamics. We also provide sensitivity results, where we quantify how the equilibria of such games move in response to changes in parameters of the game (for example, the introduction of incentives to players)."
1698,"Optimization with Multivariate Conditional Value-at-Risk Constraints","Noyan, Nilay and Rudolf, Gabor","OPERATIONS RESEARCH","61","4","990-1013","2013","JUL-AUG","","","For many decision-making problems under uncertainty, it is crucial to develop risk-averse models and specify the decision makers' risk preferences based on multiple stochastic performance measures (or criteria). Incorporating such multivariate preference rules into optimization models is a fairly recent research area. Existing studies focus on extending univariate stochastic dominance rules to the multivariate case. However, enforcing multivariate stochastic dominance constraints can often be overly conservative in practice. As an alternative, we focus on the widely applied risk measure conditional value-at-risk (CVaR), introduce a multivariate CVaR relation, and develop a novel optimization model with multivariate CVaR constraints based on polyhedral scalarization. To solve such problems for finite probability spaces, we develop a cut generation algorithm, where each cut is obtained by solving a mixed-integer problem. We show that a multivariate CVaR constraint reduces to finitely many univariate CVaR constraints, which proves the finite convergence of our algorithm. We also show that our results can be naturally extended to a wider class of coherent risk measures. The proposed approach provides a flexible and computationally tractable way of modeling preferences in stochastic multicriteria decision making. We conduct a computational study for a budget allocation problem to illustrate the effect of enforcing multivariate CVaR constraints and demonstrate the computational performance of the proposed solution methods."
1699,"Online Make-to-Order Joint Replenishment Model: Primal-Dual Competitive Algorithms","Buchbinder, Niv and Kimbrel, Tracy and Levi, Retsef and Makarychev, Konstantin and Sviridenko, Maxim","OPERATIONS RESEARCH","61","4","1014-1029","2013","JUL-AUG","","","In this paper, we study an online make-to-order variant of the classical joint replenishment problem (JRP) that has been studied extensively over the years and plays a fundamental role in broader planning issues, such as the management of supply chains. In contrast to the traditional approaches of the stochastic inventory theory, we study the problem using competitive analysis against a worst-case adversary. Our main result is a 3-competitive deterministic algorithm for the online version of the JRP. We also prove a lower bound of approximately 2.64 on the competitiveness of any deterministic online algorithm for the problem. Our algorithm is based on a novel primal-dual approach using a new linear programming relaxation of the offline JRP model. The primal-dual approach that we propose departs from previous primal-dual and online algorithms in rather significant ways. We believe that this approach can extend the range of problems to which online and primal-dual algorithms can be applied and analyzed."
1700,"Statistical Analysis with Little's Law","Kim, Song-Hee and Whitt, Ward","OPERATIONS RESEARCH","61","4","1030-1045","2013","JUL-AUG","","","The theory supporting Little's Law (L = lambda W) is now well developed, applying to both limits of averages and expected values of stationary distributions, but applications of Little's Law with actual system data involve measurements over a finite-time interval, which are neither of these. We advocate taking a statistical approach with such measurements. We investigate how estimates of L and lambda can be used to estimate W when the waiting times are not observed. We advocate estimating confidence intervals. Given a single sample-path segment, we suggest estimating confidence intervals using the method of batch means, as is often done in stochastic simulation output analysis. We show how to estimate and remove bias due to interval edge effects when the system does not begin and end empty. We illustrate the methods with data from a call center and simulation experiments."
1701,"Optimal Production Management When Demand Depends on the Business Cycle","Cadenillas, Abel and Lakner, Peter and Pinedo, Michael","OPERATIONS RESEARCH","61","4","1046-1062","2013","JUL-AUG","","","We assume that the cumulative consumer demand for an item follows a Brownian motion, with both the drift and the variance parameters modulated by a continuous-time Markov chain that represents the regime of the economy. The management of the company would like to maintain the inventory level as close as possible to a target inventory level and would also like to produce at a rate that is as close as possible to a target production rate. The company is penalized for deviations from the target levels, and the objective is to minimize the total discounted penalty costs. We consider two models. In the first model the management of the company knows the state of the economy, whereas in the second model the management does not know it. We solve both problems and obtain the optimal production policy and the minimal total expected discounted cost. Furthermore, we compare the total expected discounted costs of the two models and determine the value of knowing the regime of the economy. We also solve the above problems in the case when the consumer demand rate follows a geometric Brownian motion modulated by a continuous-time Markov chain that represents the regime of the economy."
1702,"OR Forum - Blotto Politics","Washburn, Alan","OPERATIONS RESEARCH","61","3","532-543","2013","MAY-JUN","","","This paper considers abstract election games motivated by the United States Electoral College. There are two political parties, and the electoral votes in each state go to the party that spends the most money there, with an adjustment for a head start that one party or the other may have in that state. The states have unequal numbers of electoral votes, and elections are decided by majority rules. Each party has a known budget, and much depends on the information that informs how that budget is spent. Three situations are considered: (1) one party's spending plan is known to the other, (2) spending is gradually revealed as the parties spend continuously in time, and (3) neither side knows anything about the other's spending. The last situation resembles a Blotto game, hence the title."
1703,"The Impact of Size and Occupancy of Hospital on the Extent of Ambulance Diversion: Theory and Evidence","Allon, Gad and Deo, Sarang and Lin, Wuqin","OPERATIONS RESEARCH","61","3","544-562","2013","MAY-JUN","","","In recent years, growth in the demand for emergency medical services, along with decline in the number of hospitals with emergency departments (EDs), has raised concerns about the ability of the EDs to provide adequate service. Many EDs frequently report periods of overcrowding during which they are forced to divert incoming ambulances to neighboring hospitals, a phenomenon known as ambulance diversion. The objective of this paper is to study the impact of key operational characteristics of the hospitals such as the number of ED beds, the number of inpatient beds, and the utilization of inpatient beds on the extent to which hospitals go on ambulance diversion. We propose a simple queueing network model to describe the patient flow between the ED and the inpatient department. We analyze this network using two different approximations-diffusion and fluid-to derive two separate sets of measures for inpatient occupancy and ED size. We use these sets of measures to form hypotheses and test them by estimating a sample selection model using data on a cross section of hospitals from California. We find that the measures derived from the diffusion approximation provide better explanation of the data than those derived from the fluid approximation. For this model, we find that the fraction of time that the ED spends on diversion is decreasing in the spare capacity of the inpatient department and in the size of the ED, where both are appropriately normalized for the size of the inpatient department. In addition, controlling for these hospital-specific factors, we find that the fraction of time on diversion at a hospital increases with the number of hospitals in its neighborhood. We also find that certain hospitals, owing to their location, ownership, and trauma center status, are more likely to choose ambulance diversion to mitigate overcrowding than others."
1704,"Generating Applicable Synthetic Instances for Branch Problems","Lopes, Leo and Smith-Miles, Kate","OPERATIONS RESEARCH","61","3","563-577","2013","MAY-JUN","","","Generating valid synthetic instances for branch problems-those that contain a core problem like knapsack or graph coloring, but add several complications-is hard. It is even harder to generate instances that are applicable to the specific goals of an experiment and help to support the claims made. This paper presents a methodology for tuning instance generators of branch problems so that synthetic instances are similar to real ones and are capable of eliciting different behaviors from solvers. A statistic is proposed to summarize the applicability of instances for drawing a valid conclusion. The methodology is demonstrated on the Udine timetabling problem. Examples and the necessary cyberinfrastructure are available as a project from Computational Infrastructure for Operations Research (COIN-OR)."
1705,"Multiarea Stochastic Unit Commitment for High Wind Penetration in a Transmission Constrained Network","Papavasiliou, Anthony and Oren, Shmuel S.","OPERATIONS RESEARCH","61","3","578-592","2013","MAY-JUN","","","In this paper we present a unit commitment model for studying the impact of large-scale wind integration in power systems with transmission constraints and system component failures. The model is formulated as a two-stage stochastic program with uncertain wind production in various locations of the network as well as generator and transmission line failures. We present a scenario selection algorithm for selecting and weighing wind power production scenarios and composite element failures, and we provide a parallel dual decomposition algorithm for solving the resulting mixed-integer program. We validate the proposed scenario selection algorithm by demonstrating that it outperforms alternative reserve commitment approaches in a 225 bus model of California with 130 generators and 375 transmission lines. We use our model to quantify day-ahead generator capacity commitment, operating cost impacts, and renewable energy utilization levels for various degrees of wind power integration. We then demonstrate that failing to account for transmission constraints and contingencies can result in significant errors in assessing the economic impacts of renewable energy integration."
1706,"Approximation Algorithms for the Stochastic Lot-Sizing Problem with Order Lead Times","Levi, Retsef and Shi, Cong","OPERATIONS RESEARCH","61","3","593-602","2013","MAY-JUN","","","We develop new algorithmic approaches to compute provably near-optimal policies for multiperiod stochastic lot-sizing inventory models with positive lead times, general demand distributions, and dynamic forecast updates. The policies that are developed have worst-case performance guarantees of 3 and typically perform very close to optimal in extensive computational experiments. The newly proposed algorithms employ a novel randomized decision rule. We believe that these new algorithmic and performance analysis techniques could be used in designing provably near-optimal randomized algorithms for other stochastic inventory control models and more generally in other multistage stochastic control problems."
1707,"Technical Note-Optimal Control Policy for Capacitated Inventory Systems with Remanufacturing","Gong, Xiting and Chao, Xiuli","OPERATIONS RESEARCH","61","3","603-611","2013","MAY-JUN","","","This paper studies the optimal control policy for capacitated periodic-review inventory systems with remanufacturing. The serviceable products can be either manufactured from raw materials or remanufactured from returned products; but the system has finite capacities in manufacturing, remanufacturing, and/or total manufacturing/remanufacturing operations in each period. Using L-natural convexity and lattice analysis, we show that, for systems with a remanufacturing capacity and a manufacturing/total capacity, the optimal remanufacturing policy is a modified remanufacture-down-to policy and the optimal manufacturing policy is a modified total-up-to policy. Our study reveals that the optimal policies always give production priority to remanufacturing for systems with a remanufacturing capacity and/or a total capacity; but this priority fails to hold for systems with a manufacturing capacity."
1708,"Simple Policies for Dynamic Pricing with Imperfect Forecasts","Chen, Yiwei and Farias, Vivek F.","OPERATIONS RESEARCH","61","3","612-624","2013","MAY-JUN","","","We consider the classical single-product dynamic pricing problem allowing the scale of demand intensity to be modulated by an exogenous market size stochastic process. This is a natural model of dynamically changing market conditions. We show that for a broad family of Gaussian market-size processes, simple dynamic pricing rules that are essentially agnostic to the specification of this market-size process perform provably well. The pricing policies we develop are shown to compensate for forecast imperfections (or a lack of forecast information altogether) by frequent reoptimization and reestimation of the instantaneous market size."
1709,"Optimal Stopping and Early Exercise: An Eigenfunction Expansion Approach","Li, Lingfei and Linetsky, Vadim","OPERATIONS RESEARCH","61","3","625-643","2013","MAY-JUN","","","This paper proposes a new approach to solve finite-horizon optimal stopping problems for a class of Markov processes that includes one-dimensional diffusions, birth-death processes, and jump diffusions and continuous-time Markov chains obtained by time-changing diffusions and birth-and-death processes with Levy subordinators. When the expectation operator has a purely discrete spectrum in the Hilbert space of square-integrable payoffs, the value function of a discrete optimal stopping problem has an expansion in the eigenfunctions of the expectation operator. The Bellman's dynamic programming for the value function then reduces to an explicit recursion for the expansion coefficients. The value function of the continuous optimal stopping problem is then obtained by extrapolating the value function of the discrete problem to the limit via Richardson extrapolation. To illustrate the method, the paper develops two applications: American-style commodity futures options and Bermudan-style abandonment and capacity expansion options in commodity extraction projects under the subordinate Ornstein-Uhlenbeck model with mean-reverting jumps with the value function given by an expansion in Hermite polynomials."
1710,"Optimal Sequential Exploration: Bandits, Clairvoyants, and Wildcats","Brown, David B. and Smith, James E.","OPERATIONS RESEARCH","61","3","644-665","2013","MAY-JUN","","","This paper was motivated by the problem of developing an optimal policy for exploring an oil and gas field in the North Sea. Where should we drill first? Where do we drill next? In this and many other problems, we face a trade-off between earning (e.g., drilling immediately at the sites with maximal expected values) and learning (e.g., drilling at sites that provide valuable information) that may lead to greater earnings in the future. These sequential exploration problems resemble a multiarmed bandit problem, but probabilistic dependence plays a key role: outcomes at drilled sites reveal information about neighboring targets. Good exploration policies will take advantage of this information as it is revealed. We develop heuristic policies for sequential exploration problems and complement these heuristics with upper bounds on the performance of an optimal policy. We begin by grouping the targets into clusters of manageable size. The heuristics are derived from a model that treats these clusters as independent. The upper bounds are given by assuming each cluster has perfect information about the results from all other clusters. The analysis relies heavily on results for bandit superprocesses, a generalization of the multiarmed bandit problem. We evaluate the heuristics and bounds using Monte Carlo simulation and, in the North Sea example, we find that the heuristic policies are nearly optimal."
1711,"Data Envelopment Analysis with Nonhomogeneous DMUs","Cook, Wade D. and Harrison, Julie and Imanirad, Raha and Rouse, Paul and Zhu, Joe","OPERATIONS RESEARCH","61","3","666-676","2013","MAY-JUN","","","Data envelopment analysis (DEA), as originally proposed, is a methodology for evaluating the relative efficiencies of a set of homogeneous decision-making units (DMUs) in the sense that each uses the same input and output measures (in varying amounts from one DMU to another). In some situations, however, the assumption of homogeneity among DMUs may not apply. As an example, consider the case where the DMUs are plants in the same industry that may not all produce the same products. Evaluating efficiencies in the absence of homogeneity gives rise to the issue of how to fairly compare a DMU to other units, some of which may not be exactly in the same business. A related problem, and one that has been examined extensively in the literature, is the missing data problem; a DMU produces a certain output, but its value is not known. One approach taken to address this problem is to create a value for the missing output (e.g., substituting zero, or by taking the average of known values), and use it to fill in the gaps. In the present setting, however, the issue isn't that the data for the output is missing for certain DMUs, but rather that the output isn't produced. We argue herein that if a DMU has chosen not to produce a certain output, or for any reason cannot produce that output, and therefore does not put the resources in place to do so, then it would be inappropriate to artificially assign that DMU a zero value or some average value for the nonexistent factor. Specifically, the desire is to fairly evaluate a DMU for what it does, rather than penalize or credit it for what it doesn't do. In the current paper we present DEA-based models for evaluating the relative efficiencies of a set of DMUs where the requirement of homogeneity is relaxed. We then use these models to examine the efficiencies of a set of manufacturing plants."
1712,"The Robust Capacitated Vehicle Routing Problem Under Demand Uncertainty","Gounaris, Chrysanthos E. and Wiesemann, Wolfram and Floudas, Christodoulos A.","OPERATIONS RESEARCH","61","3","677-693","2013","MAY-JUN","","","The robust capacitated vehicle routing problem (CVRP) under demand uncertainty is studied to address the minimum cost delivery of a product to geographically dispersed customers using capacity-constrained vehicles. Contrary to the deterministic CVRP, which postulates that the customer demands for the product are deterministic and known, the robust CVRP models the customer demands as random variables, and it determines a minimum cost delivery plan that is feasible for all anticipated demand realizations. Robust optimization counterparts of several deterministic CVRP formulations are derived and compared numerically. Robust rounded capacity inequalities are developed, and it is shown how they can be separated efficiently for two broad classes of demand supports. Finally, it is analyzed how the robust CVRP relates to the chance-constrained CVRP, which allows a controlled degree of supply shortfall to decrease delivery costs."
1713,"A Graph Patrol Problem with Random Attack Times","Lin, Kyle Y. and Atkinson, Michael R. and Chung, Timothy H. and Glazebrook, Kevin D.","OPERATIONS RESEARCH","61","3","694-710","2013","MAY-JUN","","","This paper presents a patrol problem, where a patroller traverses a graph through edges to detect potential attacks at nodes. To design a patrol policy, the patroller needs to take into account not only the graph structure, but also the different attack time distributions, as well as different costs incurred due to successful attacks, at different nodes. We consider both random attackers and strategic attackers. A random attacker chooses which node to attack according to a probability distribution known to the patroller. A strategic attacker plays a two-person zero-sum game with the patroller. For each case, we give an exact linear program to compute the optimal solution. Because the linear programs quickly become computationally intractable as the problem size grows, we develop index-based heuristics. In the random-attacker case, our heuristic is optimal when there are two nodes, and in a suitably chosen asymptotic regime. In the strategic-attacker case, our heuristic is optimal when there are two nodes if the attack times are deterministic taking integer values. In our numerical experiments, our heuristic typically achieves within 1% of optimality with computation time orders of magnitude less than what is required to compute the optimal policy."
1714,"Scheduling Arrivals to a Stochastic Service Delivery System Using Copositive Cones","Kong, Qingxia and Lee, Chung-Yee and Teo, Chung-Piaw and Zheng, Zhichao","OPERATIONS RESEARCH","61","3","711-726","2013","MAY-JUN","","","In this paper we investigate a stochastic appointment-scheduling problem in an outpatient clinic with a single doctor. The number of patients and their sequence of arrivals are fixed, and the scheduling problem is to determine an appointment time for each patient. The service durations of the patients are stochastic, and only the mean and covariance estimates are known. We do not assume any exact distributional form of the service durations, and we solve for distributionally robust schedules that minimize the expectation of the weighted sum of patients' waiting time and the doctor's overtime. We formulate this scheduling problem as a convex conic optimization problem with a tractable semidefinite relaxation. Our model can be extended to handle additional support constraints of the service durations. Using the primal dual optimality conditions, we prove several interesting structural properties of the optimal schedules. We develop an efficient semidefinite relaxation of the conic program and show that we can still obtain near-optimal solutions on benchmark instances. in the existing literature. We apply our approach to develop a practical appointment schedule at an eye clinic that can significantly improve the efficiency of the appointment system in the clinic, compared to an existing schedule."
1715,"Robust Partitioning for Stochastic Multivehicle Routing","Carlsson, John Gunnar and Delage, Erick","OPERATIONS RESEARCH","61","3","727-744","2013","MAY-JUN","","","The problem of coordinating a fleet of vehicles so that all demand points on a territory are serviced and the workload is most evenly distributed among the vehicles is a hard one. For this reason, it is often an effective strategy to first divide the service region and impose that each vehicle is only responsible for its own subregion. This heuristic also has the practical advantage that over time, drivers become more effective at serving their territory and customers. In this paper, we assume that client locations are unknown at the time of partitioning the territory and that each of them will be drawn identically and independently according to a distribution that is actually also unknown. In practice, it might be impossible to identify precisely the distribution if, for instance, information about the demand is limited to historical data. Our approach Suggests partitioning the region with respect to the worst-case distribution that satisfies first- and second-order moments information. As a side product, our analysis constructs for each subregion a closed-form expression for the worst-case density function, thus providing useful insights about what affects the completion time most heavily. The successful implementation of our approach relies on two branch-and-bound algorithms: whereas the first finds a globally optimal partition of a convex polygon into two convex subregions, the second finds a local optimum for the harder n-partitioning problem. Finally, simulations of a parcel delivery problem will demonstrate that our data-driven approach makes better use of historical data as it becomes available."
1716,"Optimal Cardinality Constrained Portfolio Selection","Gao, Jianjun and Li, Duan","OPERATIONS RESEARCH","61","3","745-761","2013","MAY-JUN","","","One long-standing challenge in both the optimization and investment communities is to devise an efficient algorithm to select a small number of assets from an asset pool such that a portfolio objective is optimized. This cardinality constrained investment situation naturally arises due to the presence of various forms of market friction, such as transaction costs and management fees, or even due to the consideration of mental cost. Unfortunately, the combinatorial nature of such a portfolio selection problem formulation makes the exact solution process NP-hard in general. We focus in this paper on the cardinality constrained mean-variance portfolio selection problem. Instead of tailoring such a difficult problem into the general solution framework of mixed-integer programming formulation, we explore the special structures and rich geometric properties behind the mathematical formulation. Applying the Lagrangian relaxation to the primal problem results in a pure cardinality constrained portfolio selection problem, which possesses a symmetric property, and to which geometric approaches can be developed. Different from the existing literature that has primarily focused on some direct relaxations of the cardinality constraint, we consider modifying the objective function to some separable relaxations, which are immune to the hard cardinality constraint. More specifically, we develop efficient lower bounding schemes by using the circumscribed box, the circumscribed ball, and the circumscribed axis-aligned ellipsoid to approximate the objective contour of the problem. In particular, all these cardinality constrained relaxation problems can be solved analytically. Furthermore, we derive efficient polynomial-time algorithms for the corresponding dual search problems. Most promisingly, the lower bounding scheme using the circumscribed axis-aligned ellipsoid leads to a semidefinite programming (SDP) formulation and offers a sharp bound and high-quality feasible solution. By integrating these lower bounding schemes into a branch-and-bound algorithm (BnB), our solution scheme outperforms CPLEX significantly in identifying the exact optimal portfolio."
1717,"Optimal Budget Allocation for Sample Average Approximation","Royset, Johannes O. and Szechtman, Roberto","OPERATIONS RESEARCH","61","3","762-776","2013","MAY-JUN","","","The sample average approximation approach to solving stochastic programs induces a sampling error, caused by replacing an expectation by a sample average, as well as an optimization error due to approximating the solution of the resulting sample average problem. We obtain estimators of an optimal solution and the optimal value of the original stochastic program after executing a finite number of iterations of an optimization algorithm applied to the sample average problem. We examine the convergence rate of the estimators as the computing budget tends to infinity, and we characterize the allocation policies that maximize the convergence rate in the case of sublinear, linear, and superlinear convergence regimes for the optimization algorithm."
1718,"Joint Optimization of Sampling and Control of Partially Observable Failing Systems","Kim, Michael Jong and Makis, Viliam","OPERATIONS RESEARCH","61","3","777-790","2013","MAY-JUN","","","Stochastic control problems that arise in reliability and maintenance optimization typically assume that information used for decision-making is obtained according to a predetermined sampling schedule. In many real applications, however, there is a high sampling cost associated with collecting such data. It is therefore of equal importance to determine when information should be collected and to decide how this information should be utilized for maintenance decision-making. This type of joint optimization has been a long-standing problem in the operations research and maintenance optimization literature, and very few results regarding the structure of the optimal sampling and maintenance policy have been published. In this paper, we formulate and analyze the joint optimization of sampling and maintenance decision-making in the partially observable Markov decision process framework. We prove the optimality of a policy that is characterized by three critical thresholds, which have practical interpretation and give new insight into the value of condition-based maintenance programs in life-cycle asset management. Illustrative numerical comparisons are provided that show substantial cost savings over existing suboptimal policies."
1719,"Mining Coal or Finding Terrorists: The Expanding Search Paradigm","Alpern, Steve and Lidbetter, Thomas","OPERATIONS RESEARCH","61","2","265-279","2013","MAR-APR","","","We show how to optimize the search for a hidden object, terrorist, or simply Hider, located at a point H according to a known or unknown distribution v on a rooted network Q. We modify the traditional pathwise search approach to a more general notion of expanding search. When the Hider is restricted to the nodes of Q, an expanding search S consists of an ordering (a(1), a(2), ... ) of the arcs of a spanning subtree such that the root node is in a(1) and every arc a(i) is adjacent to a previous arc a(j), j < i. If a(k) contains H, the search time T is lambda(a(1)) + ... + lambda(a(k)), where lambda is length measure on Q. For more general distributions v, an expanding search S is described by the nested family of connected sets S(t) that specify the area of Q that has been covered by time t. S(0) is the root, lambda(S(t)) = t, and T = min{t: H is an element of S(t)}. For a known Hider distribution v on a tree Q, the expected time minimizing strategy <(S)over bar> begins with the rooted subtree Q' maximizing the density v(Q')/lambda(Q'). (For arbitrary networks, we use this criterion on all spanning subtrees.) The search (S) over bar can be interpreted as the optimal method of mining known coal seams, when the time to move miners or machines is negligible compared to digging time. When the Hider distribution is unknown, we consider the zero-sum search game where the Hider picks H, the Searcher S, and the payoff is T. For trees Q, the value is V = (lambda(Q) D)/2, where D is a mean distance from root to leaf nodes. If Q is 2-arc connected, V = lambda(Q)/2. Applications and interpretations of the expanding search paradigm are given, particularly to multiple agent search."
1720,"Dynamic Business Share Allocation in a Supply Chain with Competing Suppliers","Li, Hongmin and Zhang, Hao and Fine, Charles H.","OPERATIONS RESEARCH","61","2","280-297","2013","MAR-APR","","","This paper studies a repeated game between a manufacturer and two competing suppliers with imperfect monitoring. We present a principal-agent model for managing long-term supplier relationships using a unique form of measurement and incentive scheme. We measure a supplier's overall performance with a rating equivalent to its continuation Utility (the expected total discounted utility of its future payoffs), and incentivize supplier effort with larger allocations of future business. We obtain the vector of the two suppliers' ratings as the state of a Markov decision process, and we solve an infinite horizon contracting problem in which the manufacturer allocates business volume between the two suppliers and updates their ratings dynamically based on their current ratings and the current performance outcome. Our contributions are both theoretical and managerial: we propose a repeated principal-agent model with a novel incentive scheme to tackle a common, but challenging, incentive problem in a multiperiod supply chain setting. Assuming binary effort choices and performance outcomes by the suppliers, we characterize the structure of the optimal contract through a novel fixed-point analysis. Our results provide a theoretical foundation for the emergence of business-as-usual (low effort) trapping states and tournament competition (high effort) recurrent states as the long-run incentive drivers for motivating critical suppliers."
1721,"An Exact Algorithm for the Two-Echelon Capacitated Vehicle Routing Problem","Baldacci, Roberto and Mingozzi, Aristide and Roberti, Roberto and Clavo, Roberto Wolfler","OPERATIONS RESEARCH","61","2","298-314","2013","MAR-APR","","","In the two-echelon capacitated vehicle routing problem (2E-CVRP), the delivery to customers from a depot uses intermediate depots, called satellites. The 2E-CVRP involves two levels of routing problems. The first level requires a design of the routes for a vehicle fleet located at the depot to transport the customer demands to a subset of the satellites. The second level concerns the routing of a vehicle fleet located at the satellites to serve all customers from the satellites supplied from the depot. The objective is to minimize the sum of routing and handling costs. This paper describes a new mathematical formulation of the 2E-CVRP used to derive valid lower bounds and an exact method that decomposes the 2E-CVRP into a limited set of multidepot capacitated vehicle routing problems with side constraints. Computational results on benchmark instances show that the new exact algorithm outperforms the state-of-the-art exact methods."
1722,"An Exact Algorithm for the Capacitated Arc Routing Problem with Deadheading Demand","Bartolini, Enrico and Cordeau, Jean-Francois and Laporte, Gilbert","OPERATIONS RESEARCH","61","2","315-327","2013","MAR-APR","","","We study an extension of the capacitated arc routing problem (CARP) called the capacitated arc routing problem with deadheading demand (CARPDD). This problem extends the classical capacitated arc routing problem by introducing an additional capacity consumption incurred by a vehicle deadheading an edge. It can be used, e.g., to model time or distance constrained arc routing problems. We show that the strongest CARP lower bounds can be weak when directly applied to the CARPDD, and we introduce a new family of valid inequalities shown to significantly strengthen these bounds. We develop an exact algorithm for the CARPDD based on cut-and-column generation and branch and price, and we report extensive computational results on a large set of benchmark instances. The same exact algorithm is also tested on classical CARP benchmark sets and is shown to improve upon the best known exact algorithms for the CARP."
1723,"Staffing and Control of Instant Messaging Contact Centers","Luo, Jun and Zhang, Jiheng","OPERATIONS RESEARCH","61","2","328-343","2013","MAR-APR","","","In addition to traditional call centers, many companies have started building a new kind of customer contact center, in which agents communicate with customers via instant messaging (IM) over the Internet rather than phone calls. A distinctive feature of the service centers based on IM is that one agent can serve multiple customers in parallel. We choose to model such a center as a server pool consisting of many limited processor-sharing servers. We characterize the underlying stochastic processes by establishing a fluid approximation in the many-server heavy-traffic regime. The limiting behavior of the stochastic processes is shown to involve a stochastic averaging principle, and the fluid approximation provides insights into the optimal staffing and control for such service centers."
1724,"Flexible Server Allocation and Customer Routing Policies for Two Parallel Queues When Service Rates Are Not Additive","Ahn, Hyun-Soo and Lewis, Mark E.","OPERATIONS RESEARCH","61","2","344-358","2013","MAR-APR","","","We consider the question of how routing and allocation can be coordinated to meet the challenge of demand variability in a parallel queueing system serving two types of customers. A decision maker decides whether to keep customers at the station at which they arrived or to reroute them to the other station. At the same time, the decision maker has two servers and must decide where to allocate their effort. We analyze this joint decision-making scenario with both routing and station-dependent holding costs, but add an important twist. We allow the combined service rate (when the servers work at the same station) to be superadditive or subadditive. This captures positive or negative externalities that arise during collaboration. We seek an optimal control policy under the discounted or long-run average cost criteria. Our results show that in the superadditive case jobs should never be routed away from the lower-cost queue. When jobs are rerouted from the higher-cost queue to the low-cost queue the optimal control is monotone in the respective queue lengths. Moreover, we show that the optimal allocation is a nonidling priority rule based on the holding costs. In the subadditive case we find that the optimal policy need not exhibit such a simple structure. In fact, the optimal allocation need not prioritize one station (it may split the servers), and the optimal routing need not be monotone in the number of customers in each queue. We characterize the optimal policy for a few canonical cases and discuss why intuitive policies need not be optimal in the general case. An extensive numerical study examines the benefit of dynamically controlling both routing and resource allocation; we discuss when using one of the two levers-dynamic routing and dynamic allocation-is sufficient and when using both controls is warranted."
1725,"Utility Copula Functions Matching All Boundary Assessments","Abbas, Ali E.","OPERATIONS RESEARCH","61","2","359-371","2013","MAR-APR","","","The construction of a multiattribute utility function is an important step in decision analysis and can be a challenging task unless some decomposition of the utility function is performed. When every attribute is utility independent of its complement, the utility elicitation task is significantly simplified because the functional form of the utility function requires only one conditional utility function for each attribute, and some normalizing constants. When utility independence conditions do not hold, the conditional utility function of an attribute may vary across the domain of the complement attributes, and therefore a single conditional utility assessment for each attribute may not be sufficient to capture the decision maker's preferences. This paper proposes a method to construct utility functions that have the flexibility to match the variations in the conditional utility function, across the domain of the attributes, using univariate utility assessments at the boundary values. The approach incorporates the boundary assessments into a new function, which we call the double-sided utility copula. This formulation provides a wealth of new functional forms that the analyst may use to incorporate utility dependence in multiattribute decision problems. The utility copula function also allows for the flexibility to incorporate a wide range of trade-off assessments among the attributes, while keeping the utility assessments at the boundary values fixed. It is also useful in determining the order of approximation provided by using certain independence assumptions in a multiattribute decision problem when the attributes are utility dependent."
1726,"Expert Elicitation of Adversary Preferences Using Ordinal Judgments","Wang, Chen and Bier, Vicki M.","OPERATIONS RESEARCH","61","2","372-385","2013","MAR-APR","","","We introduce a simple elicitation process where subject-matter experts provide only ordinal judgments of the attractiveness of potential targets, and the adversary utility of each target is assumed to involve multiple attributes. Probability distributions over the various attribute weights are then mathematically derived (using either probabilistic inversion or Bayesian density estimation). This elicitation process reduces the burden of time-consuming orientation and training in traditional methods of attribute weight elicitation, and explicitly captures the existing uncertainty and disagreement among experts, rather than attempts to achieve consensus by eliminating them. We identify the relationship between the two methods and conduct sensitivity analysis to elucidate how these methods handle expert consensus or disagreement. We also present a real-world application on elicitation of adversarial preferences over various attack scenarios to show the applicability of our proposed methods."
1727,"A General Framework for Designing Approximation Schemes for Combinatorial Optimization Problems with Many Objectives Combined into One","Mittal, Shashi and Schulz, Andreas S.","OPERATIONS RESEARCH","61","2","386-397","2013","MAR-APR","","","In this paper, we present a general framework for designing approximation schemes for combinatorial optimization problems in which the objective function is a combination of more than one function. Examples of such problems include those in which the objective function is a product or ratio of two linear functions, parallel machine scheduling problems with the makespan objective, robust versions of weighted multiobjective optimization problems, and assortment optimization problems with logit choice models. The main idea behind our approximation schemes is the construction of an approximate Pareto-optimal frontier of the functions that constitute the given objective. Using this idea, we give the first fully polynomial-time approximation schemes for the max-min resource allocation problem with a fixed number of agents, combinatorial optimization problems in which the objective function is the sum of a fixed number of ratios of linear functions, or the product of a fixed number of linear functions, and assortment optimization problems with logit choice model."
1728,"Balance Optimization Subset Selection (BOSS): An Alternative Approach for Causal Inference with Observational Data","Nikolaev, Alexander G. and Jacobson, Sheldon H. and Cho, Wendy K. Tam and Sauppe, Jason J. and Sewell, Edward C.","OPERATIONS RESEARCH","61","2","398-412","2013","MAR-APR","","","Scientists in all disciplines attempt to identify and document causal relationships. Those not fortunate enough to be able to design and implement randomized control trials must resort to observational studies. To make causal inferences outside the experimental realm, researchers attempt to control for bias sources by postprocessing observational data. Finding the subset of data most conducive to unbiased or least biased treatment effect estimation is a challenging, complex problem. However, the rise in computational power and algorithmic sophistication leads to an operations research solution that circumvents many of the challenges presented by methods employed over the past 30 years."
1729,"A Linear Programming Approach to Nonstationary Infinite-Horizon Markov Decision Processes","Ghate, Archis and Smith, Robert L.","OPERATIONS RESEARCH","61","2","413-425","2013","MAR-APR","","","Nonstationary infinite-horizon Markov decision processes (MDPs) generalize the most well-studied class of sequential decision models in operations research, namely, that of stationary MDPs, by relaxing the restrictive assumption that problem data do not change over time. Linear programming (LP) has been very successful in obtaining structural insights and devising solution methods for stationary MDPs. However, an LP approach for nonstationary MDPs is currently missing. This is because the LP formulation of a nonstationary infinite-horizon MDP includes countably infinite variables and constraints, and research on such infinite-dimensional LPs has traditionally faced several hurdles. For instance, duality results may not hold; an extreme point may not be a basic feasible solution; and in the context of a simplex algorithm, a pivot operation may require infinite data and computations, and a sequence of improving extreme points need not converge in value to optimal In this paper, we tackle these challenges and establish (1) weak and strong duality, (2) complementary slackness, (3) a basic feasible solution characterization of extreme points, (4) a one-to-one correspondence between extreme points and deterministic Markovian policies, and (5) we devise a simplex algorithm for an infinite-dimensional LP formulation of nonstationary infinite-horizon MDPs. Pivots in this simplex algorithm use finite data, perform finite computations, and generate a sequence of improving extreme points that converges in value to optimal. Moreover, this sequence of extreme points gets arbitrarily close to the set of optimal extreme points. We also prove that decisions prescribed by these extreme points are eventually exactly optimal in all states of the nonstationary infinite-horizon MDP in early periods."
1730,"Weight Restrictions and Free Production in Data Envelopment Analysis","Podinovski, Victor V. and Bouzdine-Chameeva, Tatiana","OPERATIONS RESEARCH","61","2","426-437","2013","MAR-APR","","","It is known that the incorporation of weight restrictions in models of data envelopment analysis may result in their infeasibility. In our paper we investigate this effect in detail. We show that the infeasibility is only one of several possible outcomes that point to a particular problem with weight restrictions. For example, the use of weight restrictions may also lead to zero or negative efficiency scores of some units. Removing problematic units from the data set does not necessarily remove the underlying problem caused by the weight restrictions and only makes it undetected. We prove that all such problems arise when weight restrictions induce free or unlimited production of outputs in the underlying technology. This is unacceptable from the production theory point of, view and indicates that the weight restrictions need reassessing. We develop analytical criteria and computational methods that allow us to identify the above problematic situations."
1731,"Probabilistic Set Covering with Correlations","Ahmed, Shabbir and Papageorgiou, Dimitri J.","OPERATIONS RESEARCH","61","2","438-452","2013","MAR-APR","","","We consider two variants of a probabilistic set covering (PSC) problem. The first variant assumes that there is uncertainty regarding whether a selected set can cover an item, and the objective is to determine a minimum-cost combination of sets so that each item is covered with a prespecified probability. The second variant seeks to maximize the minimum probability that a selected set can cover all items. To date, literature on this problem has focused on the special case in which uncertainties are independent. In this paper, we formulate deterministic mixed-integer programming models for distributionally robust PSC problems with correlated uncertainties. By exploiting the supermodularity of certain substructures and analyzing their polyhedral properties, we develop strong valid inequalities to strengthen the formulations. Computational results illustrate that our modeling approach can outperform formulations in which correlations are ignored and that our algorithms can significantly reduce overall computation time."
1732,"The Implicit Hitting Set Approach to Solve Combinatorial Optimization Problems with an Application to Multigenome Alignment","Moreno-Centeno, Erick and Karp, Richard M.","OPERATIONS RESEARCH","61","2","453-468","2013","MAR-APR","","","We develop a novel framework, the implicit hitting set approach, for solving a class of combinatorial optimization problems. The explicit hitting set problem is as follows: given a set U and a family S of subsets of U, find a minimum-cardinality set that intersects (hits) every set in S. In the implicit hitting set problem (IHSP), the family of subsets S is not explicitly listed (its size is, generally, exponential in terms of the size of U); instead, it is given via a polynomial-time oracle that verifies if a given set H is a hitting set or returns a set in S that is not hit by H. Many NP-hard problems can be straightforwardly formulated as implicit hitting set problems. We show that the implicit hitting set approach is valuable in developing exact and heuristic algorithms for solving this class of combinatorial optimization problems. Specifically, we provide a generic algorithmic strategy, which combines efficient heuristics and exact methods, to solve any IHSP. Given an instance of an IHSP, the proposed algorithmic strategy gives a sequence of feasible solutions and lower bounds on the optimal solution value and ultimately yields an optimal solution. We specialize this algorithmic strategy to solve the multigenome alignment problem and present computational results that illustrate the effectiveness of the implicit hitting set approach."
1733,"Basis Paths and a Polynomial Algorithm for the Multistage Production-Capacitated Lot-Sizing Problem","Hwang, Hark-Chin and Ahn, Hyun-Soo and Kaminsky, Philip","OPERATIONS RESEARCH","61","2","469-482","2013","MAR-APR","","","We consider the multilevel lot-sizing problem with production capacities (MLSP-PC), in which production and transportation decisions are made for a serial supply chain with capacitated production and concave cost functions. Existing approaches to the multistage version of this problem are limited to nonspeculative cost functions-up to now, no algorithm for the multistage version of this model with general concave cost functions has been developed. In this paper, we develop the first polynomial algorithm for the MLSP-PC with general concave costs at all of the stages, and we introduce a novel approach to overcome the limitations of previous approaches. In contrast to traditional approaches to lot-sizing problems, in which the problem is decomposed by time periods and is analyzed unidirectionally in time, we solve the problem by introducing the concept of a basis path, which is characterized by time and stage. Our dynamic programming algorithm proceeds both forward and backward in time along this basis path, enabling us to solve the problem in polynomial time."
1734,"LP Bounds in an Interval-Graph Algorithm for Orthogonal-Packing Feasibility","Belov, Gleb and Rohling, Heide","OPERATIONS RESEARCH","61","2","483-497","2013","MAR-APR","","","We consider the feasibility problem OPP (orthogonal packing problem) in higher-dimensional orthogonal packing: given a set of d-dimensional (d >= 2) rectangular items, decide whether all of them can be orthogonally packed in the given rectangular container without rotation. The one-dimensional (1D) bar LP relaxation of OPP reduces the latter to a 1D cutting-stock problem where the packing of each stock bar represents a possible 1D stitch through an OPP layout. The dual multipliers of the LP provide us with another kind of powerful bounding information (conservative scales). We investigate how the set of possible 1D packings can be tightened using the overlapping information of item projections on the axes, with the goal to tighten the relaxation. We integrate the bar relaxation into an interval-graph algorithm for OPP, which operates on such overlapping relations. Numerical results on 2D and 3D instances demonstrate the efficiency of tightening leading to a speedup and stabilization of the algorithm."
1735,"On a Level-Set Characterization of the Value Function of an Integer Program and Its Application to Stochastic Programming","Trapp, Andrew C. and Prokopyev, Oleg A. and Schaefer, Andrew J.","OPERATIONS RESEARCH","61","2","498-511","2013","MAR-APR","","","We propose a level-set approach to characterize the value function of a pure linear integer program with inequality constraints. We study theoretical properties of our characterization and show how they can be exploited to optimize a class of stochastic integer programs through a value function reformulation. Specifically, we develop algorithmic approaches that solve two-stage multidimensional knapsack problems with random budgets, yielding encouraging computational results."
1736,"Enhancing Stochastic Kriging Metamodels with Gradient Estimators","Chen, Xi and Ankenman, Bruce E. and Nelson, Barry L.","OPERATIONS RESEARCH","61","2","512-528","2013","MAR-APR","","","Stochastic kriging is a new metamodeling technique for effectively representing the mean response surface implied by a stochastic simulation; it takes into account both stochastic simulation noise and uncertainty about the underlying response surface of interest. We show theoretically, through some simplified models, that incorporating gradient estimators into stochastic kriging tends to significantly improve surface prediction. To address the issue of which type of gradient estimator to use, when there is a choice, we briefly review stochastic gradient estimation techniques; we then focus on the properties of infinitesimal perturbation analysis and likelihood ratio/score function gradient estimators and make recommendations. To conclude, we use simulation experiments with no simplifying assumptions to demonstrate that the use of stochastic kriging with gradient estimators provides more reliable prediction results than stochastic kriging alone."
1737,"OR Forum-Quantum Mechanics and Human Decision Making","Agrawal, Paras M. and Sharda, Ramesh","OPERATIONS RESEARCH","61","1","1-16","2013","JAN-FEB","","","In physics, at the beginning of the twentieth century it was recognized that some experiments could not be explained by the conventional classical mechanics, but the same could be explained by the newly discovered quantum theory. It resulted in a new mechanics called quantum mechanics that revolutionized scientific and technological developments. Again, at the beginning of the twenty-first century, it is being recognized that some experiments related to the human decision-making processes could not be explained by the conventional classical decision theory but the same could be explained by the models based on quantum mechanics. It is now recognized that we need quantum mechanics in psychology as well as in economics and finance. In this paper we attempt to advance and explain the present understanding of applicability of quantum mechanics to the human decision-making processes. Using the postulates analogous to the postulates of quantum mechanics, we show the derivation of the quantum interference equation to illustrate the quantum approach. The explanation of disjunction effect experiments of Tversky and Shafir (Tversky A, Shafir E (1992) The disjunction effect in choice under uncertainty. Psych. Sci. 3(5): 305-309) has been chosen to demonstrate the necessity of a quantum model. Further, to suggest the possibility of application of the quantum theory to the business-related decisions, some terms such as price operator, state of mind of the acquiring firm, etc., are introduced and discussed in context of the merger/acquisition of business firms. The possibility of the development in areas such as quantum finance, quantum management, application of quantum mechanics to the human dynamics related to healthcare management, etc., is also indicated."
1738,"Data Quality of Query Results with Generalized Selection Conditions","Dey, Debabrata and Kumar, Subodha","OPERATIONS RESEARCH","61","1","17-31","2013","JAN-FEB","","","Information systems play a very important role in managerial decision making within modern organizations. While making different types of decisions (at operational, tactical, and strategic levels), managers are increasingly relying on information gleaned from various databases, data warehouses, and data streams feeding them. The quality of organizational decisions, therefore, often depends on the quality of the information derived from these databases and data streams, and a manager is able to make better use of the information if she also understands the quality level of that information. Previous research has examined how the quality level of a database query output can be estimated based on the quality level of the input data. In this research, we generalize this stream of research and allow a query to have general selection conditions involving multiple attributes with any combination of conjunction or disjunction of subconditions that may include functions of multiple attributes. Results of this research can easily be implemented in real-world decision contexts."
1739,"When Is the Right Time to Refresh Knowledge Discovered from Data?","Fang, Xiao and Sheng, Olivia R. Liu and Goes, Paulo","OPERATIONS RESEARCH","61","1","32-44","2013","JAN-FEB","","","Knowledge discovery in databases (KDD) techniques have been extensively employed to extract knowledge from massive data stores to support decision making in a wide range of critical applications. Maintaining the currency of discovered knowledge over evolving data sources is a fundamental challenge faced by all KDD applications. This paper addresses the challenge from the perspective of deciding the right times to refresh knowledge. We define the knowledge-refreshing problem and model it as a Markov decision process. Based on the identified properties of the Markov decision process model, we establish that the optimal knowledge-refreshing policy is monotonically increasing in the system state within every appropriate partition of the state space. We further show that the problem of searching for the optimal knowledge-refreshing policy can be reduced to the problem of finding the optimal thresholds and propose a method for computing the optimal knowledge-refreshing policy. The effectiveness and the robustness of the computed optimal knowledge-refreshing policy are examined through extensive empirical studies addressing a real-world knowledge-refreshing problem. Our method can be applied to refresh knowledge for KDD applications that employ major data-mining models."
1740,"Building Reliable Air-Travel Infrastructure Using Empirical Data and Stochastic Models of Airline Networks","Arikan, Mazhar and Deshpande, Vinayak and Sohoni, Milind","OPERATIONS RESEARCH","61","1","45-64","2013","JAN-FEB","","","Flight delays have been a growing issue and they have reached an all-time high in recent years, with the airlines' on-time performance at its worst level in 2007 since 1995. A recent report by the Joint Economic Committee of the U. S. Congress chaired by Senator Charles E. Schumer has estimated that the total cost to the U. S. economy because of flight delays was as much as $41 billion in 2007. The goal of this paper is to build stochastic models of airline networks and utilize publicly available data to answer the following policy questions: Which are the bottleneck airports in the U. S. air-travel infrastructure (i.e., airports that cause most delay propagation)? How would increasing airport capacity at these airports alleviate delay propagation? What are the appropriate metrics for measuring the robustness of airline schedules? How could these schedules be made more robust? Which flight in an aircraft rotation is a bottleneck flight (and, hence, deserves managerial attention)? Flight delays are typically attributed to two factors: (i) the randomness in the intrinsic travel time for a scheduled flight (which is the travel time excluding propagated delays), and (ii) the propagation of this randomness through the air-travel network and infrastructure. We model both of these factors that cause travel delays. The contribution of this paper is twofold. First, we develop stochastic models, using empirical data, to analyze the propagation of delays through air-transportation networks. Our stochastic models allow us to develop three important robustness measures for airline networks. Second, our analysis enables us to make policy recommendations regarding managing bottleneck resources in the air-travel infrastructure, which, if addressed, could lead to a significant improvement in air-travel reliability."
1741,"Technical Note-Managing a Secret Project","Pinker, Edieal and Szmerekovsky, Joseph and Tilson, Vera","OPERATIONS RESEARCH","61","1","65-72","2013","JAN-FEB","","","We study project scheduling in a competitive setting taking the perspective of a project manager with an adversary, using a Stackelberg game format. The project manager seeks to limit the adversary's opportunity to react to the project and therefore wants to manage the project in a way that keeps the adversary in the dark as long as possible while completing the project on time. We formulate and illustrate a new form of project management problem for secret projects where the project manager uses a combination of deception, task scheduling, and crashing to minimize the time between when the adversary initiates a response to the project to when the project is completed. We propose a novel mixed-integer linear programming formulation for the problem and determine characteristics of optimal schedules in this context. Using a detailed example of nuclear weapons development, we illustrate the interconnectedness of the deception, task scheduling, and crashing, and how these influence adversary behavior."
1742,"Fairness, Efficiency, and Flexibility in Organ Allocation for Kidney Transplantation","Bertsimas, Dimitris and Farias, Vivek F. and Trichakis, Nikolaos","OPERATIONS RESEARCH","61","1","73-87","2013","JAN-FEB","","","We propose a scalable, data-driven method for designing national policies for the allocation of deceased donor kidneys to patients on a waiting list in a fair and efficient way. We focus on policies that have the same form as the one currently used in the United States. In particular, we consider policies that are based on a point system that ranks patients according to some priority criteria, e. g., waiting time, medical urgency, etc., or a combination thereof. Rather than making specific assumptions about fairness principles or priority criteria, our method offers the designer the flexibility to select his desired criteria and fairness constraints from a broad class of allowable constraints. The method then designs a point system that is based on the selected priority criteria and approximately maximizes medical efficiency-i.e., life-year gains from transplant-while simultaneously enforcing selected fairness constraints. Among the several case studies we present employing our method, one case study designs a point system that has the same form, uses the same criteria, and satisfies the same fairness constraints as the point system that was recently proposed by U. S. policy makers. In addition, the point system we design delivers an 8% increase in extra life-year gains. We evaluate the performance of all policies under consideration using the same statistical and simulation tools and data as the U. S. policy makers use. Other case studies perform a sensitivity analysis (for instance, demonstrating that the increase in extra life-year gains by relaxing certain fairness constraints can be as high as 30%) and also pursue the design of policies targeted specifically at remedying criticisms leveled at the recent point system proposed by U. S. policy makers."
1743,"Technical Note-Optimal Inventory Policy in the Presence of a Long-Term Supplier and a Spot Market","Chen, Youhua (Frank) and Xue, Weili and Yang, Jian","OPERATIONS RESEARCH","61","1","88-97","2013","JAN-FEB","","","We consider a stochastic inventory control problem in which a buyer makes procurement decisions while facing periodic random demand and two supply sources, namely, a long-term contract supplier and a spot market. The contract between the buyer and the supplier partially shields the latter from the vicissitudes of the spot market, in that the price paid by the buyer to the supplier is only partially linked to the spot price at the moment. After fulfilling the minimum-order commitment with the supplier, the buyer has the full freedom to source from both the supplier and the market. Procurement from the spot market also incurs a fixed setup cost. We show that an optimal policy consists of three different policy forms, with the realization of each depending on the buyer's inventory level and the prevalent spot price. Certain conditions are identified under which monotone trends exist between policy parameters and the current spot price."
1744,"Dynamic Pay-Per-Action Mechanisms and Applications to Online Advertising","Nazerzadeh, Hamid and Saberi, Amin and Vohra, Rakesh","OPERATIONS RESEARCH","61","1","98-111","2013","JAN-FEB","","","We examine the problem of allocating an item repeatedly over time amongst a set of agents. The value that each agent derives from consumption of the item may vary over time. Furthermore, it is private information to the agent, and prior to consumption it may be unknown to that agent. We describe a mechanism based on a sampling-based learning algorithm that under suitable assumptions is asymptotically individually rational, asymptotically Bayesian incentive compatible, and asymptotically ex ante efficient. Our mechanism can be interpreted as a pay-per-action or pay-per-acquisition (PPA) charging scheme in online advertising. In this scheme, instead of paying per click, advertisers pay only when a user takes a specific action (e. g., purchases an item or fills out a form) on their websites."
1745,"Allocating Cost of Service to Customers in Inventory Routing","Ozener, Okan Orsan and Ergun, Ozlem and Savelsbergh, Martin","OPERATIONS RESEARCH","61","1","112-125","2013","JAN-FEB","","","Vendor-managed inventory (VMI) replenishment is a collaboration between a supplier and its customers, where the supplier is responsible for managing the customers' inventory levels. In the VMI setting we consider, the supplier exploits synergies between customers, e. g., their locations, usage rates, and storage capacities, to reduce distribution costs. Due to the intricate interactions between customers, calculating a fair cost-to-serve for each customer is a daunting task. However, cost-to-serve information is useful when marketing to new customers or when revisiting routing and delivery quantity decisions. We design mechanisms for this cost allocation problem and determine their characteristics both analytically and computationally."
1746,"Risk Aversion, Indivisible Timing Options, and Gambling","Henderson, Vicky and Hobson, David","OPERATIONS RESEARCH","61","1","126-137","2013","JAN-FEB","","","In this paper we model the behavior of a risk-averse agent who seeks to maximize expected utility and who has an indivisible asset and a timing option over when to sell this asset. Our main contribution is to show that, contrary to intuition, optimal behavior for such a risk-averse agent can include risk-increasing gambles. For example, a manager with a choice over when to disinvest from a project, a private homeowner with a property to sell, or an employee with a grant of American-style stock options may be better off taking positions in other assets with zero Sharpe ratio that are uncorrelated with the underlying project, house, or stock price risk. The results have wider implications for the modeling and interpretation of portfolio optimization problems involving American-style timing decisions."
1747,"Rollout Policies for Dynamic Solutions to the Multivehicle Routing Problem with Stochastic Demand and Duration Limits","Goodson, Justin C. and Ohlmann, Jeffrey W. and Thomas, Barrett W.","OPERATIONS RESEARCH","61","1","138-154","2013","JAN-FEB","","","We develop a family of rollout policies based on fixed routes to obtain dynamic solutions to the vehicle routing problem with stochastic demand and duration limits (VRPSDL). In addition to a traditional one-step rollout policy, we leverage the notions of the pre- and post-decision state to distinguish two additional rollout variants. We tailor our rollout policies by developing a dynamic decomposition scheme that achieves high quality solutions to large problem instances with reasonable computational effort. Computational experiments demonstrate that our rollout policies improve upon the performance of a rolling horizon procedure and commonly employed fixed-route policies, with improvement over the latter being more substantial."
1748,"Distributed Welfare Games","Marden, Jason R. and Wierman, Adam","OPERATIONS RESEARCH","61","1","155-168","2013","JAN-FEB","","","Game-theoretic tools are becoming a popular design choice for distributed resource allocation algorithms. A central component of this design choice is the assignment of utility functions to the individual agents. The goal is to assign each agent an admissible utility function such that the resulting game possesses a host of desirable properties, including scalability, tractability, and existence and efficiency of pure Nash equilibria. In this paper we formally study this question of utility design on a class of games termed distributed welfare games. We identify several utility design methodologies that guarantee desirable game properties irrespective of the specific application domain. Lastly, we illustrate the results in this paper on two commonly studied classes of resource allocation problems: coverage problems and coloring problems."
1749,"Computing the Nondominated Surface in Tri-Criterion Portfolio Selection","Hirschberger, Markus and Steuer, Ralph E. and Utz, Sebastian and Wimmer, Maximilian and Qi, Yue","OPERATIONS RESEARCH","61","1","169-183","2013","JAN-FEB","","","Computing the nondominated set of a multiple objective mathematical program has long been a topic in multiple criteria decision making. In this paper, motivated by the desire to extend Markowitz portfolio selection to an additional linear criterion (dividends, liquidity, sustainability, etc.), we demonstrate an exact method for computing the nondominated set of a tri-criterion program that is all linear except for the fact that one of its objectives is to minimize a convex quadratic function. With the nondominated set of the resulting quad-lin-lin program being a surface composed of curved platelets, a multiparametric algorithm is devised for computing the platelets so that they can be graphed precisely. In this way, graphs of the tri-criterion nondominated surface can be displayed so that, as in traditional portfolio selection, a most preferred portfolio can be selected while in full view of all other contenders for optimality. Finally, by giving an example for socially responsible investors, we demonstrate that our algorithm can outperform standard portfolio strategies for multicriterial decision makers."
1750,"A Polynomial Time Algorithm for Rayleigh Ratio on Discrete Variables: Replacing Spectral Techniques for Expander Ratio, Normalized Cut, and Cheeger Constant","Hochbaum, Dorit S.","OPERATIONS RESEARCH","61","1","184-198","2013","JAN-FEB","","","A general form of minimizing the Rayleigh ratio on discrete variables is shown here, for the first time, to be polynomial time solvable. This is significant because major problems in clustering, partitioning, and imaging can be presented as the Rayleigh ratio minimization on discrete variables and an orthogonality constraint. These challenging problems are modeled as the normalized cut problem, the graph expander ratio problem, the Cheeger constant problem, or the conductance problem, all of which are NP-hard. These problems have traditionally been solved, heuristically, using the spectral technique. A unified framework is provided here whereby all these problems are formulated as a constrained minimization form of a quadratic ratio, referred to here as the Rayleigh ratio. The quadratic ratio is to be minimized on discrete variables and a single sum constraint that we call the balance or orthogonality constraint. When the discreteness constraints on the variables are disregarded, the resulting continuous relaxation is solved by the spectral method. It is shown here that the Rayleigh ratio minimization subject to the discreteness constraints requiring each variable to assume one of two values in {-b, 1} is solvable in strongly polynomial time, equivalent to a single minimum s, t cut algorithm on a graph of same size as the input graph, for any nonnegative value of b. This discrete form for the Rayleigh ratio problem was often assumed to be NP-hard. Not only is it shown here that the discrete Rayleigh ratio problem is polynomial time solvable, but also the algorithm is more efficient than the spectral algorithm. Furthermore, an experimental study demonstrates that the new algorithm provides in practice an improvement, often dramatic, on the quality of the results of the spectral method, both in terms of approximating the true optimum of the Rayleigh ratio problem on both the discrete variables and the balance constraint, and in terms of the subjective partition quality. A further contribution here is the introduction of a problem, the quantity-normalized cut, generalizing all the Rayleigh ratio problems. The discrete version of that problem is also solved with the efficient algorithm presented. This problem is shown, in a companion paper, to enable the modeling of features essential to clustering that are valuable in practical applications."
1751,"Design of Survivable Networks Using Three- and Four-Partition Facets","Agarwal, Yogesh","OPERATIONS RESEARCH","61","1","199-213","2013","JAN-FEB","","","This paper considers the problem of designing a multicommodity network with single facility type subject to the requirement that under failure of any single edge, the network should permit a feasible flow of all traffic. We study the polyhedral structure of the problem by considering the multigraph obtained by shrinking the nodes, but not the edges, in a k-partition of the original graph. A key theorem is proved according to which a facet of the k-node problem defined on the multigraph resulting from a k-partition is also facet defining for the larger problem under a mild condition. After reviewing the prior work on two-partition inequalities, we develop two classes of three-partition inequalities and a large number of inequality classes based on four-partitions. Proofs of facet-defining status for some of these are provided, while the rest are stated without proof. Computational results show that the addition of three-and four-partition inequalities results in substantial increase in the bound values compared to those possible with two-partition inequalities alone. Problems of 35 nodes and 80 edges with fully dense traffic matrices have been solved optimally within a few minutes of computer time."
1752,"Multiple Objectives Satisficing Under Uncertainty","Lam, Shao-Wei and Tsan Sheng Ng and Sim, Melvyn and Song, Jin-Hwa","OPERATIONS RESEARCH","61","1","214-227","2013","JAN-FEB","","","We propose a class of functions, called multiple objective satisficing (MOS) criteria, for evaluating the level of compliance of a set of objectives in meeting their targets collectively under uncertainty. The MOS criteria include the joint targets' achievement probability (joint success probability criterion) as a special case and also extend to situations when the probability distributions are not fully characterized. We focus on a class of MOS criteria that favors diversification, which has the potential to mitigate severe shortfalls in scenarios when any objective fails to achieve its target. Naturally, this class excludes joint success probability. We further propose the shortfall-aware MOS criterion (S-MOS), which is inspired by the probability measure and is diversification favoring. We also show how to build tractable approximations of the S-MOS criterion. Because the S-MOS criterion maximization is not a convex optimization problem, we propose improvement algorithms via solving sequences of convex optimization problems. We report encouraging computational results on a blending problem in meeting specification targets even in the absence of full probability distribution description."
1753,"Blind Fair Routing in Large-Scale Service Systems with Heterogeneous Customers and Servers","Ward, Amy R. and Armony, Mor","OPERATIONS RESEARCH","61","1","228-243","2013","JAN-FEB","","","In a call center, arriving customers must be routed to available servers, and servers that have just become available must be scheduled to help waiting customers. These dynamic routing and scheduling decisions are very difficult, because customers have different needs and servers have different skill levels. A further complication is that it is preferable that these decisions are made blindly; that is, they depend only on the system state and not on system parameter information such as call arrival rates and service speeds. This is because this information is generally not known with certainty. Ideally, a dynamic control policy for making routing and scheduling decisions balances customer and server needs by keeping customer delays low but still fairly dividing the workload amongst the various servers. In this paper, we propose a blind dynamic control policy for parallel-server systems with multiple customer classes and server pools that is based on the number of customers waiting and the number of agents idling. We show that in the Halfin-Whitt many-server heavy-traffic limiting regime, our proposed blind policy performs extremely well when the objective is to minimize customer holding costs subject to server fairness, as defined by how the system idleness is divided among servers. To do this, we formulate an approximating diffusion control problem (DCP) and compare the performance of the nonblind DCP solution to a feasible policy for the DCP that is blind. We establish that the increase in the DCP objective function value is small over a wide range of parameter values. We then use simulation to validate that a small increase in the DCP objective function value is indicative of our proposed blind policy performing very well."
1754,"Redundancy Optimization for Critical Components in High-Availability Technical Systems","Oener, Kurtulus Baris and Scheller-Wolf, Alan and van Houtum, Geert-Jan","OPERATIONS RESEARCH","61","1","244-264","2013","JAN-FEB","","","We consider a user who buys a number of identical technical systems (e. g., medical, manufacturing, or communication systems) for which she must have very high availability. In such a situation, there are typically several options that the user can choose to facilitate this availability: cold standby redundancy for critical components, buying spare parts with the systems so failed parts can be replaced quickly, and/or application of an emergency procedure to expedite repairs when there is a stock out. To these options we introduce another: the possibility of initiating an emergency shipment when stock is one. Thus, the user may choose different combinations of the redundancy decision and the timing of applications of the emergency procedure, as well as how much spare parts inventory to purchase. We formulate the problem as the minimization of the total costs-acquisition, spare parts, and repair-incurred for the systems over their lifetimes, under a constraint for the total uptime of all systems. We optimally solve the problem by decomposing the multicomponent problem into single-component problems and then conducting exact analysis on these single-component problems. Using these, we construct an efficient frontier that reflects the trade-off between the uptime and the total costs of the systems. In addition, we provide a method to rank the components by the relative value of investing in redundancy. We illustrate these results through numerical examples."
1755,"OR Forum-Intelligence Operations Research: The 2010 Philip McCord Morse Lecture","Kaplan, Edward H.","OPERATIONS RESEARCH","60","6","1297-1309","2012","NOV-DEC","","","This paper is the archival record of the INFORMS Philip McCord Morse Lecture delivered in 2010. It considers applications of operations research to intelligence problems in national security and counterterrorism. The phrase intelligence operations research can be interpreted in two different ways: as intelligence operations research, meaning studies to characterize and improve the operations of intelligence agencies themselves, and as intelligence operations research, meaning the application of operations research methods to specific substantive intelligence problems. After defining intelligence, I review the intelligence production process (or the intelligence cycle) with reference to the intelligence community of the United States. I then consider the extent to which operations research has been deployed inside this intelligence community and summarize previous attempts to apply operations research methods to intelligence problems. I close with some suggestions for future intelligence operations research studies. Subject classifications: intelligence; national security; counterterrorism; intelligence operations. Area of review: OR Forum. History: Received August 2010; revision received March 2011; accepted February 2012. Published online in Articles in Advance July 3, 2012."
1756,"A Hierarchical Framework for Organizing a Software Development Process","Iravani, Foad and Dasu, Sriram and Ahmadi, Reza","OPERATIONS RESEARCH","60","6","1310-1322","2012","NOV-DEC","","","Every year, companies that produce commercial tax preparation software struggle with thousands of state and federal changes to tax laws and forms. Three competitors dominate the market with its short selling season, and release delays slash profits. Tax authorities issue updates August December, and all changes must be processed and incorporated before year end. Systematic resource allocation and process manageinent are crucial yet problematic due to the volume and complexity of changes, brief production time frame, and feedback loops for bug resolution. A leading tax software provider asked us to propose systematic approaches for managing process flow and staffing development stages with the goal of releasing the new version on time at minimum cost. To that end, we developed deterministic models that partitioned tax forms into development groups and determined staffing levels for each group. Partitioning forms into groups simplified workflow management and staffing decisions. To provide a range of resource configurations, we used two modeling approaches. Numerical experiments showed that our models capture the salient features of the process and that our heuristics perform well. Implementing our models reduced company overtime hours by 31% and total workforce cost by 13%. Subject classifications: product development; software development; tax software; workforce management; resource allocation grouping index; integer programming. Area of review: OR Practice. History: Received February 2011; revisions received October 2011, May 2012; accepted June 2012. Published online in Articles in Advance November 20, 2012."
1757,"Optimizing Intensive Care Unit Discharge Decisions with Patient Readmissions","Chan, Carri W. and Farias, Vivek F. and Bambos, Nicholas and Escobar, Gabriel J.","OPERATIONS RESEARCH","60","6","1323-1341","2012","NOV-DEC","","","This work examines the impact of discharge decisions under uncertainty in a capacity-constrained high-risk setting: the intensive care unit (ICU). New arrivals to an ICU are typically very high-priority patients and, should the ICU be full upon their arrival, discharging a patient currently residing in the ICU may be required to accommodate a newly admitted patient. Patients so discharged risk physiologic deterioration, which might ultimately require readmission; models of these risks are currently unavailable to providers. These readmissions in turn impose an additional load on the capacity-limited ICU resources. We study the impact of several different ICU discharge strategies on patient mortality and total readmission load. We focus on discharge rules that prioritize patients based on some measure of criticality assuming the availability of a model of readmission risk. We use empirical data from over 5,000 actual ICU patient flows to calibrate our model. The empirical study suggests that a predictive model of the readmission risks associated with discharge decisions, in tandem with simple index policies of the type proposed, can provide very meaningful throughput gains in actual ICUs while at the same time maintaining, or even improving upon, mortality rates. We explicitly provide a discharge policy that accomplishes this. In addition to our empirical work, we conduct a rigorous performance analysis for the family of discharge policies we consider. We show that our policy is optimal in certain regimes, and is otherwise guaranteed to incur readmission related costs no larger than a factor of ((p) over cap +1) of an optimal discharge strategy, where (p) over cap is a certain natural measure of system utilization. Subject classifications: dynamic programming; healthcare; approximation algorithms. Area of review: Policy Modeling and Public Sector OR. History: Received October 2009; revisions received May 2010, December 2010, August 2011, February 2012, April 2012; accepted July 2012."
1758,"Safe Dike Heights at Minimal Costs: The Nonhomogeneous Case","Brekelmans, Ruud and den Hertog, Dick and Roos, Kees and Eijgenraam, Carel","OPERATIONS RESEARCH","60","6","1342-1355","2012","NOV-DEC","","","Dike height optimization is of major importance to the Netherlands because a large part of the country lies below sea level, and high water levels in rivers can cause floods. Recently impovements have been made on the cost-benefit model introduced by van Dantzig after the devastating flood in the Netherlands in 1953. We consider the extension of this model to nonhomogeneous dike rings, which may also be applicable to other deltas in the world. A nonhomogeneous dike ring consists of different segments with different characteristics with respect to flooding and investment costs. The individual segments can be heightened independently at different moments in time and by different amounts, making the problem considerably more complex than the homogeneous case. We show how the problem can be modeled as a mixed-integer nonlinear programming problem, and we present an iterative algorithm that can be used to solve the problem. Moreover, we consider a robust optimization approach to deal with uncertainty in the model parameters. The method has been implemented and integrated in software, which is used by the government to determine how the safety standards in the Dutch Water Act should be changed. Subject classifications: flood prevention; MINLP; cost-benefit analysis; robust optimization. Area of review: Special Issue on OR for the Public Interest-Security and Critical Infrastructure. History: Received September 2010; revisions received April 2011, June 2011; accepted August 2011. Published online in Articles in Advance November 20, 2012."
1759,"Pattern-Based Modeling and Solution of Probabilistically Constrained Optimization Problems","Lejeune, Miguel A.","OPERATIONS RESEARCH","60","6","1356-1372","2012","NOV-DEC","","","We propose a new modeling and solution method for probabilistically constrained optimization problems. The methodology is based on the integration of-the stochastic programming and combinatorial pattern recognition fields. It permits the fast solution of stochastic optimization problems in which the random variables are represented by an extremely large number of scenarios. The method involves the binarization of the probability distribution and the generation of a consistent partially defined Boolean function (pdBf) representing the combination (F, p) of the binarized probability distribution F and the enforced probability level p. We show that the pdBf representing (F, p) can be compactly extended as a disjunctive normal form (DNF). The DNF is a collection of combinatorial p-patterns, each defining sufficient conditions for a probabilistic constraint to hold. We propose two linear programming formulations for the generation of p-patterns that can be subsequently used to derive a linear programming inner approximation of the original stochastic problem. A formulation allowing for the concurrent generation of a p-pattern and the solution of the deterministic equivalent of the stochastic problem is also proposed. The number of binary variables included in the deterministic equivalent formulation is not an increasing function of the number of scenarios used to represent uncertainty. Results show that large-scale stochastic problems, in which up to 50,000 scenarios are used to describe the stochastic variables, can be consistently solved to optimality within a few seconds. Subject classifications: programming; stochastic; probability; combinatorial pattern; probabilistic constraint; Boolean programming. Area of review: Games, Information, and Networks. History: Received August 2010; revisions received July 2011, April 2012, June 2012; accepted September 2012."
1760,"Computing Optimal Recovery Policies for Financial Markets","Benth, Fred E. and Dahl, Geir and Mannino, Carlo","OPERATIONS RESEARCH","60","6","1373-1388","2012","NOV-DEC","","","The current financial crisis motivates the study of correlated defaults in financial systems. In this paper we focus on such a model, which is based on Markov random fields. This is a probabilistic model in which uncertainty in default probabilities incorporates experts' opinions on the default risk (based on various credit ratings). We consider a bilevel optimization model for finding an optimal recovery policy: which companies should be supported given a fixed budget. This is closely linked to the problem of finding a maximum likelihood estimator of the defaulting set of agents, and we show how to compute this solution efficiently using combinatorial methods. We also prove properties of such optimal solutions and give a practical procedure for estimation of model parameters. Computational examples are presented, and experiments indicate that our methods can find optimal recovery policies for up to about 100 companies. The overall approach is evaluated on a real-world problem concerning the major banks in Scandinavia and public loans. To our knowledge, this is a first attempt to apply combinatorial optimization techniques to this important and expanding area of default risk analysis. Subject classifications: financial models; discrete optimization; bilevel programming; Markov random field. Area of review: Financial Engineering. History: Received October 2009; revisions received February 2010, December 2010, March 2011; accepted April 2011. Published online in Articles in Advance November 20, 2012."
1761,"Inverse Optimization: A New Perspective on the Black-Litterman Model","Bertsimas, Dimitris and Gupta, Vishal and Paschalidis, Ioannis Ch.","OPERATIONS RESEARCH","60","6","1389-1403","2012","NOV-DEC","","","The Black-Litterman (BL) model is a widely used asset allocation model in the financial industry. In this paper, we provide a new perspective. The key insight is to replace the statistical framework in the original approach with ideas from inverse optimization. This insight allows us to significantly expand the scope and applicability of the BL model. We provide a richer formulation that, unlike the original model, is flexible enough to incorporate investor information on volatility and market dynamics. Equally importantly, our approach allows us to move beyond the traditional mean-variance paradigm of the original model and construct BL-type estimators for more general notions of risk such as coherent risk measures. Computationally, we introduce and study two new BL-type estimators and their corresponding portfolios: a mean variance inverse optimization (MV-IO) portfolio and a robust mean variance inverse optimization (RMV-IO) portfolio. These two approaches are motivated by ideas from arbitrage pricing theory and volatility uncertainty. Using numerical simulation and historical backtesting, we show that both methods often demonstrate a better risk-reward trade-off than their BL counterparts and are more robust to incorrect investor views. Subject classifications: finance: portfolio optimization; programming: inverse optimization; statistics: estimation. Area of review: Financial Engineering. History: Received May 2011; revisions received November 2011, January 2012; accepted June 2012. Published online in Articles in Advance November 20, 2012."
1762,"Clearance Pricing Optimization for a Fast-Fashion Retailer","Caro, Felipe and Gallien, Jeremie","OPERATIONS RESEARCH","60","6","1404-1422","2012","NOV-DEC","","","Fast-fashion retailers such as Zara offer continuously changing assortments and use minimal in-season promotions. Their clearance pricing problem is thus challenging because it involves comparatively more different articles of unsold inventory with less historical price data points. Until 2007, Zara used a manual and informal decision-making process for determining price markdowns. In collaboration with their pricing team, we since designed and implemented an alternative process relying on a formal forecasting model feeding a price optimization model. As part of a controlled field experiment conducted in all Belgian and Irish stores during the 2008 fall-winter season, this new process increased clearance revenues by approximately 6%. Zara is currently using this process worldwide for its markdown decisions during clearance sales. Subject classifications: retailing; markdown pricing; clearance sales; fast-fashion; revenue management; forecasting; field test; model implementation. Area of review: OR Practice. History: Received June 2011; revision received May 2012; accepted June 2012."
1763,"A Little Flexibility Is All You Need: On the Asymptotic Value of Flexible Capacity in Parallel Queuing Systems","Bassamboo, Achal and Randhawa, Ramandeep S. and Van Mieghem, Jan A.","OPERATIONS RESEARCH","60","6","1423-1435","2012","NOV-DEC","","","We analytically study optimal capacity and flexible technology selection in parallel queuing systems. We consider N stochastic arrival streams that may wait in N queues before being processed by one of many resources (technologies) that differ in their flexibility. A resource's ability to process k different arrival types or classes is referred to as level-k flexibility. We determine the capacity portfolio (consisting of all resources at all levels of flexibility) that minimizes linear capacity and linear holding costs in high-volume systems where the arrival rate lambda -> infinity. We prove that a little flexibility is all you need: the optimal portfolio invests O(lambda) in specialized resources and only O(root lambda) in flexible resources and these optimal capacity choices bring the system into heavy traffic. Further, considering symmetric systems (with type-independent parameters), a novel folding methodology allows the specification of the asymptotic queue count process for any capacity portfolio under longest-queue scheduling in closed form that is amenable to optimization. This allows us to sharpen a little flexibility is all you need: the asymptotically optimal flexibility configuration for symmetric systems with mild economies of scope invests a lot in specialized resources but only a little in flexible resources and only in level-2 flexibility, but effectively nothing (o(root lambda)) in level-k > 2 flexibility. We characterize tailored pairing as the theoretical benchmark configuration that maximizes the value of flexibility when demand and service uncertainty are the main concerns. Subject classifications: flexibility; capacity optimization; queueing network; diffusion approximation. Area of review: Manufacturing, Service, and Supply Chain Operations. History: Received June 2009; revisions received November 2010, October 2011, May 2012; accepted July 2012."
1764,"Coordination of Outsourced Operations at a Third-Party Facility Subject to Booking, Overtime, and Tardiness Costs","Cai, Xiaoqiang and Vairaktarakis, George L.","OPERATIONS RESEARCH","60","6","1436-1450","2012","NOV-DEC","","","We consider an outsourcing problem where a group of manufacturers outsource jobs to a single third party who owns a specialized facility needed to process these jobs. The third party announces the time slots available on her facility, and the associated prices. Manufacturers reserve, on a first-come-first-book basis, time slots that they desire to utilize. Booking of overtime is possible, at a higher cost. A job completed after its due date incurs a tardiness cost. Each manufacturer books chunks of facility time and sequences his jobs over the time slots booked to minimize his booking, overtime, and tardiness costs. This model captures the main features of outsourcing operations in industries such as semiconductor manufacturing, biotechnology, and drug R&D. In current practice, the third party executes all outsourced jobs without performing optimization and coordination. We investigate the issue of the third party serving as a coordinator to create a win-win solution for all. We propose a model based on a cooperative game as follows: (i) Upon receiving the booking requests from the manufacturers, the third party derives an optimal solution if manufacturers cooperate, and computes the savings achieved. (ii) She devises a savings sharing scheme so that, in monetary terms, every manufacturer is better off to coordinate than to act independently or coalesce with a subgroup of manufacturers. (iii) For her work, the third party withholds a portion rho of the booking revenue paid by the manufacturers for time slots that are released after coordination. We further design a truth-telling mechanism that can prevent any self-interested manufacturer from purposely reporting false job data to take advantage of the coordination scheme. Finally, we perform a computational experiment to assess the value of coordination to the various parties involved. Subject classifications: outsourcing; scheduling and planning; cooperative game; truth-telling mechanism. Area of review: Operations and Supply Chains. History: Received April 2009; revisions received May 2009, December 2009, February 2012, June 2012; accepted July 2012."
1765,"Valuing Changes in Investment Opportunities","Abbas, Ali E.","OPERATIONS RESEARCH","60","6","1451-1460","2012","NOV-DEC","","","Arrow and Pratt introduced a measure of risk aversion the negative ratio of the second to the first derivative of the utility function. This measure has found widespread use in the valuation of uncertain lotteries and in the calculation of the risk premium of an investment. This paper introduces two new measures for characterizing changes in the valuation of uncertain lotteries when their outcomes are modified by a monotone transformation. The first is a characteristic transformation of a utility function, U. and a monotone transformation, g. The shape of the characteristic transformation determines an upper bound, lower bound, or equality on the magnitude of the certainty equivalent of the modified lottery. The second is a measure of change in certainty equivalent, eta(g), whose sign also determines upper or lower bounds, and whose magnitude determines the change in value of a small-risk lottery when its outcomes are modified by a monotone transformation. For shift (and scale) transformations on the lottery outcomes, both the characteristic transformation and the measure of change, eta(g), provide new characterizations for the notions of decreasing absolute (and relative) risk aversion with wealth. Subject classifications: utility theory; risk attitude; valuation. Area of review: Decision Analysis. History: Received January 2010; revisions received July 2010, January 2011, March 2011, September 2011, January 2012, March 2012; accepted June 2012. Published online in Articles in Advance November 20, 2012."
1766,"Algorithmic Solutions for Envy-Free Cake Cutting","Deng, Xiaotie and Qi, Qi and Saberi, Amin","OPERATIONS RESEARCH","60","6","1461-1476","2012","NOV-DEC","","","We study the problem of finding an envy-free allocation of a cake to d + 1 players using d cuts. Two models are considered, namely, the oracle-function model and the polynomial-time function model. In the oracle-function model, we are interested in the number of times an algorithm has to query the players about their preferences to find an allocation with the envy less than c. We derive a matching lower and upper bound of theta(1/is an element of)(d-1) for players with Lipschitz utilities and any d > 1. In the polynomial-time function model, where the utility functions are given explicitly by polynomial-time algorithms, we show that the envy-free cake-cutting problem has the same complexity as finding a Brouwer's fixed point, or, more formally, it is PPAD-complete. On the flip side, for monotone utility functions, we propose a fully polynomial-time algorithm (FPTAS) to find an approximate envy-free allocation of a cake among three people using two cuts. Subject classifications: fair division; cake cutting; envy-free; FPTAS; fixed point; PPAD. Area of review: Optimization. History: Received April 2010; revisions received March 2011, September 2011; accepted January 2012."
1767,"Base-2 Expansions for Linearizing Products of Functions of Discrete Variables","Adams, Warren P. and Henry, Stephen M.","OPERATIONS RESEARCH","60","6","1477-1490","2012","NOV-DEC","","","This paper presents an approach for representing functions of discrete variables, and their products, using logarithmic numbers of binary variables. Given a univariate function whose domain consists of n distinct values, it begins by employing a base-2 expansion to express the function in terms of the ceiling of log(2) n binary and n continuous variables, using linear restrictions to equate the functional values with the possible binary realizations. The representation of the product of such a function with a nonnegative variable is handled via an appropriate scaling of the linear restrictions. Products of m functions are treated in an inductive manner from i = 2 to m, where each step i uses such a scaling to express the product of function i and a nonnegative variable denoting a translated version of the product of functions 1 through i - 1 as a newly defined variable. The resulting representations, both in terms of one function and many, are important for reformulating general discrete variables as binary, and also for linearizing mixed-integer generalized geometric and discrete nonlinear programs, where it is desired to economize on the number of binary variables. The approach provides insight into, improves upon, and subsumes related linearization methods for products of functions of discrete variables. Subject classifications: programming: integer, nonlinear, theory: Area of review: Optimization. History: Received January 2011; revision received July 2011; accepted October 2011. Published online in Articles in Advance November 20, 2012."
1768,"The Bin Packing Problem with Precedence Constraints","Dell'Amico, Mauro and Diaz, Jose Carlos Diaz and Iori, Manuel","OPERATIONS RESEARCH","60","6","1491-1504","2012","NOV-DEC","","","Given a set of identical capacitated bins, a set of weighted items, and a set of precedences among such items, we are interested in determining the minimum number of bins that can accommodate all items and can be ordered in such a way that all precedences are satisfied. The problem, denoted as the bin packing problem with precedence constraints (BPP-P), has a very intriguing combinatorial structure and models many assembly and scheduling issues. According to our knowledge, the BPP-P has received little attention in the literature, and in this paper we address it for the first time with exact solution methods. In particular, we develop reduction criteria, a large set of lower bounds, a variable neighborhood search upper bounding technique, and a branch-and-bound algorithm. We show the effectiveness of the proposed algorithms by means of extensive computational tests on benchmark instances and comparison with standard integer linear programming techniques. Subject classifications: bin packing problem; precedence constraints; branch-and-bound. Area of review: Optimization. History: Received May 2010; revisions received May 2011, September 2011; accepted November 2011. Published online in Articles in Advance November 20, 2012."
1769,"Congestion-Based Lead-Time Quotation for Heterogenous Customers with Convex-Concave Delay Costs: Optimality of a Cost-Balancing Policy Based on Convex Hull Functions","Akan, Mustafa and Ata, Baris and Olsen, Tava","OPERATIONS RESEARCH","60","6","1505-1519","2012","NOV-DEC","","","We consider a congestible system serving multiple classes of customers who differ in their delay sensitivity and valuation of service (or product). Customers are endowed with convex-concave delay cost functions. A system manager offers a menu of lead times and corresponding prices to arriving customers, who then choose the lead-time price pair that maximizes their net utility (value minus disutility of delay and price). We investigate how such menus should be chosen dynamically (depending on the system backlog) to maximize welfare. We formulate a novel fluid model of the problem and show that the cost-balancing policy (based on the convex hulls of the delay cost functions) is socially optimal if the system manager can tell customer types apart. If types are indistinguishable to the system manager, the cost-balancing policy is also incentive compatible under social optimization. Finally, we show through a simulation study that the cost-balancing policy does well in the context of the original (stochastic) problem by testing it against various natural benchmarks. Subject classifications: stochastic uncertainty; diffusion models; review/lead-times policies. Area of review: Manufacturing, Service, and Supply Chain Operations. History: Received August 2008; revisions received December 2009, November 2010, April 2011; accepted June 2011. Published online in Articles in Advance November 20, 2012."
1770,"Optimality of Myopic Policies for Dynamic Lot-Sizing Problems in Serial Production Lines with Random Yields and Autoregressive Demand","Sobel, Matthew J. and Babich, Volodymyr","OPERATIONS RESEARCH","60","6","1520-1536","2012","NOV-DEC","","","We study lot-size policies in a serial, multistage manufacturing/inventory system with two key generalizations, namely (1) random yields at each production stage and (2) an autoregressive demand process. Previous research shows that the optimal policies in models with random yields (even in models with a single installation) lack the familiar order-up-to structure and are not myopic. Thus, dynamic programming algorithms are needed to compute optimal policies, and one encounters the curse of dimensionality; this is exacerbated here by the need to expand the size and dimension of the state space to accommodate the autoregressive demand feature. Nevertheless, although our model is more complex, we prove that there is an optimal policy with the order-up-to feature and, more importantly, that the optimal policy is myopic. This avoids the computational burden of dynamic programming. Our results depend on two assumptions concerning the stochastic yield, namely that the expected yield at a work station is proportional to the lot size, and the distribution of the deviation of the yield from its mean does not depend on the lot size. We introduce the concept of echelon-like variables, a generalization of Clark and Scarf's classical concept of echelon variables, to derive the structure of optimal policies. Furthermore, we show that the same kind of policy is optimal for several criteria: infinite-horizon discounted cost, infinite-horizon long-run average cost, and finite-horizon discounted cost (with the appropriate choice of the salvage value function)."
1771,"Blind Network Revenue Management","Besbes, Omar and Zeevi, Assaf","OPERATIONS RESEARCH","60","6","1537-1550","2012","NOV-DEC","","","We consider a general class of network revenue management problems, where mean demand at each point in time is determined by a vector of prices, and the objective is to dynamically adjust these prices so as to maximize expected revenues over a finite sales horizon. A salient feature of our problem is that the decision maker can only observe realized demand over time but does not know the underlying demand function that maps prices into instantaneous demand rate. We introduce a family of blind pricing policies that are designed to balance trade-offs between exploration (demand learning) and exploitation (pricing to optimize revenues). We derive bounds on the revenue loss incurred by said policies in comparison to the optimal dynamic pricing policy that knows the demand function a priori, and we prove that asymptotically, as the volume of sales increases, this gap shrinks to zero."
1772,"Stabilizing Customer Abandonment in Many-Server Queues with Time-Varying Arrivals","Liu, Yunan and Whitt, Ward","OPERATIONS RESEARCH","60","6","1551-1564","2012","NOV-DEC","","","An algorithm is developed to determine time-dependent staffing levels to stabilize the time-dependent abandonment probabilities and expected delays at positive target values in the M-1/GI/s(1) + GI many-server queueing model, which has a nonhomogeneous Poisson arrival process (the M-1), has general service times (the first GI), and allows customer abandonment according to a general patience distribution (the +GI). New offered-load and modified-offered-load approximations involving infinite-server models are developed for that purpose. Simulations show that the approximations are effective. A many-server heavy-traffic limit in the efficiency-driven regime shows that (i) the proposed approximations achieve the goal asymptotically as the scale increases, and (ii) it is not possible to simultaneously stabilize the mean queue length in the same asymptotic regime."
1773,"OR Forum-A POMDP Approach to Personalize Mammography Screening Decisions","Ayer, Turgay and Alagoz, Oguzhan and Stout, Natasha K.","OPERATIONS RESEARCH","60","5","1019-1034","2012","SEP-OCT","","","Breast cancer is the most common nonskin cancer and the second leading cause of cancer death in U.S. women. Although mammography is the most effective modality for breast cancer screening, it has several potential risks, including high false-positive rates. Therefore, the balance of benefits and risks, which depend on personal characteristics, is critical in designing a mammography screening schedule. In contrast to prior research and existing guidelines that consider population-based screening recommendations, we propose a personalized mammography screening policy based on the prior screening history and personal risk characteristics of women. We formulate a finite-horizon, partially observable Markov decision process (POMDP) model for this problem. Our POMDP model incorporates two methods of detection (self or screen), age-specific unobservable disease progression, and age-specific mammography test characteristics. We solve this POMDP optimally after setting transition probabilities to values estimated from a validated microsimulation model. Additional published data is used to specify other model inputs such as sensitivity and specificity of test results. Our results show that our proposed personalized screening schedules outperform the existing guidelines with respect to the total expected quality-adjusted life years, while significantly decreasing the number of mammograms and false-positives. We also report the lifetime risk of developing undetected invasive cancer associated with each screening scenario."
1774,"Optimizing Boat Resources at the U.S. Coast Guard: Deterministic and Stochastic Models","Wagner, Michael R. and Radovilsky, Zinovy","OPERATIONS RESEARCH","60","5","1035-1049","2012","SEP-OCT","","","The United States Coast Guard (USCG), a part of the U.S. Department of Homeland Security, is the nation's leading agency in maritime security, safety, and stewardship. One of the primary USCG resources is a fleet of boats (maritime vessels less than 65 feet in length) of various types that must be allocated to USCG stations nationwide. This paper describes the academic-industry collaboration between the authors and the USCG, which resulted in the development of an integer linear programming model that optimally matches supplies of various types of boats to station demands. The paper also introduces a model for the optimal sharing of scarce boat resources. In addition, we generalize our model, using value-at-risk and robust optimization ideas, to manage the risk of boat shortages. The paper reports on the USCG implementation process and discusses internal resistance issues and eventual adoption. We describe USCG modifications to the model recommendations due to practicalities not captured by our model. Finally, we present the significant improvements to USCG quantitative performance metrics that resulted from our model's recommendations. These include a considerable reduction of excess capacity and boat shortages at the stations, a decrease in the overall fleet size with a simultaneous increase in boat utilization, and overall reduction of the fleet operating cost. We also discuss in depth how our model effected these improvements."
1775,"Process Location and Product Distribution with Uncertain Yields","Caro, Felipe and Rajaram, Kumar and Wollenweber, Jens","OPERATIONS RESEARCH","60","5","1050-1063","2012","SEP-OCT","","","We present a framework to analyze the process location and product distribution problem with uncertain yields for a large multinational food processing company. This problem consists of selecting the location of processes, the assignment of products, and the distribution of production quantities to markets in order to minimize total expected costs. It differs from the traditional facility location problem due to characteristics that are inherent to process industry sectors. These include significant economies of scale at high volumes, large switchover times, and production yield uncertainty. We model the problem as a nonlinear mixed-integer program. A challenging aspect of this problem is that the objective function is neither convex nor concave. We develop an exact approach to linearize the objective function. We present heuristics to solve the problem and also construct lower bounds based on a reduction of the constraint set to evaluate the quality of the solutions. This framework has been used to make process choice and product allocation decisions at the food processing company, and the estimated annual cost savings are around 10%, or $50 million. In addition, the insights from the model have had a significant strategic and organizational impact at this company. Our framework and conclusions are relevant to other industrial sectors with similar characteristics, such as pharmaceuticals and specialty chemical manufacturers."
1776,"Measuring Eco-Inefficiency: A New Frontier Approach","Chen, Chien-Ming and Delmas, Magali A.","OPERATIONS RESEARCH","60","5","1064-1079","2012","SEP-OCT","","","Growing social concerns over the environmental externalities associated with business activities are pushing firms to identify activities that create economic value with less environmental impact and to become more eco-efficient. Over the past two decades, researchers have increasingly used frontier efficiency models to evaluate productive efficiency in the presence of undesirable outputs, such as greenhouse gas emissions or toxic emissions. In this paper, we identify critical flaws in existing frontier models and show that these models can identify eco-inefficient firms as eco-efficient. We develop a new eco-inefficiency frontier model that rectifies these problems. Our model calculates an eco-inefficiency score for each firm and improvements in outputs necessary to attain eco-efficiency. We demonstrate through a Monte Carlo experiment that our eco-inefficiency model provides a more reliable measurement of corporate eco-inefficiency than the existing frontier models. We also extend the single-output Cobb-Douglas production function to multiple desirable and undesirable outputs. This extension allows for greater flexibility in the simulation analysis of frontier models."
1777,"Patient Streaming as a Mechanism for Improving Responsiveness in Emergency Departments","Saghafian, Soroush and Hopp, Wallace J. and Van Oyen, Mark P. and Desmond, Jeffrey S. and Kronick, Steven L.","OPERATIONS RESEARCH","60","5","1080-1097","2012","SEP-OCT","","","Crisis-level overcrowding conditions in emergency departments (EDs) have led hospitals to seek out new patient-flow designs to improve both responsiveness and safety. One approach that has attracted attention and experimentation in the emergency medicine community is a system in which ED beds and care teams are segregated and patients are streamed based on predictions of whether they will be discharged or admitted to the hospital. In this paper, we use a combination of analytic and simulation models to determine whether such a streaming policy can improve ED performance, where it is most likely to be effective, and how it should be implemented for maximum performance. Our results suggest that the concept of streaming can indeed improve patient flow, but only in some situations. First, ED resources must be shared across streams rather than physically separated. This leads us to propose a new virtual-streaming patient flow design for EDs. Second, this type of streaming is most effective in EDs with (1) a high percentage of admitted patients, (2) longer care times for admitted patients than discharged patients, (3) a high day-to-day variation in the percentage of admitted patients, (4) long patient boarding times (e.g., caused by hospital bed-block), and (5) high average physician utilization. Finally, to take full advantage of streaming, physicians assigned to admit patients should prioritize upstream (new) patients, whereas physicians assigned to discharge patients should prioritize downstream (old) patients."
1778,"A Single-Supplier, Multiple-Retailer Model with Single-Season, Multiple-Ordering Opportunities, and Fixed Ordering Cost","Jain, Apurva and Moinzadeh, Kamran and Zhou, Yong-Pin","OPERATIONS RESEARCH","60","5","1098-1110","2012","SEP-OCT","","","In this paper, we discuss the replenishment decision of seasonal products in a two-echelon distribution system consisting of a supplier and multiple retailers. Because of long manufacturing lead time, the supplier orders its entire stock for the season well in advance. The retailers, on the other hand, can replenish their inventory from the supplier throughout the season as demand realizes. Demand at each retailer follows a Poisson process. Each retailer order incurs a fixed cost, and the usual understocking and overstocking costs occur. When retailer lead time is negligible, we show that it is optimal for the retailer to follow a time-based, order-up-to policy and order only when inventory is depleted. We also characterize the structure of the optimal policy and propose a number of heuristics for easier computation. For the supplier, we express the distribution of total demand. This allows the supplier to solve a classic newsvendor problem to determine the total stock for the season. We find that the optimal retailer policy can sometimes cause large demand variation for the supplier, resulting in lower supplier profit. In centralized settings, this may even result in lower system profit than some naive retailer heuristics, creating inefficiency in the supply chain. We offer insights on potential causes and managerial implications."
1779,"Comparative Statics Analysis of Multiproduct Newsvendor Networks Under Responsive Pricing","Bish, Ebru K. and Zeng, Xin and Liu, Juqi and Bish, Douglas R.","OPERATIONS RESEARCH","60","5","1111-1124","2012","SEP-OCT","","","We propose a novel analytic approach for the comparative statics analysis of multiproduct multiresource newsvendor networks under responsive pricing. Our approach involves exploiting the properties of the primal mathematical programming formulation and of the dual variables and linking those properties to the concept of convex orders and to properties of the underlying demand function. The use of convex orders allows us to establish our main results without restriction to a specific demand distribution. A major strength of our approach is that it is scalable, i.e., it applies to newsvendor networks with any number of nonindependent (i.e., demand or resource sharing) products and resources, without an exponential increase in effort as problem size increases. This is unlike the current approaches commonly used in the operations management literature, which typically involve a parametric analysis of the recourse problem, followed by the use of Jacobians and the implicit function theorem. Providing a rigorous framework for comparative statics analysis, which can be applied to other problems that are not amenable to traditional parametric analysis, is our main contribution. We demonstrate this approach on the optimal capacity decision problem in multiproduct newsvendor networks under responsive pricing, formulated as a two-stage stochastic programming problem with recourse: The firm determines the resource capacities ex ante, in the first stage, when demand intercepts are uncertain, and makes the pricing and production decisions ex post. in the second stage, when demand intercepts (e.g., market conditions) are fully observed. This particular problem and its variants are well studied in the operations management literature. A comparative statics analysis is integral to the study of the capacity investment decision, as it allows answers to important questions such as the following: Does the firm acquire more or less of the different resources available as demand uncertainty increases? Does the firm benefit from an increase in demand uncertainty? Using our proposed approach, we establish comparative statics results on how the newsvendor's expected profit and optimal capacity decision change with demand risk in multiproduct multiresource newsvendor networks. We also extend our analysis to the study of demand dependence in two-product networks."
1780,"Understanding the Performance of the Long Chain and Sparse Designs in Process Flexibility","Simchi-Levi, David and Wei, Yehua","OPERATIONS RESEARCH","60","5","1125-1141","2012","SEP-OCT","","","The long chain has been an important concept in the design of flexible processes. This design concept, as well as other sparse designs, have been applied by the automotive and other industries as a way to increase flexibility in order to better match available capacities with variable demands. Numerous empirical studies have validated the effectiveness of these designs. However, there is little theory that explains the effectiveness of the long chain, except when the system size is large, i.e., by applying an asymptotic analysis. Our attempt in this paper is to develop a theory that explains the effectiveness of long chain designs for finite size systems. First, we uncover a fundamental property of long chains, supermodularity, that serves as an important building block in our analysis. This property is used to show that the marginal benefit, i.e., the increase in expected sales, increases as the long chain is constructed, and the largest benefit is always achieved when the chain is closed by adding the last arc to the system. Then, supermodularity is used to show that the performance of the long chain is characterized by the difference between the performances of two open chains. This characterization immediately leads to the optimality of the long chain among 2-flexibility designs. Finally, under independent and identically distributed (i.i.d.) demand, this characterization gives rise to three developments: (i) an effective algorithm to compute the performances of long chains using only matrix multiplications; (ii) a result that the gap between the fill rate of full flexibility and that of the long chain increases with system size, thus implying that the effectiveness of the long chain relative to full flexibility increases as the number of products decreases; (iii) a risk-pooling result implying that the fill rate of a long chain increases with the number of products, but this increase converges to zero exponentially fast."
1781,"Pricing Games and Impact of Private Demand Information in Decentralized Assembly Systems","Kalkanci, Basak and Erhun, Feryal","OPERATIONS RESEARCH","60","5","1142-1156","2012","SEP-OCT","","","This paper analyzes decentralized assembly systems under asymmetric demand information and sequential contracting. We reveal new insights on the value of contract type (price-only versus complex), demand information (complete versus asymmetric), and contract sequence (first mover versus second mover) to different players. Our results for the basic model show the following: (1) Complex contracts increase the suppliers' aggregate profit; however, individual suppliers do not necessarily benefit from a complex contracting equilibrium. We identify the conditions under which each supplier benefits from such an equilibrium. (2) Eliminating information asymmetry is not always beneficial for the suppliers because obtaining information might bring only marginal value and hence might not be realistically justified. Furthermore, a downstream supplier might prefer information asymmetry to complete information, especially when demand variability is moderate. (3) Unless there is a high demand risk, the first-mover advantage is prevalent when the assembler is a price-taker. We extend our basic model to analyze two additional scenarios. First, we study cases where the suppliers may offer contracts of different complexity. Beyond enriching our understanding of contract choice in decentralized assembly systems, such variations enhance the analysis beyond the standard methodology of principal-agent models and utilize solution techniques from optimal control. Second, we analyze the situation where the suppliers may possess different levels of information on demand under complex contracts. We show that an upstream supplier always benefits from a downstream supplier's superior information. However, the additional information might decrease the downstream supplier's profit, especially when the forecast variability is low compared to the total demand variability in the system. Our results for the basic model and its extensions confirm that studying interactions between suppliers, specifically under different contract types and information structures, in assembly systems presents rich opportunities for future research."
1782,"Flexible PMP Approach for Large-Size Cell Formation","Goldengorin, Boris and Krushinsky, Dmitry and Slomp, Jannes","OPERATIONS RESEARCH","60","5","1157-1166","2012","SEP-OCT","","","Lately, the problem of cell formation (CF) has gained a lot of attention in the industrial engineering literature. Since it was formulated (more than 50 years ago), the problem has incorporated additional industrial factors and constraints while its solution methods have been constantly improving in terms of the solution quality and CPU times. However, despite all the efforts made, the available solution methods (including those for a popular model based on the p-median problem, PMP) are prone to two major types of errors. The first error (the modeling one) occurs when the intended objective function of the CF (as a rule, verbally formulated) is substituted by the objective function of the PMP. The second error (the algorithmic one) occurs as a direct result of applying a heuristic for solving the PMP. In this paper we show that for instances that make sense in practice, the modeling error induced by the PMP is negligible. We exclude the algorithmic error completely by solving the adjusted pseudo-Boolean formulation of the PMP exactly, which takes less than one second on a general-purpose PC and software. Our experimental study shows that the PMP-based model produces high-quality cells and in most cases outperforms several contemporary approaches."
1783,"Cut-First Branch-and-Price-Second for the Capacitated Arc-Routing Problem","Bode, Claudia and Irnich, Stefan","OPERATIONS RESEARCH","60","5","1167-1182","2012","SEP-OCT","","","This paper presents the first full-fledged branch-and-price (bap) algorithm for the capacitated arc-routing problem (CARP). Prior exact solution techniques either rely on cutting planes or the transformation of the CARP into a node-routing problem. The drawbacks are either models with inherent symmetry, dense underlying networks, or a formulation where edge flows in a potential solution do not allow the reconstruction of unique CARP tours. The proposed algorithm circumvents all these drawbacks by taking the beneficial ingredients from existing CARP methods and combining them in a new way. The first step is the solution of the one-index formulation of the CARP in order to produce strong cuts and an excellent lower bound. It is known that this bound is typically stronger than relaxations of a pure set-partitioning CARP model. Such a set-partitioning master program results from a Dantzig-Wolfe decomposition. In the second phase, the master program is initialized with the strong cuts, CARP tours are iteratively generated by a pricing procedure, and branching is required to produce integer solutions. This is a cut-first bap-second algorithm and its main function is, in fact, the splitting of edge flows into unique CARP tours."
1784,"Reliable Traffic Sensor Deployment Under Probabilistic Disruptions and Generalized Surveillance Effectiveness Measures","Li, Xiaopeng and Ouyang, Yanfeng","OPERATIONS RESEARCH","60","5","1183-1198","2012","SEP-OCT","","","Sensor systems as critical components of a transportation network provide a variety of real-time traffic surveillance information for traffic management and control. The deployment of sensors significantly affects their overall surveillance effectiveness. This paper proposes a reliable sensor location model to optimize surveillance effectiveness when sensors are subject to site-dependent probabilistic failures, and a general effectiveness measure is proposed to encompass most existing measures needed for engineering practice (e.g., flow volume coverage, vehicle-mile coverage, and squared error reduction). The problem is first formulated into a compact mixed-integer program, and we develop a variety of solution algorithms (including a custom-designed Lagrangian relaxation algorithm) and analyze their properties. We also propose alternative formulations including a continuum approximation model for single corridor problems and reliable fixed-charge sensor location models. Numerical case studies are conducted to test the performance of the proposed algorithms and draw managerial insights on how different parameter settings (e.g., failure probability and spatial heterogeneity) affect overall surveillance effectiveness and the optimal sensor deployment."
1785,"One-Switch Conditions for Multiattribute Utility Functions","Abbas, Ali E. and Bell, David E.","OPERATIONS RESEARCH","60","5","1199-1212","2012","SEP-OCT","","","We introduce a variety of new independence conditions for multiattribute utility functions that permit preference dependencies among the attributes of a decision problem. The hierarchy of new conditions varies in the degree to which it specifies the functional form, ranging from more general solutions with weaker constraints, to more specific solutions with stronger constraints. This formulation provides a wealth of new functional forms that a decision maker may use in a multiattribute decision problem. In addition, it may be used to tailor the utility elicitation process to the comfort level of the decision maker. The new conditions, and the corresponding functional forms, are based on the idea of limiting the number of switches that a decision maker may make between two decision alternatives as a parameter of the problem varies. We show how this formulation also relates many widely used concepts in single and multiattribute utility theory."
1786,"Geo-Graphs: An Efficient Model for Enforcing Contiguity and Hole Constraints in Planar Graph Partitioning","King, Douglas M. and Jacobson, Sheldon H. and Sewell, Edward C. and Cho, Wendy K. Tam","OPERATIONS RESEARCH","60","5","1213-1228","2012","SEP-OCT","","","Political districting is an intractable problem with significant ramifications for political representation. Districts often are required to satisfy some legal constraints, but these typically are not very restrictive, allowing decision makers to influence the composition of these districts without violating relevant laws. For example, while districts must often comprise a single contiguous area, a vast collection of acceptable solutions (i.e., sets of districts) remains. Choosing the best set of districts from this collection can be treated as a (planar) graph partitioning problem. When districts must be contiguous, successfully solving this problem requires an efficient computational method for evaluating contiguity constraints; common methods for assessing contiguity can require significant computation as the problem size grows. This paper introduces the geo-graph, a new graph model that ameliorates the computational burdens associated with enforcing contiguity constraints in planar graph partitioning when each vertex corresponds to a particular region of the plane. Through planar graph duality, the geo-graph provides a scale-invariant method for enforcing contiguity constraints in local search. Furthermore, geo-graphs allow district holes (which typically are considered undesirable) to be rigorously and efficiently integrated into the partitioning process."
1787,"Ranking Games and Gambling: When to Quit When You're Ahead","Anderson, Edward","OPERATIONS RESEARCH","60","5","1229-1244","2012","SEP-OCT","","","It is common for rewards to be given on the basis of a rank ordering, so that relative performance amongst a cohort is the criterion. In this paper we formulate an equilibrium model in which an agent makes successive decisions on whether or not to gamble and is rewarded on the basis of a rank ordering of the final position amongst competing players. One application of this model is to the behavior of mutual fund managers who are paid depending on funds under management, which in turn are greatly influenced by annual or quarterly rank orderings. Our model deals with a situation in which fund managers can elect either to pick stocks or to use a market-tracking strategy. In equilibrium the distribution of the final position will have a negative skew. We explore how this distribution depends on the number of players, the probability of success when gambling, the structure of the rewards, and on information regarding the performance of other players."
1788,"A Simple Approximation Algorithm for Computing Arrow-Debreu Prices","Ghiyasvand, Mehdi and Orlin, James B.","OPERATIONS RESEARCH","60","5","1245-1248","2012","SEP-OCT","","","We consider the Arrow-Debreu market with linear utilities in which there is a set G of divisible goods and a set B of buyers. Each buyer starts with an initial endowment of goods. The buyer's utility function is a linearly separable function of the goods that the buyer purchases. We develop a simple and efficient algorithm for determining an approximate market equilibrium. Our algorithm finds an E-approximate solution in O(n/epsilon(vertical bar B vertical bar vertical bar G vertical bar)) time, where n = vertical bar B vertical bar+ vertical bar G vertical bar. The running time can be further improved to O(n/epsilon(m+ vertical bar B vertical bar log vertical bar B vertical bar) where in is the number of pairs (i, j) such that buyer i has some utility for purchasing good j."
1789,"Is Tail-Optimal Scheduling Possible?","Wierman, Adam and Zwart, Bert","OPERATIONS RESEARCH","60","5","1249-1257","2012","SEP-OCT","","","This paper focuses on the competitive analysis of scheduling disciplines in a large deviations setting. Although there are policies that are known to optimize the sojourn time tail under a large class of heavy-tailed job sizes (e.g., processor sharing and shortest remaining processing time) and there are policies known to optimize the sojourn time tail in the case of light-tailed job sizes (e.g., first come first served), no policies are known that can optimize the sojourn time tail across both light- and heavy-tailed job size distributions. We prove that no such Work-conserving, nonanticipatory, nonlearning policy exists, and thus that a policy must learn (or know) the job size distribution in order to optimize the sojourn time tail."
1790,"First in Line Waiting Times as a Tool for Analysing Queueing Systems","Koole, G. M. and Nielsen, B. F. and Nielsen, T. B.","OPERATIONS RESEARCH","60","5","1258-1266","2012","SEP-OCT","","","We introduce a new approach to modelling queueing systems where the priority or the routing of customers depends on the time the first customer has waited in the queue. This past waiting time of the first customer in line, W-FIL, is used as the primary variable for our approach. A Markov chain is used for modelling the system where the states represent both the number of free servers and a discrete approximation to W-FIL. This approach allows us to obtain waiting time distributions for complex systems, such as the N-design routing scheme widely used, e.g., in call centers and systems with dynamic priorities."
1791,"Performance Guarantees for Empirical Markov Decision Processes with Applications to Multiperiod Inventory Models","Cooper, William L. and Rangarajan, Bharath","OPERATIONS RESEARCH","60","5","1267-1281","2012","SEP-OCT","","","We consider Markov decision processes with unknown transition probabilities and unknown single-period expected cost functions, and we study a method for estimating these quantities from historical or simulated data. The method requires knowledge of the system equations that govern state transitions as well as the single-period cost functions (but not the single-period expected cost functions). The estimation procedure is based upon taking expectations with respect to the empirical distribution functions of such data. Once the estimates are in place, the method computes a policy by solving the obtained empirical Markov decision process as if the estimates were correct. For MDPs that satisfy some conditions, we provide explicit, easily computed expressions for the probability that the procedure will produce a policy whose true expected cost is within any specified absolute distance of the actual optimal expected cost of the true Markov decision process. We also provide expressions for the number of historical or simulated data values that is sufficient for the procedure to produce a policy whose true expected cost is, with a prescribed probability, within a prescribed absolute distance of the actual optimal expected cost of the true Markov decision process. We apply our results to multiperiod inventory models. In addition, we provide a specialized analysis of such inventory models that also yields relative, rather than absolute, accuracy guarantees. We make comparisons with related results that have recently appeared, and we provide numerical examples."
1792,"An Overloaded Multiclass FIFO Queue with Abandonments","Jennings, Otis B. and Reed, Josh E.","OPERATIONS RESEARCH","60","5","1282-1295","2012","SEP-OCT","","","In this paper we consider a single-server queue fed by K independent renewal arrival streams, each representing a different job class. Jobs are processed in a FIFO fashion, regardless of class. The total amount of work arriving to the system exceeds the server's capacity. That is, the nominal traffic intensity of the system is assumed to be greater than one. Jobs arriving to the system grow impatient and abandon the queue after a random amount of time if service has not yet begun. Interarrival, service, and abandonment times are assumed to be generally distributed and class specific. We approximate this system using both fluid and diffusion limits. To this end, we consider a sequence of systems indexed by n in which the arrival and service rates are proportional to n; the abandonment distribution remains fixed across the sequence. In our first main result, we show that in the limit as n tends to infinity, the virtual waiting time process converges to a limiting deterministic process. This limit may be characterized as the solution to a first-order ordinary differential equation (ODE). Specific examples are then presented for which the ODE may be explicitly solved. In our second main result, we refine the deterministic fluid approximation by showing that the fluid-centered and diffusion-scaled virtual waiting time process weakly converges to an Ornstein-Uhlenbeck process whose drift and infinitesimal variance both vary over time. This process may also be solved for explicitly, thus yielding approximations to the transient as well as steady-state behavior of the virtual waiting time process."
1793,"Conditional Value-at-Risk and Average Value-at-Risk: Estimation and Asymptotics","Chun, So Yeon and Shapiro, Alexander and Uryasev, Stan","OPERATIONS RESEARCH","60","4","739-756","2012","JUL-AUG","","","We discuss linear regression approaches to the estimation of law-invariant conditional risk measures. Two estimation procedures are considered and compared; one is based on residual analysis of the standard least-squares method, and the other is in the spirit of the M-estimation approach used in robust statistics. In particular, value-at-risk and average value-at-risk measures are discussed in detail. Large sample statistical inference of the estimators is derived. Furthermore, finite sample properties of the proposed estimators are investigated and compared with theoretical derivations in an extensive Monte Carlo study. Empirical results on the real data (different financial asset classes) are also provided to illustrate the performance of the estimators."
1794,"A Broader View of Designing the Liver Allocation System","Akan, Mustafa and Alagoz, Oguzhan and Ata, Baris and Erenay, Fatih Safa and Said, Adnan","OPERATIONS RESEARCH","60","4","757-770","2012","JUL-AUG","","","We consider the problem of designing an efficient system for allocating donated livers to patients waiting for transplantation. The trade-off between medical urgency and efficiency is at the heart of the liver allocation problem. We model the transplant waiting list as a multiclass fluid model of overloaded queues, which captures the disease evolution by allowing the patients to switch between classes, i.e., health levels. We consider the bicriteria objective of minimizing total number of patient deaths while waiting for transplantation (NPDWT) and maximizing total quality-adjusted life years (QALYs) through a weighted combination. On one hand, under the objective of minimizing NPDWT, the current policy of United Network for Organ Sharing (UNOS) emerges as the optimal policy, providing a theoretical justification for the current practice. On the other hand, under the metric of maximizing QALYs, the optimal policy is an intuitive dynamic index policy that ranks patients based on their marginal-benefit from transplantation, i.e., the difference in benefit with versus without transplantation. Finally, we perform a detailed simulation study to compare the performances of our proposed policies and the current UNOS policy along the following metrics: total QALYs, NPDWT, number of patient deaths after transplantation, number of total patient deaths, and number of wasted livers. Numerical experiments show that our proposed policy for maximizing QALYs outperforms the current UNOS policy along all metrics except the NPDWT."
1795,"Bullwhip Effect Measurement and Its Implications","Chen, Li and Lee, Hau L.","OPERATIONS RESEARCH","60","4","771-784","2012","JUL-AUG","","","The bullwhip effect, or demand information distortion, has been a subject of both theoretical and empirical studies in the operations management literature. In this paper, we develop a simple set of formulas that describe the traditional bullwhip measure as a combined outcome of several important drivers, such as finite capacity, batch-ordering, and seasonality. Our modeling framework is descriptive in nature as it features certain plausible approximations that are commonly employed in practical inventory systems. The results are nonetheless compelling and can be used to explain various conflicting observations in previous empirical studies. Building on the theoretical framework, we discuss the managerial implications of the bullwhip measurement. We show that the measurement can be completely noninformative about the underlying supply chain cost performance if it is not linked to the operational details (such as decision intervals and leadtimes). Specifically, we show that an aggregated measurement over relatively long time periods can mask the operational-level bullwhip. In addition, we show that masking also exists under product or location aggregation in some illustrative cases."
1796,"Ordering Policies for Periodic-Review Inventory Systems with Quantity-Dependent Fixed Costs","Caliskan-Demirag, Ozgun and Chen, Youhua (Frank) and Yang, Yi","OPERATIONS RESEARCH","60","4","785-796","2012","JUL-AUG","","","We consider a stochastic periodic-review inventory control system in which the fixed cost depends on the order quantity. In particular, we investigate the optimal ordering policies under three fixed cost structures. The first structure is motivated by transportation and production contracts and considers two fixed costs: if the order size is within a specified limit C, then the fixed cost is K-1; otherwise, it is K-2, where K-1 <= K-2. The second structure contains multiple fixed costs in which the same incremental fixed cost K is incurred for any additional order quantity up to a given identical batch capacity C. In the third structure, in addition to the K incurred as in the previous case, a common fixed cost is charged for any nonzero order size. An example of the former case arises when an order is shipped with a homogeneous fleet of trucks with per-truck fixed costs. A situation in which a fixed administrative cost plus a quantity-dependent trucking cost is incurred for each shipment exemplifies the latter case. For the first cost structure, we separate the analysis according to the conditions (1) K-1 <= K-2 <= 2K(1) and (2) K-1 <= K-2. Under condition (1), we introduce a new concept called C-(K-1, K-2)-convexity, which enables us to almost completely characterize the optimal ordering policy. Under the general condition (2), we utilize a modified notion to provide a partial characterization of the optimal policy and propose a heuristic policy that performs well under a wide variety of model parameters. For the second cost structure, we show that it is optimal to order an integer multiple of the batch capacity to raise the inventory level to a specified range or band of length C, and then to order an additional full or partial batch size depending on the cost function, with no ordering required above the band. We also characterize a similar optimal policy for the third cost structure. Using different techniques, our study extends or redevelops several existing results in the literature."
1797,"Technical Note - On Optimal Policies for Inventory Systems with Batch Ordering","Huh, Woonghee Tim and Janakiraman, Ganesh","OPERATIONS RESEARCH","60","4","797-802","2012","JUL-AUG","","","We study a periodically reviewed multiechelon inventory system in series such that order quantities at every stage have to be multiples of a given stage-specific batch size. The batch sizes are nested in the sense that the batch size for every stage is an integer multiple of the batch size for its downstream stage. The problem is that of determining the policy that minimizes the expected discounted sum of costs over a finite horizon. The result is that an echelon (R, nQ) policy is optimal when demands are independent across periods or, more generally, Markov-modulated. We also comment on algorithmic implications of our result and on extensions."
1798,"Strategies for a Centralized Single Product Multiclass M/G/1 Make-to-Stock Queue","Abouee-Mehrizi, Hossein and Balcioglu, Baris and Baron, Opher","OPERATIONS RESEARCH","60","4","803-812","2012","JUL-AUG","","","Make-to-stock queues are typically investigated in the M/M/1 settings. For centralized single-item systems with backlogs, the multilevel rationing (MR) policy is established as optimal and the strict priority (SP) policy is a practical compromise, balancing cost and ease of implementation. However, the optimal policy is unknown when service time is general, i.e., for M/G/1 queues. Dynamic programming, the tool commonly used to investigate the MR policy in make-to-stock queues, is less practical when service time is general. In this paper we focus on customer composition: the proportion of customers of each class to the total number of customers in the queue. We do so because the number of customers in M/G/1 queues is invariant for any nonidling and nonanticipating policy. To characterize customer composition, we consider a series of two-priority M/G/1 queues where the first service time in each busy period is different from standard service times, i.e., this first service time is exceptional. We characterize the required exceptional first service times and the exact solution of such queues. From our results, we derive the optimal cost and control for the MR and SP policies for M/G/1 make-to-stock queues."
1799,"Priority Assignment in Emergency Response","Jacobson, Evin Uzun and Argon, Nilay Tanik and Ziya, Serhan","OPERATIONS RESEARCH","60","4","813-832","2012","JUL-AUG","","","In the aftermath of mass-casualty events, key resources (such as ambulances and operating rooms) can be overwhelmed by the sudden jump in patient demand. To ration these resources, patients are assigned different priority levels, a process that is called triage. According to triage protocols in place, each patient's priority level is determined based on that patient's injuries only. However, recent work from the emergency medicine literature suggests that when determining priorities, resource limitations and the scale of the event should also be taken into account in order to do the greatest good for the greatest number. This article investigates how this can be done and what the potential benefits would be. We formulate the problem as a priority assignment problem in a clearing system with multiple classes of impatient jobs. Jobs are classified based on their lifetime (i.e., their tolerance for wait), service time, and reward distributions. Our objective is to maximize the expected total reward, e.g., the expected total number of survivors. Using sample-path methods and stochastic dynamic programming, we identify conditions under which the state information is not needed for prioritization decisions. In the absence of these conditions, we partially characterize the optimal policy, which is possibly state dependent, and we propose a number of heuristic policies. By means of a numerical study, we demonstrate that simple state-dependent policies that prioritize less urgent jobs when the total number of jobs is large perform well, especially when jobs are time-critical."
1800,"Learning Consumer Tastes Through Dynamic Assortments","Ulu, Canan and Honhon, Dorothee and Alptekinoglu, Aydin","OPERATIONS RESEARCH","60","4","833-849","2012","JUL-AUG","","","How should a firm modify its product assortment over time when learning about consumer tastes? In this paper, we study dynamic assortment decisions in a horizontally differentiated product category for which consumers' diverse tastes can be represented as locations on a Hotel ling line. We presume that the firm knows all possible consumer locations, comprising a finite set, but does not know their probability distribution. We model this problem as a discrete-time dynamic program; each period, the firm chooses an assortment and sets prices to maximize the total expected profit over a finite horizon, given its subjective beliefs over consumer tastes. The consumers then choose a product from the assortment that maximizes their own utility. The firm observes sales, which provide censored information on consumer tastes, and it updates beliefs in a Bayesian fashion. There is a recurring trade-off between the immediate profits from sales in the current period (exploitation) and the informational gains to be exploited in all future periods (exploration). We show that one can (partially) order assortments based on their information content and that in any given period the optimal assortment cannot be less informative than the myopically optimal assortment. This result is akin to the well-known stock more result in censored newsvendor problems with the newsvendor learning about demand through sales when lost sales are not observable. We demonstrate that it can be optimal for the firm to alternate between exploration and exploitation, and even offer assortments that lead to losses in the current period in order to gain information on consumer tastes. We also develop a Bayesian conjugate model that reduces the state space of the dynamic program and study value of learning using this conjugate model."
1801,"Solving an Infinite Horizon Adverse Selection Model Through Finite Policy Graphs","Zhang, Hao","OPERATIONS RESEARCH","60","4","850-864","2012","JUL-AUG","","","This paper studies an infinite horizon adverse selection model with an underlying Markov information process. It introduces a graphic representation of continuation contracts and continuation payoff frontiers, namely finite policy graph, and provides an algorithm to approximate the optimal policy graph through iterations. The algorithm performs an additional step after each value iteration-replacing dominated points on the previous continuation payoff frontier by points on the new frontier and reevaluating the new frontier. This dominance-free reevaluation step accelerates the convergence of the continuation payoff frontiers. Numerical examples demonstrate the effectiveness of this algorithm and properties of the optimal contracts."
1802,"Robust Assortment Optimization in Revenue Management Under the Multinomial Logit Choice Model","Rusmevichientong, Paat and Topaloglu, Huseyin","OPERATIONS RESEARCH","60","4","865-882","2012","JUL-AUG","","","We study robust formulations of assortment optimization problems under the multinomial logit choice model. The novel aspect of our formulations is that the true parameters of the logit model are assumed to be unknown, and we represent the set of likely parameter values by a compact uncertainty set. The objective is to find an assortment that maximizes the worst-case expected revenue over all parameter values in the uncertainty set. We consider both static and dynamic settings. The static setting ignores inventory consideration, whereas in the dynamic setting, there is a limited initial inventory that must be allocated over time. We give a complete characterization of the optimal policy in both settings, show that it can be computed efficiently, and derive operational insights. We also propose a family of uncertainty sets that enables the decision maker to control the trade-off between increasing the average revenue and protecting against the worst-case scenario. Numerical experiments show that our robust approach, combined with our proposed family of uncertainty sets, is especially beneficial when there is significant uncertainty in the parameter values. When compared to other methods, our robust approach yields over 10% improvement in the worst-case performance, but it can also maintain comparable average revenue if average revenue is the performance measure of interest."
1803,"Optimal Pricing in Networks with Externalities","Candogan, Ozan and Bimpikis, Kostas and Ozdaglar, Asuman","OPERATIONS RESEARCH","60","4","883-905","2012","JUL-AUG","","","We study the optimal pricing strategies of a monopolist selling a divisible good (service) to consumers who are embedded in a social network. A key feature of our model is that consumers experience a (positive) local network effect. In particular, each consumer's usage level depends directly on the usage of her neighbors in the social network structure. Thus, the monopolist's optimal pricing strategy may involve offering discounts to certain agents who have a central position in the underlying network. Our results can be summarized as follows. First, we consider a setting where the monopolist can offer individualized prices and derive a characterization of the optimal price for each consumer as a function of her network position. In particular, we show that it is optimal for the monopolist to charge each agent a price that consists of three components: (i) a nominal term that is independent of the network structure, (ii) a discount term proportional to the influence that this agent exerts over the rest of the social network (quantified by the agent's Bonacich centrality), and (iii) a markup term proportional to the influence that the network exerts on the agent. In the second part of the paper, we discuss the optimal strategy of a monopolist who can only choose a single uniform price for the good and derive an algorithm polynomial in the number of agents to compute such a price. Third, we assume that the monopolist can offer the good in two prices, full and discounted, and we study the problem of determining which set of consumers should be given the discount. We show that the problem is NP-hard; however, we provide an explicit characterization of the set of agents who should be offered the discounted price. Next, we describe an approximation algorithm for finding the optimal set of agents. We show that if the profit is nonnegative under any feasible price allocation, the algorithm guarantees at least 88% of the optimal profit. Finally, we highlight the value of network information by comparing the profits of a monopolist who does not take into account"
1804,"Release Time Scheduling and Hub Location for Next-Day Delivery","Yaman, Hande and Karasan, Oya Ekin and Kara, Bahar Y.","OPERATIONS RESEARCH","60","4","906-917","2012","JUL-AUG","","","Inspired by a real-life problem faced by one of the largest ground-based cargo companies of Turkey, the current study introduces a new facet to the hub location literature. The release time scheduling and hub location problem aims to select a specified number of hubs from a fixed set of demand centers, to allocate each demand center to a hub, and to decide on the release times of trucks from each demand center in such a way that the total amount of cargo guaranteed to be delivered to every potential destination by the next day is not below a threshold and the total routing cost is minimized. The paper introduces integer programming models to solve this problem in the special cases when the cargo uniformly arrives to each demand center during the day and the more realistic pattern of when the cargo arrivals exhibit a piecewise linear form. Several classes of valid inequalities are proposed to strengthen the formulations. Extensions with multiple service levels and discrete sets for release times are also discussed. Computational results show the computational viability of the models under realistic scenarios as well as the validity of the proposed problems in answering several interesting questions from the cargo sector's perspective."
1805,"A Polyhedral Study of Multiechelon Lot Sizing with Intermediate Demands","Zhang, Minjiao and Kuecuekyavuz, Simge and Yaman, Hande","OPERATIONS RESEARCH","60","4","918-935","2012","JUL-AUG","","","In this paper, we study a multiechelon uncapacitated lot-sizing problem in series (m-ULS), where the output of the intermediate echelons has its own external demand and is also an input to the next echelon. We propose a polynomial-time dynamic programming algorithm, which gives a tight, compact extended formulation for the two-echelon case (2-ULS). Next, we present a family of valid inequalities for m-ULS, show its strength, and give a polynomial-time separation algorithm. We establish a hierarchy between the alternative formulations for 2-ULS. In particular, we show that our valid inequalities can be obtained from the projection of the multicommodity formulation. Our computational results show that this extended formulation is very effective in solving our uncapacitated multi-item two-echelon test problems. In addition, for capacitated multi-item, multiechelon problems, we demonstrate the effectiveness of a branch-and-cut algorithm using the proposed inequalities."
1806,"Robust and Stochastically Weighted Multiobjective Optimization Models and Reformulations","Hu, Jian and Mehrotra, Sanjay","OPERATIONS RESEARCH","60","4","936-953","2012","JUL-AUG","","","We introduce and study a family of models for multiexpert multiobjective/criteria decision making. These models use a concept of weight robustness to generate a risk-averse decision. In particular, the multiexpert multicriteria robust weighted sum approach (McRow) introduced in this paper identifies a (robust) Pareto decision that minimizes the worst-case weighted sum of objectives over a given weight region. The corresponding objective value, called the robust value of a decision, is shown to be increasing and concave in the weight. set. We study compact reformulations of the McRow model with polyhedral and conic descriptions of the weight regions. The McRow model is developed further for stochastic multiexpert multicriteria decision making by allowing ambiguity or randomness in the weight region as well as the objective functions. The properties of the proposed approach are illustrated with a few textbook examples. The usefulness of the stochastic McRow model is demonstrated using a disaster planning example and an agriculture revenue management example."
1807,"Three Ideas for the Quadratic Assignment Problem","Fischetti, Matteo and Monaci, Michele and Salvagnin, Domenico","OPERATIONS RESEARCH","60","4","954-964","2012","JUL-AUG","","","We address the exact solution of the famous esc instances of the quadratic assignment problem. These are extremely hard instances that remained unsolved-even allowing for a tremendous computing power-by using all previous techniques from the literature. During this challenging task we found that three ideas were particularly useful and qualified as a breakthrough for our approach. The present paper is about describing these ideas and their impact in solving esc instances. Our method was able to solve, in a matter of seconds or minutes on a single PC, all easy cases (all esc16{*} plus esc32e and esc32g). The three very hard instances esc32c, esc32d, and esc64a were solved in less than half an hour, in total, on a single PC. We also report the solution, in about five hours, of tai64c. By using a facility-flow splitting procedure, we were also able to solve to proven optimality, for the first time, esc32h (in about two hours) as well as the big fish esc128. (To our great surprise, the solution of the latter required just a few seconds on a single PC.)"
1808,"Dynamic Pricing Under a General Parametric Choice Model","Broder, Josef and Rusmevichientong, Paat","OPERATIONS RESEARCH","60","4","965-980","2012","JUL-AUG","","","We consider a stylized dynamic pricing model in which a monopolist prices a product to a sequence of T customers who independently make purchasing decisions based on the price offered according to a general parametric choice model. The parameters of the model are unknown to the seller, whose objective is to determine a pricing policy that minimizes the regret, which is the expected difference between the seller's revenue and the revenue of a clairvoyant seller who knows the values of the parameters in advance and always offers the revenue-maximizing price. We show that the regret of the optimal pricing policy in this model is Theta(root T), by establishing an Omega(root T) lower bound on the worst-case regret under an arbitrary policy, and presenting a pricing policy based on maximum-likelihood estimation whose regret is O(root T) across all problem instances. Furthermore, we show that when the demand curves satisfy a well-separated condition, the T-period regret of the optimal policy is Theta(log T). Numerical experiments show that our policies perform well."
1809,"Hazard Rate Scaling of the Abandonment Distribution for the GI/M/n plus GI Queue in Heavy Traffic","Reed, Josh and Tezcan, Tolga","OPERATIONS RESEARCH","60","4","981-995","2012","JUL-AUG","","","We Obtain a heavy traffic limit for the GI/M/n + GI queue, which includes the entire patience time distribution. Our main approach is to scale the hazard rate function of the patience time distribution in such a way that our resulting diffusion approximation contains the entire hazard rate function. We then show through numerical studies that for various performance measures, our approximations tend to outperform those commonly used in practice. The robustness of our results is also demonstrated by applying them to solving constraint satisfaction problems arising in the context of telephone call craters."
1810,"Overflow Networks: Approximations and Implications to Call Center Outsourcing","Gurvich, Itai and Perry, Ohad","OPERATIONS RESEARCH","60","4","996-1009","2012","JUL-AUG","","","Motivated by call center cosourcing problems, we consider a service network operated under an overflow mechanism. Calls are first routed to an in-house (or dedicated) service station that has a finite waiting room. If the waiting room is full, the call is overflowed to an outside provider (an overflow station) that might also be serving overflows from other stations. We establish approximations for overflow networks with many servers under a resource-pooling assumption that stipulates, in our context, that the fraction of overflowed calls is nonnegligible. Our two main results are (i) an approximation for the overflow processes via limit theorems and (ii) asymptotic independence between each of the in-house stations and the overflow station. In particular, we show that, as the system becomes large, the dependency between each in-house station and the overflow station becomes negligible. Independence between stations in overflow networks is assumed in the literature on call centers, and we provide a rigorous support for those useful heuristics."
1811,"OR Forum-Modeling the Impacts of Electricity Tariffs on Plug-In Hybrid Electric Vehicle Charging, Costs, and Emissions","Sioshansi, Ramteen","OPERATIONS RESEARCH","60","3","506-516","2012","MAY-JUN","","","Plug-in hybrid electric vehicles (PHEVs) have been touted as a transportation technology with lower fuel costs and emissions impacts than other vehicle types. Most analyses of PHEVs assume that the power system operator can either directly or indirectly control PHEV charging to coordinate it with power system operations. This paper examines the incentives of individual drivers making charging decisions with different electricity tariffs, and it compares the cost and emissions impacts of these charging patterns to the ideal case of charging controlled by the system operator. Our results show that real-time pricing performs worst among all of the tariffs we consider, because linear prices are inherently limited in signaling efficient use of resources in a system with nonconvexities. We also show that controlling overnight PHEV charging is significantly more important than limiting midday vehicle charging."
1812,"A New Algorithm for the Open-Pit Mine Production Scheduling Problem","Chicoisne, Renaud and Espinoza, Daniel and Goycoolea, Marcos and Moreno, Eduardo and Rubio, Enrique","OPERATIONS RESEARCH","60","3","517-528","2012","MAY-JUN","","","For the purpose of production scheduling, open-pit mines are discretized into three-dimensional arrays known as block models. Production scheduling consists of deciding which blocks should be extracted, when they should be extracted, and what to do with the blocks once they are extracted. Blocks that are close to the surface should be extracted first, and capacity constraints limit the production in each time period. Since the 1960s, it has been known that this problem can be cast as an integer programming model. However, the large size of some real instances (3-10 million blocks, 15-20 time periods) has made these models impractical for use in real planning applications, thus leading to the use of numerous heuristic methods. In this article we study a well-known integer programming formulation of the problem that we refer to as C-PIT. We propose a new decomposition method for solving the linear programming relaxation (LP) of C-PIT when there is a single capacity constraint per time period. This algorithm is based on exploiting the structure of the precedence-constrained knapsack problem and runs in O(mn log n) in which n is the number of blocks and m a function of the precedence relationships in the mine. Our computations show that we can solve, in minutes, the LP relaxation of real-sized mine-planning applications with up to five million blocks and 20 time periods. Combining this with a quick rounding algorithm based on topological sorting, we obtain integer feasible solutions to the more general problem where multiple capacity constraints per time period are considered. Our implementation obtains solutions within 6% of optimality in seconds. A second heuristic step, based on local search, allows us to find solutions within 3% in one hour on all instances considered. For most instances, we obtain solutions within 1-2% of optimality if we let this heuristic run longer. Previous methods have been able to tackle only instances with up to 150,000 blocks and 15 time periods."
1813,"Conflicting Congestion Effects in Resource Allocation Games","Feldman, Michal and Tamir, Tami","OPERATIONS RESEARCH","60","3","529-540","2012","MAY-JUN","","","We study strategic resource allocation settings, where jobs correspond to self-interested players who choose resources with the objective of minimizing their individual cost. Our framework departs from the existing game-theoretic models mainly in assuming conflicting congestion effects, but also in assuming an unlimited supply of resources. In our model, a job's cost is composed of both its resource's load (which increases with congestion) and its share in the resource's activation cost (which decreases with congestion). We provide results for a job-scheduling setting with heterogeneous jobs and identical machines. We show that if the resource's activation cost is shared equally among its users, a pure Nash equilibrium (NE) might not exist. In contrast, the proportional sharing rule induces a game that admits a pure NE, which can also be computed in polynomial time. As part of the algorithm's analysis, we establish a new, nontrivial property of schedules obtained by the longest processing time algorithm. We also observe that, unlike in congestion games, best-response dynamics (BRD) are not guaranteed to converge to a Nash equilibrium. Finally, we measure the inefficiency of equilibria with respect to the minimax objective function, and prove that there is no universal bound for the worst-case inefficiency (as quantified by the price of anarchy measure). However, the best-case inefficiency (quantified by the price of stability measure) is bounded by 5/4, and this is tight. These results add another layer to the growing literature on the price of anarchy and stability, which studies the extent to which selfish behavior affects system efficiency."
1814,"Optimal Market-Making with Risk Aversion","Huang, Kan and Simchi-Levi, David and Song, Miao","OPERATIONS RESEARCH","60","3","541-565","2012","MAY-JUN","","","Market-makers have the obligation to trade any given amount of assets at quoted bid or ask prices, and their inventories are exposed to the potential loss when the market price moves in an undesirable direction. One approach to reduce the risk brought by price uncertainty is to adjust the inventory at the price of losing potential spread gain. Using stochastic dynamic programming, we show that a threshold inventory control policy is optimal with respect to an exponential utility criterion and a mean-variance trade-off model. Symmetric and monotone properties of the threshold levels are also established."
1815,"Financing the Newsvendor: Supplier vs. Bank, and the Structure of Optimal Trade Credit Contracts","Kouvelis, Panos and Zhao, Wenhui","OPERATIONS RESEARCH","60","3","566-580","2012","MAY-JUN","","","We consider a supply chain with a retailer and a supplier: A newsvendor-like retailer has a single opportunity to order a product from a supplier to satisfy future uncertain demand. Both the retailer and supplier are capital constrained and in need of short-term financing. In the presence of bankruptcy risks for both the retailer and supplier, we model their strategic interaction as a Stackelberg game with the supplier as the leader. We use the supplier early payment discount scheme as a decision framework to analyze all decisions involved in optimally structuring the trade credit contract (discounted wholesale price if paying early, financing rate if delaying payment) from the supplier's perspective. Under mild assumptions we conclude that a risk-neutral supplier should always finance the retailer at rates less than or equal to the risk-free rate. The retailer, if offered an optimally structured trade credit contract, will always prefer supplier financing to bank financing. Furthermore, under optimal trade credit contracts, both the supplier's profit and supply chain efficiency improve, and the retailer might improve his profits relative to under bank financing (or equivalently, a rich retailer under wholesale price contracts), depending on his current wealth (working capital and collateral)."
1816,"Technical Note-A Note on the Structure of Joint Inventory-Pricing Control with Leadtimes","Pang, Zhan and Chen, Frank Y. and Feng, Youyi","OPERATIONS RESEARCH","60","3","581-587","2012","MAY-JUN","","","We consider a joint inventory-pricing control problem for a periodic-review, single-stage inventory system with a positive order leadtime and a linear order cost. Demands in consecutive periods are independent, but their distributions depend on the price in accordance with a stochastic demand function of additive form. Pricing and ordering decisions are made simultaneously at the beginning of each period. The objective is to maximize the total expected discounted profit over a finite horizon. We partially characterize the structure of the optimal joint ordering and pricing policies. We also show that our structural analysis can be extended to a multistage (or serial) inventory system with constant or stochastic leadtimes and an assemble-to-order system with price-sensitive demand."
1817,"Quadratic Core-Selecting Payment Rules for Combinatorial Auctions","Day, Robert W. and Cramton, Peter","OPERATIONS RESEARCH","60","3","588-603","2012","MAY-JUN","","","We report on the use of a quadratic programming technique in recent and upcoming spectrum auctions in Europe. Specifically, we compute a unique point in the core that minimizes the sum of squared deviations from a reference point, for example, from the Vickrey-Clarke-Groves payments. Analyzing the Karush-Kuhn-Tucker conditions, we demonstrate that the resulting payments can be decomposed into a series of economically meaningful and equitable penalties. Furthermore, we discuss the benefits of this combinatorial auction, explore the use of alternative reserve pricing approaches in this context, and indicate the results of several hundred computational runs using CATS data."
1818,"Technical Note-Branch-and-Price-and-Cut Approach to the Robust Network Design Problem Without Flow Bifurcations","Lee, Chungmok and Lee, Kyungsik and Park, Kyungchul and Park, Sungsoo","OPERATIONS RESEARCH","60","3","604-610","2012","MAY-JUN","","","This paper presents a robust optimization approach to the network design problem under traffic demand uncertainty. We consider the specific case of the network design problem in which there are several alternatives in edge capacity installations and the traffic cannot be split over several paths. A new decomposition approach is proposed that yields a strong LP relaxation and enables traffic demand uncertainty to be addressed efficiently through localization of the uncertainty to each edge of the underlying network. A branch-and-price-and-cut algorithm is subsequently developed and tested on a set of benchmark instances."
1819,"A Hybrid Genetic Algorithm for Multidepot and Periodic Vehicle Routing Problems","Vidal, Thibaut and Crainic, Teodor Gabriel and Gendreau, Michel and Lahrichi, Nadia and Rei, Walter","OPERATIONS RESEARCH","60","3","611-624","2012","MAY-JUN","","","We propose an algorithmic framework that successfully addresses three vehicle routing problems: the multidepot VRP, the periodic VRP, and the multidepot periodic VRP with capacitated vehicles and constrained route duration. The metaheuristic combines the exploration breadth of population-based evolutionary search, the aggressive-improvement capabilities of neighborhood-based metaheuristics, and advanced population-diversity management schemes. Extensive computational experiments show that the method performs impressively in terms of computational efficiency and solution quality, identifying either the best known solutions, including the optimal ones, or new best solutions for all currently available benchmark instances for the three problem classes. The proposed method also proves extremely competitive for the capacitated VRP."
1820,"Habit Formation from Correlation Aversion","Lichtendahl, Jr., Kenneth C. and Chao, Raul O. and Bodily, Samuel E.","OPERATIONS RESEARCH","60","3","625-637","2012","MAY-JUN","","","Making plans about how much to consume and how much to invest in risky assets over an uncertain lifetime is a fundamental economic challenge. The leading models of this planning problem use either additive or habit-forming preferences. For the most part, these models assume an individual is either correlation neutral or correlation seeking in consumption, respectively. In this paper, we introduce two habit-forming, correlation-averse preference models. With these preferences, we find closed-form solutions to the classic consumption and portfolio planning problem. Our solutions recommend that a correlation-averse decision maker follow a habit in their consumption plans. While such habits traditionally have been associated with correlation-seeking preferences, our model leads to consumption habits from correlation-averse preferences."
1821,"Fixed-Charge Transportation Problem: Facets of the Projection Polyhedron","Agarwal, Yogesh and Aneja, Yash","OPERATIONS RESEARCH","60","3","638-654","2012","MAY-JUN","","","In this paper we consider the well-known fixed-charge transportation problem. To send any flow from source si to destination t(j), we incur a unit variable shipping cost of c(ij) and a fixed cost f(ij). Here we study the structure of the projection polyhedron of this problem, in the space of 0-1 variables associated with fixed charges, and we develop several classes of valid inequalities and derive conditions under which they are facet defining. In some cases, if the conditions are not satisfied, we show how they can be lifted to define facets. Several heuristics for generating and adding these facets are presented. Using these results, we develop a computationally effective algorithm for solving the problem. The computational results clearly indicate the usefulness of this approach."
1822,"Approximate Dynamic Programming via a Smoothed Linear Program","Desai, Vijay V. and Farias, Vivek F. and Moallemi, Ciamac C.","OPERATIONS RESEARCH","60","3","655-674","2012","MAY-JUN","","","We present a novel linear program for the approximation of the dynamic programming cost-to-go function in high-dimensional stochastic control problems. LP approaches to approximate DP have typically relied on a natural projection of a well-studied linear program for exact dynamic programming. Such programs restrict attention to approximations that are lower bounds to the optimal cost-to-go function. Our program-the smoothed approximate linear program-is distinct from such approaches and relaxes the restriction to lower bounding approximations in an appropriate fashion while remaining computationally tractable. Doing so appears to have several advantages: First, we demonstrate bounds on the quality of approximation to the optimal cost-to-go function afforded by our approach. These bounds are, in general, no worse than those available for extant LP approaches and for specific problem instances can be shown to be arbitrarily stronger. Second, experiments with our approach on a pair of challenging problems (the game of Tetris and a queueing network control problem) show that the approach outperforms the existing LP approach (which has previously been shown to be competitive with several ADP algorithms) by a substantial margin."
1823,"Technical Note-A Sampling-Based Approach to Appointment Scheduling","Begen, Mehmet A. and Levi, Retsef and Queyranne, Maurice","OPERATIONS RESEARCH","60","3","675-681","2012","MAY-JUN","","","We consider the problem of appointment scheduling with discrete random durations but under the more realistic assumption that the duration probability distributions are not known and only a set of independent samples is available, e.g., historical data. For a given sequence of appointments (jobs, tasks), the goal is to determine the planned starting time of each appointment such that the expected total underage and overage costs due to the mismatch between allocated and realized durations is minimized. We use the convexity and subdifferential of the objective function of the appointment scheduling problem to determine bounds on the number of independent samples required to obtain a provably near-optimal solution with high probability."
1824,"Optimization Under Probabilistic Envelope Constraints","Xu, Huan and Caramanis, Constantine and Mannor, Shie","OPERATIONS RESEARCH","60","3","682-699","2012","MAY-JUN","","","Chance constraints are an important modeling tool in stochastic optimization, providing probabilistic guarantees that a solution succeeds in satisfying a given constraint. Although they control the probability of success, they provide no control whatsoever in the event of a failure. That is, they do not distinguish between a slight overshoot or undershoot of the bounds and more catastrophic violation. In short, they do not capture the magnitude of violation of the bounds. This paper addresses precisely this topic, focusing on linear constraints and ellipsoidal (Gaussian-like) uncertainties. We show that the problem of requiring different probabilistic guarantees at each level of constraint violation can be reformulated as a semi-infinite optimization problem. We provide conditions that guarantee polynomial-time solvability of the resulting semi-infinite formulation. We show further that this resulting problem is what has been called a comprehensive robust optimization problem in the literature. As a byproduct, we provide tight probabilistic bounds for comprehensive robust optimization. Thus, analogously to the connection between chance constraints and robust optimization, we provide a broader connection between probabilistic envelope constraints and comprehensive robust optimization."
1825,"A Stochastic Competitive R&D Race Where Winner Takes All","Canbolat, Pelin G. and Golany, Boaz and Mund, Inbal and Rothblum, Uriel G.","OPERATIONS RESEARCH","60","3","700-715","2012","MAY-JUN","","","The paper considers a race among multiple firms that compete over the development of a product. The first firm to complete the development gains a reward, whereas the other firms gain nothing. Each firm decides how much to invest in developing the product, and the time it completes the development is a random variable that depends on the investment level. The paper provides a method for explicitly computing a unique Nash equilibrium, parametrically in the interest rate; for a given interest rate, the Nash equilibrium is determined in time that is linear in the number of firms. The structure of the solution yields insights about the behavior of the participants. Furthermore, an explicit expression for a unique globally optimal solution is obtained and compared to the unique Nash equilibrium."
1826,"A Stochastic Network Under Proportional Fair Resource Control-Diffusion Limit with Multiple Bottlenecks","Ye, Heng-Qing and Yao, David D.","OPERATIONS RESEARCH","60","3","716-738","2012","MAY-JUN","","","We study a multiclass stochastic processing network operating under the so-called proportional fair allocation scheme, and following the head-of-the-line processor-sharing discipline. Specifically, each server's capacity is shared among the job classes that require its service, and it is allocated, in every state of the network, among the first waiting job of each class to maximize a log-utility function. We establish the limiting regime of the network under diffusion scaling, allowing multiple bottlenecks in the network, and relaxing some of the conditions required in prior studies. We also identify the class of allocation schemes among which the proportional fair allocation minimizes a quadratic cost objective function of the diffusion-scaled queue lengths, and we illustrate the limitation of this asymptotic optimality through a counterexample."
1827,"A Simulation Optimization Approach to Long-Term Care Capacity Planning","Zhang, Yue and Puterman, Martin L. and Nelson, Matthew and Atkins, Derek","OPERATIONS RESEARCH","60","2","249-261","2012","MAR-APR","","","This paper describes a methodology for setting long-term care capacity levels over a multiyear planning horizon to achieve target wait time service levels. Our approach integrates demographic and survival analysis, discrete event simulation, and optimization. Based on this methodology, we developed a decision support system for use in practice. We illustrate this approach through two case studies; one for a regional health authority in British Columbia, Canada, and the other for a long-term care facility. We also compare our approach to the fixed ratio approach used in practice and the SIPP (stationary, independent, period by period) and MOL (modified offered load) approaches developed in the call center literature. Our results suggest that our approach is preferable. The fixed ratio approach lacks a rigorous foundation, and the SIPP and MOL approaches do not perform reliably mainly because of long service times. We conclude the paper with policy recommendations."
1828,"Technology Adoption with Uncertain Future Costs and Quality","Smith, James E. and Ulu, Canan","OPERATIONS RESEARCH","60","2","262-274","2012","MAR-APR","","","In this paper we study the impact of uncertainty about future innovations in quality and costs on consumers' technology adoption decisions. We model the uncertainty in the technology's quality and costs as a Markov process and consider three models of the adoption decision. The first model assumes that consumers do a simple net present value (NPV) analysis that compares the NPV of adopting to that of not adopting, without considering the possibility of waiting. The second model is a stochastic dynamic program that considers the possibility of waiting and views the adoption decision as a one-time event, i.e., the consumer will only make a single purchase, the only question is when. The third model allows repeat purchases so the consumer may upgrade by purchasing new versions of the technology whenever it suits her. We study structural properties of these models, e.g., the following: What changes in qualities and costs will make the consumer better off? What changes will encourage adoption? We will see that the simple NPV and single-purchase model have many intuitive properties: with the right notion of improvements and reasonable assumptions about the technology changes, we find that improvements in the technology make the consumer better off and encourage adoption. Here improvements are defined using a partial order on quality and cost pairs. The results are more complicated in the repeat-purchase model. Under the same conditions on technology changes, technology improvements will make the consumer better off. However, except for special cases of transitions, these improvements may make the consumer better off and discourage adoption."
1829,"Lagrangian Duality and Branch-and-Bound Algorithms for Optimal Power Flow","Phan, Dzung T.","OPERATIONS RESEARCH","60","2","275-285","2012","MAR-APR","","","This paper investigates a Lagrangian dual problem for solving the optimal power flow problem in rectangular form that arises from power system analysis. If strong duality does not hold for the dual, we propose two classes of branch-and-bound algorithms that guarantee to solve the problem to optimality. The lower bound for the objective function is obtained by the Lagrangian duality, whereas the feasible set subdivision is based on the rectangular or ellipsoidal bisection. The numerical experiments are reported to demonstrate the effectiveness of the proposed algorithms. We note that no duality gap is observed for any of our test problems."
1830,"Technical Note-On the Quasiconcavity of Lost-Sales Inventory Models with Fixed Costs","Li, Qing and Yu, Peiwen","OPERATIONS RESEARCH","60","2","286-291","2012","MAR-APR","","","We show that under a set of conditions, both the maximal profit function and the objective function in several lost-sales inventory models with fixed costs are quasiconcave. Not only is the quasiconcavity property useful computationally, it also leads to a sharper characterization of the optimal policies. Neither the proof of the quasiconcavity property itself nor the proof of the optimal policies by using the property requires the machinery of K-concavity or any of its K-related extensions, and hence they are intuitively appealing."
1831,"Stochastic Optimization of Sensor Placement for Diver Detection","Molyboha, Anton and Zabarankin, Michael","OPERATIONS RESEARCH","60","2","292-312","2012","MAR-APR","","","A comprehensive framework for diver detection by a hydrophone network in an urban harbor is presented. It includes a signal processing algorithm and a diver detection test and formulates optimal hydrophone placement as a two-stage stochastic optimization problem with respect to different scenarios of underwater noise. The signal processing algorithm identifies sound intensity peaks associated with diver breathing and outputs a diver number measuring the likelihood of diver presence, whereas the diver detection test aggregates the diver numbers obtained from the hydrophones in a linear statistic and optimizes the statistic's coefficients and a detection threshold for each noise scenario. The serial dependence of the diver numbers on a short time scale (several detection periods) is modeled by a hidden Markov chain, and finding the worst-case diver's trajectory for each hydrophone placement and noise scenario is reduced to a linear programming problem. The framework is tested in numerical experiments with real-life data for circular and elliptic hydrophone placements and is shown to be superior to a deterministic energy-based approach."
1832,"Estimating Primary Demand for Substitutable Products from Sales Transaction Data","Vulcano, Gustavo and van Ryzin, Garrett and Ratliff, Richard","OPERATIONS RESEARCH","60","2","313-334","2012","MAR-APR","","","We propose a method for estimating substitute and lost demand when only sales and product availability data are observable, not all products are displayed in all periods (e.g., due to stockouts or availability controls), and the seller knows its aggregate market share. The model combines a multinomial logit (MNL) choice model with a nonhomogeneous Poisson model of arrivals over multiple periods. Our key idea is to view the problem in terms of primary (or first-choice) demand; that is, the demand that would have been observed if all products had been available in all periods. We then apply the expectation-maximization (EM) method to this model, and we treat the observed demand as an incomplete observation of primary demand. This leads to an efficient, iterative procedure for estimating the parameters of the model. All limit points of the procedure are provably stationary points of the incomplete data log-likelihood function. Every iteration of the algorithm consists of simple, closed-form calculations. We illustrate the effectiveness of the procedure on simulated data and two industry data sets."
1833,"Generalized Quantity Competition for Multiple Products and Loss of Efficiency","Kluberg, Jonathan and Perakis, Georgia","OPERATIONS RESEARCH","60","2","335-350","2012","MAR-APR","","","We study a generalized model of quantity (Cournot) oligopolistic competition. The impact of competition on social surplus and firms' profit is analyzed. Firms produce multiple differentiated products and face production constraints. We compare the social surplus produced by competing firms and by colluding firms with the maximum achievable total surplus in the market. Similarly, we quantify the loss of profit that firms incur by competing instead of colluding. Our goal is to understand how the presence of competition affects the firms and society as a whole, but also to determine what are the key drivers of the inefficiencies that arise due to competition."
1834,"Cargo Capacity Management with Allotments and Spot Market Demand","Levin, Yuri and Nediak, Mikhail and Topaloglu, Huseyin","OPERATIONS RESEARCH","60","2","351-365","2012","MAR-APR","","","We consider a problem faced by an airline that operates a number of parallel flights to transport cargo between a particular origin to destination pair. The airline can sell its cargo capacity either through allotment contracts or on the spot market, where customers exhibit choice behavior between different flights. The goal is to simultaneously select allotment contracts among available bids and find a booking control policy for the spot market to maximize the sum of the profit from the allotments and the total expected profit from the spot market. We formulate the booking control problem on the spot market as a dynamic program and construct approximations to its value functions, which can be used to estimate the total expected profit from the spot market. We show that our value function approximations provide upper bounds on the optimal total expected profit from the spot market, and they allow us to solve the allotment selection problem through a sequence of linear mixed-integer programs with a special structure. Furthermore, the value function approximations are useful for construing a booking control policy for the spot market with desirable monotonic properties. Computational experiments show that the proposed approach can be scaled to realistic problems and provides well-performing allotment allocation and booking control decisions."
1835,"A Conic Integer Programming Approach to Stochastic Joint Location-Inventory Problems","Atamtuerk, Alper and Berenguer, Gemma and Shen, Zuo-Jun (Max)","OPERATIONS RESEARCH","60","2","366-381","2012","MAR-APR","","","We study several joint facility location and inventory management problems with stochastic retailer demand. In particular, we consider cases with uncapacitated facilities, capacitated facilities, correlated retailer demand, stochastic lead times, and multicommodities. We show how to formulate these problems as conic quadratic mixed-integer problems. Valid inequalities, including extended polymatroid and extended cover cuts, are added to strengthen the formulations and improve the computational results. Compared to the existing modeling and solution methods, the new conic integer programming approach not only provides a more general modeling framework but also leads to fast solution times in general."
1836,"A Column-Generation Based Tactical Planning Method for Inventory Routing","Michel, S. and Vanderbeck, F.","OPERATIONS RESEARCH","60","2","382-397","2012","MAR-APR","","","Inventory routing problems combine the optimization of product deliveries (or pickups) with inventory control at customer sites. The application that motivates this paper concerns the planning of single-product pickups over time; each site accumulates stock at a deterministic rate; the stock is emptied on each visit. At the tactical planning stage considered here, the objective is to minimize a surrogate measure of routing cost while achieving some form of regional clustering by partitioning the sites between the vehicles. The fleet size is given but can potentially be reduced. Planning consists of assigning customers to vehicles in each time period, but the routing, i.e., the actual sequence in which vehicles visit customers, is considered an operational decision. The planning is due to be repeated over the time horizon with constrained periodicity. We develop a truncated branch-and-price-and-cut algorithm combined with rounding and local search heuristics that yield both primal solutions and dual bounds. On a large-scale industrial test problem (with close to 6,000 customer visits to schedule), we obtain a solution within 6.25% deviation from the optimal to our model. A rough comparison between an operational routing resulting from our tactical solution and the industrial practice shows a 10% decrease in the number of vehicles as well as in the travel distance. The key to the success of the approach is the use of a state-space relaxation technique in formulating the master program to avoid the symmetry in time."
1837,"Piecewise Linear Multicriteria Programs: The Continuous Case and Its Discontinuous Generalization","Fang, Ya Ping and Meng, Kaiwen and Yang, Xiao Qi","OPERATIONS RESEARCH","60","2","398-409","2012","MAR-APR","","","In this paper we study piecewise linear multicriteria programs, that is, multicriteria programs with either a continuous or discontinuous piecewise linear objective function and a polyhedron set constraint. We obtain an algebraic representation of a semi-closed polyhedron and apply it to show that the image of a semi-closed polyhedron under a continuous linear function is always one semi-closed polyhedron. We establish that the (weak) Pareto solution/point set of a piecewise linear multicriteria program is the union of finitely many semi-closed polyhedra. We propose an algorithm for finding the Pareto point set of a continuous piecewise linear bi-criteria program and generalize it to the discontinuous case. We apply our algorithm to solve the discontinuous hi-criteria portfolio selection problem with an l(infinity) risk measure and transaction costs and show that this algorithm can be improved by using an ideal point strategy."
1838,"Belief Propagation for Min-Cost Network Flow: Convergence and Correctness","Gamarnik, David and Shah, Devavrat and Wei, Yehua","OPERATIONS RESEARCH","60","2","410-428","2012","MAR-APR","","","Distributed, iterative algorithms operating with minimal data structure while performing little computation per iteration are popularly known as message passing in the recent literature. Belief propagation (BP), a prototypical message-passing algorithm, has gained a lot of attention across disciplines, including communications, statistics, signal, processing, and machine learning as an attractive, scalable, general-purpose heuristic for a wide class of optimization and statistical inference problems. Despite its empirical success, the theoretical understanding of BP is far from complete. With the goal of advancing the state of art of our understanding of BP, we study the performance of BP in the context of the capacitated minimum-cost network flow problem a cornerstone in the development of the theory of polynomial-time algorithms for optimization problems and widely used in the practice of operations research. As the main result of this paper, we prove that BP converges to the optimal solution in pseudopolynomial time, provided that the optimal solution of the underlying network flow problem instance is unique and the problem parameters are integral. We further provide a simple modification of the BP to obtain a fully polynomial-time randomized approximation scheme (FPRAS) without requiring uniqueness of the optimal solution. This is the first instance where BP is proved to have fully polynomial running time. Our results thus provide a theoretical justification for the viability of BP as an attractive method to solve an important class of optimization problems."
1839,"Approximating the Nonlinear Newsvendor and Single-Item Stochastic Lot-Sizing Problems When Data Is Given by an Oracle","Halman, Nir and Orlin, James B. and Simchi-Levi, David","OPERATIONS RESEARCH","60","2","429-446","2012","MAR-APR","","","The single-item stochastic lot-sizing problem is to find an inventory replenishment policy in the presence of discrete stochastic demands under periodic review and finite time horizon. A closely related problem is the single-period newsvendor model. It is well known that the newsvendor problem admits a closed formula for the optimal order quantity whenever the revenue and salvage values are linear increasing functions and the procurement (ordering) cost is fixed plus linear. The optimal policy for the single-item lot-sizing model is also well known under similar assumptions. In this paper we show that the classical (single-period) newsvendor model with fixed plus linear ordering cost cannot be approximated to any degree of accuracy when either the demand distribution or the cost functions are given by an oracle. We provide a fully polynomial time approximation scheme for the nonlinear single-item stochastic lot-sizing problem, when demand distribution is given by an oracle, procurement costs are provided as nondecreasing oracles, holding/backlogging/disposal costs are linear, and lead time is positive. Similar results exist for the nonlinear newsvendor problem. These approximation schemes are designed by extending the technique of K-approximation sets and functions."
1840,"A New Stochastic Derivative Estimator for Discontinuous Payoff Functions with Application to Financial Derivatives","Wang, Yongqiang and Fu, Michael C. and Marcus, Steven I.","OPERATIONS RESEARCH","60","2","447-460","2012","MAR-APR","","","Motivated by infinitesimal perturbation analysis (IPA) and the likelihood ratio (LR) method, we derive a new unbiased stochastic derivative estimator for a class of discontinuous payoff functions that arise in many options pricing settings from finance. Our method includes IPA and the LR method as special cases and can be applied to functions of more general forms containing indicator functions. This new estimator can be computed from a single sample path or simulation, whereas existing estimators generally require additional simulations for the class of discontinuous payoff functions considered here. We apply this method to sensitivity analysis for European call options and American-style call options, and numerical experiments indicate that the estimator is computationally more efficient than other estimators."
1841,"Staffing Call Centers with Impatient Customers: Refinements to Many-Server Asymptotics","Zhang, Bo and van Leeuwaarden, Johan S. H. and Zwart, Bert","OPERATIONS RESEARCH","60","2","461-474","2012","MAR-APR","","","In call centers it is crucial to staff the right number of agents so that the targeted service levels are met. These staffing problems typically lead to constraint satisfaction problems that are hard to solve. During the last decade, a beautiful many-server asymptotic theory has been developed to solve such problems for large call centers, and optimal staffing rules are known to obey the square-root staffing principle. This paper presents refinements to many-server asymptotics and this staffing principle for a Markovian queueing model with impatient customers."
1842,"Exact FCFS Matching Rates for Two Infinite Multitype Sequences","Adan, Ivo and Weiss, Gideon","OPERATIONS RESEARCH","60","2","475-489","2012","MAR-APR","","","{Motivated by queues with multitype servers and multitype customers, we consider an infinite sequence of items of types C = {c(1),... c(I)}, and another infinite sequence of items of types J = {s(I),... s(J)"
1843,"A Diffusion Regime with Nondegenerate Slowdown","Atar, Rami","OPERATIONS RESEARCH","60","2","490-500","2012","MAR-APR","","","We study a diffusion regime-earlier considered by Gurvich, Mandelbaum, Shaikhet, and Whitt in the case of the M/M/N queue which may be regarded in a sense that we make precise, as a midpoint between two well-known heavy traffic diffusion regimes, the conventional and the quality and efficiency driven regimes. Unlike the other two, this regime, which we call the nondegenerate slowdown regime, enjoys the property that delay and service time are of the same order of magnitude, a property that is often desirable from a modeling viewpoint. Our main result is that in the case of heterogeneous exponential multiserver systems. this regime gives rise to new limit processes for the sojourn time. In particular, the joint limit law of the delay and service time processes is identified as a reflected Brownian motion and an independent process, whose marginal is a size-biased mixture of exponentials. Our results also motivate the formulation and study of new diffusion control problems based on sojourn time cost."
1844,"Optimizing Long-Term Production Plans in Underground and Open-Pit Copper Mines","Epstein, Rafael and Goic, Marcel and Weintraub, Andres and Catalan, Jaime and Santibanez, Pablo and Urrutia, Rodolfo and Cancino, Raul and Gaete, Sergio and Aguayo, Augusto and Caro, Felipe","OPERATIONS RESEARCH","60","1","4-17","2012","JAN-FEB","","","We present a methodology for long-term mine planning based on a general capacitated multicommodity network flow formulation. It considers underground and open-pit ore deposits sharing multiple downstream processing plants over a long horizon. The purpose of the model is to optimize several mines in an integrated fashion, but real size instances are hard to solve due to the combinatorial nature of the problem. We tackle this by solving the relaxation of a tight linear formulation, and we round the resulting near-integer solution with a customized procedure. The model has been implemented at Codelco, the largest copper producer in the world. Since 2001, the system has been used on a regular basis and has increased the net present value of the production plan for a single mine by 5%. Moreover, integrating multiple mines provided an additional increase of 3%. The system has allowed planners to evaluate more scenarios. In particular, the model was used to study the option of delaying by four years the conversion of Chiquicamata, Codelco's largest open-pit mine, to underground operations."
1845,"The Planning of Guaranteed Targeted Display Advertising","Turner, John","OPERATIONS RESEARCH","60","1","18-33","2012","JAN-FEB","","","As targeted advertising becomes prevalent in a wide variety of media vehicles, planning models become increasingly important to ad networks that need to match ads to appropriate audience segments, provide a high quality of service (meet advertisers' goals), and ensure that ad serving opportunities are not wasted. We define Guaranteed Targeted Display Advertising (GTDA) as a class of media vehicles that include webpage banner ads, video games, electronic outdoor billboards, and the next generation of digital TV, and formulate the GTDA planning problem as a transportation problem with quadratic objective. By modeling audience uncertainty, forecast errors, and the ad server's execution of the plan, we derive sufficient conditions that state when our quadratic objective is a good surrogate for several ad delivery performance metrics. Moreover, our quadratic objective allows us to construct duality-based bounds for evaluating aggregations of the audience space, leading to two efficient algorithms for solving large problems: the first intelligently refines the audience space into successively smaller blocks, and the second uses scaling to find a feasible solution given a fixed audience space partition. Near-optimal schedules can often be produced despite significant aggregation."
1846,"Design and Operations of Gas Transmission Networks","Babonneau, Frederic and Nesterov, Yurii and Vial, Jean-Philippe","OPERATIONS RESEARCH","60","1","34-47","2012","JAN-FEB","","","Problems dealing with the design and operations of gas transmission networks are challenging. The standard approaches lead to a difficult nonlinear nonconvex optimization problem. To get around this difficulty, we use a minimum energy principle to define stationary flows in the network. This solution minimizes the total energy dissipated in the system. We extend the minimization process to the choice of suitable diameters on the reinforcing arcs and add a constraint that limits the monetary cost of investment and of purchase and delivery of gas. Under a suitable and acceptable approximation of the structure of the investment cost function, the new problem turns out to be convex and tractable even for very large networks."
1847,"Network Optimization Models for Resource Allocation in Developing Military Countermeasures","Golany, Boaz and Kress, Moshe and Penn, Michal and Rothblum, Uriel G.","OPERATIONS RESEARCH","60","1","48-63","2012","JAN-FEB","","","A military arms race is characterized by an iterative development of measures and countermeasures. An attacker attempts to introduce new weapons in order to gain some advantage, whereas a defender attempts to develop countermeasures that can mitigate or even eliminate the effects of the weapons. This paper addresses the defender's decision problem: given limited resources, which countermeasures should be developed and how much should be invested in their development to minimize the damage caused by the attacker's weapons over a certain time horizon. We formulate several optimization models, corresponding to different operational settings, as constrained shortest-path problems and variants thereof. We then demonstrate the potential applicability and robustness of this approach with respect to various scenarios."
1848,"Pricing Asian Options Under a Hyper-Exponential Jump Diffusion Model","Cai, Ning and Kou, Steven","OPERATIONS RESEARCH","60","1","64-77","2012","JAN-FEB","","","We obtain a closed-form solution for the double-Laplace transform of Asian options under the hyper-exponential jump diffusion model. Similar results were available previously only in the special case of the Black-Scholes model (BSM). Even in the case of the BSM, our approach is simpler as we essentially use only Ito's formula and do not need more advanced results such as those of Bessel processes and Lamperti's representation. As a by-product we also show that a well-known recursion relating to Asian options has a unique solution in a probabilistic sense. The double-Laplace transform can be inverted numerically via a two-sided Euler inversion algorithm. Numerical results indicate that our pricing method is fast, stable, and accurate; and it performs well even in the case of low volatilities."
1849,"Sequential Importance Sampling and Resampling for Dynamic Portfolio Credit Risk","Deng, Shaojie and Giesecke, Kay and Lai, Tze Leung","OPERATIONS RESEARCH","60","1","78-91","2012","JAN-FEB","","","We provide a sequential Monte Carlo method for estimating rare-event probabilities in dynamic, intensity-based point process models of portfolio credit risk. The method is based on a change of measure and involves a resampling mechanism. We propose resampling weights that lead, under technical conditions, to a logarithmically efficient simulation estimator of the probability of large portfolio losses. A numerical analysis illustrates the features of the method and contrasts it with other rare-event schemes recently developed for portfolio credit risk, including an interacting particle scheme and an importance sampling scheme."
1850,"Lower Bounds and Heuristics for Supply Chain Stock Allocation","Marklund, Johan and Rosling, Kaj","OPERATIONS RESEARCH","60","1","92-105","2012","JAN-FEB","","","Assume that in periods with stochastic demand remain until the next replenishment arrives at a central warehouse. How should the available inventory be allocated among N retailers? This paper presents a new policy and a new lower bound for the expected cost of this problem. The lower bound becomes tight as N -> infinity. The infinite horizon problem then decomposes into N independent m-period problems with optimal retailer ship-up-to levels that decrease over the in periods, and the warehouse is optimally replenished by an order-up-to level that renders zero (local) warehouse safety stock at the end of each replenishment cycle. Based on the lower bound solution, we suggest a heuristic for finite N. In a numerical study it outperforms the heuristic by Jackson [Jackson, P. L. 1988. Stock allocation in a two-echelon distribution system or what to do until your ship comes in. Management Sci. 34(7) 880-895], and the new lower bound improves on Clark and Scarf's [Clark, A. J., H. Scarf. 1960. Optimal policies for a multi-echelon inventory problem. Management Sci. 6(4) 475-490] bound when N is not too small. Moreover, the warehouse zero-safety-stock heuristic is comparable to Clark and Scarf's warehouse policy for lead times that are not too long. The suggested approach is quite general and may be applied to other logistical problems. In the present application it retains some of the risk-pooling benefits of holding central warehouse stock."
1851,"A Branch-Price-and-Cut Algorithm for Single-Product Maritime Inventory Routing","Engineer, Faramroze G. and Furman, Kevin C. and Nemhauser, George L. and Savelsbergh, Martin W. P. and Song, Jin-Hwa","OPERATIONS RESEARCH","60","1","106-122","2012","JAN-FEB","","","A branch-price-and-cut algorithm is developed for a complex maritime inventory-routing problem with varying storage capacities and production/consumption rates at facilities. The resulting mixed-integer pricing problem is solved exactly and efficiently using a dynamic program that exploits certain extremal characteristics of the pricing problem. The formulation is tightened by using the problem's boundary conditions in preprocessing and to restrict the set of columns that are produced by the pricing problem. Branching schemes and cuts are introduced that can be implemented efficiently and that preserve the structure of the pricing problem. Some of the cuts are inspired by the capacity cuts known for the vehicle-routing problem, whereas others specifically target fractional solutions brought about by individual vessels competing for limited inventory at load ports and limited storage capacity at discharge ports. The branch-price-and-cut approach solves practically sized problems motivated by the operations of an oil company to optimality, and it provides reasonable bounds for larger instances."
1852,"Approximation Algorithms for VRP with Stochastic Demands","Gupta, Anupam and Nagarajan, Viswanath and Ravi, R.","OPERATIONS RESEARCH","60","1","123-127","2012","JAN-FEB","","","We consider the vehicle routing problem with stochastic demands (VRPSD). We give randomized approximation algorithms achieving approximation guarantees of 1 + alpha for split-delivery VRPSD, and 2 + alpha for unsplit-delivery VRPSD; here alpha is the best approximation guarantee for the traveling salesman problem. These bounds match the best known for even the respective deterministic problems [Altinkemer, K., B. Gavish. 1987. Heuristics for unequal weight delivery problems with a fixed error guarantee. Oper Res. Lett. 6(4) 149-158; Altinkemer, K., B. Gavish. 1990. Heuristics for delivery problems with constant error guarantees. Transportation Res. 24(4) 294-297] We also show that the cyclic heuristic for split-delivery VRPSD achieves a constant approximation ratio, as conjectured in Bertsimas [Bertsimas, D. J. 1992. A vehicle routing problem with stochastic demand. Oper Res. 40(3) 574-585]."
1853,"Polymatroid Optimization, Submodularity, and Joint Replenishment Games","He, Simai and Zhang, Jiawei and Zhang, Shuzhong","OPERATIONS RESEARCH","60","1","128-137","2012","JAN-FEB","","","In this paper we consider the problem of maximizing a separable concave function over a polymatroid. More specifically, we study the submodularity of its optimal objective value in the parameters of the objective function. This question is interesting in its own right and is encountered in many applications. But our research has been motivated mainly by a cooperative game associated with the well-known joint replenishment model. By applying our general results on polymatroid optimization, we prove that this cooperative game is submodular (i.e., its characteristic cost function is submodular) if the joint setup cost is a normalized and nondecreasing submodular function. Furthermore, the same result holds true for a more general one-warehouse multiple retailer game, which affirmatively answers an open question posed by Anily and Haviv [Anily, S., M. Haviv. 2007. The cost allocation problem for the first order interaction joint replenishment model. Oper Res. 55(2) 292-302]."
1854,"On the Complexity of Nonoverlapping Multivariate Marginal Bounds for Probabilistic Combinatorial Optimization Problems","Doan, Xuan Vinh and Natarajan, Karthik","OPERATIONS RESEARCH","60","1","138-149","2012","JAN-FEB","","","Given a combinatorial optimization problem with an arbitrary partition of the set of random objective coefficients, we evaluate the tightest-possible bound on the expected optimal value for joint distributions consistent with the given multivariate marginals of the subsets in the partition. For univariate marginals, this bound was first proposed by Meilijson and Nadas [Meilijson, I., A. Nadas. 1979. Convex majorization with an application to the length of critical path. J. Appl. Probab. 16(3) 671-677]. We generalize the bound to nonoverlapping multivariate marginals using multiple-choice integer programming. New instances of polynomial-time computable bounds are identified for discrete distributions. For the problem of selecting up to M items out of a set of N items of maximum total weight, the multivariate marginal bound is shown to be computable in polynomial time, when the size of each subset in the partition is O(log N). For an activity-on-arc PERT network, the partition is naturally defined by subsets of incoming arcs into nodes. The multivariate marginal bound on expected project duration is shown to be computable in time polynomial in the maximum number of scenarios for any subset and the size of the network. As an application, a polynomial-time solvable two-stage stochastic program for project crashing is identified. An important feature of the bound developed in this paper is that it is exactly achievable by a joint distribution, unlike many of the existing bounds."
1855,"Price of Correlations in Stochastic Optimization","Agrawal, Shipra and Ding, Yichuan and Saberi, Amin and Ye, Yinyu","OPERATIONS RESEARCH","60","1","150-162","2012","JAN-FEB","","","When decisions are made in the presence of high-dimensional stochastic data, handling joint distribution of correlated random variables can present a formidable task, both in terms of sampling and estimation as well as algorithmic complexity. A common heuristic is to estimate only marginal distributions and substitute joint distribution by independent (product) distribution. In this paper, we study possible loss incurred on ignoring correlations through a distributionally robust stochastic programming model, and we quantify that loss as price of correlations (PUG). Using techniques of cost sharing from game theory, we identify a wide class of problems for which POC has a small upper bound. To our interest, this class will include many stochastic convex programs, uncapacitated facility location, Steiner tree, and submodular functions, suggesting that the intuitive approach of assuming independent distribution acceptably approximates the robust model for these stochastic optimization problems. Additionally, we demonstrate hardness of bounding POC via examples of subadditive and supermodular functions that have large POC. We find that our results are also useful for solving many deterministic optimization problems like welfare maximization, k-dimensional matching, and transportation problems, under certain conditions."
1856,"Asymptotic Optimality of Balanced Routing","Chen, Hong and Ye, Heng-Qing","OPERATIONS RESEARCH","60","1","163-179","2012","JAN-FEB","","","Consider a system with K parallel servers, each with its own waiting room. Upon arrival, a job is routed to the queue of one of the servers. Finding a routing policy that minimizes the total workload in the system is a known difficult problem in general. Even if the optimal policy is identified, the policy would require the full queue length information at the arrival of each job; for example, the join-the-shortest-queue policy (which is known to be optimal for identical servers with exponentially distributed service times) would require comparing the queue lengths of all the servers. In this paper, we consider a balanced routing policy that examines only a subset of c servers, with 1 <= c <= K: specifically, upon the arrival of a job, choose a subset of c servers with a probability proportional to their service rates, and then route the job to the one with the shortest queue among the c chosen servers. Under Such a balanced policy, we derive the diffusion limits of the queue length processes and the workload processes. We note that the diffusion limits are the same for these processes regardless the choice of c, as long as c >= 2. We further show that the proposed balanced routing policy for any fixed c >= 2 is asymptotically optimal in the sense that it minimizes the workload over all time in the diffusion limit. In addition, the policy helps to distribute work among all the servers evenly."
1857,"The Knowledge Gradient Algorithm for a General Class of Online Learning Problems","Ryzhov, Ilya O. and Powell, Warren B. and Frazier, Peter I.","OPERATIONS RESEARCH","60","1","180-195","2012","JAN-FEB","","","We derive a one-period look-ahead policy for finite- and infinite-horizon online optimal learning problems with Gaussian rewards. Our approach is able to handle the case where our prior beliefs about the rewards are correlated, which is not handled by traditional multiarmed bandit methods. Experiments show that our KG policy performs competitively against the best-known approximation to the optimal policy in the classic bandit problem, and it outperforms many learning policies in the correlated case."
1858,"Consistency of Multidimensional Convex Regression","Lim, Eunji and Glynn, Peter W.","OPERATIONS RESEARCH","60","1","196-208","2012","JAN-FEB","","","Convex regression is concerned with computing the best fit of a convex function to a data set of n observations in which the independent variable is (possibly) multidimensional. Such regression problems arise in operations research, economics, and other disciplines in which imposing a convexity constraint on the regression function is natural. This paper studies a least-squares estimator that is computable as the solution of a quadratic program and establishes that it converges almost surely to the true function as n -> infinity under modest technical assumptions. In addition to this multidimensional consistency result, we identify the behavior of the estimator when the model is misspecified (so that the true function is nonconvex), and we extend the consistency result to settings in which the function must be both convex and nondecreasing (as is needed for consumer preference utility functions)."
1859,"Sequential Correlated Equilibria in Stopping Games","Heller, Yuval","OPERATIONS RESEARCH","60","1","209-224","2012","JAN-FEB","","","In many situations, such as trade in stock exchanges, agents have many opportunities to act within a short interval of time. The agents in such situations can often coordinate their actions in advance, but coordination during the game consumes too much time. An equilibrium in such situations has to be sequential in order to handle mistakes made by players. In this paper, we present a new solution concept for infinite-horizon dynamic games, which is appropriate for such situations: a sequential normal-form correlated approximate equilibrium. Under additional assumptions, we show that every such game admits this kind of equilibrium."
1860,"A Copulas-Based Approach to Modeling Dependence in Decision Trees","Wang, Tianyang and Dyer, James S.","OPERATIONS RESEARCH","60","1","225-242","2012","JAN-FEB","","","This paper presents a general framework based on copulas for modeling dependent multivariate uncertainties through the use of a decision tree. The proposed dependent decision tree model allows multiple dependent uncertainties with arbitrary marginal distributions to be represented in a decision tree with a sequence of conditional probability distributions. This general framework could be naturally applied in decision analysis and real options valuations, as well as in more general applications of dependent probability trees. While this approach to modeling dependencies can be based on several popular copula families as we illustrate, we focus on the use of the normal copula and present an efficient computational method for multivariate decision and risk analysis that can be standardized for convenient application."
1861,"Nurse Staffing in Medical Units: A Queueing Perspective","de Vericourt, Francis and Jennings, Otis B.","OPERATIONS RESEARCH","59","6","1320-1331","2011","NOV-DEC","","","In this paper, we present a closed queueing model to determine efficient nurse staffing policies. We explicitly model the workload experienced by s nurses within a single medical unit with n homogeneous patients as a closed M / M / s / / n queueing system, where each patient alternates between requiring assistance and not. The performance of the medical unit is based on the probability of excessive delay, the relative frequency with which the delay between the onset of patient neediness and the provision of care from a nurse exceeds a given time threshold. Using new many-server asymptotic results, we find that effective staffing policies should deviate from threshold-specific nurse-to-patient ratios by factors that take into account the total number of patients present in the unit. In particular, our staffing rule significantly differs from California Bill AB 394, legislation that mandates fixed nurse-to-patient staffing ratios. Simulations show that our results are robust to delay-dependent service times, generally distributed service times, and nonhomogeneous patients, i.e., those with different acuity levels."
1862,"Generation Capacity Expansion in a Risky Environment: A Stochastic Equilibrium Analysis","Ehrenmann, Andreas and Smeers, Yves","OPERATIONS RESEARCH","59","6","1332-1346","2011","NOV-DEC","","","We cast models of the generation capacity expansion type formally developed for the monopoly regime into equilibrium models better adapted for a competitive environment. We focus on some of the risks faced today by investors in generation capacity and thus pose the problem as a stochastic equilibrium model. We illustrate the approach on the problem of the incentive to invest. Agents can be risk neutral or risk averse. We model risk aversion through the CVaR of plants' profit. The CVaR induces risk-adjusted probabilities according to which investors value their plants. The model is formulated as a complementarity problem (including the CVaR valuation of investments). An illustration is provided on a small problem that captures several features of today's electricity world: a choice often restricted to coal and gas units, a peaky load curve because of wind penetration, uncertain fuel prices, and an evolving carbon market. We assess the potential of the approach by comparing energy-only and capacity market organizations in this risky environment. Our results can be summarized as follows: a deterministic analysis overlooks some changes of capacity structure induced by risk, whether in the capacity market or energy-only organizations. The risk-neutral analysis also misses a shift towards less capital-intensive technologies that may result from risk aversion. Last, risk aversion also increases the shortage of capacity compared to the risk-neutral view in the energy-only market when the price cap is low. This may have a dramatic impact on the bill to the final consumer. The approach relies on mathematical programming techniques and can be extended to full-size problems. The results are illustrative and may deserve more investigation."
1863,"Optimal Energy Commitments with Storage and Intermittent Supply","Kim, Jae Ho and Powell, Warren B.","OPERATIONS RESEARCH","59","6","1347-1360","2011","NOV-DEC","","","We formulate and solve the problem of making advance energy commitments for wind farms in the presence of a storage device with conversion losses, mean-reverting price process, and an autoregressive energy generation process from wind. We derive an optimal commitment policy under the assumption that wind energy is uniformly distributed. Then, the stationary distribution of the storage level corresponding to the optimal policy is obtained, from which the economic value of the storage as the relative increase in the expected revenue due to the existence of storage is obtained."
1864,"Dynamic Pricing with Loss-Averse Consumers and Peak-End Anchoring","Nasiry, Javad and Popescu, Ioana","OPERATIONS RESEARCH","59","6","1361-1368","2011","NOV-DEC","","","We study the dynamic pricing implications of a new, behaviorally motivated reference price mechanism based on the peak-end memory mode. This model suggests that consumers anchor on a reference price that is a weighted average of the lowest and most recent prices. Loss-averse consumers are more sensitive to perceived losses than gains relative to this reference price. We find that a range of constant pricing policies is optimal for the corresponding dynamic pricing problem. This range is wider the more consumers anchor on lowest prices, and it persists when buyers are loss neutral, in contrast with previous literature. In a transient regime, the optimal pricing policy is monotone and converges to a steady-state price, which is lower the more extreme and salient the low-price anchor is. Our results suggest that behavioral regularities, such as peak-end anchoring and loss aversion, limit the benefits of varying prices, and caution that the adverse effects of deep discounts on the firm's optimal prices and profits might be more enduring than previous models predict."
1865,"Integrated Optimization of Procurement, Processing, and Trade of Commodities","Devalkar, Sripad K. and Anupindi, Ravi and Sinha, Amitabh","OPERATIONS RESEARCH","59","6","1369-1381","2011","NOV-DEC","","","We consider the integrated optimization problem of procurement, processing, and trade of commodities in a multiperiod setting. Motivated by the operations of a prominent commodity processing firm, we model a firm that procures an input commodity and has processing capacity to convert the input into a processed commodity. The processed commodity is sold using forward contracts, while the input itself can be traded at the end of the horizon. We solve this problem optimally and derive closed-form expressions for the marginal value of input and output inventory. We find that the optimal procurement and processing decisions are governed by price-dependent inventory thresholds. We use commodity markets data for the soybean complex to conduct numerical studies and find that approximating the joint price processes of multiple output commodities using a single, composite output product and using the approximate price process to determine procurement and processing decisions is near optimal. Compared to a myopic spread-option-based heuristic, the optimization-based dynamic programming policy provides significant benefits under conditions of tight processing capacities and high price volatilities. Finally, we propose an approximation procedure to compute heuristic policies and an upper bound to compare the heuristic against, when commodity prices follow multifactor processes."
1866,"We Will Be Right with You: Managing Customer Expectations with Vague Promises and Cheap Talk","Allon, Gad and Bassamboo, Achal and Gurvich, Itai","OPERATIONS RESEARCH","59","6","1382-1394","2011","NOV-DEC","","","Delay announcements informing customers about anticipated service delays are prevalent in service-oriented systems. How delay announcements can influence customers in service systems is a complex problem that depends on both the dynamics of the underlying queueing system and on the customers' strategic behavior. We examine this problem of information communication by considering a model in which both the firm and the customers act strategically: the firm in choosing its delay announcement while anticipating customer response, and the customers in interpreting these announcements and in making the decision about when to join the system and when to balk. We characterize the equilibrium language that emerges between the service provider and her customers. The analysis of the emerging equilibria provides new and interesting insights into customer-firm information sharing. We show that even though the information provided to customers is nonverifiable, it improves the profits of the firm and the expected utility of the customers. The robustness of the results is illustrated via various extensions of the model. In particular, studying models with incomplete information on the system parameters allows us also to highlight the role of information provision in managing customer expectations regarding the congestion in the system. Further, the information could be as simple as high congestion/low congestion announcements, or it could be as detailed as the true state of the system. We also show that firms may choose to shade some of the truth by using intentional vagueness to lure customers."
1867,"Efficient Simulation of Value at Risk with Heavy-Tailed Risk Factors","Fuh, Cheng-Der and Hu, Inchi and Hsu, Ya-Hui and Wang, Ren-Her","OPERATIONS RESEARCH","59","6","1395-1406","2011","NOV-DEC","","","Simulation of small probabilities has important applications in many disciplines. The probabilities considered in value-at-risk (VaR) are moderately small. However, the variance reduction techniques developed in the literature for VaR computation are based on large-deviations methods, which are good for very small probabilities. Modeling heavy-tailed risk factors using multivariate t distributions, we develop a new method for VaR computation. We show that the proposed method minimizes the variance of the importance-sampling estimator exactly, whereas previous methods produce approximations to the exact solution. Thus, the proposed method consistently outperforms existing methods derived from large deviations theory under various settings. The results are confirmed by a simulation study."
1868,"Optimal Selection of Airport Runway Configurations","Bertsimas, Dimitris and Frankovich, Michael and Odoni, Amedeo","OPERATIONS RESEARCH","59","6","1407-1419","2011","NOV-DEC","","","We present a mixed integer programming (MIP) model to solve the problems of (i) selecting an airport's optimal sequence of runway configurations and (ii) determining the optimal balance of arrivals and departures to be served at any moment. These problems, the runway configuration management (RCM) problem and the arrival/departure runway balancing (ADRB) problem, respectively, are of critical importance in minimizing the delay of both in-flight and on-the-ground aircraft along with their associated costs. We show that under mild assumptions on the time required to change between configurations, large realistic problem instances can be solved within several seconds. Furthermore, as assumptions are relaxed, optimal solutions are still found within several minutes. Comparison with a sophisticated baseline heuristic reveals that in many cases the potential reduction in cost from using the method is significant and could be expected to be of the order of at least 10%. Finally, we present an extension of the MIP model to solve these two problems for a group of airports in a metropolitan area such as New York (metroplex), where operations at each airport within the metroplex might have an impact on operations at some of the other airports due to limitations in shared airspace."
1869,"Convexity Results for the Erlang Delay and Loss Formulae When the Server Utilization Is Held Constant","Harel, Arie","OPERATIONS RESEARCH","59","6","1420-1426","2011","NOV-DEC","","","This paper proves a long-standing conjecture regarding the optimal design of the M/M/s queue. The classical Erlang delay formula is shown to be a convex function of the number of servers when the server utilization is held constant. This means that when the server utilization is held constant, the marginal decrease in the probability that all servers are busy in the M/M/s queue brought about by the addition of two extra servers is always less than twice the decrease brought about by the addition of one extra server. As a consequence, a method of marginal analysis yields the optimal number of servers that minimize the waiting and service costs when the server utilization is held constant. In addition, it is shown that the expected number of customers in the queue and in the system, as well as the expected waiting time and sojourn in the M/M/s queue, are convex in the number of servers when the server utilization is held constant. These results are useful in design studies involving capacity planning in service operations. The classical Erlang loss formula is also shown to be a convex function of the number of servers when the server utilization is held constant."
1870,"Shadow-Routing Based Control of Flexible Multiserver Pools in Overload","Stolyar, Alexander L. and Tezcan, Tolga","OPERATIONS RESEARCH","59","6","1427-1444","2011","NOV-DEC","","","We consider a general parallel server system model with multiple customer classes and several flexible multiserver pools, in the many-server asymptotic regime where the input rates and server pool sizes are scaled up linearly to infinity. Service of a customer brings a constant reward, which depends on its class. The objective is to maximize the long-run reward rate. Our primary focus is on overloaded systems. Unlike in the case when the system is not overloaded, where the main decision is how to allocate resources to incoming customers, in this case it is also crucial to determine which customers will be admitted to the system. We propose a real-time, parsimonious, robust routing policy, SHADOW-RM, which does not require the knowledge of customer input rates and does not solve any optimization problem explicitly, and we prove its asymptotic optimality. Then, by combining SHADOW-RM with another policy, SHADOW-LB, proposed in our previous work for systems that are not overloaded, we suggest policy SHADOW-TANDEM, which automatically and seamlessly detects overload and reduces to one of the schemes, SHADOW-RM or SHADOW-LB, accordingly. Extensive simulations demonstrate a remarkably good performance of proposed policies."
1871,"Rational Generating Functions and Integer Programming Games","Koeppe, Matthias and Ryan, Christopher Thomas and Queyranne, Maurice","OPERATIONS RESEARCH","59","6","1445-1460","2011","NOV-DEC","","","We explore the computational complexity of computing pure Nash equilibria for a new class of strategic games called integer programming games, with differences of piecewise-linear convex functions as payoffs. Integer programming games are games where players' action sets are integer points inside of polytopes. Using recent results from the study of short rational generating functions for encoding sets of integer points pioneered by Alexander Barvinok, we present efficient algorithms for enumerating all pure Nash equilibria, and other computations of interest, such as the pure price of anarchy and pure threat point, when the dimension and number of convex linear pieces in the payoff functions are fixed. Sequential games where a leader is followed by competing followers (a Stackelberg-Nash setting) are also considered."
1872,"A Study of Interactions in the Risk Assessment of Complex Engineering Systems: An Application to Space PSA","Borgonovo, E. and Smith, C. L.","OPERATIONS RESEARCH","59","6","1461-1476","2011","NOV-DEC","","","Risk managers are often confronted with the evaluation of operational policies in which two or more system components are simultaneously affected by a change. In these instances, the decision-making process should be informed by the relevance of interactions. However, because of system and model complexity, a rigorous study for determining whether and how interactions quantitatively impact operational choices has not been developed yet. In light of the central role played by the multilinearity of the decision support models, we investigate the presence of interactions in multilinear functions first. We identify interactions that can be a priori excluded from the analysis. We introduce sensitivity measures that apportion the model output change to individual factors and interaction contributions in an exact fashion. The sensitivity measures are linked to graphical representation methods as tornado diagrams and Pareto charts, and a systematic way of inferring managerial insights is presented. We then specialize the findings to reliability and probabilistic safety assessment (PSA) problems. We set forth a procedure for determining the magnitude of changes that make interactions relevant in the analysis. Quantitative results are discussed by application to a PSA model developed at NASA to support decision making in space mission planning and design. Numerical findings show that suboptimal decisions concerning the components on which to focus managerial attention can be made, if the decision-making process is not informed by the relevance of interactions."
1873,"Benders Decomposition for Large-Scale Uncapacitated Hub Location","Contreras, Ivan and Cordeau, Jean-Francois and Laporte, Gilbert","OPERATIONS RESEARCH","59","6","1477-1490","2011","NOV-DEC","","","This paper describes an exact algorithm capable of solving large-scale instances of the well-known uncapacitated hub location problem with multiple assignments. The algorithm applies Benders decomposition to a strong path-based formulation of the problem. The standard decomposition algorithm is enhanced through the inclusion of several features such as the use of a multicut reformulation, the generation of strong optimality cuts, the integration of reduction tests, and the execution of a heuristic procedure. Extensive computational experiments were performed to evaluate the efficiency and robustness of the algorithm. Computational results obtained on classical benchmark instances (with up to 200 nodes) and on a new and more difficult set of instances (with up to 500 nodes) confirm the efficiency of the algorithm."
1874,"The Worst-Case Efficiency of Cost Sharing Methods in Resource Allocation Games","Harks, Tobias and Miller, Konstantin","OPERATIONS RESEARCH","59","6","1491-1503","2011","NOV-DEC","","","Resource allocation problems play a key role in many applications, including traffic networks, telecommunication networks, and economics. In most applications, the allocation of resources is determined by a finite number of independent players, each optimizing an individual objective function. An important question in all these applications is the degree of suboptimality caused by selfish resource allocation. We consider the worst-case efficiency of cost sharing methods in resource allocation games in terms of the ratio of the minimum guaranteed surplus of a Nash equilibrium and the maximal surplus. Our main technical result is an upper bound on the efficiency loss that depends on the class of allowable cost functions and the class of allowable cost sharing methods. We demonstrate the power of this bound by evaluating the worst-case efficiency loss for three well-known cost sharing methods: incremental cost sharing, marginal cost pricing, and average cost sharing."
1875,"Revised Delivery-Time Quotation in Scheduling with Tardiness Penalties","Steiner, George and Zhang, Rui","OPERATIONS RESEARCH","59","6","1504-1511","2011","NOV-DEC","","","There are many situations in supply chain scheduling when the supplier finds it impossible to meet the promised due dates for some orders. We present a model for the rescheduling of orders with simultaneous assignment of attainable revised due dates to minimize due date escalation and tardiness penalties for the supplier. We show that the problem is equivalent to minimizing the total tardiness with rejection with respect to the original due dates. We prove that the problem is NP-hard and present a pseudopolynomial algorithm for it. We also present a fully polynomial time approximation scheme for the problem. Finally, we discuss the implications of our solution for setting fair tardiness penalties when due dates have to be renegotiated because of the delays."
1876,"Refining Square-Root Safety Staffing by Expanding Erlang C","Janssen, A. J. E. M. and van Leeuwaarden, J. S. H. and Zwart, Bert","OPERATIONS RESEARCH","59","6","1512-1522","2011","NOV-DEC","","","We apply a new corrected diffusion approximation for the Erlang C formula to determine staffing levels in cost minimization and constraint satisfaction problems. These problems are motivated by large customer contact centers that are modeled as an M/M/s queue with s the number of servers or agents. The proposed staffing levels are refinements of the celebrated square-root safety-staffing rule and have the appealing property that they are as simple as the conventional square-root safety-staffing rule. In addition, we provide theoretical support for the empirical fact that square-root safety-staffing works well for moderate-sized systems."
1877,"An Optimal Policy for Joint Dynamic Price and Lead-Time Quotation","Feng, Jiejian and Liu, Liming and Liu, Xiaoming","OPERATIONS RESEARCH","59","6","1523-1527","2011","NOV-DEC","","","For a dynamic joint price and lead-time quotation problem with a fairly general demand function, we show that the policy consisting of a threshold and a reward-maximizing lead-time is optimal. This policy offers some interesting managerial insights. Under this policy, finding the exact optimal quotation can be accomplished by single-variable policy iterations of unimodal value functions."
1878,"Decentralized Inventory Sharing with Asymmetric Information","Yan, Xinghao and Zhao, Hui","OPERATIONS RESEARCH","59","6","1528-1538","2011","NOV-DEC","","","We study the information asymmetry issues in a decentralized inventory-sharing system consisting of a manufacturer and two independent retailers, who privately hold demand information, noncooperatively place their orders, but cooperatively share inventories with each other. We find that although the manufacturer needs retailers' mean demand and standard deviation for her wholesale price decision, each retailer only needs to know the other retailer's demand standard deviation for his order quantity decision. However, an incentive compatibility analysis shows that retailers have incentives to share their demand information untruthfully. Although a truth-inducing scheme can be developed for a system with symmetric retailers who share information between themselves, no such scheme can be developed to ensure truth-telling to the manufacturer. Further, we develop a coordination mechanism (CIS) for the decentralized inventory-sharing system, considering information asymmetry. We show that CIS coordinates the manufacturer-retailers system and leads to an all-win situation under complete information. More importantly, CIS minimizes the value of information such that each party can obtain expected profits very close to their first-best profits even under asymmetric information and hence indirectly solves the information asymmetry problem. To our knowledge, this work is the first to study decentralized inventory sharing and its coordination considering asymmetric information."
1879,"Cellular Bucket Brigades","Lim, Yun Fong","OPERATIONS RESEARCH","59","6","1539-1545","2011","NOV-DEC","","","Workers in a bucket brigade production system perform unproductive travel when they walk to get more work from their colleagues. We introduce a new design of bucket brigades to reduce unproductive travel. Under the new design, each worker works on one side of an aisle when he proceeds in one direction and works on the other side when he proceeds in the reverse direction. We propose simple rules for workers to share work under the new design and find a sufficient condition for the system to self-balance. Numerical examples suggest that the improvement in throughput by the new design can be as large as 30%. Even with a 20% reduction in labor, the new design can still increase throughput by 7%."
1880,"Dynamic Reserve Selection: Optimal Land Retention with Land-Price Feedbacks","Toth, Sandor F. and Haight, Robert G. and Rogers, Luke W.","OPERATIONS RESEARCH","59","5","1059-1078","2011","SEP-OCT","","","Urban growth compromises open space and ecosystem functions. To mitigate the negative effects, some agencies use reserve selection models to identify conservation sites for purchase or retention. Existing models assume that conservation has no impact on nearby land prices. We propose a new integer program that relaxes this assumption via adaptive cost coefficients. Our model accounts for the two key land price feedbacks that arise in markets where conservation competes with development: the amenity premium and price increases driven by shifts in market equilibriums. We illustrate the mechanics of the proposed model in a real land retention context. The results suggest that in competitive land markets, the optimal conservation strategy during the initial phase of the retention effort might be to use available dollars to buy fewer parcels with smaller total area that are under high risk of development. We show that failure to capture the land-price feedbacks can lead to significant losses in biological conservation. The present study is the first to create a reserve selection model that captures the economic theory of competitive land markets in a dynamic framework, produces tangible, parcel-level conservation recommendations, and works on problems with thousands of potential site selection decisions and several planning periods."
1881,"Parameterized Supply Function Bidding: Equilibrium and Efficiency","Johari, Ramesh and Tsitsiklis, John N.","OPERATIONS RESEARCH","59","5","1079-1089","2011","SEP-OCT","","","We consider a model where a finite number of producers compete to meet an infinitely divisible but inelastic demand for a product. Each firm is characterized by a production cost that is convex in the output produced, and firms act as profit maximizers. We consider a uniform price market design that uses supply function bidding: firms declare the amount they would supply at any positive price, and a single price is chosen to clear the market. We are interested in evaluating the impact of price-anticipating behavior both on the allocative efficiency of the market and on the prices seen at equilibrium. We show that by restricting the strategy space of the firms to parameterized supply functions, we can provide upper bounds on both the inflation of aggregate cost at the Nash equilibrium relative to the socially optimal level, as well as the markup of the Nash equilibrium price above the competitive level: as long as N > 2 firms are competing, these quantities are both upper bounded by 1 + 1/(N - 2). This result holds even in the presence of asymmetric cost structure across firms. We also discuss several extensions, generalizations, and related issues."
1882,"Process Flexibility Revisited: The Graph Expander and Its Applications","Chou, Mabel C. and Chua, Geoffrey A. and Teo, Chung-Piaw and Zheng, Huan","OPERATIONS RESEARCH","59","5","1090-1105","2011","SEP-OCT","","","We examine how to design a flexible process structure for a production system to match supply with demand more effectively. We argue that good flexible process structures are essentially highly connected graphs, and we use the concept of graph expansion (a measure of graph connectivity) to achieve various insights into this design problem. Whereas existing literature on process flexibility has focused on the expected performance of process structure, we analyze in this paper the worst-case performance of the flexible structure design problem under a more general setting, which encompasses a large class of objective functions. Chou et al. [Chou, M. C., G. Chua, C. P. Teo, H. Zheng. 2010. Design for process flexibility: Efficiency of the long chain and sparse structure. Oper. Res. 58(1) 43-58] showed the existence of a sparse process structure that performs nearly as well as the fully flexible system on average, but the approach using random sampling yields few insights into the nature of the process structure. We show that the Psi-expander structure, a variant of the graph expander structure (a highly connected but sparse graph) often used in communication networks, is within epsilon-optimality of the fully flexible system for all demand scenarios. Furthermore, the same expander structure works uniformly well for all objective functions in our class. Based on this insight, we derive design guidelines for general nonsymmetrical systems and develop a simple and easy-to-implement heuristic to design flexible process structures. Numerical results show that this simple heuristic performs well for a variety of numerical examples previously studied in the literature and compares favourably even with the best solutions obtained via extensive simulation and known demand distribution."
1883,"Wait-Time Predictors for Customer Service Systems with Time-Varying Demand and Capacity","Ibrahim, Rouba and Whitt, Ward","OPERATIONS RESEARCH","59","5","1106-1118","2011","SEP-OCT","","","We develop new, improved real-time delay predictors for many-server service systems with a time-varying arrival rate, a time-varying number of servers, and customer abandonment. We develop four new predictors, two of which exploit an established deterministic fluid approximation for a many-server queueing model with those features. These delay predictors can be used to make delay announcements. We use computer simulation to show that the proposed predictors outperform previous predictors."
1884,"Acquisition of Project-Specific Assets with Bayesian Updating","Kwon, H. Dharma and Lippman, Steven A.","OPERATIONS RESEARCH","59","5","1119-1130","2011","SEP-OCT","","","We study the impact of learning on the optimal policy and the time-to-decision in an infinite-horizon Bayesian sequential decision model with two irreversible alternatives: exit and expansion. In our model, a firm undertakes a small-scale pilot project to learn, via Bayesian updating, about the project's profitability, which is known to be in one of two possible states. The firm continuously observes the project's cumulative profit, but the true state of the profitability is not immediately revealed because of the inherent noise in the profit stream. The firm bases its exit or expansion decision on the posterior probability distribution of the profitability. The optimal policy is characterized by a pair of thresholds for the posterior probability. We find that the time-to-decision does not necessarily have a monotonic relation with the arrival rate of new information."
1885,"Optimizing the Societal Benefits of the Annual Influenza Vaccine: A Stochastic Programming Approach","Oezaltin, Osman Y. and Prokopyev, Oleg A. and Schaefer, Andrew J. and Roberts, Mark S.","OPERATIONS RESEARCH","59","5","1131-1143","2011","SEP-OCT","","","Seasonal influenza is a major public health concern, and the first line of defense is the flu shot. Antigenic drifts and the high rate of influenza transmission require annual updates to the flu shot composition. The World Health Organization recommends which flu strains to include in the annual vaccine, based on surveillance and epidemiological analysis. There are two critical decisions regarding the flu shot design. One is its composition; currently, three strains constitute the flu shot, and they influence vaccine effectiveness. Another critical decision is the timing of the composition decisions, which affects the flu shot production. Both of these decisions have to be made under uncertainty many months before the flu season starts. We quantify the trade-offs involved through a multistage stochastic mixed-integer program that determines the optimal flu shot composition and its timing in a stochastic and dynamic environment. We incorporate risk sensitivity through mean-risk models. Our results provide valuable insights for pressing policy issues."
1886,"Integration of Inventory and Pricing Decisions with Costly Price Adjustments","Chen, Xin and Zhou, Sean X. and Chen, Youhua (Frank)","OPERATIONS RESEARCH","59","5","1144-1158","2011","SEP-OCT","","","Motivated by the widespread adoption of dynamic pricing in industry and the empirical evidence of costly price adjustments, in this paper we consider a periodic-review inventory model with price adjustment costs that consist of both fixed and variable components. In each period, demand is stochastic and price-dependent. The firm needs to coordinate the pricing and inventory replenishment decisions in each period to maximize its total discounted profit over a finite planning horizon. We develop the general model and characterize the optimal policies for two special scenarios, namely, a model with inventory carryover and no fixed price-change costs and a model with fixed price-change costs and no inventory carryover. Finally, we propose an intuitive heuristic policy to tackle the general system whose optimal policy is expected to be very complicated. Our numerical studies show that this heuristic policy performs well."
1887,"A Fluid Approximation for Service Systems Responding to Unexpected Overloads","Perry, Ohad and Whitt, Ward","OPERATIONS RESEARCH","59","5","1159-1170","2011","SEP-OCT","","","In a recent paper we considered two networked service systems, each having its own customers and designated service pool with many agents, where all agents are able to serve the other customers, although they may do so inefficiently. Usually the agents should serve only their own customers, but we want an automatic control that activates serving some of the other customers when an unexpected overload occurs. Assuming that the identity of the class that will experience the overload or the timing and extent of the overload are unknown, we proposed a queue-ratio control with thresholds: When a weighted difference of the queue lengths crosses a prespecified threshold, with the weight and the threshold depending on the class to be helped, serving the other customers is activated so that a certain queue ratio is maintained. We then developed a simple deterministic steady-state fluid approximation, based on flow balance, under which this control was shown to be optimal, and we showed how to calculate the control parameters. In this sequel we focus on the fluid approximation itself and describe its transient behavior, which depends on a heavy-traffic averaging principle. The new fluid model developed here is an ordinary differential equation driven by the instantaneous steady-state probabilities of a fast-time-scale stochastic process. The averaging principle also provides the basis for an effective Gaussian approximation for the steady-state queue lengths. Effectiveness of the approximations is confirmed by simulation experiments."
1888,"Rating Customers According to Their Promptness to Adopt New Products","Hochbaum, Dorit S. and Moreno-Centeno, Erick and Yelland, Phillip and Catena, Rodolfo A.","OPERATIONS RESEARCH","59","5","1171-1183","2011","SEP-OCT","","","Databases are a significant source of information in organizations and play a major role in managerial decision-making. This study considers how to process commercial data on customer purchasing timing to provide insights on the rate of new product adoption by the company's consumers. Specifically, we show how to use the separation-deviation model (SD-model) to rate customers according to their proclivity for adopting products for a given line of high-tech products. We provide a novel interpretation of the SD-model as a unidimensional scaling technique and show that, in this context, it outperforms several dimension-reduction and scaling techniques. We analyze the results with respect to various dimensions of the customer base and report on the generated insights."
1889,"An Interior Point Constraint Generation Algorithm for Semi-Infinite Optimization with Health-Care Application","Oskoorouchi, Mohammad R. and Ghaffari, Hamid R. and Terlaky, Tamas and Aleman, Dionne M.","OPERATIONS RESEARCH","59","5","1184-1197","2011","SEP-OCT","","","We propose an interior point constraint generation (IPCG) algorithm for semi-infinite linear optimization (SILO) and prove that the algorithm converges to an epsilon-solution of SILO after a finite number of constraints is generated. We derive a complexity bound on the number of Newton steps needed to approach the updated mu-center after adding multiple violated constraints and a complexity bound on the total number of constraints that is required for the overall algorithm to converge. We implement our algorithm to solve the sector duration optimization problem arising in Leksell Gamma Knife (R) Perfexion (TM) (Elekta, Stockholm Sweden) treatment planning, a highly specialized treatment for brain tumors. Using real patient data provided by the Department of Radiation Oncology at Princess Margaret Hospital in Toronto, Ontario, Canada, we show that our algorithm can efficiently handle problems in real-life health-care applications by providing a quality treatment plan in a timely manner. Comparing our computational results with MOSEK, a commercial software package, we show that the IPCG algorithm outperforms the classical primal-dual interior point methods on sector duration optimization problem arising in Perfexion (TM) treatment planning. We also compare our results with that of a projected gradient method. In both cases we show that IPCG algorithm obtains a more accurate solution substantially faster."
1890,"The Impact of Delaying the Delay Announcements","Allon, Gad and Bassamboo, Achal","OPERATIONS RESEARCH","59","5","1198-1210","2011","SEP-OCT","","","Many service providers use delay announcements to inform customers of anticipated delays. However, this information is usually not provided immediately but after a short period of time (spent either waiting or occupied by the system). The focus of this paper is on the impact of this postponement on the ability of the firm to influence customer behavior by communicating nonverifiable congestion information to its customers, as well as on the profits and utilities for the firm and the customers, respectively. We show that this postponement can actually help the firm create credibility and augment the resulting equilibrium. However, in other settings this delay can also detract from the resulting equilibrium. Furthermore, we show that whenever credibility is created it improves not only the profit for the firm but also the customers' overall utility under certain settings."
1891,"General Bounds and Finite-Time Improvement for the Kiefer-Wolfowitz Stochastic Approximation Algorithm","Broadie, Mark and Cicek, Deniz and Zeevi, Assaf","OPERATIONS RESEARCH","59","5","1211-1224","2011","SEP-OCT","","","We consider the Kiefer-Wolfowitz (KW) stochastic approximation algorithm and derive general upper bounds on its mean-squared error. The bounds are established using an elementary induction argument and phrased directly in the terms of tuning sequences of the algorithm. From this we deduce the nonnecessity of one of the main assumptions imposed on the tuning sequences by Kiefer and Wolfowitz [Kiefer, J., J. Wolfowitz. 1952. Stochastic estimation of the maximum of a regression function. Ann. Math. Statist. 23(3) 462-466] and essentially all subsequent literature. The optimal choice of sequences is derived for various cases of interest, and an adaptive version of the KW algorithm, scaled-and-shifted KW (or SSKW), is proposed with the aim of improving its finite-time behavior. The key idea is to dynamically scale and shift the tuning sequences to better match them with characteristics of the unknown function and noise level, and thus improve algorithm performance. Numerical results are provided that illustrate that the proposed algorithm retains the convergence properties of the original KW algorithm while dramatically improving its performance in some cases."
1892,"Projected Perspective Reformulations with Applications in Design Problems","Frangioni, Antonio and Gentile, Claudio and Grande, Enrico and Pacifici, Andrea","OPERATIONS RESEARCH","59","5","1225-1232","2011","SEP-OCT","","","The perspective relaxation (PR) is a general approach for constructing tight approximations to mixed-integer nonlinear programs (MINLP) with semicontinuous variables. The PR of a MINLP can be formulated either as a mixed-integer second-order cone program (MI-SOCP), provided that the original objective function is SOCP-representable, or as a semi-infinite MINLP. In this paper, we show that under some further assumptions (rather restrictive, but satisfied in several practical applications), the PR of a mixed-integer quadratic program (MIQP) can also be reformulated as a piecewise-quadratic program (QP), ultimately yielding a QP relaxation of roughly the same size of the standard continuous relaxation. Furthermore, if the original problem has some exploitable structure, then this structure is typically preserved in the reformulation, thus allowing the construction of specialized approaches for solving the PR. We report on implementing these ideas on two MIQPs with appropriate structure: a sensor placement problem and a quadratic-cost (single-commodity) network design problem."
1893,"Exact Simulation of Point Processes with Stochastic Intensities","Giesecke, K. and Kakavand, H. and Mousavi, M.","OPERATIONS RESEARCH","59","5","1233-1245","2011","SEP-OCT","","","Point processes with stochastic arrival intensities are ubiquitous in many areas, including finance, insurance, reliability, health care, and queuing. They can be simulated from a Poisson process by time scaling with the cumulative intensity. The paths of the cumulative intensity are often generated with a discretization method. However, discretization introduces bias into the simulation results. The magnitude of the bias is difficult to quantify. This paper develops a sampling method that eliminates the need to discretize the cumulative intensity. The method is based on a projection argument and leads to unbiased simulation estimators. It is exemplified for a point process whose intensity is a function of a jump-diffusion process and the point process itself. In this setting, the method facilitates the exact sampling of both the point process and the driving jump-diffusion process. Numerical experiments demonstrate the effectiveness of the method."
1894,"Patrolling Games","Alpern, Steve and Morton, Alec and Papadaki, Katerina","OPERATIONS RESEARCH","59","5","1246-1257","2011","SEP-OCT","","","A key operational problem for those charged with the security of vulnerable facilities (such as airports or art galleries) is the scheduling and deployment of patrols. Motivated by the problem of optimizing randomized, and thus unpredictable, patrols, we present a class of patrolling games. The facility to be patrolled can be thought of as a network or graph Q of interconnected nodes (e. g., rooms, terminals), and the Attacker can choose to attack any node of Q within a given time T. He requires m consecutive periods there, uninterrupted by the Patroller, to commit his nefarious act (and win). The Patroller can follow any path on the graph. Thus, the patrolling game is a win-lose game, where the Value is the probability that the Patroller successfully intercepts an attack, given best play on both sides. We determine analytically either the Value of the game, or bounds on the Value, for various classes of graphs, and we discuss possible extensions and generalizations."
1895,"Find-and-Fetch Search on a Tree","Alpern, Steve","OPERATIONS RESEARCH","59","5","1258-1268","2011","SEP-OCT","","","We introduce a new type of search game called the find-and-fetch game F(Q, O). The Hider simply picks any point H in the network Q. The Searcher starts at time zero at a given point O of Q, moving at unit speed until he reaches H (finds the Hider). Then he returns at a given speed rho along the shortest path back to O, arriving at time R, the payoff. This models the problem faced in many types of search, including search-and-rescue problems and foraging problems of animals (where food must be found and returned to the lair). When Q is a binary tree, we derive optimal probabilities for the Searcher to branch at the nodes. These probabilities give a positive bias towards searching longer branches first. We show that the minimax value of the return time R (the game value of F(Q, O)) is mu + D/rho, where mu is the total length of Q and D is the mean distance from the root O to the leaves (terminal nodes) of Q, where the mean is taken with respect to what is known as the equal branch density distribution. As rho goes to infinity, our problem reduces to the search game model where the payoff is simply the time to reach the Hider, and our results tend to those obtained by Gal [Gal, S. 1979. Search games with mobile and immobile hider. SIAM J. Control Optim. 17(1) 99-122] and Anderson and Gal [Anderson, E. J., S. Gal. 1990. Search in a maze. Probab. Engrg. Inform. Sci. 4(3) 311-318] for that model. We also apply our return time formula mu + D/rho to determine the ideal location for the root (lair or rescue center) O, assuming it can be moved. In the traditional find only model, the location of O does not matter."
1896,"New Route Relaxation and Pricing Strategies for the Vehicle Routing Problem","Baldacci, Roberto and Mingozzi, Aristide and Roberti, Roberto","OPERATIONS RESEARCH","59","5","1269-1283","2011","SEP-OCT","","","In this paper, we describe an effective exact method for solving both the capacitated vehicle routing problem (CVRP) and the vehicle routing problem with time windows (VRPTW) that improves the method proposed by Baldacci et al. [Baldacci, R., N. Christofides, A. Mingozzi. 2008. An exact algorithm for the vehicle routing problem based on the set partitioning formulation with additional cuts. Math. Programming 115(2) 351-385] for the CVRP. The proposed algorithm is based on the set partitioning (SP) formulation of the problem. We introduce a new route relaxation called ng-route, used by different dual ascent heuristics to find near-optimal dual solutions of the LP-relaxation of the SP model. We describe a column-and-cut generation algorithm strengthened by valid inequalities that uses a new strategy for solving the pricing problem. The new ng-route relaxation and the different dual solutions achieved allow us to generate a reduced SP problem containing all routes of any optimal solution that is finally solved by an integer programming solver. The proposed method solves four of the five open Solomon's VRPTW instances and significantly improves the running times of state-of-the-art algorithms for both VRPTW and CVRP."
1897,"An Exact Method for the Capacitated Location-Routing Problem","Baldacci, Roberto and Mingozzi, Aristide and Calvo, Roberto Wolfler","OPERATIONS RESEARCH","59","5","1284-1296","2011","SEP-OCT","","","The capacitated location-routing problem (LRP) consists of opening one or more depots on a given set of a-priori defined depot locations, and designing, for each opened depot, a number of routes in order to supply the demands of a given set of customers. With each depot are associated a fixed cost for opening it and a capacity that limits the quantity that can be delivered to the customers. The objective is to minimize the sum of the fixed costs for opening the depots and the costs of the routes operated from the depots. This paper describes a new exact method for solving the LRP based on a set-partitioning-like formulation of the problem. The lower bounds produced by different bounding procedures, based on dynamic programming and dual ascent methods, are used by an algorithm that decomposes the LRP into a limited set of multicapacitated depot vehicle-routing problems (MCDVRPs). Computational results on benchmark instances from the literature show that the proposed method outperforms the current best-known exact methods, both for the quality of the lower bounds achieved and the number and the dimensions of the instances solved to optimality."
1898,"A Computational Approach for Optimal Joint Inventory-Pricing Control in an Infinite-Horizon Periodic-Review System","Feng, Youyi and Chen, Youhua (Frank)","OPERATIONS RESEARCH","59","5","1297-1303","2011","SEP-OCT","","","This note considers a joint inventory-pricing control problem in an infinite-horizon periodic-review system. Demand in a period is random and depends on the posted price. Besides the holding and shortage costs, the system incurs inventory-replenishment costs that consist of both variable and fixed components. At the beginning of each period, a joint inventory and pricing decision is made. Under the long-run average profit criterion, we show that an optimal policy exists within the class of so-called (s, S, p) policies. This is established based on our algorithmic development, which also results in an algorithm for finding an optimal (s, S, p) policy."
1899,"A Note on Profit Maximization and Monotonicity for Inbound Call Centers","Koole, Ger and Pot, Auke","OPERATIONS RESEARCH","59","5","1304-1308","2011","SEP-OCT","","","We consider an inbound call center with a fixed reward per call and communication and agent costs. By controlling the number of lines and the number of agents, we can maximize the profit. Abandonments are included in our performance model. Monotonicity results for the maximization problem are obtained, which lead to an efficient optimization procedure. We give a counterexample to the concavity in the number of agents, which is equivalent to saying that the law of diminishing returns does not hold. Numerical results are given."
1900,"An Erratum on the Multiproduct Network Equilibrium Model","Wu, Yunan and Cheng, T. C. E.","OPERATIONS RESEARCH","59","5","1309-1310","2011","SEP-OCT","","","We give examples to show that the necessary conditions of Theorem 2.1 and Theorem 3.4 in Cheng and Wu [Cheng, T. C. E., Y. N. Wu. 2006. A multiproduct, multicriterion supply-demand network equilibrium model. Oper. Res. 54(3) 544-554] for a multiproduct network equilibrium model may not hold."
1901,"American Options Under Stochastic Volatility","Chockalingam, Arun and Muthuraman, Kumar","OPERATIONS RESEARCH","59","4","793-809","2011","JUL-AUG","","","The problem of pricing an American option written on an underlying asset with constant price volatility has been studied extensively in literature. Real-world data, however, demonstrate that volatility is not constant, and stochastic volatility models are used to account for dynamic volatility changes. Option pricing methods that have been developed in literature for pricing under stochastic volatility focus mostly on European options. We consider the problem of pricing American options under stochastic volatility, which has had relatively much less attention from literature. First, we develop a transformation procedure to compute the optimal-exercise policy and option price and provide theoretical guarantees for convergence. Second, using this computational tool, we explore a variety of questions that seek insights into the dependence of option prices, exercise policies, and implied volatilities on the market price of volatility risk and correlation between the asset and stochastic volatility. The speed and accuracy of the procedure are compared against existing methods as well."
1902,"A Complementarity Framework for Forward Contracting Under Uncertainty","Shanbhag, Uday V. and Infanger, Gerd and Glynn, Peter W.","OPERATIONS RESEARCH","59","4","810-834","2011","JUL-AUG","","","We consider a particular instance of a stochastic multi-leader multi-follower equilibrium problem in which players compete in the forward and spot markets in successive periods. Proving the existence of such equilibria has proved difficult, as has the construction of globally convergent algorithms for obtaining such points. By conjecturing a relationship between forward and spot decisions, we consider a variant of the original game and relate the equilibria of this game to a related simultaneous stochastic Nash game where forward and spot decisions are made simultaneously. We characterize the complementarity problem corresponding to the simultaneous Nash game and prove that it is indeed solvable. Moreover, we show that an equilibrium to this Nash game is a local Nash equilibrium of the conjectured variant of the multi-leader multi-follower game of interest. Numerical tests reveal that the difference between equilibrium profits between the original and constrained games are small. Under uncertainty, the equilibrium point of interest is obtainable as the solution to a stochastic mixed-complementarity problem. Based on matrix-splitting methods, a globally convergent decomposition method is suggested for such a class of problems. Computational tests show that the effort grows linearly with the number of scenarios. Further tests show that the method can address larger networks as well. Finally, some policy-based insights are drawn from utilizing the framework to model a two-settlement six-node electricity market."
1903,"A Network of Time-Varying Many-Server Fluid Queues with Customer Abandonment","Liu, Yunan and Whitt, Ward","OPERATIONS RESEARCH","59","4","835-846","2011","JUL-AUG","","","To describe the congestion in large-scale service systems, we introduce and analyze a non-Markovian open network of many-server fluid queues with customer abandonment, proportional routing, and time-varying model elements. Proportions of the fluid completing service from each queue are immediately routed to the other queues, with the fluid not routed to one of the queues being immediately routed out of the network. The fluid queue network serves as an approximation for the corresponding non-Markovian open network of many-server queues with Markovian routing, where all model elements may be time varying. We establish the existence of a unique vector of (net) arrival rate functions at each queue and the associated time-varying performance. In doing so, we provide the basis for an efficient algorithm, even for networks with many queues."
1904,"Tight Bounds for Some Risk Measures, with Applications to Robust Portfolio Selection","Chen, Li and He, Simai and Zhang, Shuzhong","OPERATIONS RESEARCH","59","4","847-865","2011","JUL-AUG","","","In this paper we develop tight bounds on the expected values of several risk measures that are of interest to us. This work is motivated by the robust optimization models arising from portfolio selection problems. Indeed, the whole paper is centered around robust portfolio models and solutions. The basic setting is to find a portfolio that maximizes (respectively, minimizes) the expected utility (respectively, disutility) values in the midst of infinitely many possible ambiguous distributions of the investment returns fitting the given mean and variance estimations. First, we show that the single-stage portfolio selection problem within this framework, whenever the disutility function is in the form of lower partial moments (LPM), or conditional value-at-risk (CVaR), or value-at-risk (VaR), can be solved analytically. The results lead to the solutions for single-stage robust portfolio selection models. Furthermore, the results also lead to a multistage adjustable robust optimization (ARO) solution when the disutility function is the second-order LPM. Exploring beyond the confines of convex optimization, we also consider the so-called S-shaped value function, which plays a key role in the prospect theory of Kahneman and Tversky. The nonrobust version of the problem is shown to be NP-hard in general. However, we present an efficient procedure for solving the robust counterpart of the same portfolio selection problem. In this particular case, the consideration of the robustness actually helps to reduce the computational complexity. Finally, we consider the situation whereby we have some additional information about the chance that a quadratic function of the random distribution reaches a certain threshold. That information helps to further reduce the ambiguity in the robust model. We show that the robust optimization problem in that case can be solved by means of semidefinite programming (SDP), if no more than two additional chance inequalities are to be incorporated."
1905,"Managing a Noncooperative Supply Chain with Limited Capacity","Parker, Rodney P. and Kapuscinski, Roman","OPERATIONS RESEARCH","59","4","866-881","2011","JUL-AUG","","","We consider a two-stage serial supply chain with capacity limits, where each installation is operated by managers attempting to minimize their own costs. A multiple-period model is necessitated by the multiple stages, capacity limits, stochastic demand, and the explicit consideration of inventories. With appropriate salvage value functions, a Markov equilibrium policy is found. Intuitive profit dominance allows for existence of a unique equilibrium solution, which is shown to be a modified echelon base-stock policy. This equilibrium policy structure is sustained in the infinite horizon. A numerical study compares the behavior of the decentralized system with the first-best integrated capacitated system. The performance of this decentralized system relative to the integrated system across other parameters can be very good over a broad range of values. This implies that an acceptable system performance may be attained without the imposition of a contract or other coordinating mechanism, which themselves may encounter difficulties in implementation in the form of negotiation, execution, or enforcement of these agreements. We find instances where tighter capacities may actually enhance channel efficiency. We also examine the effect of capacity utilization on the system suboptimality."
1906,"Dynamic Pricing of Limited Inventories When Customers Negotiate","Kuo, Chia-Wei and Ahn, Hyun-Soo and Aydin, Goeker","OPERATIONS RESEARCH","59","4","882-897","2011","JUL-AUG","","","Although take-it-or-leave-it pricing is the main mode of operation for many retailers, a number of retailers discreetly allow price negotiation when some haggle-prone customers ask for a bargain. At these retailers, the posted price, which itself is subject to dynamic adjustments in response to the pace of sales during the selling season, serves two important roles: (i) it is the take-it-or-leave-it price to many customers who do not bargain, and (ii) it is the price from which haggle-prone customers negotiate down. To effectively measure the benefit of dynamic pricing and negotiation in such a retail environment, one must take into account the interactions among inventory, dynamic pricing, and negotiation. The outcome of the negotiation (and the final price a customer pays) depends on the inventory level, the remaining selling season, the retailer's bargaining power, and the posted price. We model the retailer's dynamic pricing problem as a dynamic program, where the revenues from both negotiation and posted pricing are embedded in each period. We characterize the optimal posted price and the resulting negotiation outcome as a function of inventory and time. We also show that negotiation is an effective tool to achieve price discrimination, particularly when the inventory level is high and/or the remaining selling season is short, even when implementing negotiation is costly."
1907,"A Sequential Sampling Procedure for Stochastic Programming","Bayraksan, Guezin and Morton, David P.","OPERATIONS RESEARCH","59","4","898-913","2011","JUL-AUG","","","We develop a sequential sampling procedure for a class of stochastic programs. We assume that a sequence of feasible solutions with an optimal limit point is given as input to our procedure. Such a sequence can be generated by solving a series of sampling problems with increasing sample size, or it can be found by any other viable method. Our procedure estimates the optimality gap of a candidate solution from this sequence. If the point estimate of the optimality gap is sufficiently small according to our termination criterion, then we stop. Otherwise, we repeat with the next candidate solution from the sequence under an increased sample size. We provide conditions under which this procedure (i) terminates with probability one and (ii) terminates with a solution that has a small optimality gap with a prespecified probability."
1908,"Purchasing Under Asymmetric Demand and Cost Information: When Is More Private Information Better?","Kostamis, Dimitris and Duenyas, Izak","OPERATIONS RESEARCH","59","4","914-928","2011","JUL-AUG","","","We study a supply chain consisting of one supplier and one OEM (original equipment manufacturer). The OEM faces stochastic demand for a final product that requires assembly of two major components, one of which is procured exclusively from the supplier. In the absence of competition, the supplier is able to make a take-it-or-leave-it offer to the OEM in the form of a menu of price-quantity contracts. The OEM possesses private information across two dimensions: (1) demand forecasts about the final product, and (2) production cost of the in-house component. Both pieces of information are relevant to the total supply chain profit, thus affecting the supplier's optimal offer. By initially assuming an exogenous information structure, we characterize the supplier's optimal contract menu for a simple case and demonstrate that more dimensions of asymmetric information are not always preferable for the OEM but could be beneficial for the supply chain. We subsequently examine whether this preference for one less dimension of private information implies disclosure of private information to the supplier when the information structure is endogenized. Our results indicate that if OEMs that are indifferent between disclosing and keeping information private choose to disclose it, disclosure of any verifiable information from all OEMs is always an equilibrium, whereas nondisclosure might fail to be an equilibrium. We also consider the possibility of the OEM and the supplier contracting at the ex-ante stage, i.e., before the OEM observes his private information. When both dimensions of the OEM's private information are verifiable and the cost of disclosing information is small enough, an ex-ante agreement on information disclosure is always possible; otherwise its feasibility depends on the problem parameters."
1909,"Adaptive Data-Driven Inventory Control with Censored Demand Based on Kaplan-Meier Estimator","Huh, Woonghee Tim and Levi, Retsef and Rusmevichientong, Paat and Orlin, James B.","OPERATIONS RESEARCH","59","4","929-941","2011","JUL-AUG","","","Using the well-known product-limit form of the Kaplan-Meier estimator from statistics, we propose a new class of nonparametric adaptive data-driven policies for stochastic inventory control problems. We focus on the distribution-free newsvendor model with censored demands. The assumption is that the demand distribution is not known and there are only sales data available. We study the theoretical performance of the new policies and show that for discrete demand distributions they converge almost surely to the set of optimal solutions. Computational experiments suggest that the new policies converge for general demand distributions, not necessarily discrete, and demonstrate that they are significantly more robust than previously known policies. As a by-product of the theoretical analysis, we obtain new results on the asymptotic consistency of the Kaplan-Meier estimator for discrete random variables that extend existing work in statistics. To the best of our knowledge, this is the first application of the Kaplan-Meier estimator within an adaptive optimization algorithm, in particular, the first application to stochastic inventory control models. We believe that this work will lead to additional applications in other domains."
1910,"Identifying Good Nursing Levels: A Queuing Approach","Yankovic, Natalia and Green, Linda V.","OPERATIONS RESEARCH","59","4","942-955","2011","JUL-AUG","","","Nursing care is arguably the single biggest factor in both the cost of hospital care and patient satisfaction. Inadequate inpatient nursing levels have also been cited as a significant factor in medical errors and emergency room overcrowding. Yet, there is widespread dissatisfaction with the current methods of determining nurse staffing levels, including the most common one of using minimum nurse-to-patient ratios. In this paper, we represent the nursing system as a variable finite-source queuing model. We develop a reliable, tractable, easily parameterized two-dimensional model to approximate the actual interdependent dynamics of bed occupancy levels and demands for nursing. We use this model to show how unit size, nursing intensity, occupancy levels, and unit length-of-stay affect the impact of nursing levels on performance and thus how inflexible nurse-to-patient ratios can lead to either understaffing or overstaffing. The model is also useful for estimating the impact of nurse staffing levels on emergency department overcrowding."
1911,"An Economic Model for Resource Allocation in Grid Computing","Caramia, Massimiliano and Giordani, Stefano","OPERATIONS RESEARCH","59","4","956-972","2011","JUL-AUG","","","Allocating resources in grid computing requires local and external schedulers to communicate in order to achieve an efficient management of the resources themselves. To this end, some economic/market-based models have been introduced in the literature, where users, external schedulers, and local schedulers negotiate to optimize their objectives. In this paper, we propose a tender/contract-net model for the grid resource allocation problem, showing the interactions among the involved actors. The performance of the proposed market-based approach is experimentally compared with a round-robin allocation protocol, a system-centric least-cost allocation approach, and also a market-based approach available from the literature."
1912,"Robust Optimization Made Easy with ROME","Goh, Joel and Sim, Melvyn","OPERATIONS RESEARCH","59","4","973-985","2011","JUL-AUG","","","We introduce ROME, an algebraic modeling toolbox for a class of robust optimization problems. ROME serves as an intermediate layer between the modeler and optimization solver engines, allowing modelers to express robust optimization problems in a mathematically meaningful way. In this paper, we discuss how ROME can be used to model (1) a service-constrained robust inventory management problem, (2) a project-crashing problem, and (3) a robust portfolio optimization problem. Through these modeling examples, we highlight the key features of ROME that allow it to expedite the modeling and subsequent numerical analysis of robust optimization problems. ROME is freely distributed for academic use at http://www.robustopt.com."
1913,"Strategic Behavior and Social Optimization in Markovian Vacation Queues","Guo, Pengfei and Hassin, Refael","OPERATIONS RESEARCH","59","4","986-997","2011","JUL-AUG","","","We consider a single server queueing system in which service shuts down when there are no customers present and is resumed only when the queue length reaches a given critical length. We analyze the strategic response of customers to this mechanism and compare it to the overall optimal behavior, with and without information on delay. The results are significantly different from those obtained when the server is continuously available. We show that there may exist multiple equilibria in such a system and the optimal arrival rate may be greater or smaller than that of the decentralized equilibrium. Finally, the critical length is taken as a decision variable, and the optimal operations policy is discussed by taking strategic customers into consideration."
1914,"Efficient Nested Simulation for Estimating the Variance of a Conditional Expectation","Sun, Yunpeng and Apley, Daniel W. and Staum, Jeremy","OPERATIONS RESEARCH","59","4","998-1007","2011","JUL-AUG","","","In a two-level nested simulation, an outer level of simulation samples scenarios, while the inner level uses simulation to estimate a conditional expectation given the scenario. Applications include financial risk management, assessing the effects of simulation input uncertainty, and computing the expected value of gathering more information in decision theory. We show that an ANOVA-like estimator of the variance of the conditional expectation is unbiased under mild conditions, and we discuss the optimal number of inner-level samples to minimize this estimator's variance given a fixed computational budget. We show that as the computational budget increases, the optimal number of inner-level samples remains bounded. This finding contrasts with previous work on two-level simulation problems in which the inner-and outer-level sample sizes must both grow without bound for the estimation error to approach zero. The finding implies that the variance of a conditional expectation can be estimated to arbitrarily high precision by a simulation experiment with a fixed inner-level computational effort per scenario, which we call a one-and-a-half-level simulation. Because the optimal number of inner-level samples is often quite small, a one-and-a-half-level simulation can avoid the heavy computational burden typically associated with two-level simulation."
1915,"Network Cargo Capacity Management","Levina, Tatsiana and Levin, Yuri and McGill, Jeff and Nediak, Mikhail","OPERATIONS RESEARCH","59","4","1008-1023","2011","JUL-AUG","","","We consider the problem faced by an airline that is flying both passengers and cargo over a network of locations on a fixed periodic schedule. Bookings for many classes of cargo shipments between origin-destination pairs in this network are made in advance, but the weight and volume of aircraft capacity available for cargo as well as the exact weight and volume of each shipment are not known at the time of booking. The problem is to control cargo accept/reject decisions to maximize expected profits while ensuring effective dispatch of accepted shipments through the network. This network stochastic dynamic control problem has very high computational complexity. We propose a linear programming and stochastic simulation-based computational method for learning approximate control policies and discuss their structural properties. The proposed method is flexible and can utilize historical booking data as well as decisions generated by default control policies."
1916,"Multiple Variable Proportionality in Data Envelopment Analysis","Cook, Wade D. and Zhu, Joe","OPERATIONS RESEARCH","59","4","1024-1032","2011","JUL-AUG","","","Data envelopment analysis (DEA) provides an optimization methodology for deriving an efficiency score for each member of a set of peer decision-making units. Under the original DEA model it was assumed that there is constant returns to scale (CRS). This idea was later extended to the more general case that allowed for variable returns to scale (VRS). In both of these structures, it is assumed that the returns to scale (RTS) classification, consistent with the classical definition, applies to the entire (input, output) bundle. In many settings it can be the case that the output bundle can be separated into distinct subsets or business units wherein an RTS-type behavior may be different for one subgroup than for another. We refer to such situations as involving multiple variable proportionality (MVP). Examples of MVP can occur when there are different product subgroupings in a company, different wards in hospitals, different programs in a university, and so on. Identification of such differential behavior can provide management with important insights regarding the most productive proportionality size (MPPS) in each of those subgroups. In the current paper we introduce DEA-based tools that address those situations where MVP exists."
1917,"Procurement Strategies with Unreliable Suppliers","Federgruen, Awi and Yang, Nan","OPERATIONS RESEARCH","59","4","1033-1039","2011","JUL-AUG","","","We propose and analyze a general periodic-review model in which the firm has access to a set of potential suppliers, each with specific yield and price characteristics. Assuming that unsatisfied demand is backlogged, the firm incurs three types of costs: (i) procurement costs, (ii) inventory-carrying costs for units carried over from one period to the next, and (iii) backlogging costs. A procurement strategy requires the specification, in each period, of (i) the set of suppliers to be retained, (ii) their respective shares in this period's replenishments, as well as (iii) the traditional aggregate order placed (among the various suppliers). We show how the optimal procurement strategy can be obtained with an efficient algorithm. A base-stock policy is no longer optimal, but in each period there exists a maximum inventory level, such that orders are placed if and only if the starting inventory is below this threshold. In each period it is optimal to retain a given number of suppliers that are cheapest in terms of that period's effective cost rates, i. e., the expected cost per usable unit. The optimal number of suppliers to be retained in a given period depends on all current and future parameters and distributions, but this dependence can be aggregated into a single so-called benchmark cost measure. Under Normal yield and demand distributions, the suppliers' market shares are determined by a single aggregate score, itself the product of a simple reliability score and a cost score."
1918,"Inventory Systems with a Generalized Cost Model","Huh, Woonghee Tim and Janakiraman, Ganesh and Muharremoglu, Alp and Sheopuri, Anshul","OPERATIONS RESEARCH","59","4","1040-1047","2011","JUL-AUG","","","We study a single-stage inventory system with a generalized shortage penalty cost that includes the following three components: (i) a cost that is an increasing function of the number of backordered units in a period, (ii) a fixed cost incurred for each period in which there is a backorder irrespective of how many units are backordered, and finally (iii) a cost that is an increasing function of the number of periods a customer is backordered. We show the problem can be transformed into one in which the backorder cost depends on the inventory position only. Then we present two sets of conditions; the first one restricts our attention to a special case of the generalized penalty cost model while the second one restricts our attention to stationary demand models with some distributional assumptions. Under the first (resp. second) set of conditions, we show that the expected cost in a period can be expressed as a convex (resp. quasiconvex) function of the after-ordering inventory position. We use this property to prove the optimality of order-up-to policies under both sets of conditions and discuss extensions to the cases where either a fixed ordering cost or a batch ordering constraint is present."
1919,"Little's Law as Viewed on Its 50th Anniversary","Little, John D. C.","OPERATIONS RESEARCH","59","3","536-549","2011","MAY-JUN","","","Fifty years ago, the author published a paper in Operations Research with the title, A proof for the queuing formula: L = lambda W [Little, J. D. C. 1961. A proof for the queuing formula: L = lambda W. Oper. Res. 9(3) 383-387]. Over the years, L = lambda W has become widely known as Little's Law. Basically, it is a theorem in queuing theory. It has become well known because of its theoretical and practical importance. We report key developments in both areas with the emphasis on practice. In the latter, we collect new material and search for insights on the use of Little's Law within the fields of operations management and computer architecture."
1920,"A Unified Framework for Dynamic Prediction Market Design","Agrawal, Shipra and Delage, Erick and Peters, Mark and Wang, Zizhuo and Ye, Yinyu","OPERATIONS RESEARCH","59","3","550-568","2011","MAY-JUN","","","Recently, coinciding with and perhaps driving the increased popularity of prediction markets, several novel pari-mutuel mechanisms have been developed such as the logarithmic market-scoring rule (LMSR), the cost-function formulation of market makers, utility-based markets, and the sequential convex pari-mutuel mechanism (SCPM). In this work, we present a convex optimization framework that unifies these seemingly unrelated models for centrally organizing contingent claims markets. The existing mechanisms can be expressed in our unified framework by varying the choice of a concave value function. We show that this framework is equivalent to a convex risk minimization model for the market maker. This facilitates a better understanding of the risk attitudes adopted by various mechanisms. The unified framework also leads to easy implementation because we can now find the cost function of a market maker in polynomial time by solving a simple convex optimization problem. In addition to unifying and explaining the existing mechanisms, we use the generalized framework to derive necessary and sufficient conditions for many desirable properties of a prediction market mechanism such as proper scoring, truthful bidding (in a myopic sense), efficient computation, controllable risk measure, and guarantees on the worst-case loss. As a result, we develop the first proper, truthful, risk-controlled, loss-bounded (independent of the number of states) mechanism; none of the previously proposed mechanisms possessed all these properties simultaneously. Thus, our work provides an effective tool for designing new prediction market mechanisms. We also discuss possible applications of our framework to dynamic resource pricing and allocation in general trading markets."
1921,"A Geometric Perspective on Lifting","Conforti, Michele and Cornuejols, Gerard and Zambelli, Giacomo","OPERATIONS RESEARCH","59","3","569-577","2011","MAY-JUN","","","Recently it has been shown that minimal inequalities for a continuous relaxation of mixed-integer linear programs are associated with maximal lattice-free convex sets. In this paper, we show how to lift these inequalities for integral nonbasic variables by considering maximal lattice-free convex sets in a higher dimensional space. We apply this approach to several examples. In particular, we identify cases in which the lifting is unique."
1922,"Sourcing Flexibility, Spot Trading, and Procurement Contract Structure","Pei, Pamela Pen-Erh and Simchi-Levi, David and Tunca, Tunay I.","OPERATIONS RESEARCH","59","3","578-601","2011","MAY-JUN","","","We analyze the structure and pricing of option contracts for an industrial good in the presence of spot trading. We combine the analysis of spot trading and buyers' disparate private valuations for different suppliers' products, and we jointly endogenize the determination of three major dimensions in contract design: (i) sales contracts versus options contracts, (ii) flat-price versus volume-dependent contracts, and (iii) volume discounts versus volume premia. We build a model in which a supplier of an industrial good transacts with a manufacturer who uses the supplier's product to produce an end good with an uncertain demand. We show that, consistent with industry observations, volume-dependent optimal sales contracts always demonstrate volume discounts (i.e., involve concave pricing). However, options are more complex agreements, and optimal option contracts can involve both volume discounts and volume premia. Three major contract structures commonly emerge in optimality. First, if the seller has a high discount rate relative to the buyer and the seller's production costs or the production capacity is low, the optimal contracts tend to be flat-price sales contracts. Second, when the seller has a relatively high discount rate compared to the buyer but production costs or production capacity are high, the optimal contracts are sales contracts with volume discounts. Third, if the buyer's discount rate is high relative to the seller's, then the optimal contracts tend to be volume-dependent options contracts and can involve both volume discounts and volume premia. However, when the seller's production capacity is sufficiently low, it is possible to observe flat-price option contracts. Furthermore, we provide links between production and spot market characteristics, contract design, and efficiency."
1923,"Valuation of Storage at a Liquefied Natural Gas Terminal","Lai, Guoming and Wang, Mulan X. and Kekre, Sunder and Scheller-Wolf, Alan and Secomandi, Nicola","OPERATIONS RESEARCH","59","3","602-616","2011","MAY-JUN","","","The valuation of the real option to store liquefied natural gas (LNG) at the downstream terminal of an LNG value chain is an important problem in practice. Because the exact valuation of this real option is computationally intractable, we develop a novel and tractable heuristic model for its strategic valuation that integrates models of LNG shipping, natural gas price evolution, and inventory control and sale into the wholesale natural gas market. We incorporate real and estimated data to quantify the value of this real option and its dependence on the throughput of an LNG chain, the type of price variability, the type of inventory control policy employed, and the level of stochastic variability in both the shipping model and the natural gas price model used. In addition, we develop an imperfect information dual upper bound to assess the effectiveness of our heuristic and find that our method is near optimal. Our approach also has potential relevance to value the real option to store other commodities in facilities located downstream from a commodity production or transportation stage, such as petroleum and agricultural products, chemicals, and metals, or the real option to store the input used in the production of a commodity such as electricity."
1924,"Sequential Convex Approximations to Joint Chance Constrained Programs: A Monte Carlo Approach","Hong, L. Jeff and Yang, Yi and Zhang, Liwei","OPERATIONS RESEARCH","59","3","617-630","2011","MAY-JUN","","","When there is parameter uncertainty in the constraints of a convex optimization problem, it is natural to formulate the problem as a joint chance constrained program (JCCP), which requires that all constraints be satisfied simultaneously with a given large probability. In this paper, we propose to solve the JCCP by a sequence of convex approximations. We show that the solutions of the sequence of approximations converge to a Karush-Kuhn-Tucker (KKT) point of the JCCP under a certain asymptotic regime. Furthermore, we propose to use a gradient-based Monte Carlo method to solve the sequence of convex approximations."
1925,"Selecting Optimal Alternatives and Risk Reduction Strategies in Decision Trees","Sherali, Hanif D. and Dalkiran, Evrim and Glickman, Theodore S.","OPERATIONS RESEARCH","59","3","631-647","2011","MAY-JUN","","","In this paper we conduct a quantitative analysis for a strategic risk management problem that involves allocating certain available failure-mitigating and consequence-alleviating resources to reduce the failure probabilities of system safety components and subsequent losses, respectively, together with selecting optimal strategic decision alternatives, to minimize the risk or expected loss in the event of a hazardous occurrence. Using a novel decision tree optimization approach to represent the cascading sequences of probabilistic events as controlled by key decisions and investment alternatives, the problem is modeled as a nonconvex mixed-integer 0-1 factorable program. We develop a specialized branch-and-bound algorithm in which lower bounds are computed via tight linear relaxations of the original problem that are constructed by utilizing a polyhedral outer-approximation mechanism in concert with two alternative linearization schemes having different levels of tightness and complexity. We also suggest three alternative branching schemes, each of which is proven to guarantee convergence to a global optimum for the underlying problem. Extensive computational results and sensitivity analyses are presented to provide insights and to demonstrate the efficacy of the proposed algorithm."
1926,"Heavy-Traffic Analysis of a Multiple-Phase Network with Discriminatory Processor Sharing","Verloop, I. M. and Ayesta, U. and Nunez-Queija, R.","OPERATIONS RESEARCH","59","3","648-660","2011","MAY-JUN","","","We analyze a generalization of the discriminatory processor-sharing (DPS) queue in a heavy-traffic setting. Customers present in the system are served simultaneously at rates controlled by a vector of weights. We assume that customers have phase-type distributed service requirements and allow that customers have different weights in various phases of their service. In our main result we establish a state-space collapse for the queue-length vector in heavy traffic. The result shows that in the limit, the queue-length vector is the product of an exponentially distributed random variable and a deterministic vector. This generalizes a previous result by Rege and Sengupta [Rege, K. M., B. Sengupta. 1996. Queue length distribution for the discriminatory processor-sharing queue. Oper. Res. 44(4) 653-657], who considered a DPS queue with exponentially distributed service requirements. Their analysis was based on obtaining all moments of the queue-length distributions by solving systems of linear equations. We undertake a more direct approach by showing that the probability-generating function satisfies a partial differential equation that allows a closed-form solution after passing to the heavy-traffic limit. Making use of the state-space collapse result, we derive interesting properties in heavy traffic: (i) For the DPS queue, we obtain that, conditioned on the number of customers in the system, the residual service requirements are asymptotically independent and distributed according to the forward recurrence times. (ii) We then investigate how the choice for the weights influences the asymptotic performance of the system. In particular, for the DPS queue we show that the scaled holding cost reduces as classes with a higher value for d(k)/E(B(k) (fwd) ) obtain a larger share of the capacity, where d(k) is the cost associated to class k, and E(B(k)(fwd)) is the forward recurrence time of the class-k service requirement. The applicability of this result for a moderately loaded system is investigated by numerical experiments."
1927,"The Strategy-Focused Factory in Turbulent Times","Brumme, Hendrik and Simonovich, Daniel and Skinner, Wickham and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1513-1523","2015","OCT","Focused Factories;Manufacturing Strategy;Structural And Infrastructural Changes;Innovation Factory;Operational Excellence Factory;Solutions Factory","","Few unfocused factories outperform competitors, but focus is elusive because the environment is constantly evolving and this requires changes to a factory's key tasks. So how can focus be achieved and sustained? We present insights derived from an historical analysis of the German Hewlett-Packard server plant which went through a series of focus changes over the years. Using this example, we provide clues for the right timing of focus changes and discuss critical structural and infrastructural changes required during the focus transitions, as well as cross-functional coordination and leadership challenges. Our assertion is that production operations constitute a system that can adapt to disruptive change by using the levers of manufacturing policies to stay focused on a limited but absolutely essential task which creates a strategic advantage."
1928,"Optimal Expediting Policies for a Serial Inventory System with Stochastic Lead Time","Kim, Chiwon and Klabjan, Diego and Simchi-Levi, David","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1524-1536","2015","OCT","Multi-Echelon Supply Chain;Inventory Management;Dynamic Ordering;Expediting;Stochastic Lead Time","","In recent supply chains, often operating multiple delivery modes such as standard freight shipping and air is an effective way of addressing both delivery lead time uncertainties and service rates. We propose a model on how to optimally operate multiple delivery modes. We consider a serial supply chain and an expediting option from intermediate installations to the downstream of the chain. The goods move stochastically among the installations and the system faces a stochastic demand. We identify systems that yield simple optimal policies, in which both regular ordering and expediting follow a variant of the base stock policy. Expediting allows the system to be leaner due to the reduced regular order amount. In addition, we provide managerial insights linking expediting, base stock levels, and expediting costs based on analytical and numerical results."
1929,"Investing in a Shared Supplier in a Competitive Market: Stochastic Capacity Case","Qi, Anyan and Ahn, Hyun-Soo and Sinha, Amitabh","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1537-1551","2015","OCT","Capacity Investment;Supplier Development;Cournot Competition;Non-Cooperative Game","","When firms invest in a shared supplier, one key concern is whether the invested capacity will be used for a competitor. In practice, this concern is addressed by restricting the use of the capacity. We consider what happens when two competing firms invest in a shared supplier. We consider two scenarios that differ in how capacity is used: exclusive capacity and first-priority capacity. We model firms' investment and production decisions, and analyze the equilibrium outcomes in terms of the number of investing firms and capacity levels for each scenario; realized capacity is a stochastic function of investment levels. We also identify conditions under which the spillover effect occurs, where one firm taps into the other firm's invested capacity. Although the spillover supposedly intensifies competition, it actually discourages firms' investment. We also characterize the firms' and supplier's preference about the capacity type. While the non-investing firm always prefers spillovers from the first-priority capacity, the investing firm does not always want to shut off the other firm's access to its leftover capacity, especially when allowing spillover induces the other firm not to invest. The supplier's preference depends on the trade-off between over-investment and flexibility."
1930,"Managing the Performance Trade-Offs from Partner Integration: Implications of Contract Choice in R&D Projects","MacCormack, Alan and Mishra, Anant","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1552-1569","2015","OCT","Partner Integration;Contract Choice;R&D Project Management;Relational Contracting;Partnering Performance","","Formal contracts represent an important governance instrument with which firms exercise control of and compensate partners in R&D projects. The specific type of contract used, however, can vary significantly across projects. In some, firms' govern partnering relationships through fixed-price contracts, whereas in others, firms' use more flexible time and materials or performance-based contracts. How do these choices affect the costs and benefits that arise from greater levels of partner integration? Furthermore, how are these relationships affected when the choice of contract is misaligned with the scope and objectives of the partnering relationship? Our study addresses these questions using data from 172 R&D projects that involve partners. We find that, (i) greater partner integration is associated with higher project costs for all contract types; (ii) greater partner integration is associated with higher product quality only in projects that adopt more flexible time and materials or performance-based contracts; and (iii) in projects where the choice of contract is misaligned with the scope and objectives of the partnering relationship, greater partner integration is associated with higher project costs, but not with higher product quality. Our results shed light on the subtle interplay between formal and relational contracting. They have important implications for practice, with respect to designing optimal governance structures in partnered R&D projects."
1931,"Long-Term Contracting: The Role of Private Information in Dynamic Supply Risk Management","Gao, Long","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1570-1579","2015","OCT","Supply Risk;Information Asymmetry;Inventory;Contracting;Dynamic Programming","","We examine the critical role of evolving private information in managing supply risk. The problem features a dyadic channel where a dominant buyer operates a multiperiod inventory system with lost sales and fixed cost. He replenishes from a supplier, whose private state of production is vulnerable to random shocks and evolves dynamically over time. We characterize the optimal inventory policy with a simple semi-stationary structure; it distorts order quantity for limiting information rent only in the initial period; the optimal payment compensates for production cost in every period but concedes real information rent only in the initial period. These properties allow us to derive an easy-to-implement revenue-sharing contract that facilitates ex ante strategic planning and ex post dynamic execution. This work advances our understanding on when and how to use private information in dynamic risk management."
1932,"The Role of Contract Expirations in Service Parts Management","Pince, Cerag and Frenk, J. B. G. and Dekker, Rommert","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1580-1597","2015","OCT","Service Parts;Contract Expirations;Inventory;Obsolescence;After Sales","","The majority of after-sales service providers manage their service parts inventory by focusing on the availability of service parts. This approach, combined with automatic replenishment systems, leads to reactive inventory control policies where base stock levels are adjusted only after a service contract expires. Consequently, service providers often face excess stock of critical service parts that are difficult to dispose due to their specificity. In this study, we address this problem by developing inventory control policies taking into account contract expirations. Our key idea is to reduce the base stock level of the one-for-one policy before obsolescence (a full or partial drop in demand rate) occurs and let demand take away excess stock. We refer to this policy as the single-adjustment policy. We benchmark the single-adjustment policy with the multiple-adjustment policy (allowing multiple base stock adjustments) formulated as a dynamic program and verify that for a wide range of instances the single-adjustment policy is an effective heuristic for the multiple-adjustment policy. We also compare the single-adjustment policy with the world-dependent base stock policy offered by Song and Zipkin (1993) and identify the parameter combinations where both policies yield similar costs. We consider two special cases of the single-adjustment policy where the base stock level is kept fixed or the base stock adjustment is postponed to the contract expiration time. We find that the initial demand rate, contract expiration time, and size of the drop in demand rate are the three key parameters driving the choice between the single-adjustment policy and its special cases."
1933,"Bounding Optimal Expected Revenues for Assortment Optimization under Mixtures of Multinomial Logits","Feldman, Jacob and Topaloglu, Huseyin","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1598-1620","2015","OCT","Multinomial Logit Model;Assortment Optimization;Lagrangian Relaxation;Retail Operations;Choice Modeling","","We consider assortment problems under a mixture of multinomial logit models. There is a fixed revenue associated with each product. There are multiple customer types. Customers of different types choose according to different multinomial logit models whose parameters depend on the type of the customer. The goal is to find a set of products to offer so as to maximize the expected revenue obtained over all customer types. This assortment problem under the multinomial logit model with multiple customer types is NP-complete. Although there are heuristics to find good assortments, it is difficult to verify the optimality gap of the heuristics. In this study, motivated by the difficulty of finding optimal solutions and verifying the optimality gap of heuristics, we develop an approach to construct an upper bound on the optimal expected revenue. Our approach can quickly provide upper bounds and these upper bounds can be quite tight. In our computational experiments, over a large set of randomly generated problem instances, the upper bounds provided by our approach deviate from the optimal expected revenues by 0.15% on average and by less than one percent in the worst case. By using our upper bounds, we are able to verify the optimality gaps of a greedy heuristic accurately, even when optimal solutions are not available."
1934,"Scalable Dynamic Bid Prices for Network Revenue Management in Continuous Time","Kirshner, Samuel Nathan and Nediak, Mikhail","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1621-1635","2015","OCT","Network Revenue Management;Dynamic Bid Prices;Second-Order Cone Programming","","This study develops an approximate optimal control problem to produce time-dependent bid prices for the airline network revenue management problem. The main contributions of our study are the analysis of time-dependent bid prices in continuous time and the use of splines to modify the problem into an approximate second-order cone program (ASOCP). The spline representation of bid prices permits the number of variables to depend solely on the number of resources and not on the size of the booking horizon. The advantage of this framework is the ASOCP's scalability, which we demonstrate by solving for bid prices on an industrial-sized network. The numerical experiments highlight the ASOCP's ability to solve industrial sized problems in seconds."
1935,"A Note on Sourcing Decisions with Stochastic Supplier Reliability and Stochastic Demand","van Delft, Christian and Vial, Jean-Philippe","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1636-1639","2015","OCT","Sourcing;Supplier Selection;Random Yield","","This note complements the study of Burke, Carillo, and Vakharia ( hereafter BCV) which analyzes a class of single-product multisourcing problems under stochastic demand and random yields. The purpose is twofold. First, we prove that the objective function used by these authors is only a lower bound for the expected profit for which we provide the correct expression. Second, we show on some of the numerical instances provided in BCV's study that the structure and the performance of the BCV ordering policy may be substantially different from the optimal ordering policy. We conclude by giving general qualitative insights characterizing suboptimality of the BCV solution."
1936,"Two Backorder Compensation Mechanisms in Inventory Systems with Impatient Customers","Chen, Jian and Huang, Shuo and Hassin, Refael and Zhang, Nan","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1640-1656","2015","OCT","Strategic Customers;Compensation Mechanism;Pricing;Auction;Make-To-Stock;Queuing;Nash Equilibrium","","We study a compensation mechanism design problem with customer-choice behavior in a continuous review setting where the production and demand processes are stochastic. When a stockout occurs, the firm controls backorders on the basis of certain compensation policies. Customers make decisions to maximize their utility, which is decreasing in the price, the waiting time, and the customer's impatience factor. We assume that the impatience factor is private information held by the customer only. Two compensation mechanisms are designed to control backorders, namely uniform compensation and priority auction with an admission price. Under uniform compensation, the firm offers the same discount to all customers, whereas under auction compensation, priority is granted according to the customers' bid prices. We obtain the optimal stockout price and base stock level under each mechanism, and analyze the properties of the respective optimal policies. Assuming linear waiting costs with uniformly distributed impatience factor, we find that the auction mechanism (1) maintains a lower base stock level and results in greater profit and (2) benefits customers with relatively lower or higher impatience factors, but customers with a medium impatience factor may be rendered worse off. We further show that both compensation mechanisms are suitable for products with a high unit profit, a high lost sales penalty cost, and a high holding cost."
1937,"Opportunism in Distribution Networks: The Role of Network Embeddedness and Dependence","Dong, Maggie Chuoyan and Liu, Zhiqiang and Yu, Yimin and Zheng, Jin-Hui","PRODUCTION AND OPERATIONS MANAGEMENT","24","10","1657-1670","2015","OCT","Opportunism;Network Effect;Embeddedness;Dependence;Multi-Methodological Research","","Prior research documents the value of network relationships to firm behavior but is relatively silent on how networks influence opportunism in distribution channels. Focusing on a common type of distribution networks in which multiple distributors serve a single, dominant supplier, this study moves beyond a dyadic view to examine how a focal distributor's relational and structural embeddedness in such a distribution network influences its opportunism toward the dominant supplier. In particular, we postulate that a distributor's relational embeddedness in the network curbs its opportunism, whereas its network centrality, as a form of structural embeddedness in the network, promotes its opportunism. Moreover, we propose that relational embeddedness magnifies the role of a focal distributor's dependence on the supplier in suppressing the distributor's opportunism, whereas network centrality buffers such a role. We first empirically test these hypotheses using data collected from car dealers in China; the results provide support for the hypotheses. We then develop an analytical model to validate and further explain the underlying mechanisms of the network effects. Our analytical results not only validate the empirical results but also provide guidance for managers on controlling opportunism in distribution networks."
1938,"Conceptualizing Social Responsibility in Operations Via Stakeholder Resource-Based View","Sodhi, ManMohan S.","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1375-1389","2015","SEP","Social Responsibility;Sustainability;Resource-Based View;Stakeholder Theory;Utility Theory","","We seek to conceptualize social responsibility for operations management (OM) research to develop a social responsibility lens through which to view operations. To do so, we first consider the corporate social responsibility, sustainability, as well as the bottom-of-the-pyramid and shared value approaches and identify three challenges to developing such a lens: selecting the level of analysis, tackling the huge multitude of objectives, and developing theoretical underpinnings. We then propose a stakeholder resource-based view (SRBV) building on resource-based view, stakeholder theory, and utility theory to address these challenges. Under SRBV, all stakeholders are treated on a par with each other. These different stakeholders are all presumed to seek maximizing their respective (expected) utility, with different drivers shaping their preferences and do so they use their respective resources, routines and dynamic capabilities. SRBV provides (a) a descriptive framework for qualitative research, (b) an instrumental framework for empirical research, and (c) a normative framework for analytical research. It enables tackling many opportunities for OM research to do with social responsibility and we outline some of these in each of the three types of research methodologies."
1939,"Addressing the Challenge of Modeling for Decision-Making in Socially Responsible Operations","Besiou, Maria and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1390-1401","2015","SEP","Socially Responsible Operations;Operations Research;Management Science;Stakeholders","","Companies seek sustainability by combining the quest for profitability with the pursuit of social responsibility. Since socially responsible operations are characterized by the presence of multiple stakeholders with conflicting goals, applying classical optimization models would seem premature; we first need to capture the behavior of the entire system before attempting to optimize sub-systems to ensure that we focus on the ones driving the behavior of interest. Alternative methodologies are required if we are to gain insight into the most important drivers of socially responsible operations in order to apply traditional operations research (OR)/management science (MS) models correctly. This study presents an umbrella approach which combines different methodologies to tackle the complexity, unfamiliar context, and counter-intuitive behavior of socially responsible operations at the overall system level."
1940,"Carrots or Sticks? Improving Social and Environmental Compliance at Suppliers Through Incentives and Penalties","Porteous, Angharad H. and Rammohan, Sonali V. and Lee, Hau L.","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1402-1413","2015","SEP","Social And Environmental Responsibility;Supplier Non-Compliances And Violations;Responsible Supplier Management;Supplier Incentives And Penalties","","Firms are increasingly looking to eradicate social and environmental non-compliances at their suppliers in response to increasing regulations, consumer demand, potential for supply chain disruptions, and to improve their social, environmental, and economic supply chain performance. This study develops a model of the relationship between the buyer's supplier incentives and penalties for the supplier's social and environmental compliance, and the outcomes in terms of reduction in supplier social and environmental violations as well as the buyer's own operating costs. This model is tested empirically through analysis of a dataset of opinion-based survey responses from practitioners at 334 companies across 17 industries. The analysis finds specific penalties and incentives that are positively associated with reduced supplier violations and reduced buyer operating costs. In particular, offering suppliers incentives of increased business and training for improving social and environmental performance is strongly associated with a reduction in both violations and operating costs."
1941,"Aggregating Smallholder Farmers in Emerging Economies","An, Jaehyung and Cho, Soo-Haeng and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1414-1429","2015","SEP","Cooperatives;Socially Responsible Operations;Cournot Competition","","The agricultural sector plays an important role in emerging economies even though most farmers are trapped in the poverty cycle owing to their smallholdings. Aggregating farmers through formal or informal cooperatives (coops) can enable them to: (i) reduce production cost; (ii) increase/stabilize process yield; (iii) increase brand awareness; (iv) eliminate unnecessary intermediaries; and (v) eliminate price uncertainty. To examine whether these effects will benefit the members of such aggregation when they compete with other individual farmers, we present separate models to capture the essence of these five effects. For each effect, we find that it is beneficial for a farmer to be part of the aggregation only when the size of the aggregation is below a certain threshold. Also, while certain effects are beneficial to the market as a whole, other effects are hurtful due to higher market price and/or lower production quantity."
1942,"Incentive for Peer-to-Peer Knowledge Sharing among Farmers in Developing Economies","Chen, Ying-Ju and Shanthikumar, J. George and Shen, Zuo-Jun Max","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1430-1440","2015","SEP","Socially Responsible Operations;Knowledge Sharing;Strategic Farmers' Behavior;Game Theory","","This study examines the peer-to-Peer interactions among farmers when both knowledge learning and sharing are available. We construct a stylized model in which heterogeneous farmers are endowed with their initial production capabilities and can post questions in the platform for help. A representative expert regularly monitors the forum and provides answers to the farmers' questions, but may be non-responsive sometimes due to the limited capacity. A knowledgeable core user (farmer) can choose to be silent or responsive, and is allowed to strategically determine the informativeness of her answers. The farmers face the minimum quantity restriction for attracting the buyers, and must make production before the time of sales. We show that in equilibrium the core user never provides answers that are more informative than the expert's, irrespective of her ex ante knowledge level. Redesigning or restructuring the platform does not help eliminate this inefficient knowledge provision. We also find that hiring more staff to frequently monitor the forum turns out to be detrimental for the peer-to-peer interactions. Moreover, the competition on knowledge sharing between the platform expert and the core user features strategic complementarity sometimes but strategic substitution at other times. Third, charging for the platform usage may discourage uninformative answers, but it could also discourage the core user from sharing knowledge with other farmers."
1943,"The Economic Value of Market Information for Farmers in Developing Economies","Chen, Ying-Ju and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1441-1452","2015","SEP","Social Responsibility;Information Provision;Value Creation;Game Theory","","In developing countries, farmers lack information for making informed production, manufacturing/selling decisions to improve their earnings. To alleviate poverty, various non-governmental organizations (NGOs) and for-profit companies have developed different ways to distribute information about market price, crop advisory and farming technique to farmers. We investigate a fundamental question: will information create economic value for farmers? We construct a stylized model in which farmers face an uncertain market price (demand) and must make production decisions before the market price is realized. Each farmer has an imprecise private signal and an imprecise public signal to estimate the actual market price. By examining the equilibrium outcomes associated with a Cournot competition game, we show that private signals do create value by improving farmers' welfare. However, this value deteriorates as the public signal becomes available (or more precise). In contrast, in the presence of private signals, the public signal does not always create value for the farmers. Nevertheless, both private and public signals will reduce price variation. We also consider two separate extensions that involve non-identical private signal precisions and farmers' risk-aversion, and we find that the sameresults continue to hold. More importantly, we find that the public signal can reduce welfare inequality when farmers have non-identical private signal precisions. Also, risk-aversion can dampen the value created by private or public information."
1944,"Municipal Groundwater Management: Optimal Allocation and Control of a Renewable Natural Resource","Murali, Karthik and Lim, Michael K. and Petruzzi, Nicholas C.","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1453-1472","2015","SEP","Groundwater Management;Triple Bottom Line;Water Transfers;Privatization","","We study a municipal groundwater management problem to determine optimal allocation and control policies in the presence of water transfer opportunities. We establish and characterize threshold polices governing export or import decisions of a given municipality. In the spirit of the Triple Bottom Line (3BL), we ascertain that exporting (importing) water through a water market defined by an exogenous export/import price is detrimental (beneficial) to both society and the environment within the municipality. In contrast, fixed quantity trading between two municipalities defined by an endogenously negotiated export/import price can have positive as well as negative impacts from a global 3BL perspective. In particular, typical trading scenarios that occur between municipalities can be detrimental to the environment. We also study the implications of privatization, and find that a privatized municipality would be more (less) likely to export (import) water as compared to its non-privatized counterpart, resulting in negative implications for society within the municipality. However, if exports are banned, privatization can benefit the environment by mitigating the damage caused by the extraction differential, a phenomenon analogous to the green paradox. Moreover, careful and restricted privatization of municipalities can lead to positive global 3BL impacts from fixed quantity trading."
1945,"Repurposing Materials and Waste through Online Exchanges: Overcoming the Last Hurdle","Dhanorkar, Suvrat and Donohue, Karen and Linderman, Kevin","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1473-1493","2015","SEP","Socially Responsible Operations;Materials And Waste Exchange;Sustainability;Online Markets;Closed Loop Supply Chains","","Online material and waste exchanges (OMWEs) provide online channels to repurpose by-products, unused materials and waste from industrial and commercial facilities. Unfortunately, OMWE's also have challenges. First, sellers may have access to other disposal options and, as a result, may not fully commit to the exchange. Second, buyers can face high uncertainty about the product exchanged and the transaction being undertaken. Overcoming these challenges is the last hurdle to making OMWEs successful. This study investigates the factors that reduce the buyers' uncertainty and increase the sellers' commitment to the OMWE. We analyze novel transaction-level data from an online exchange (MNExchange.org) combined with other archival public records on county-level repurposing and disposal statistics. First, we find that regional repurposing policies and alternatives have a complementary effect on sellers' commitment toward OMWEs, resulting in increased OMWE exchanges. However, regional disposal policies and alternatives have a substitution effect on sellers' commitment, resulting in reduced exchange success. Further, greater product and transaction information reduce the buyer's uncertainty and increase exchange success. Finally, the analysis shows that users' (buyers and sellers) heavily rely on their prior experience with OMWEs. Specifically, higher familiarity between the buyer-seller pair and familiarity with the OMWE system leads to higher likelihood of exchange success. This study lays the foundation for understanding OMWEs and has important implications for developing policies and operations to increase online transactions of by-products, materials and wastes."
1946,"Supply Chain Design and Carbon Penalty: Monopoly vs. Monopolistic Competition","Park, Seung Jae and Cachon, Gerard P. and Lai, Guoming and Seshadri, Sridhar","PRODUCTION AND OPERATIONS MANAGEMENT","24","9","1494-1508","2015","SEP","Sustainability;Supply Chain Design;Policy Making;Carbon Tax;Monopolistic Competition","","This paper studies whether imposing carbon costs changes the supply chain structure and social welfare. We explore the problem from a central policymaker's perspective who wants to maximize social welfare. We consider two stakeholders, retailers, and consumers, who optimize their own objectives (i.e., profits and net utility) and three competitive settings (i.e., monopoly, monopolistic competition with symmetric market share, and monopolistic competition with asymmetric market share). For the monopoly case, we find that when the retailer's profit is high, imposing some carbon emission charges on the retailer and the consumers does not substantially change the supply chain structure or the social welfare. However, when the retailer's profit is low, imposing carbon costs optimally can lead to a significant increase in social welfare. Moreover, the impact of imposing carbon emission charges becomes more significant when the degree of competition increases. Additionally, the quantum of benefit may depend only on factors common across industries, such as fuel and carbon costs."
1947,"The Implications of Utilizing Market Information and Adopting Agricultural Advice for Farmers in Developing Economies","Tang, Christopher S. and Wang, Yulan and Zhao, Ming","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1197-1215","2015","AUG","Emerging Markets;Social Responsibility;Operational Improvements;Competitive Production Strategies","","To alleviate poverty in developing countries, governments and non-governmental organizations disseminate two types of information: (i) agricultural advice to enable farmers to improve their operations (cost reduction, quality improvement, and process yield increase); and (ii) market information about future price/demand to enable farmers to make better production planning decisions. This information is usually disseminated free of charge. While farmers can use the market information to improve their production plans without incurring any (significant) cost, adopting agricultural advice to improve operations requires upfront investment, for example, equipment, fertilizers, pesticides, and higher quality seeds. In this study, we examine whether farmers should use market information to improve their production plans (or adopt agricultural advice to improve their operations) when they engage in Cournot competition under both uncertain market demand and uncertain process yield. Our analysis indicates that both farmers will use the market information to improve their profits in equilibrium. Hence, relative to the base case in which market information is not available, the provision of market information can improve the farmers' total welfare (i.e., total profit for both farmers). Moreover, when the underlying process yield is highly uncertain or when the products are highly heterogeneous, the provision of market information is welfare-maximizing in the sense that the maximum total welfare of farmers is attained when both farmers utilize market information in equilibrium. Furthermore, in equilibrium, whether a farmer adopts the agricultural advice depends on the size of the requisite upfront investment. More importantly, we show that agricultural advice is not always welfare improving unless the upfront investment is sufficiently low. This result implies that to improve farmers' welfare, governments should consider offering farmer subsidies."
1948,"Decision Making and Cognition in Multi-Echelon Supply Chains: An Experimental Study","Narayanan, Arunachalam and Moritz, Brent B.","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1216-1234","2015","AUG","Bullwhip Effect;Behavioral Operations;Cognitive Reflection","","Supply chain performance often depends on the individual decisions of channel members. Even when individuals have access to relevant information, order variation tends to increase when moving up the supply chain, a phenomenon known as the bullwhip effect. While prior research has investigated several structural/environmental factors which can mitigate the bullwhip effect, the underlying behavioral factors contributing to it are an open question. Using a production and distribution decision-making simulation representing a four-stage serial supply chain, we find that the cognitive profile of decision makers contributes to the bullwhip effect. We found that the specific decision tendency to underweight the supply line is linked to an individual's level of cognitive reflection. Furthermore, performance differs for entire supply chains and for specific echelons, and holds under standard mitigation efforts. The findings have implications for supply chain design, education, and industry."
1949,"Class-Based Storage with a Finite Number of Items: Using More Classes is not Always Better","Yu, Yugang and de Koster, Rene B. M. and Guo, Xiaolong","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1235-1247","2015","AUG","Logistics;Warehousing;Storage Policy;Abc Class-Based Storage;As;R System","","Class-based storage is widely studied in the literature and applied in practice. It divides all stored items into a number of classes according to their turnover. A class of items with higher turnover is allocated to a region closer to the warehouse depot. In the literature, it has been shown that the use of more storage classes leads to a shorter travel time for storing and retrieving items. A basic assumption in this literature is that the required storage space for all items equals their average inventory level, which is valid only if an infinite number of items can be stored in each storage region. This study revisits class-based storage by considering each storage space to contain only a finite number of items. We develop a travel time model and an algorithm that can be used for determining the optimal number and boundaries of storage classes in warehouses. Different from the conventional research, our findings illustrate that commonly a small number of classes is optimal. In addition, we find the travel time is fairly insensitive to the number of storage classes in a wide range around the optimum. This suggests that a manager can select a near-optimal number of storage classes in an easy way and need not be worried about the impact of storage-class reconfigurations. We validate our findings for various cases, including different ABC-demand curves, space-sharing factors, number of items, storage rack shapes, discrete storage locations, and stochastic item demand."
1950,"The Effects of Multitasking on Operations Scheduling","Hall, Nicholas G. and Leung, Joseph Y. -T. and Li, Chung-Lun","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1248-1265","2015","AUG","Scheduling;Multitasking;Polynomial Time Algorithm;Cost And Value Of Multitasking","","This study considers a typical scheduling environment that is influenced by the behavioral phenomenon of multitasking. Under multitasking, the processing of a selected job suffers from interruption by other jobs that are available but unfinished. This situation arises in a wide variety of applications; for example, administration, manufacturing, and process and project management. Several classical solution methods for scheduling problems no longer apply in the presence of multitasking. The solvability of any scheduling problem under multitasking is no easier than that of the corresponding classical problem. We develop optimal algorithms for some fundamental and practical single machine scheduling problems with multitasking. For other problems, we show that they are computationally intractable, even though in some cases the corresponding problem in classical scheduling is efficiently solvable. We also study the cost increase and value gained due to multitasking. This analysis informs companies about how much it would be worthwhile to invest in measures to reduce or encourage multitasking."
1951,"Storing Fresh Produce for Fast Retrieval in an Automated Compact Cross-Dock System","Zaerpour, Nima and Yu, Yugang and de Koster, Rene B. M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1266-1284","2015","AUG","Warehousing;Cross-Docking;Compact Storage System;Shared Storage;Robust Assignment","","We study temporary storage of fresh produce in a cross-dock center. In order to minimize cooling cost, compact storage systems are used. A major disadvantage of these systems is that additional retrieval time is needed, caused by necessary reshuffles due to the improper storage sequence of unit loads. In practice therefore, a dedicated storage policy is used in which every storage lane in the system accommodates only one product. However, this policy does not use the planned arrival time information of the outbound trucks. To exploit this information, this study proposes a mathematical model for a shared storage policy that minimizes total retrieval time. The policy allows different products to share the same lane. In order to solve real-sized problems, an effective and efficient heuristic is proposed, based on a greedy construction and an improvement part, which provides near optimal solutions. The gaps between the results of the heuristic and the lower bound are mostly less than 1%. The resulting shared storage policy is generally robust against disturbances in arrival or departure times. We compare our shared storage heuristic with dedicated storage to determine which policy performs best under which circumstances. For most practical cases, shared storage appears to outperform dedicated storage, with a shorter response time and better storage lane utilization."
1952,"Capacity Sharing and Cost Allocation among Independent Firms with Congestion","Yu, Yimin and Benjaafar, Saif and Gerchak, Yigal","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1285-1310","2015","AUG","Capacity Sharing;Queueing Systems;Joint Ventures;Cost Allocation;Cooperative Game Theory","","We analyze the benefit of production/service capacity sharing for a set of independent firms. Firms have the choice of either operating their own production/service facilities or investing in a facility that is shared. Facilities are modeled as queueing systems with finite service rates. Firms decide on capacity levels (the service rate) to minimize delay costs and capacity investment costs possibly subject to service-level constraints on delay. If firms decide to operate a shared facility they must also decide on a scheme for sharing the capacity cost. We formulate the problem as a cooperative game and identify settings under which capacity sharing is beneficial and there is a cost allocation that is in the core under either the first-come, first-served policy or an optimal priority policy. We show that capacity sharing may not be beneficial in settings where firms have heterogeneous work contents and service variabilities. In such cases, we specify conditions under which capacity sharing may still be beneficial for a subset of the firms."
1953,"Point-of-Dispensing Location and Capacity Optimization via a Decision Support System","Ramirez-Nafarrate, Adrian and Lyon, Joshua D. and Fowler, John W. and Araz, Ozgur M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1311-1328","2015","AUG","Emergency Response;Point-Of-Dispensing;Facility Location And Resource Allocation Problems;Genetic Algorithms;Queuing Theory","","Dispensing of mass prophylaxis can be critical to public health during emergency situations and involves complex decisions that must be made in a short period of time. This study presents a model and solution approach for optimizing point-of-dispensing (POD) location and capacity decisions. This approach is part of a decision support system designed to help officials prepare for and respond to public health emergencies. The model selects PODs from a candidate set and suggests how to staff each POD so that average travel and waiting times are minimized. A genetic algorithm (GA) quickly solves the problem based on travel and queuing approximations (QAs) and it has the ability to relax soft constraints when the dispensing goals cannot be met. We show that the proposed approach returns solutions comparable with other systems and it is able to evaluate alternative courses of action when the resources are not sufficient to meet the performance targets."
1954,"Strategic Inventory and Supply Chain Behavior","Hartwig, Robin and Inderfurth, Karl and Sadrieh, Abdolkarim and Voigt, Guido","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1329-1345","2015","AUG","Supply Chain Coordination;Vertical Contracts;Fair Behavior;Intertemporal Supplier Pricing","","Based on a serial supply chain model with two periods and price-sensitive demand, we present the first experimental test of the effect of strategic inventories on supply chain performance. In theory, if holding costs are sufficiently low, the buyer builds up a strategic inventory (even if no operational reasons for stock-holding exist) to limit the supplier's market power, and to increase the own profit share. As it turns out, this enhances the overall supply chain performance. The supplier anticipates the effect of the strategic inventory and differentiates prices to capture a part of the increased supply chain profits. Our results show that the positive effects of strategic inventories are even more pronounced than theoretically predicted, because strategic inventories empower buyers by shifting the perception of the fair split. Overall, strategic inventories have a double positive effect, a strategic and a behavioral, both reducing the average wholesale prices and dampening the double marginalization effect. The latter effect leads to more equitable payoffs."
1955,"Supply Chain Consequences of Subsidies for Corporate Social Responsibility","Arya, Anil and Mittendorf, Brian","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1346-1357","2015","AUG","Corporate Social Responsibility;Philanthropy;Pricing;Supply Chains","","The use of government incentives tied to market prices as means of boosting corporate social responsibility (CSR) has expanded notably in recent decades. Enhanced business tax deductions for charitable donations and credits for conservation easements are notable cases. While providing incentives for socially desirable behavior to achieve legislative goals has intuitive appeal, the broader economic consequences are not always fully understood. In this study, we examine such wider consequences for supply chains when subsidies for CSR are offered. One effect we identify is that since incentives are typically tied to market value, firms have not only an added incentive to achieve societal objectives (say by donating inventory) but also an incentive to raise output (retail) market prices. A second consequence is that since firms forgo potential revenues by engaging in socially desired behavior, they become increasingly sensitive to supplier pricing; in an uncoordinated supply chain this leads to input (wholesale) price concessions. Among other things, the results underscore that incentives put in place to meet broader societal objectives also have notable ramifications for suppliers, retailers, and consumers in primary markets."
1956,"Competition and Coordination in a Two-Channel Supply Chain","David, Amy and Adida, Elodie","PRODUCTION AND OPERATIONS MANAGEMENT","24","8","1358-1370","2015","AUG","Supply Chain Management;Game Theory;Dual-Channel;Incentives And Contracting","","We study competition and coordination in a supply chain in which a single supplier both operates a direct channel and sells its product through multiple differentiated retailers. We study analytically the supply chain with symmetric retailers and find that the supplier prefers to have as many retailers as possible in the market, even if the retailers' equilibrium retail price is lower than that of the supplier, and even if the number of retailers and their cost or market advantage prevent sales through the direct channel. We find that the two-channel supply chain may be subject to inefficiencies not present in the single-channel supply chain. We show that several contracts known to coordinate a single-channel supply chain do not coordinate the two-channel supply chain; thus we propose a linear quantity discount contract and demonstrate its ability to perfectly coordinate the two-channel supply chain with symmetric retailers. We provide some analytical results for the supply chain with asymmetric retailers and propose an efficient solution approach for finding the equilibrium. We find numerically that the supplier still benefits from having more retailers in the market and that linear quantity discount contracts can mitigate supply chain inefficiency, though they no longer achieve perfect coordination."
1957,"Inventory Planning for a Modular Product Family","Paul, Anand and Tan, Yinliang (Ricky) and Vakharia, Asoo J.","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1033-1053","2015","JUL","Modular Products;Inventory Planning;Fill Rates","","This paper is motivated by observing that an increasing number of firms are offering modular products assembled with multiple option choices for the consumer. Starting with the PC offerings by Dell which allowed (and still allows) users to configure their product by choosing among multiple choices for each option, the current market place seems to have evolved to a make-to-stock scenario where Apple offers its IPAD series with multiple models each with a unique storage size, color, and wireless chip technology. The focus of our work is on determining the optimal stocking level of modular end-products. Our analysis is based on a benchmark model with the aim of maximizing expected profit subject to an aggregate fill rate constraint as well as variant-specific individual fill rates under a make-to-stock setting. To further assess the robustness of our finding, we consider the extensions of correlated market preferences over options, price-dependent demand, and alternative probability distributions for characterizing uncertainty in market preferences or aggregate demand. Finally we also show how to extend the single period model into a multiple-period setting. Through extensive computational analysis, we find that more precise estimates of market preferences for various modular options constitute extremely valuable information that goes beyond the usefulness of forecasts of aggregate market demand. From a practical perspective, this might be indicative of another classic marketing-operations trade-off. Offering more options for consumers would be preferred by marketing managers since this would reach more consumers and hence, enhance product sales. On the other hand, the ability to obtaining greater forecast accuracy would decline when the number of options increase. Hence, from an operational perspective, it would be preferred to limit option choices (so that better forecasts can be obtained) since this would lead to lower stocking costs and hence, higher profits."
1958,"E-Procurement Infusion and Operational Process Impacts in MRO Procurement: Complementary or Substitutive Effects?","Yu, Seunghee and Mishra, Abhay Nath and Gopal, Anandasivam and Slaughter, Sandra and Mukhopadhyay, Tridas","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1054-1070","2015","JUL","Electronic Procurement Infusion;Intensity Of Use;Mro;Organizational Acceptance;Procurement Performance","","The procurement of maintenance, repair, and operating (MRO) goods has remained a relatively understudied topic in the literature. Though vital cost efficiencies can be extracted from procurement processes through investments in e-procurement systems, there is little empirical work that addresses how such systems should be deployed within organizations. In this study, we focus on the role of e-procurement systems in MRO procurement and study two critical aspects of infusion. The first dimension captures the depth of e-procurement use within the procurement function, while the second dimension depicts the breadth of use. We argue that these two dimensions of e-procurement use, and their interaction, will be related to the performance of the MRO procurement process. Using survey data from 193 service organizations and structural equation modeling techniques, we show that the two infusion dimensions are significantly associated with improved process performance. Additionally, we show a substantial substitutive effect between the two use dimensions on performance. Our work has significant implications for managers who seek to gain efficiencies by the deployment of Internet-based technologies within operational processes. Our conceptualization of e-procurement infusion along two dimensions provides a more fine-grained analysis of performance benefits accruing from the infusion of information technologies within organizations."
1959,"Implications of Channel Structure and Operational Mode Upon a Manufacturer's Durability Choice","Bhaskaran, Sreekumar R. and Gilbert, Stephen M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1071-1085","2015","JUL","Durable Goods;Channel Structure;Competition;Product Life Cycle","","Motivated by the observation that durability ratings of automobile manufacturers are not necessarily linked to the proportion of leasing but tend to decrease with the density of their dealer networks, we explore the interactions between channel structure (direct interaction with consumers vs. through an intermediary(ies)) and mode of operations (leasing vs. selling) and their implications for a manufacturer's willingness to invest in making her product more durable. Using a manufacturer who leases her product directly to consumers as a point of reference, we find that an isolated change in either the channel structure (selling through an intermediary), or the operational mode (leasing to selling) can decrease the manufacturer's willingness to provide durability. However, if combined, these two changes together may strengthen the manufacturer's willingness to invest in durability. Specifically, the traditional result that a manufacturer who leases provides more durability than one who sells, can be reversed in a decentralized channel."
1960,"Flexibility Structure and Capacity Design with Human Resource Considerations","Aksin, O. Zeynep and Cakan, Nesrin and Karaesmen, Fikri and Ormeci, E. Lerzan","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1086-1100","2015","JUL","Flexibility;Call Centers;Multidimensional Newsvendor;Gradient Estimation Via Perturbation Analysis","","Most service systems consist of multidepartmental structures with multiskill agents that can deal with several types of service requests. The design of flexibility in terms of agents' skill sets and assignments of requests is a critical issue for such systems. The objective of this study was to identify preferred flexibility structures when demand is random and capacity is finite. We compare structures recommended by the flexibility literature to structures we observe in practice within call centers. To enable a comparison of flexibility structures under optimal capacity, the capacity optimization problem for this setting is formulated as a two-stage stochastic optimization problem. A simulation-based optimization procedure for this problem using sample-path gradient estimation is proposed and tested, and used in the subsequent comparison of the flexibility structures being studied. The analysis illustrates under what conditions on demand, cost, and human resource considerations, the structures found in practice are preferred."
1961,"Staffing Call Centers with Uncertain Arrival Rates and Co-sourcing","Kocaga, Yasar Levent and Armony, Mor and Ward, Amy R.","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1101-1117","2015","JUL","Call Center Operations;Co-Sourcing;Staffing;Overflow Routing;Parameter Uncertainty","","In a call center, staffing decisions must be made before the call arrival rate is known with certainty. Once the arrival rate becomes known, the call center may be over-staffed, in which case staff are being paid to be idle, or under-staffed, in which case many callers hang-up in the face of long wait times. Firms that have chosen to keep their call center operations in-house can mitigate this problem by co-sourcing; that is, by sometimes outsourcing calls. Then, the required staffing N depends on how the firm chooses which calls to outsource in real time, after the arrival rate realizes and the call center operates as a M/M/N+M queue with an outsourcing option. Our objective is to find a joint policy for staffing and call outsourcing that minimizes the long-run average cost of this two-stage stochastic program when there is a linear staffing cost per unit time and linear costs associated with abandonments and outsourcing. We propose a policy that uses a square-root safety staffing rule, and outsources calls in accordance with a threshold rule that characterizes when the system is too crowded. Analytically, we establish that our proposed policy is asymptotically optimal, as the mean arrival rate becomes large, when the level of uncertainty in the arrival rate is of the same order as the inherent system fluctuations in the number of waiting customers for a known arrival rate. Through an extensive numerical study, we establish that our policy is extremely robust. In particular, our policy performs remarkably well over a wide range of parameters, and far beyond where it is proved to be asymptotically optimal."
1962,"Fractional Price Matching Policies Arising from the Ocean Freight Service Industry","Lee, Chung-Yee and Tang, Christopher S. and Yin, Rui and An, Jaehyung","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1118-1134","2015","JUL","Ocean Freight;Fractional Price Matching;Pricing Contracts","","We consider a situation in which shippers (customers) can purchase ocean freight services either directly from a carrier (service provider)in advance or from the spot market just before the departure of an ocean liner. The price is known in the former case, while the spot price is uncertain ex-ante in the latter case. Consequently, some shippers are reluctant to book directly from the carrier in advance unless the carrier is willing to partially match the realized spot price when it is lower than the regular price. This study is an initial attempt to examine if the carrier should bear some of the price risk by offering a fractional price matching contract that can be described as follows. The shipper pays the regular freight price in advance; however, the shipper will get a refund if the realized spot price is below the regular price, where the refund is a fraction of the difference between the regular price and the realized spot price. By modeling the dynamics between the carrier and the shippers as a sequential game, we show that the carrier can use the fractional price matching contract to generate a higher demand from the shippers compared to no price matching contract by increasing the fraction in equilibrium. However, as the carrier increases the fraction, the carrier should increase the regular price to compensate for bearing additional risk. By selecting the fractional price matching contract optimally, we show that the carrier can afford to offer this price matching mechanism without incurring revenue loss: the optimal fractional price matching contract is revenue neutral."
1963,"Up Then Down: Bid-Price Trends in Revenue Management","Pang, Zhan and Berman, Oded and Hu, Ming","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1135-1147","2015","JUL","Bid Price;Dynamic Pricing;Revenue Management;Stochastic Dynamic Programming","","In the classic revenue management (RM) problem of selling a fixed quantity of perishable inventories to price-sensitive non-strategic consumers over a finite horizon, the optimal pricing decision at any time depends on two important factors: consumer valuation and bid price. The former is determined exogenously by the demand side, while the latter is determined jointly by the inventory level on the supply side and the consumer valuations in the time remaining within the selling horizon. Because of the importance of bid prices in theory and practice of RM, this study aims to enhance the understanding of the intertemporal behavior of bid prices in dynamic RM environments. We provide a probabilistic characterization of the optimal policies from the perspective of bid-price processes. We show that an optimal bid-price process has an upward trend over time before the inventory level falls to one and then has a downward trend. This intertemporal up-then-down pattern of bid-price processes is related to two fundamental static properties of the optimal bid prices: (i) At any given time, a lower inventory level yields a higher optimal bid price, which is referred to as the resource scarcity effect; (ii) Given any inventory level, the optimal bid price decreases with time; that is referred to as the resource perishability effect. The demonstrated upward trend implies that the optimal bid-price process is mainly driven by the resource scarcity effect, while the downward trend implies that the bid-price process is mainly driven by the resource perishability effect. We also demonstrate how optimal bid price and consumer valuation, as two competing forces, interact over time to drive the optimal-price process. The results are also extended to the network RM problems."
1964,"Maximizing Revenue Through Two-Dimensional Shelf-Space Allocation","Geismar, H. Neil and Dawande, Milind and Murthi, B. P. S. and Sriskandarajah, Chelliah","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1148-1163","2015","JUL","Shelf-Space Allocation;Two-Dimensional Display;Retail;Location Effects","","We consider the problem of optimally allocating contiguous rectangular presentation spaces in order to maximize revenues. Such problems are encountered in the arrangement of products in retail shelf-space and in the design of feature advertising displays or webpages. Specifically, we allow (i) the shape of a product's presentation to have a vertical as well as a horizontal component and (ii) displays to extend across multiple shelves for in-store presentations. Since the vertical location of the shelf on which a product is displayed affects its sales, each vertical location is assigned its own effectiveness with regard to revenue generation. The problem of maximizing the total weighted revenue of a display is strongly NP-hard. Therefore, we decompose it into two subproblems. The first consists of allocating products to different cabinets. In the second, within each cabinet, each product's units are arranged in a contiguous rectangle and assigned a location. These subproblems are solved using an innovative approach that uses a combination of integer programming and an algorithm for the maximum-weight independent set problem. Based on computational studies on both real-world and simulated data, we demonstrate the efficiency and effectiveness of our approach. Specifically, the revenue generated by this scheme is within 1% of the optimum for actual data and within 5% for simulated data."
1965,"Balancing Production and Distribution in Paper Manufacturing","Geismar, H. Neil and Murthy, Nagesh M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1164-1178","2015","JUL","Coordination;Distribution;Bin-Packing;Non-Bipartite Matching;Paper Industry","","A paper manufacturing plant minimizes its production cost by using long production runs that combine the demands from its various customers. As jobs are completed, they are released to distribution for delivery. Deliveries are made by railcars, each of which is dedicated to one customer. Long production runs imply that maximizing railcar utilization requires holding the cars over several days or holding completed jobs within the loading facility. Each of these methods imposes a cost onto the distribution function. We find how distribution can minimize its cost, given production's schedule. We then consider the problem of minimizing the company's overall cost of both production and distribution. A computational study using general data illustrates that the distribution cost is reduced by 25.80% through our proposed scheme, and that the overall cost is reduced an additional 4.40% through our coordination mechanism. An optimal algorithm is derived for a specific plant's operations."
1966,"Concerning Workload Control and Order Release: The Pre-Shop Pool Sequencing Decision","Thuerer, Matthias and Land, Martin J. and Stevenson, Mark and Fredendall, Lawrence D. and Godinho Filho, Moacir","PRODUCTION AND OPERATIONS MANAGEMENT","24","7","1179-1192","2015","JUL","Order Release;Pre-Shop Pool Sequencing Rule;Workload Control;Simulation","","Every production planning concept that incorporates controlled order release will initially withhold jobs from the shop floor and create a pre-shop pool. Order release is a key component of the Workload Control concept that aims to maintain work-in-process within limits while ensuring due dates are met. Order release includes two decisions: (i) a sequencing decision that establishes the order in which jobs are considered for release; and, (ii) a selection decision that determines the criteria for choosing jobs for release. While selection has received much research attention, sequencing has been largely neglected. Using simulation, this study uncovers the potential for performance improvement in the sequencing decision and improves our understanding of how order release methods should be designed. Although most prior studies apply time-oriented sequencing rules and load-oriented selection rules, analysis reveals that load balancing considerations should also be incorporated in the sequencing decision. But an exclusive focus on load balancing is shown to increase mean tardiness and, paradoxically, require high workloads. A new sequencing rule is developed that only balances loads when multiple orders become urgent. It avoids high mean tardiness and allows the shop to operate at a low workload level. At the same time, the percentage tardy is reduced by up to 50% compared to a purely time-oriented rule. The findings have implications not only for Workload Control but for any concept that features order release control, such as ConWIP and Drum-Buffer-Rope."
1967,"Dynamic Pricing, Production, and Channel Coordination with Stochastic Learning","Li, Tao and Sethi, Suresh P. and He, Xiuli","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","857-882","2015","JUN","Learning Curve;Pricing;Inventory Management;Channel Coordination;Revenue Sharing Contracts","","We consider a decentralized two-period supply chain in which a manufacturer produces a product with benefits of cost learning, and sells it through a retailer facing a price-dependent demand. The manufacturer's second-period production cost declines linearly in the first-period production, but with a random learning rate. The manufacturer may or may not have the inventory carryover option. We formulate the resulting problems as two-period Stackelberg games and obtain their feedback equilibrium solutions explicitly. We then examine the impact of mean learning rate and learning rate variability on the pricing strategies of the channel members, on the manufacturer's production decisions, and on the retailer's procurement decisions. We show that as the mean learning rate or the learning rate variability increases, the traditional double marginalization problem becomes more severe, leading to greater efficiency loss in the channel. We obtain revenue sharing contracts that can coordinate the dynamic supply chain. In particular, when the manufacturer may hold inventory, we identify two major drivers for inventory carryover: market growth and learning rate variability. Finally, we demonstrate the robustness of our results by examining a model in which cost learning takes place continuously."
1968,"MRP Planned Orders in a Multiple-Supplier Environment with Differing Lead Times","Riezebos, Jan and Zhu, Stuart X.","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","883-895","2015","JUN","Different Lead Times;Discrete Lot-Sizing;Mrp;Multiple Suppliers;Order Crossovers","","This study examines a deterministic material requirements planning (MRP) problem where lead times at subsequent ordering moments differ. Adequate replenishment methods that can cope with lead time differences are lacking because of the order crossover phenomenon, that is, replenishment orders are not received in the sequence they are ordered. This study specifies how to handle order crossovers and recalculate planned order releases after an update of gross requirements. The optimal (s, S) policy is based on dynamic programing. The state space is kept to a minimum due to three fundamental insights. The performance of the optimal solution approach is compared with two heuristics based on relaxations and a benchmark approach in which order crossovers are ignored. A numerical analysis reveals that average cost savings up to 25% are possible if the optimal policy is used instead of the benchmark approach. The contribution of this study is threefold: (1) it generalizes theory on MRP ordering, allowing for lead time differences and order crossovers; (2) it develops new fundamental insights and an optimal solution procedure, leading to substantial cost saving; and (3) it provides good-performing heuristics for a general and realistic replenishment problem that can replace the current replenishment methods within MRP."
1969,"Dynamic Pricing of New Services in Subscription Markets","Penmetsa, Nabita and Gal-Or, Esther and May, Jerrold","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","896-916","2015","JUN","Commitment Power In Pricing;Dynamic Pricing;Experience-Based Learning;Game Theory;Price Discrimination;Strategic Customers","","We analyze the dynamic price discrimination strategies of a monopolist who offers new services on a subscription basis. Access to customers' subscription histories permits the monopolist to design pricing policies that can be based on customers' past purchase behavior, and on the time period in which they made their purchases. Uncertainty regarding the value of new features, and heterogeneity in consumers' valuation for existing features, creates inter-temporal incentives that influence both profits and the rate of adoption of new technology. We find that the comparison of pricing regimes critically depends on whether the monopolist finds it optimal to encourage all consumers to adopt the new technology early. The pricing regimes differ only when the prior heterogeneity in consumer valuation for the existing features is relatively large, in which case the monopolist finds it optimal to serve only the part of the population of consumers that has a relatively high valuation. The monopolist can improve his profits by committing to ignore consumer past behavior, and to vary prices based only on the time period. If a stronger commitment to never utilize any price discrimination is feasible, the profits of the monopolist are even higher. However, the First Best outcome cannot be achieved, because it requires the monopolist to discriminate in favor of returning customers, by offering them lower prices than it offers to new customers. We also investigate the effect of positive correlation between the consumer valuations for the existing and the new features of the technology. We find that, as the correlation increases, the gap in profits among the various regimes narrows, while the ranking of the regimes remains the same. In particular, with perfect correlation, time inconsistency issues that arise due to lack of commitment disappear completely for all regimes, and the First Best outcome is attainable."
1970,"Requirement or Promise? An Analysis of the First-Mover Advantage in Quality Contracting","Yan, Xinghao and Zhao, Hui and Tang, Kwei","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","917-933","2015","JUN","Quality Contracting;First-Mover Right;Quality Improvement;Information Asymmetry;Supplier Competition","","Quality contracting is critical and challenging due to the many unique issues related to quality. In this study, we analyze the first-mover right in quality contracting by considering two different strategies for the buyer: the quality requirement strategy (QR) where buyer moves first by posting quality requirement to suppliers and quality promise strategy (QP) where buyer voluntarily gives up the first-mover right to suppliers to ask them to promise quality. We study which strategy (1) better encourages suppliers' quality improvement efforts and (2) leads to a higher expected profit for the buyer. To analyze the drivers behind the buyer's choice between QR and QP, we start with the basic model where buyer faces only one supplier who has the opportunity to make quality improvements. We then gradually add other business features such as information asymmetry and supplier competition, analyzing how each feature adds/changes the driving forces and how they interact in the buyer's decision between QR and QP. We consider both the case where the wholesale price is fixed (when the buyer has the power to dictate price or price is set by the market) and the case where the wholesale price is included as a variable (when price is part of the negotiation). We find that QP always leads to the first-best quality efforts from the supplier(s) while QR limits their efforts. However, this does not guarantee higher expected profit for the buyer under QP. We provide insightful guidelines in buyer's choice between QP and QR. This research enriches the limited literature on quality contracting with quality improvement opportunity and asymmetric information."
1971,"Sourcing with Deferred Payment and Inspection under Supplier Product Adulteration Risk","Rui, Huaxia and Lai, Guoming","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","934-946","2015","JUN","Quality Control;Deferred Payment;Inspection;Moral Hazard","","We study the deferred payment and inspection mechanisms for mitigating supplier product adulteration, with endogenous procurement decision and general defect discovery process. We first derive the optimal deferred payment contract, which reveals that either entire or partial deferral can arise, depending on the moral hazard severity and the information accumulation rate. Because of the supplier's incentive to adulterate, the optimal procurement quantity under deferred payment generally is smaller than the first-best quantity. We then investigate the inspection mechanism and characterize the equilibrium. We find that under the inspection mechanism, the optimal procurement quantity is no less than the first best. A comparison between these two mechanisms shows that the deferred payment mechanism generally can outperform the inspection mechanism when either the market size is small or the profit margin is low. However, we find that these two mechanisms can also be complementary, for which we characterize a necessary condition."
1972,"Route vs. Segment: An Experiment on Real-Time Travel Information in Congestible Networks","Mak, Vincent and Gisches, Eyran J. and Rapoport, Amnon","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","947-960","2015","JUN","Transportation;Behavioral Operations;Experiments;Game Theory","","We report the results of an experimental study of route choice in congestible networks with a common origin and common destination. In one condition, in each round of play network users independently committed themselves at the origin to a three-segment route; in the other condition, they chose route segments sequentially at each network junction upon receiving en route information. At the end of each round, players received ex-post complete information about the distribution of the route choices. Although the complexity of the network defies analysis by common users, traffic patterns in both conditions converged rapidly to the equilibrium solution. We account for the observed results by a Markov adaptive learning model postulating regret minimization and inertia. We find that subjects' learning behavior was similar across conditions, except that they exhibited more inertia in the condition with en route information."
1973,"Fairness Among Servers When Capacity Decisions Are Endogenous","Geng, Xin and Huh, Woonghee Tim and Nagarajan, Mahesh","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","961-974","2015","JUN","Service System;Heterogeneous Servers;Fairness;Endogenous Capacity","","We look at a simple service system with two servers serving arriving jobs (single class). Our interest is in examining the effect of routing policies on servers when they care about fairness among themselves, and when they can endogenously choose capacities in response to the routing policy. Therefore, we study the two-server game where the servers' objective functions have a term explicitly modeling fairness. Moreover, we focus on four commonly seen policies that are from one general class. Theoretical results concerning the existence and uniqueness of the Nash equilibrium are proved for some policies. Further managerial insights are given based on simulation studies on servers' equilibrium/off-equilibrium behaviors and the resulting system efficiency performance under different policies."
1974,"An Integrated Text Analytic Framework for Product Defect Discovery","Abrahams, Alan S. and Fan, Weiguo and Wang, G. Alan and Zhang, Zhongju (John) and Jiao, Jian","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","975-990","2015","JUN","Social Media Analytics;Quality Management","","The recent surge in the usage of social media has created an enormous amount of user-generated content (UGC). While there are streams of research that seek to mine UGC, these research studies seldom tackle analysis of this textual content from a quality management perspective. In this study, we synthesize existing research studies on text mining and propose an integrated text analytic framework for product defect discovery. The framework effectively leverages rich social media content and quantifies the text using various automatically extracted signal cues. These extracted signal cues can then be used as modeling inputs for product defect discovery. We showcase the usefulness of the framework by performing product defect discovery using UGC in both the automotive and the consumer electronics domains. We use principal component analysis and logistic regression to produce a multivariate explanatory analysis relating defects to quantitative measures derived from text. For our samples, we find that a selection of distinctive terms, product features, and semantic factors are strong indicators of defects, whereas stylistic, social, and sentiment features are not. For high sales volume products, we demonstrate that significant corporate value is derivable from a reduction in defect discovery time and consequently defective product units in circulation."
1975,"Positioning Inventory in Clinical Trial Supply Chains","Fleischhacker, Adam and Anh Ninh and Zhao, Yao","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","991-1011","2015","JUN","Clinical Trial Supply Chains;Multi-Echelon Inventory Models;Finite Patient Horizon;Pharmaceutical Supply Chains","","As a result of slow patient recruitment and high patient costs in the United States, clinical trials are increasingly going global. While recruitment efforts benefit from a larger global footprint, the supply chain has to work harder at getting the right drug supply to the right place at the right time. Certain clinical trial supply chains, especially those supplying biologics, have a combination of unique attributes that have yet to be addressed by existing supply chain models. These attributes include a fixed patient horizon, an inflexible supply process, a unique set of service-level requirements, and an inability to transfer drug supplies among testing sites. We provide a new class of multi-echelon inventory models to address these unique aspects. The resulting mathematical program is a nonlinear integer programming problem with chance constraints. Despite this complexity, we develop a solution method that transforms the original formulation into a linear integer equivalent. By analyzing special cases and through numerical study of both real-life and simulated examples, we demonstrate the effectiveness of the solution and develop insights into inventory positioning and the cost drivers in clinical trial supply chains."
1976,"Split-Award Procurement AuctionsCan Bayesian Equilibrium Strategies Predict Human Bidding Behavior in Multi-Object Auctions?","Bichler, Martin and Guler, Kemal and Mayer, Stefan","PRODUCTION AND OPERATIONS MANAGEMENT","24","6","1012-1027","2015","JUN","Procurement;Multi-Object Auction;Bayes Nash Equilibrium;Risk-Aversion;Experiment","","We analyze if and when symmetric Bayes Nash equilibrium predictions can explain human bidding behavior in multi-object auctions. We focus on two sealed-bid split-award auctions with ex ante split decisions as they can be regularly found in procurement practice. These auction formats are straightforward multi-object extensions of the first-price sealed-bid auction. We derive the risk-neutral symmetric Bayes Nash equilibrium strategies and find that, although the two auction mechanisms yield the same expected costs to the buyer, other aspects of the two models, including the equilibrium bidding strategies, differ significantly. The strategic considerations in these auction formats are more involved than in single-lot first-price sealed-bid auctions, and it is questionable whether expected utility maximization can explain human bidding behavior in such multi-object auctions. Therefore, we analyzed the predictive accuracy of our equilibrium strategies in the laboratory. In human subject experiments we found underbidding, which is in line with earlier experiments on single-lot first-price sealed-bid auctions. To control for regret, we organize experiments against computerized bidders, who play the equilibrium strategy. In computerized experiments where bid functions are only used in a single auction, we found significant underbidding on low-cost draws. In experiments where the bid function is reused in 100 auctions, we could also control effectively for risk aversion, and there is no significant difference of the average bidding behavior and the risk-neutral Bayes Nash equilibrium bid function. The results suggest that strategic complexity does not serve as an explanation for underbidding in split-award procurement auctions, but risk aversion does have a significant impact."
1977,"Competitive and Collaborative Quality and Warranty Management in Supply Chains","Dai, Yue and Zhou, Sean X. and Xu, Yifan","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","129-144","2012","JAN-FEB","Product Quality;Warranty Period;Warranty-Dependent Demand;Nash Equilibrium;Supply Chain Coordination","","Product quality and product warranty coverage are two important and closely related operational decisions. A longer warranty protection period can boost sales, but it may also result in dramatically increased warranty cost, if product quality is poor. To investigate how these two decisions interact with each other and influence supply chain performance, we develop a single-period model with a supplier that provides a product to an original equipment manufacturer, which in turn sells it to customers. Customer demand is random and affected by the length of the product warranty period. Warranty costs are incurred by both the supplier and the manufacturer. We analyze two different scenarios based on which party sets the warranty period: manufacturer warranty and supplier warranty. Product quality is controlled by the supplier, and the manufacturer determines the ordering quantity. We analyze these decentralized systems and provide the structural properties of the equilibrium strategies. We also compare the results of centralized and decentralized systems and identify the conditions under which one system provides a longer warranty and better product quality than the other. Our numerical study further shows that, in decentralized settings, when the warranty period is determined by the firm sharing the larger proportion of total warranty costs, the supply chain can achieve greater system-wide profit. Both parties can therefore benefit from properly delegating the warranty decision and sharing the resulting additional profit. We further design a supplier-development and buy-back contract for coordinating decentralized supply chains. Several extensions are also discussed."
1978,"Controlling Power Retailer's Gray Activities Through Contract Design","Su, Xuemei and Mukhopadhyay, Samar K.","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","145-160","2012","JAN-FEB","Supply Chain;Contract Design;Retailing;Diversion;Gray Market","","We develop a model that captures dynamic relationships of a supply chain populated by a dominant retailer and a number of fringe retailers. The two types of retailers are asymmetric in buying power, retailing cost, and the ability to service the manufacturer's product. The wholesale prices offered through a quantity discount (QD) schedule can coordinate such a supply chain, but invite channel flow diversion type of gray trading between the dominant retailer and the fringe retailers. Our analysis is focused on how such a channel can be coordinated and the gray market activities be prevented. We propose a dynamic QD contract or a revenue-sharing contract that the manufacturer can use to fight the gray market activity. The performance of the supply chain and the manufacturer's profit under each of the two contract forms are compared and managerial guidelines are provided to help the manufacturer make a judicious choice."
1979,"Contingency Strategies in Managing Supply Systems with Uncertain Lead-Times","Kouvelis, Panos and Li, Jian","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","161-176","2012","JAN-FEB","Uncertain Supply;Random Lead-Time;Safety Lead-Time;Disruption Safety Stock;Dynamic Emergency Response","","The globalization of markets and geographic dispersion of production facilities, combined with a heavy outsourcing of supply chain processes, have substantially increased the exposure of supply chains to supply lead-times of long and uncertain nature. In this paper, we study the potential use of two contingency strategies on top of the conventionally used time bufferstatically planned safety lead-time (SL)approach to deal with the lead-time uncertainty. These are (1) the ex-ante planning for disruption safety stock (DSS) to be released when a disruption (in this case, late delivery of the order) occurs; and (2) the ex-post dynamic emergency response (DER), which dynamically decides on the timing and size of an emergency order to be placed. Our work elaborates on the optimal parameter setting for these strategies, compares their added values when used to complement the traditional SL approach, and examines how the use of the contingency strategies affects the SL and corresponding cycle length of a periodic review system. Our research finds that: (1) the above contingency strategies reduce the reliance on the SL and are cost effective when the coefficient of variation (CV) of the uncertain lead-time is high; (2) it is important to re-optimize the SL to account for the contingency plans; and (3) re-optimization of the cycle length to account for the presence of the contingency responses, as opposed to using an EOQ-determined cycle length, does not significantly improve the cost performance. However, such re-optimization does well in the SL approach when the CV of the uncertain lead-time is high."
1980,"Lead Time and Price Quotation Mode Selection: Uniform or Differentiated?","Zhao, Xuying and Stecke, Kathryn E. and Prasad, Ashutosh","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","177-193","2012","JAN-FEB","Price Quotation;Lead Time;Uniform Quotation Mode;Differentiated Quotation Mode","","Firms in service and make-to-order manufacturing industries often quote lead times and prices to customers. We define uniform quotation mode (UQM) as the strategy where a firm offers a single lead time and price quotation, and differentiated quotation mode (DQM) is where a firm offers a menu of lead times and prices for customers to choose from. Both modes are followed in practice. Firms should determine which is more profitable. We classify customers into two groups: lead time sensitive (LS) and price sensitive (PS). LS customers value lead time reduction more than PS customers. We develop mathematical models of both quotation modes and analyze them to determine the most profitable mode under specified situations as well as the best lead time and price quotations within each mode. We find that DQM is dominated by UQM whenever PS customers have positive utilities from UQM or LS customers have positive utilities from DQM. Otherwise, which quotation mode is better depends on multiple factors, such as customer characteristics (including lead time reduction valuation and product valuation of a customer, and the proportion of LS customers) and production characteristics (including the desired service level and service or production cost)."
1981,"Design of Flexible Multi-Stage Processes","Eynan, Amit and Dong, Lingxiu","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","194-203","2012","JAN-FEB","Flexible Resource;Flexible Capacity;Multi-Stage Process;Process Flexibility;Process Design","","Faced with demand uncertainty across multiple product lines, many companies have recourse to flexible capacities which can process different products in order to better balance the trade-off between capacity utilization and cost efficiency. Many studies demonstrated the potential benefit of using flexible capacity at the aggregate level by treating a whole plant or a whole process as a single stage. This paper extends these analyses by studying the benefits of flexible capacity while considering the multi-stage structure of processes and consequently determining which stages should be flexible, which should be dedicated, and how much capacity to assign to each stage. We consider a two-product firm which operates in a process-to-order environment and faces uncertain demand. Each stage of the process can be designed as dedicated or flexible. Dedicated resources are highly cost efficient but limited to the single product they are exclusively designed for, whereas flexible resources are versatile to handle several products but are more expensive. Using a general mathematical formulation our analysis shows that the optimal design may have some dedicated and some flexible stages along the process. Interestingly, this decision should be decoupled from the chronological order of the stages along the process."
1982,"Newsvendor Pricing Problem in a Two-Sided Market","Chou, Mabel C. and Sim, Chee Khian and Teo, Chung-Piaw and Zheng, Huan","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","204-208","2012","JAN-FEB","Two-Sided Market;Newsvendor Problem;Pricing Strategy","","We study the pricing problem of a platform intermediary to jointly determine the selling price of the platforms (hardware) sold to consumers and the royalty charged to content developers for content (software), when the demands for content and for platforms are interdependent. Our model elucidates the impact of supply chain replenishment costs and demand uncertainty on the strategic issues of platform pricing in a two-sided market."
1983,"Measuring Corporate Social Performance: An Efficiency Perspective","Chen, Chien-Ming and Delmas, Magali","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","789-804","2011","NOV-DEC","Corporate Social Performance;Kld;Efficiency;Data Envelopment Analysis","","Aggregation of corporate social performance (CSP) metrics poses a major challenge to researchers and practitioners. This study provides a critical evaluation of current aggregation approaches and proposes a new methodology based on data envelopment analysis (DEA) to compute a CSP index. DEA is independent of subjective weight specifications and provides an efficiency index to benchmark the CSP of firms. Using CSP data from 2190 firms in three major industries from the Kinder, Lydenberg, and Domini, Inc. database in 2007, our study presents the first application of the DEA model for CSP and ordinal data and opens up a new path for future empirical CSP research."
1984,"An Analysis of Monopolistic and Competitive Take-Back Schemes for WEEE Recycling","Toyasaki, Fuminori and Boyaci, Tamer and Verter, Vedat","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","805-823","2011","NOV-DEC","Weee;Take-Back Schemes;End-Of-Life Products;Recycling","","W e study two prevailing types of take-back schemes for electrical and electronic equipment waste recycling: monopolistic and competitive. We address key market and operating factors that make one scheme preferable to the other from the viewpoints of recyclers, manufacturers, and consumers. To this end, we model competitive decision making in both take-back schemes as two-stage sequential games between competing manufacturers and recyclers. Deriving and computing equilibria, we find that the competitive take-back scheme often accomplishes a win-win situation, that is, lower product prices, and higher recycler and manufacturer profits. Exceptionally, recyclers prefer the monopolistic scheme when the substitutability level between the manufacturers' original products is high or economies of scale in recycling are very strong. We show that consolidation of the recycling industry could benefit all stakeholders when the economies of scale in recycling are strong, provided that manufacturer's products are not highly substitutable. Higher collection rates also render recycler consolidation desirable for all stakeholders. We also identify a potential free rider problem in the monopolistic scheme when recyclers differ in operational efficiency, and propose mechanisms to eliminate the discrepancy. We show that our results and insights are robust to the degree of competition within the recycling industry."
1985,"Revenue and Cost Management for Remanufactured Products","Ovchinnikov, Anton","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","824-840","2011","NOV-DEC","Behavioral Operations;Environmental Sustainability;Remanufacturing;Demand Cannibalization;Revenue Management","","This paper considers pricing and remanufacturing strategy of a firm that decides to offer both new and remanufactured versions of its product in the market and is concerned with demand cannibalization. We present a model of demand cannibalization and a behavioral study that estimates a key modeling parameter: a fraction of consumers who switch from new to remanufactured product. As we show, this fraction has an inverted-U shape, and, thus, the underlying consumer behavior cannot be modeled using the standard methodologies that rely on consumers' willingness to pay (WTP). We find that by incorporating the inverted-U-shaped consumer behavior, the firm remanufactures under broader conditions, charges a much lower price, and typically remanufactures more units-leading to an increase of profits from remanufacturing by up to a factor of two as compared with making decisions based on the WTP only. Lastly, we find that the behavior of the low-price market segment plays an important role because the firm reacts to it differently than the WTP-based logic would suggest."
1986,"Cost Allocation in Manufacturing-Remanufacturing Operations","Toktay, L. Beril and Wei, Donna","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","841-847","2011","NOV-DEC","Cost Allocation;Transfer Prices;Remanufacturing;Closed-Loop Supply Chain;Sustainable Operations","","For firms remanufacturing their products, the total life-cycle costs and revenues from new and remanufactured products determine their profitability. In many firms, manufacturing/sales and remanufacturing/remarketing operations are carried out in different divisions. Each division is responsible for only part of the product's life cycle. Practices regarding transfer pricing across divisions vary significantly among companies, affecting the life-cycle profit performance of the product. In this research, we identify characteristics of transfer prices that achieve the firm-wide optimal solution. To this end, we consider a manufacturer who also undertakes remanufacturing operations and we focus on price (quantity) decisions. We determine that a cost allocation mechanism that allocates a portion of the initial production cost to each of the two stages of the product life cycle should be used. We also conclude that cost allocation should be implemented as a fixed cost allocation, where charges to the remanufacturing division should be determined independently of the actual quantity of units remanufactured."
1987,"The Impact of Variability and Patient Information on Health Care System Performance","Salzarulo, Peter A. and Bretthauer, Kurt M. and Cote, Murray J. and Schultz, Kenneth L.","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","848-859","2011","NOV-DEC","Health Care Operations;Service Operations Management;Appointment Scheduling","","In the delivery of health care services, variability in the patient arrival and service processes can cause excessive patient waiting times and poor utilization of facility resources. Based on data collected at a large primary care facility, this paper investigates how several sources of variability affect facility performance. These sources include ancillary tasks performed by the physician, patient punctuality, unscheduled visits to the facility's laboratory or X-ray services, momentary interruptions of a patient's examination, and examination time variation by patient class. Our results indicate that unscheduled visits to the facility's laboratory or X-ray services have the largest impact on a physician's idle time. The average patient wait is most affected by how the physician prioritizes completing ancillary tasks, such as telephone calls, relative to examining patients. We also investigate the improvement in system performance offered by using increasing levels of patient information when creating the appointment schedule. We find that the use of policies that sequence patients based on their classification improves system performance by up to 25.5%."
1988,"Linking Task Conditions to Physiology and Judgment Errors in RM Systems","Bendoly, Elliot","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","860-876","2011","NOV-DEC","Behavioral Operations;Experiment;Physiology;Motivation","","In models of optimal decision making, assumptions about managerial behavior are often made with the hope that the prescriptions offered by these models will be effective in practice, even if actual behavior occasionally strays from these assumptions. However, recent revenue management (RM) research has demonstrated what appear to be systematic deviations from normative models of decision making. These deviations can even be observed in relatively simple RM contexts. We suggest that technical errors in capacity allocation decisions are linked to issues such as arousal and stress associated with state conditions of RM tasks. Our study goes beyond existing findings by considering behavioral phenomena in concurrent task settings, where the decision maker is faced with managing decisions for more than one product or service. Physiological measures of eye dilation and blink rate are used as markers of arousal and stress in subjects engaged in RM tasks. Our analysis shows that physiological responses are indeed associated with both the state conditions of RM tasks and the number of capacity blocks managed concurrently by an individual. Deviations from modeled decision making appear to be significantly dependent upon these physiological responses. We conclude with a discussion of implications for further research and practice."
1989,"When Should a Firm Open its Source Code: A Strategic Analysis","Kort, Peter M. and Zaccour, Georges","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","877-888","2011","NOV-DEC","Open Source;Complementary Product;Competition;Software;Stage Game","","Deciding to open the source code of a software product has advantages and disadvantages. The disadvantage is that the firm loses the revenue from the software. The advantage is that the users' network can contribute to the quality of the software code, which increases the demand for the software and for a complementary product. Demand for the complementary product also goes up, because demand for a product increases when the price of its complement decreases, and under open source, the price of the software product drops down to zero. This paper examines the strategic interactions at work here, within a duopoly framework, and tries to determine the circumstances under which it is optimal for a firm to open its code. We find that firms open the source code when there is a competitive software-product market, a less competitive complementary-product market, and when the complementary product is of high quality. Furthermore, it is more profitable for the firm to open the source code if its competitor also does so. When this happens the incentive to open the code can even be higher than in a monopoly situation. More intense competition induces symmetric equilibria in which both firms choose the same strategy."
1990,"Optimal Enhancement and Lifetime of Software Systems: A Control Theoretic Analysis","Ji, Yonghua and Kumar, Subodha and Mookerjee, Vijay S. and Sethi, Suresh P. and Yeh, Denny","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","889-904","2011","NOV-DEC","Software Enhancement;Lifetime;Features;Replacement;Optimal Control Theory","","We develop an optimal control model to maximize the net value provided by a software system over its useful life. The model determines the initial number of features in the system, the level of dynamic enhancement effort, and the lifetime of the system. The various factors affecting these optimal choices are systems characteristics (e.g., complexity, age, quality), user learning, and process maturity. We also consider that there is a time lag between the addition of a feature and the realization of its benefit to users. The basic model is extended to consider the decision of replacing the existing system by a new one."
1991,"Impact of Demand Uncertainty on Stability of Supplier Alliances in Assembly Models","Sosic, Greys","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","905-920","2011","NOV-DEC","Assembly Models;Coalition Stability;Stochastic Demand","","In their recent paper, Nagarajan and Sosic study an assembly supply chain in which n suppliers sell complementary components to a downstream assembler, who faces a price-sensitive deterministic demand. Suppliers may form alliances, and each alliance then sells a kit of components to the assembler and determines the price for that kit. The assembler buys the components (kits) from the alliances and sets the selling price of the product. Nagarajan and Sosic consider three modes of competition-supplier Stackelberg, vertical Nash (VN), and assembler Stackelberg models-which correspond to different power structures in the market, and study stable supplier alliances when the assembler faces linear and isoelastic demand. In this paper, we study the impact that demand uncertainty has on stability results obtained in Nagarajan and Sosic. We first analyze models in which all decisions are made before the uncertainty is resolved, and show that the alliance of all suppliers remains stable when demand is isoelastic, or under Stackelberg models when demand is linear. However, demand uncertainty may change stability results when both parties make decisions simultaneously (VN model) and demand is linear. We then extend our results by considering scenarios in which some decisions may be postponed and made after the actual demand is known. When the ordering quantity can be determined after observing the true demand, we show that stable outcomes correspond to those obtained in the deterministic case and uncertainty has no impact on coalition stability; if only the assembler's pricing decision is postponed, we need additional conditions for stability results to carry over in the additive demand model."
1992,"The Newsvendor Problem and Price-Only Contract When Bankruptcy Costs Exist","Kouvelis, Panos and Zhao, Wenhui","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","921-936","2011","NOV-DEC","Newsvendor;Wholesale Price;Bankruptcy Risk;Bankruptcy Cost","","We study a supply chain of a supplier selling via a wholesale price contract to a financially constrained retailer who faces stochastic demand. The retailer might need to borrow money from a bank to execute his order. The bank offers a fairly priced loan for relevant risks. Failure of loan repayment leads to a costly bankruptcy (fixed administrative costs, costs proportional to sales, and a depressed collateral value). We identify the retailer's optimal order quantity as a function of the wholesale price and his total wealth (working capital and collateral). The analysis of the supplier's optimal wholesale price problem as a Stackelberg game, with the supplier the leader and the retailer the follower, leads to unique equilibrium solutions in wholesale price and order quantity, with the equilibrium order quantity smaller than the traditional newsvendor one. Furthermore, in the presence of the retailer's bankruptcy risks, increases in the retailer's wealth lead to increased supplier's wholesale prices, but without the retailer's bankruptcy risks the supplier's wholesale prices stay the same or decrease in retailer's wealth."
1993,"A Framework for Analysis of Production Authorization Card-Controlled Production Systems","MacDonald, Corinne and Gunn, Eldon A.","PRODUCTION AND OPERATIONS MANAGEMENT","20","6","937-948","2011","NOV-DEC","Production Control Systems;Simulation;Simulation Metamodeling;Neural Networks;Optimal Policy Curves","","A framework for the analysis of manufacturing systems operating under a production authorization card (PAC) system is outlined. The PAC system provides a single model, which encompasses a broad variety of control strategies, including Kanban and CONWIP. This paper describes a framework for the performance analysis and comparison of both specific and families of control strategies. The framework starts with system performance measures estimated by simulation. These simulations in turn provide training data for neural network metamodels. The metamodels allow for a variety of analysis and optimization approaches, including the construction of optimal policy curves, which can provide considerable insight into the systems under study."
1994,"The Manufacturer's Incentive to Reduce Lead Times","Kraiselburd, Santiago and Pibernik, Richard and Raman, Ananth","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","639-653","2011","SEP-OCT","Lead Time Reduction;Retailer Effort;Safety Stock Effect;Effort Effect;Manufacturer'S Sales To Retailer","","Although, ceteris paribus, reducing lead times may be desirable from an overall system perspective, an upstream party (e.g., a manufacturer) may have strong disincentives to offer shorter lead times, even if this came at no cost. We consider a setting in which the downstream party has the ability to exert a costly effort to increase demand (e.g., through sales promotions, advertising, etc.) during the selling season, and compare two situations: one where there is zero lead time (i.e., all demand can be satisfied after observing the demand realization), and one where orders need to be made before demand is realized. We identify two interacting effects that may inhibit shorter lead times. A so-called safety stock effect can be observed when a lower risk of stocking out under short lead times induces the downstream party to alter her order quantity. A second effect, termed as effort effect, arises if shorter lead times impact the downstream party's optimal sales effort, and, as a consequence, lead to different order quantities. We provide a formal characterization of both effects, insight into how these effects interact, and show under which conditions the manufacturer has an incentive to offer shorter lead times."
1995,"Real-Time Delay Estimation Based on Delay History in Many-Server Service Systems with Time-Varying Arrivals","Ibrahim, Rouba and Whitt, Ward","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","654-667","2011","SEP-OCT","Delay Estimation;Delay Announcements;Time-Varying Arrival Rates;Simulation","","Motivated by interest in making delay announcements in service systems, we study real-time delay estimators in many-server service systems, both with and without customer abandonment. Our main contribution here is to consider the realistic feature of time-varying arrival rates. We focus especially on delay estimators exploiting recent customer delay history. We show that time-varying arrival rates can introduce significant estimation bias in delay-history-based delay estimators when the system experiences alternating periods of overload and underload. We then introduce refined delay-history estimators that effectively cope with time-varying arrival rates together with non-exponential service-time and abandonment-time distributions, which are often observed in practice. We use computer simulation to verify that our proposed estimators outperform several natural alternatives."
1996,"Competitive Pricing in a Multi-Product Multi-Attribute Environment","Kachani, Soulaymane and Shmatov, Kyrylo","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","668-680","2011","SEP-OCT","Dynamic Pricing;Revenue Management","","We address the problem of simultaneous pricing of a line of several products, both complementary products and substitutes, with a number of distinct price differentiation classes for each product (e.g., volume discounts, different distribution channels, and customer segments) in both monopolistic and oligopolistic settings. We provide a generic framework to tackle this problem, consider several families of demand models, and focus on a real-world case-study example. We propose an iterative relaxation algorithm, and state sufficient conditions for convergence of the algorithm. Using historical sales and price data from a retailer, we apply our solution algorithm to suggest optimal pricing, and report on numerical results."
1997,"Optimizing Customer Forecasts for Forecast-Commitment Contracts","Durango-Cohen, Elizabeth J. and Yano, Candace A.","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","681-698","2011","SEP-OCT","Supply Contracts;Purchase Commitment;Supply Chain Coordination;Quantity Flexibility;Strategic Customers","","We study a Forecast-Commitment contract motivated by a manufacturer's desire to provide good service in the form of delivery commitments in exchange for reasonable forecasts and a purchase commitment from the customer. The customer provides a forecast for a future order and a guarantee to purchase a portion of it. In return, the supplier commits to satisfy some or all of the forecast. The supplier pays penalties for shortfalls of the commitment quantity from the forecast, and for shortfalls of the delivered quantity from the customer's final order (not exceeding the commitment quantity). These penalties allow differential service among customers. In Durango-Cohen and Yano (2006), we analyzed the supplier's problem for a given customer forecast. In this paper, we analyze the customer's problem under symmetric information, both when the customer is honest and when he strategically orders more than his demand when doing so is advantageous. We show that the customer gains little from lying, so the supplier can use his control over the contract parameters to encourage honesty. When the customer is honest, the contract achieves (near-)coordination of the supply chain in a great majority of instances, and thus provides both excellent performance and flexibility in structuring contracts."
1998,"An Efficient and Robust Design for Transshipment Networks","Lien, Robert W. and Iravani, Seyed M. R. and Smilowitz, Karen and Tzur, Michal","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","699-713","2011","SEP-OCT","Inventory Transshipment;Network Design;Inventory Pooling;Supply Chain Design;Retail Collaboration","","Transshipment, the sharing of inventory among parties at the same echelon level of a supply chain, can be used to reduce costs. The effectiveness of transshipment is in part determined by the configuration of the transshipment network. We introduce chain configurations in transshipment settings, where every party is linked in one connected loop. Under simplifying assumptions we show analytically that the chain configuration is superior to configurations suggested in the literature. In addition, we demonstrate the efficiency and robustness of chain configurations for more general scenarios and provide managerial insights regarding preferred configurations for different problem parameters."
1999,"Optimal Control of Replenishment and Substitution in an Inventory System with Nonstationary Batch Demand","Xu, He and Yao, David D. and Zheng, Shaohui","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","727-736","2011","SEP-OCT","Inventory Control;Production Substitution;Revenue Maximization;Concavity","","We study an inventory system in which a supplier supplies demand using two mutually substitutable products over a selling season of T periods, with a single replenishment opportunity at the beginning of the season. As the season starts, customer orders arrive in each period, for either type of products, following a nonstationary Poisson process with random batch sizes. The substitution model we consider combines the usual supplier-driven and customer-driven schemes, in that the supplier may choose to offer substitution, at a discount price, or may choose not to; whereas the customer may or may not accept the substitution when it is offered. The supplier's decisions are the supply and substitution rules in each period throughout the season, and the replenishment quantities for both products at the beginning of the season. With a stochastic dynamic programming formulation, we first prove the concavity of the value function, which facilitates the solution to the optimal replenishment quantities. We then show that the optimal substitution follows a threshold rule, and establish the monotonicity of the thresholds over time and with respect to key cost parameters. We also propose a heuristic exhaustive policy, and illustrate its performance through numerical examples."
2000,"Pool-Point Distribution of Zero-Inventory Products","Geismar, H. Neil and Dawande, Milind and Sriskandarajah, Chelliah","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","737-753","2011","SEP-OCT","Zero Inventory Systems;Pool-Point Delivery;Scheduling Of Production And Distribution Operations","","We study zero-inventory production-distribution systems under pool-point delivery. The zero-inventory production and distribution paradigm is supported in a variety of industries in which a product cannot be inventoried because of its short shelf life. The advantages of pool-point (or hub-and-spoke) distribution, explored extensively in the literature, include the efficient use of transportation resources and effective day-to-day management of operations. The setting of our analysis is as follows: A production facility (plant) with a finite production rate distributes its single product, which cannot be inventoried, to several pool points. Each pool point may require multiple truckloads to satisfy its customers' demand. A third-party logistics provider then transports the product to individual customers surrounding each pool point. The production rate can be increased up to a certain limit by incurring additional cost. The delivery of the product is done by identical trucks, each having limited capacity and non-negligible traveling time between the plant and the pool points. Our objective is to coordinate the production and transportation operations so that the total cost of production and distribution is minimized, while respecting the product lifetime and the delivery capacity constraints. This study attempts to develop intuition into zero-inventory production-distribution systems under pool-point delivery by considering several variants of the above setting. These include multiple trucks, a modifiable production rate, and alternative objectives. Using a combination of theoretical analysis and computational experiments, we gain insights into optimizing the total cost of a production-delivery plan by understanding the trade-off between production and transportation."
2001,"A Bayesian Inventory Model Using Real-Time Condition Monitoring Information","Li, Rong and Ryan, Jennifer K.","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","754-771","2011","SEP-OCT","Spare Parts;Inventory Management;Real-Time Information;Stochastic Models;Wiener Process","","Lack of coordination between machinery fault diagnosis and inventory management for spare parts can lead to increased inventory costs and disruptions in production activity. We develop a framework for incorporating real-time condition monitoring information into inventory decisions for spare parts. We consider a manufacturer who periodically replenishes inventory for a machine part that is subject to deterioration. The deterioration is captured via condition monitoring and modeled using a Wiener process. The resulting degradation model is used to derive the life distribution of a functioning part and to estimate the demand distribution for spare parts. This estimation is periodically updated, in a Bayesian manner, as additional information on part deterioration is obtained. We develop an inventory model that incorporates this updated demand distribution and demonstrate that a dynamic base-stock policy, in which the optimal base-stock level is a function of some subset of the observed condition monitoring information, is optimal. We propose a myopic critical fractile policy that captures the essence of the optimal policy, but is easier to compute. Computational experiments indicate that this heuristic performs quite well relative to the optimal policy. Adaptive inventory policies such as these can help manufacturers to increase machine availability and reduce inventory costs."
2002,"Facility Location: A Robust Optimization Approach","Baron, Opher and Milner, Joseph and Naseraldin, Hussein","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","772-785","2011","SEP-OCT","Facility Location;Robust Optimization;Uncertainty;Robust Counterpart","","In this research, we apply robust optimization (RO) to the problem of locating facilities in a network facing uncertain demand over multiple periods. We consider a multi-period fixed-charge network location problem for which we find (1) the number of facilities, their location and capacities, (2) the production in each period, and (3) allocation of demand to facilities. Using the RO approach we formulate the problem to include alternate levels of uncertainty over the periods. We consider two models of demand uncertainty: demand within a bounded and symmetric multi-dimensional box, and demand within a multi-dimensional ellipsoid. We evaluate the potential benefits of applying the RO approach in our setting using an extensive numerical study. We show that the alternate models of uncertainty lead to very different solution network topologies, with the model with box uncertainty set opening fewer, larger facilities. Through sample path testing, we show that both the box and ellipsoidal uncertainty cases can provide small but significant improvements over the solution to the problem when demand is deterministic and set at its nominal value. For changes in several environmental parameters, we explore the effects on the solution performance."
2003,"Shelf Space Management When Demand Depends on the Inventory Level","Baron, Opher and Berman, Oded and Perry, David","PRODUCTION AND OPERATIONS MANAGEMENT","20","5","714-726","2011","SEP-OCT","Shelf Space Allocation;Inventory Control;Observed Inventory Level;Demand Dependencies;Level Crossing Theory","","Two factors that their influence on the demand has been investigated in many papers are (i) the shelf space allocated to a product and to its complement or supplement products and (ii) the instantaneous inventory level seen by customers. Here we analyze the joint shelf space allocation and inventory decisions for multiple items with demand that depends on both factors. The traditional approach to solve inventory models with a state-dependent demand rate uses a time domain approach. However, this approach often does not lead to closed-form expressions for the profit rate with both dependencies. We analyze the problem in the inventory domain via level crossing theory. This approach leads to closed-form expressions for a large set of demand rate functions exhibiting both dependencies. These closed-form expressions substantially simplify the search for optimal solutions; thus we use them to solve the joint inventory control and shelf space allocation problem. We consider examples with two products to investigate the significance of capturing both demand dependencies. We show that in some settings it is important to capture both dependencies. We consider two heuristics, each one of them ignores one of the two dependencies. Using these heuristics it seems that ignoring the dependency on the shelf space might be less harmful than ignoring the dependency on the inventory level, which, based on computational results, can lead to profit losses of more than 6%. We demonstrate that retailers should use their operational control, e.g., reorder point, to promote higher demand products."
2004,"Reducing Customer Dissatisfaction: How Important is Learning to Reduce Service Failure?","Lapre, Michael A.","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","491-507","2011","JUL-AUG","Customer Dissatisfaction;Learning Curve;Organizational Learning;Marketing;Service Failure","","As service failures are inevitable, firms must be prepared to recover and learn from service failures. Yet, the majority of customers are still dissatisfied with the way firms resolve their complaints. Can learning to reduce service failures reduce customer dissatisfaction, and to what extent are such reductions sustainable? Previous research showed that organizational learning curves for customer dissatisfaction (i) follow a U-shaped function of operating experience and (ii) are heterogeneous across firms. In this paper, I tease out where the U-shaped learning-curve effect and learning-curve heterogeneity originate: service failure or customers' propensity to complain with a third party given the occurrence of a service failure. Using quarterly data for nine major US airlines over 11 years, I find that the U-shaped learning-curve effect and the learning-curve heterogeneity originate in the propensity to complain. In the long term, reductions in service failure did not translate in sustainable reductions in customer dissatisfaction. Customers' propensity to complain eventually went up. Managing the propensity to complain provides more opportunity for a firm to distinguish itself from competitors."
2005,"Managing Outsourced Software Projects: An Analysis of Project Performance and Customer Satisfaction","Narayanan, Sriram and Balasubramanian, Sridhar and Swaminathan, Jayashankar M.","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","508-521","2011","JUL-AUG","Outsourcing;Software Projects;Project Planning;Customer Satisfaction;Operations Management","","We examine the drivers of project performance and customer satisfaction in outsourced software projects using a proprietary panel dataset. The data cover 822 customer observations related to 182 unique projects executed by an India-based software services vendor. Adopting a multidisciplinary perspective, we investigate how project planning, team stability, and communication effectiveness impact project performance and customer satisfaction. We delineate the direct and interactive influences of the antecedent variables. We also examine how these influences are moderated by two important project contexts: (a) the nature of software work (maintenance and development vs. testing projects) and (b) project maturity (new vs. mature projects). Among other results, we demonstrate that, when project planning capabilities are high, the positive impact of team stability and communication effectiveness on project performance is even higher. In addition, our results suggest that the impact of communication on project performance is muted when team stability is high. Finally, we also demonstrate that the impact of the antecedent variables on project performance varies with the nature of software work. Our findings offer specific and actionable insights to managers that can help them manage outsourced projects better, and open up new research perspectives in the context of outsourced project management."
2006,"Regulatory Trade Risk and Supply Chain Strategy","Wang, Yimin and Gilland, Wendell and Tomlin, Brian","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","522-540","2011","JUL-AUG","Regulatory Trade Risk;Non-Tariff Barrier;Dual Sourcing;Supply Chain","","Trade regulations are an important driver of supply chain strategy in many industries. For example, the textile, paper, chemical, and steel industries grapple with significant levels of non-tariff barriers (NTBs) such as safeguard controls and countervailing duties. We explore three often observed supply chain strategies in industries subject to NTBs; direct procurement, split procurement, and outward processing arrangements (OPAs). We characterize the optimal procurement quantities for each of these three strategies, and examine how industry and country characteristics influence the firm's strategy preference. For example, we establish that the direct and split strategy profits increase in the NTB price variance but decrease in the mean price. These effects are sufficiently large that NTB price characteristics can dictate which supply chain strategy is preferred. Both the cost disadvantage and lead-time advantage of domestic production are also significant influencers of the preferred strategy, as is the domestic-country mandated production constraint associated with the OPA strategy."
2007,"Managing Technology Selection and Development Risk in Competitive Environments","Bhaskaran, Sreekumar R. and Ramachandran, Karthik","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","541-555","2011","JUL-AUG","Development Uncertainty;Innovative Capacity;Competition;Introduction Timing","","Managing development decisions for new products based on dynamically evolving technologies is a complex task, especially in highly competitive industries. Product managers often have to choose between introducing an incrementally better, safe new product early and a superior, yet highly risky, product later. Recommendations for managing such performance vs. time-to-market trade-offs often ignore competitive reactions to development decisions. In this paper, we study how a firm could incorporate the presence of a strategic competitor in making technology selection and investment decisions regarding new products. We consider a model in which an innovating firm and its rival can introduce a new product immediately or pursue a more advanced product for later launch. Further, the firm can reduce the uncertainty surrounding product development by dedicating more resources; the effectiveness of this investment depends on the firm's innovative capacity. Our model generates two sets of insights. First, in highly competitive industries, firms can adopt different technologies and effectively use introduction timing to mitigate the effects of price competition. More importantly, the firm could strategically invest in the advanced product to influence its rival's technology choice. We characterize equilibrium development and investment decisions of the firms, and derive innovative capacity hurdles that govern a firm's choice between the risky and safe alternatives. The effects of development flexibility-where firms might have the option to revert to the safe product if the advanced product fails-are also considered."
2008,"The Roles of Worker Expertise, Information Sharing Quality, and Psychological Safety in Manufacturing Process Innovation: An Intellectual Capital Perspective","Lee, Jung Young and Swink, Morgan and Pandejpong, Temyos","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","556-570","2011","JUL-AUG","Manufacturing Process Innovation;Project Management;Intellectual Capital;Worker Expertise;Psychological Safety","","This paper examines the roles of three elements of intellectual capital in implementing process innovations. Building upon prior literature, we develop a model describing how worker expertise, information sharing quality, and psychological safety work together as elements of the human, structural, and social dimensions of intellectual capital to influence the technical success of manufacturing process innovation (MPI) projects. Results of an analysis of data describing 179 MPI projects in US firms strongly support a multidimensional, process-oriented view of intellectual capital's effects on MPI project technical performance. We also find that the incrementalness of an MPI project plays a moderating role over the relationship between worker expertise and MPI performance. Our study provides insights on how intellectual capital can be more effectively accumulated in a project environment."
2009,"Threshold Incentives and Sales Variance","Sohoni, Milind G. and Chopra, Sunil and Mohan, Usha and Sendil, Nuri","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","571-586","2011","JUL-AUG","Threshold Incentives;Service And Supply Chain Operations;Sales Variance","","In this paper, we analyze the impact of two forms of commonly used threshold-based incentive schemes on the observed sales variability. The first form of the incentive comprises an additional marginal payment on crossing a specified sales threshold and the second form of the incentive scheme comprises a lumpsum bonus payment on crossing the predetermined sales threshold. We model the effect of such incentives under two specific scenarios: an exclusive dealership selling a single product and a non-exclusive dealer selling two competing products. For an exclusive dealer, we show that a bonus contract not only increases the expected sales, but, more importantly, decreases the sales (order) variance. Consequently, the bonus-based scheme allows the manufacturer to regulate sales variance better. With a non-exclusive dealer, the sales variance increases substantially with an additional marginal payment contract. However, our analysis suggests that the bonus contract continues to perform better in this case, too, if the threshold level is set appropriately using the underlying demand distribution."
2010,"Joint Mail-In Rebate Decisions in Supply Chains Under Demand Uncertainty","Geng, Qin and Mallik, Suman","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","587-602","2011","JUL-AUG","Supply Chain Management;Mail-In Rebate;Marketing-Operations Interface;Newsvendor Model;Retailing","","We study the joint decisions of offering mail-in rebates (MIRs) in a single-manufacturer-single-retailer supply chain using a game theoretic framework. Either party can offer an MIR to the end consumer if it is in his best interest. The consumer demand is stochastic and depends on the product price and the amount of MIRs. When the retail price is exogenous, we show the existence of a unique Nash equilibrium under both additive and multiplicative demand functions and characterize it completely. We show that any of the following four scenarios can be the equilibrium: both parties offer MIR, only one party offers MIR, none offers MIR. When the retail price is a decision variable for the retailer and the rebate redemption rate increases with the amount of MIR, we once again prove the existence of a unique Nash equilibrium where both the retailer and the manufacturer offer MIRs. Using a numerical study, we show that the average post-purchase price of the product is higher not only than the perceived pre-purchase price but also than the newsvendor optimal price without an MIR. This implies that an MIR makes a product look cheaper while the consumers actually pay more on average."
2011,"The Effect of Liability and Patch Release on Software Security: The Monopoly Case","Kim, Byung Cho and Chen, Pei-Yu and Mukhopadhyay, Tridas","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","603-617","2011","JUL-AUG","Software Security;Liability;Patch Release;Security Awareness;Monopoly","","An abundance of flawed software has been identified as the main cause of the poor security of computer networks because major viruses and worms exploit the vulnerabilities of such software. As an incentive mechanism for software security quality improvement, software liability has been intensely discussed among both academics and practitioners for a long time. An alternative approach to managing software security is patch release, which has been widely adopted in practice. In this paper, we examine these two different ways of mitigating customer risk in the software market: liability and patch release. We study the impact of both mechanisms on a monopolistic software vendor's decision on security quality. We find the conditions under which each mechanism is effective in terms of improving security quality and increasing social surplus. The heterogeneous nature of loss is identified to be a key factor for the effectiveness of the liability mechanism. On the other hand, patch release can be effective and welfare-enhancing regardless of the nature of loss as long as customers incur low patching cost, and/or the vendor incurs low patch development cost. We also examine the impact of customer misperception of the outcome from vulnerable software on the effectiveness of liability."
2012,"Distribution Planning to Optimize Profits in the Motion Picture Industry","Somlo, Barbara and Rajaram, Kumar and Ahmadi, Reza","PRODUCTION AND OPERATIONS MANAGEMENT","20","4","618-636","2011","JUL-AUG","Motion Picture Industry;Forecasting;Distribution Planning;Theater Selection;Optimization","","We consider the distribution planning problem in the motion picture industry. This problem involves forecasting theater-level box office revenues for a given movie and using these forecasts to choose the best locations to screen a movie. We first develop a method that predicts theater-level box office revenues over time for a given movie as a function of movie attributes and theater characteristics. These estimates are then used by the distributor to choose where to screen the movie. The distributor's location selection problem is modeled as an integer programming-based optimization model that chooses the location of theaters in order to optimize profits. We tested our methods on realistic box office data and show that it has the potential to significantly improve the distributor's profits. We also develop some insights into why our methods outperform existing practice, which are crucial to their successful practical implementation."
2013,"An Empirical Study of the Relations Between Hospital Volume, Teaching Status, and Service Quality","Theokary, Carol and Ren, Zhong Justin","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","303-318","2011","MAY-JUN","Volume;Teaching Status;Process Quality;Healthcare Operations","","This paper contributes to research on quality drivers in healthcare settings by examining the relationships between patient volume, teaching mission, and process quality in US hospitals. To develop a model that accurately assesses the impact of patient volume and teaching status on quality, we draw on three related research streams pertaining to the volume-quality relationship, the comparative quality of care in teaching and non-teaching hospitals, and quality drivers in service institutions. We propose the impact of patient volume on process quality varies across hospitals with different teaching intensities. The test of this proposition uses a large data set that measures process quality for treatments for heart attacks and heart failures in all major US hospitals. Our results suggest that, as hospital teaching intensity increases, greater patient volume is associated with decreased process quality. Never before was such a relationship uncovered. This initial finding has important practical implications. First, the regionalization policy of hospitals should be re-evaluated in light of their teaching function. Second, the root causes for the lower quality scores of large, high resident-to-bed ratio teaching hospitals, compared with smaller versions, must be found."
2014,"Performance Effects Related to the Sequence of Integration of Healthcare Technologies","Angst, Corey M. and Devaraj, Sarv and Queenan, Carrie C. and Greenwood, Brad","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","319-333","2011","MAY-JUN","Sequence;Healthcare Technology;Interoperability;Technology Integration;Healthcare Performance","","There is a natural order to most events in life: Everything from learning to read to DNA sequences in molecular biology follows some predetermined, structured methodology that has been refined to yield improved results. Likewise, it would seem that firms could benefit by adopting and implementing technologies in some logical way so as to increase their overall performance. In this study of 555 hospitals, we investigate the order in which medical technologies are transformed into information technologies through a process of converting them from stand-alone technologies to interoperable, integrated information systems and whether certain configurations of sequences of integration yield additional value. We find that sequence does matter and that hospitals that integrated foundational technologies first-which in this case are known to be more complex-tend to perform better. Theoretical and practical implications of this finding and others are discussed."
2015,"Access to Long-Term Care: The True Cause of Hospital Congestion?","Patrick, Jonathan","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","347-358","2011","MAY-JUN","Health Care;Long-Term Care;Markov Decision Processes;Scheduling;Simulation Health Care","","Much attention has been paid to lengthy wait times in emergency departments (EDs) and much research has sought to improve ED performance. However, ED congestion is often caused by the inability to move patients into the wards while the wards in turn are often congested primarily due to patients waiting for a bed in a long-term care (LTC) facility. The scheduling of clients to LTC is a complex problem that is compounded by the variety of LTC beds (different facilities and room accommodations), the presence of client choice and the competing demands of the hospital and community populations. We present a Markov decision process (MDP) model that determines the required access in order for the census of patients waiting for LTC in the hospitals to remain below a given threshold. We further present a simulation model that incorporates both hospital and community demand for LTC in order to predict the impact of implementing the policy derived from the MDP on the community client wait times and to aid in capacity planning for the future. We test the MDP policy vs. current practice as well as against a number of other proposed policy changes."
2016,"Design and Analysis of Hospital Admission Control for Operational Effectiveness","Helm, Jonathan E. and AhmadBeygi, Shervin and Van Oyen, Mark P.","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","359-374","2011","MAY-JUN","Health Care Operations;Patient Flow Modeling;Markov Decision Processes;Admission Control","","Variability in hospital occupancy negatively impacts the cost and quality of patient care delivery through increased emergency department (ED) congestion, emergency blockages and diversions, elective cancelations, backlogs in ancillary services, overstaffing, and understaffing. Controlling inpatient admissions can effectively reduce variability in hospital occupancy to mitigate these problems. Currently there are two major gateways for admission to a hospital: the ED and scheduled elective admission. Unfortunately, in highly utilized hospitals, excessive wait times make the scheduled gateway undesirable or infeasible for a subset of patients and doctors. As a result, this group often uses the ED gateway as a means to gain admission to the hospital. To better serve these patients and improve overall hospital functioning, we propose creating a third gateway: an expedited patient care queue. We first characterize an optimal admission threshold policy using controls on the scheduled and expedited gateways for a new Markov decision process model. We then present a practical policy based on insight from the analytical model that yields reduced emergency blockages, cancelations, and off-unit census via simulation based on historical hospital data."
2017,"Blocking in Healthcare Operations: A New Heuristic and an Application","Bretthauer, Kurt M. and Heese, H. Sebastian and Pun, Hubert and Coe, Edwin","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","375-391","2011","MAY-JUN","Queuing Networks;Blocking;Healthcare;Capacity Allocation","","We consider the problem of optimal capacity allocation in a hospital setting, where patients pass through a set of units, for example intensive care and acute care (AC), or AC and post-acute care. If the second stage is full, a patient whose service at the first stage is complete is blocked and cannot leave the first stage. We develop a new heuristic for tandem systems to efficiently evaluate the effects of such blocking on system performance and we demonstrate that this heuristic performs well when compared with exact solutions and other approaches presented in the literature. In addition, we show how our tandem heuristic can be used as a building block to model more complex multi-stage hospital systems with arbitrary patient routing, and we derive insights and actionable capacity strategies for a real hospital system where such blocking occurs between units."
2018,"The Surgical Scheduling Problem: Current Research and Future Opportunities","May, Jerrold H. and Spangler, William E. and Strum, David P. and Vargas, Luis G.","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","392-405","2011","MAY-JUN","Surgical Scheduling;Resource Planning","","This paper reviews the general problem of surgical scheduling. We organize the literature based on the time frame or planning horizon of the schedule into six categories: capacity planning, process reengineering/redesign, the surgical services portfolio, procedure duration estimation, schedule construction, and schedule execution, monitoring, and control. We survey past work and suggest topics for potential future research in each of those areas."
2019,"Bi-Criteria Scheduling of Surgical Services for an Outpatient Procedure Center","Gul, Serhat and Denton, Brian T. and Fowler, John W. and Huschka, Todd","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","406-417","2011","MAY-JUN","Operating Room;Outpatient Procedure;Scheduling;Simulation;Genetic Algorithm","","Uncertainty in the duration of surgical procedures can cause long patient wait times, poor utilization of resources, and high overtime costs. We compare several heuristics for scheduling an Outpatient Procedure Center. First, a discrete event simulation model is used to evaluate how 12 different sequencing and patient appointment time-setting heuristics perform with respect to the competing criteria of expected patient waiting time and expected surgical suite overtime for a single day compared with current practice. Second, a bi-criteria genetic algorithm (GA) is used to determine if better solutions can be obtained for this single day scheduling problem. Third, we investigate the efficacy of the bi-criteria GA when surgeries are allowed to be moved to other days. We present numerical experiments based on real data from a large health care provider. Our analysis provides insight into the best scheduling heuristics, and the trade-off between patient and health care provider-based criteria. Finally, we summarize several important managerial insights based on our findings."
2020,"Reducing Surgical Ward Congestion Through Improved Surgical Scheduling and Uncapacitated Simulation","Chow, Vincent S. and Puterman, Martin L. and Salehirad, Neda and Huang, Wenhai and Atkins, Derek","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","418-430","2011","MAY-JUN","Surgical Scheduling;Mixed Integer Programming;Monte Carlo Simulation;Scheduling Guidelines;Hospital Bed Management","","High surgical bed occupancy levels often result in heightened staff stress, frequent surgical cancellations, and long surgical wait times. This congestion is in part attributable to surgical scheduling practices, which often focus on the efficient use of operating rooms but ignore resulting downstream bed utilization. This paper describes a transparent and portable approach to improve scheduling practices, which combines a Monte Carlo simulation model and a mixed integer programming (MIP) model. For a specified surgical schedule, the simulation samples from historical case records and predicts bed requirements assuming no resource constraints. The MIP model complements the simulation model by scheduling both surgeon blocks and patient types to reduce peak bed occupancies. Scheduling guidelines were developed from the optimized schedules to provide surgical planners with a simple and implementable alternative to the MIP model. This approach has been tested and delivered to planners in a health authority in British Columbia, Canada. The models have been used to propose new surgical schedules and to evaluate the impact of proposed system changes on ward congestion."
2021,"Reducing Boarding in a Post-Anesthesia Care Unit","Price, Carter and Golden, Bruce and Harrington, Michael and Konewko, Ramon and Wasil, Edward and Herring, William","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","431-441","2011","MAY-JUN","Scheduling;Integer Programming;Simulation","","When operating room schedules in hospitals are produced, the constraints and preferences of surgeons and hospital workers are a primary consideration. The downstream impact on post-operative bed availability is often ignored. This can lead to the boarding of patients overnight in the post-anesthesia care unit (PACU) because intensive care unit beds are unavailable. In this paper, we apply integer programming and simulation to develop improved surgical scheduling assignments. We want to balance new surgeries with hospital discharges in order to reduce the variability of occupied beds from one day to the next and, as a result, to reduce boarding in the PACU."
2022,"The Effect of Integrated Scheduling and Capacity Policies on Clinical Efficiency","White, Denise L. and Froehle, Craig M. and Klassen, Kenneth J.","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","442-455","2011","MAY-JUN","Healthcare;Patient Flow;Outpatient;Simulation","","In outpatient healthcare clinics, capacity, patient flow, and scheduling are rarely managed in an integrated fashion, so a question of interest is whether clinic performance can be improved if the policies that guide these decisions are set jointly. Despite the potential importance of this issue, we find surprisingly few studies that look at how the allocation of capacity, paired with various appointment scheduling policies and different patient flow configurations, affects patient flow and clinical efficiency. In this paper, we develop an empirically based discrete-event simulation to examine the interactions between patient appointment policies and capacity allocation policies (i.e., the number of available examination rooms) and how they jointly affect various performance measures, such as resource utilization and patient waiting time. Findings suggest that scheduling lower-variance, shorter appointments earlier in the clinic (and, conversely, higher-variance, longer appointments later) results in less overall patient waiting without reducing physician utilization or increasing clinic duration. Additionally, exam rooms exhibited classic bottleneck behavior: there was no effect on physician utilization by adding exam rooms beyond a certain threshold, but too few exam rooms were devastating to clinic throughput. Some significant interactions between these variables were observed, but were not influential to the level of managerial concern. Clinicians' intuition about managing capacity in healthcare settings may differ substantially from best policies."
2023,"Reserving Capacity for Urgent Patients in Primary Care","Dobson, Gregory and Hasija, Sameer and Pinker, Edieal J.","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","456-473","2011","MAY-JUN","Advanced-Access;Primary Care;Appointment Scheduling;Urgent Patients","","This paper examines the effect of the common practice of reserving slots for urgent patients in a primary health care practice on two service quality measures: the average number of urgent patients that are not handled during normal hours (either handled as overtime, referred to other physicians, or referred to the emergency room) and the average queue of non-urgent or routine patients. We formulate a stochastic model of appointment scheduling in a primary care practice. We conduct numerical experiments to optimize the performance of this system accounting for revenue and these two service quality measures as a function of the number of reserved slots for urgent patients. We compare traditional methods with the advanced-access system advocated by some physicians, in which urgent slots are not reserved, and evaluate the conditions under which alternative appointment scheduling mechanisms are optimal. Finally, we demonstrate the importance of patient arrival dynamics to their relative performance finding that encouraging routine patients to call for same-day appointments is a key ingredient for the success of advanced-access."
2024,"An Analytical Framework for Designing Community-Based Care for Chronic Diseases","Kucukyazici, Beste and Verter, Vedat and Mayo, Nancy E.","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","474-488","2011","MAY-JUN","Chronic Diseases;Community-Based Care;Markov Models;Patient Flow;Stroke","","In this study, we propose a methodological framework to provide a road map to clinicians and system planners in developing chronic disease management strategies, and designing community-based care. We extend the analytical epidemiologic model by utilizing a patient flow approach, in order to model the multiple care-provider visit patterns of patients with a specific chronic illness. The patterns of care received by a group of patients are represented in compact form by means of a Markov model that is based on a disease-specific state space. Our framework also reflects the case-mix biases as well as the care-provider level clustering of the patients. By using this approach, we identify the patterns of care, determine the care provider and patient characteristics associated with optimal management of care, and estimate the potential influence of various interventions. The framework is applied to the data of 4000+ stroke patients discharged from the acute care hospitals of Quebec to their homes. Our findings provide a basis for designing community-based care initiatives for stroke survivors in the province."
2025,"Optimal Design of a Pharmaceutical Price-Volume Agreement Under Asymmetric Information About Expected Market Size","Zhang, Hui and Zaric, Gregory S. and Huang, Tao","PRODUCTION AND OPERATIONS MANAGEMENT","20","3","334-346","2011","MAY-JUN","Price-Volume Agreement;Risk Sharing;Pharmaceutical Industry;Health Insurance","","Price-volume agreements are commonly negotiated between drug manufacturers and third-party payers for drugs. In one form a drug manufacturer pays a rebate to the payer on a portion of sales in excess of a specified threshold. We examine the optimal design of such an agreement under complete and asymmetric information about demand. We consider two types of uncertainty: information asymmetry, defined as the payer's uncertainty about mean demand; and market uncertainty, defined as both parties' uncertainty about true demand. We investigate the optimal contract design in the presence of asymmetric information. We find that an incentive compatible contract always exists; that the optimal price is decreasing in expected market size, while the rebate may be increasing or decreasing in expected market size; that the optimal contract for a manufacturer with the highest possible demand would include no rebate; and, in a special case, if the average reservation profit is non-decreasing in expected market size, then the optimal contract includes no rebates for all manufacturers. Our analysis suggests that price-volume agreements with a rebate rate of 100% are not likely to be optimal if payers have the ability to negotiate prices as part of the agreement."
2026,"Outsourcing Manufacturing: Secure Price-Masking Mechanisms for Purchasing Component Parts","Deshpande, Vinayak and Schwarz, Leroy B. and Atallah, Mikhail J. and Blanton, Marina and Frikken, Keith B.","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","165-180","2011","MAR-APR","Supply Chain;Outsourcing;Procurement;Price Masking","","This paper develops and tests a privacy-preserving business process that supports the selection of a contract manufacturer by an original equipment manufacturer (OEM), and the determination of whether the OEM or the chosen contract manufacturer will procure each of the components to be used in the manufacture of the OEM's branded product. Our secure price-masking (SPM) technology contributes to procurement theory and practice in four significant ways: First, it preserves the privacy of every party's individual component prices. Second, SPM assures that the contract manufacturers will bid their own private purchase cost (i.e., not add a margin to their cost). Third, SPM is not invertible; i.e., none of the participants can solve for the private inputs of any other participant based on its own inputs and the outputs provided to it by SPM. Fourth, the posterior distribution of any other participant's private inputs is practically indistinguishable from its prior distribution. We also describe the results of a proof-of-concept implementation."
2027,"Group Buying of Competing Retailers","Chen, Rachel R. and Roma, Paolo","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","181-197","2011","MAR-APR","Group Buying;Competition;Distribution Channel;Quantity Discounts;Retailing","","Under group buying, quantity discounts are offered based on the buyers' aggregated purchasing quantity, instead of individual quantities. As the price decreases with the total quantity, buyers receive lower prices than they otherwise would be able to obtain individually. Previous studies on group buying focus on the benefit buyers receive in reduced acquisition costs or enhanced bargaining power. In this paper, we show that buyers can instead get hurt from such cooperation. Specifically, we consider a two-level distribution channel with a single manufacturer and two retailers who compete for end customers. We show that, under linear demand curves, group buying is always preferable for symmetric (i.e., identical) retailers. For asymmetric retailers (i.e., differing in market base and/or efficiency), group buying is beneficial to the smaller (or less efficient) player. However, it can be detrimental to the larger (or more efficient) one. Despite the lower wholesale price under group buying, the manufacturer can receive a higher revenue. Interestingly, group buying is more likely to form when retailers are competitive in different dimensions. These insights are shown to be robust under general nonlinear demand curves, except for constant elastic demand with low demand elasticity."
2028,"Push or Pull? Auctioning Supply Contracts","Li, Cuihong and Scheller-Wolf, Alan","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","198-213","2011","MAR-APR","Procurement;Auctions;Supply Contracts;Push;Pull","","Consider a buyer, facing uncertain demand, who sources from multiple suppliers via online procurement auctions (open descending price-only auctions). The suppliers have heterogeneous production costs, which are private information, and the winning supplier has to invest in production capacity before the demand uncertainty is resolved. The buyer chooses to offer a push or pull contract, for which the single price and winning supplier are determined via the auction. We show that, with a pull contract, the buyer does not necessarily benefit from a larger number of suppliers participating in the auction, due to the negative effect of supplier competition on the incentive of supplier capacity investment. We thus propose an enhanced pull mechanism that mitigates this effect with a floor price. We then analyze and compare the outcomes of auctions for push and (enhanced) pull contracts, establishing when one form is preferred over the other based on the buyer's profits. We also compare our simple, price-only push and pull contract auctions to the optimal mechanisms, benchmarking the performance of the simple mechanisms as well as establishing the relative importance of auction design and contract design in procurement auctions."
2029,"An Exploratory Study of Procurement Strategies for Multi-Item RFQs in B2B Markets: Antecedents and Impact on Performance","Schoenherr, Tobias and Mabert, Vincent A.","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","214-234","2011","MAR-APR","Procurement Strategies;Environmental Conditions;Purchase Performance;Industrial Buyer Behavior;Survey Research","","This research explores procurement strategies for multi-item requests for quotation (RFQs) in business-to-business (B2B) markets using responses from 825 purchasing professionals. The study first establishes procurement strategies that differ based on their level of strategic emphasis, i.e., the importance that is placed on the pursuit of four strategic objectives. Underlying objectives, which are obtained via factor analysis, include the focus on price, security of supply, internal procurement efficiencies, and bundle building. Next, cluster analysis is used to derive prototypical strategic approaches. The three cluster groups that emerge possess the same relative ranking of the four objectives, but differ based on the intensity with which these objectives are pursued. The clusters are labelled as the three strategic groups of strategists, opportunists, and responders. The research then explores, using an industrial buyer behavior lens, the impact of environmental antecedents in determining a particular strategy. Environmental variables include purchase importance, market uncertainty, supply base availability, buyer bargaining power, item experience, and supply base experience. Finally, the study tests the impact of procurement strategy on the buyer's perceived performance, suggesting that strategists, placing more emphasis on the pursuit of strategic sourcing objectives, achieve better performance than opportunists and responders."
2030,"Differential Pricing for Information Sharing Under Competition","Jain, Aditya and Seshadri, Sridhar and Sohoni, Milind","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","235-252","2011","MAR-APR","Cournot Competition;Supply Chain Management;Information Sharing","","We consider a two-echelon supply chain with a manufacturer supplying to multiple downstream retailers engaged in differentiated Cournot competition. Each retailer has private information about uncertain demand. The manufacturer is the Stackelberg leader who sets the contract terms with the retailers, and benefits from retailers sharing their private information. When all retailers are given the same wholesale price, truthful information sharing is not an equilibrium outcome. We propose two variants of differential pricing mechanisms that induce truthful information sharing by all retailers. The first variant rewards a retailer for providing optimistic information and achieves truthful information sharing as a unique equilibrium. The differential pricing mechanism is optimal in the class of linear-price, incentive-compatible, direct mechanisms. The second variant, which incorporates provision for a fixed payment in addition to wholesale prices, preserves all the equilibrium properties of the first variant and additionally nearly coordinates the supply chain. Our analysis of differential pricing with a fixed payment provides interesting observations regarding the relationship between product substitutability, number of retailers, information precision, and market power. As products become closer substitutes and/or number of retailers increase, the manufacturer's market power increases, enabling her to extract a larger fraction of the supply chain surplus."
2031,"The Impact of Information Sharing and Advance Order Information on a Supply Chain with Balanced Ordering","Zhang, Sheng Hao and Cheung, Ki Ling","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","253-267","2011","MAR-APR","Balanced Ordering;Information Sharing;Advance Order Information;Sequencing;Supply Chain Management","","This paper considers a supply chain with one supplier and multiple retailers that face exogenous heterogeneous end-customer demands, where all parties utilize base-stock policies. Each retailer is restricted to order once in every order cycle and their orders are replenished in a balanced manner within the cycle. Our study investigates the impact of information sharing and advance order information (AOI) on the supply chain. We find that the supplier benefits from the two mechanisms via two important factors, the information about observed end-customer demands and the decision on re-establishing the replenishment sequence. We derive the supplier's optimal sequence for stochastically comparable end-customer demands with AOI and propose a sequencing rule for the setting with information sharing. Our numerical study examines the cost impacts of two proposed mechanisms on the entire supply chain."
2032,"Life-Cycle Channel Coordination Issues in Launching an Innovative Durable Product","Gutierrez, Genaro J. and He, Xiuli","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","268-279","2011","MAR-APR","Supply Chain Coordination;Innovative Durable Products;Differential Games;Revenue-Sharing Contracts","","We analyze the dynamic strategic interactions between a manufacturer and a retailer in a decentralized distribution channel used to launch an innovative durable product (IDP). The underlying retail demand for the IDP is influenced by word-of-mouth from past adopters and follows a Bass-type diffusion process. The word-of-mouth influence creates a trade-off between immediate and future sales and profits, resulting in a multi-period dynamic supply chain coordination problem. Our analysis shows that while in some environments, the manufacturer is better off with a far-sighted retailer, there are also environments in which the manufacturer is better off with a myopic retailer. We characterize equilibrium dynamic pricing strategies and the resulting sales and profit trajectories. We demonstrate that revenue-sharing contracts can coordinate the IDP's supply chain with both far-sighted and myopic retailers throughout the entire planning horizon and arbitrarily allocate the channel profit."
2033,"Theoretical and Interpretation Challenges to Using the Author Affiliation Index Method to Rank Journals","Agrawal, Vijay K. and Agrawal, Vipin and Rungtusanatham, M.","PRODUCTION AND OPERATIONS MANAGEMENT","20","2","280-300","2011","MAR-APR","Author Affiliation Index;Journal Quality;Journal Evaluation","","We formally review the Author Affiliation Index (AAI) method as originally conceived by David Harless and Robert J. Reilly from the Economics Department at the Virginia Commonwealth University School of Business and as subsequently developed and interpreted by Gorman and Kanet in their 2005 article. Through this formal review, we first highlight and discuss two important informational inputs that can impact the stability of the AAI scores for journals in any given set of to-be-evaluated journals. We then identify and challenge interpretations related to these scores (one theoretical, one statistical) offered by Gorman and Kanet that result in misleading conclusions about journal quality and that may potentially motivate inappropriate editorial behavior. For important professional decisions of hiring, performance evaluation, promotion, and tenure, we conclude by cautioning against sole reliance on the AAI method for ranking journals and against exclusive interpretation of the score computed via the AAI method as an indicator of journal quality."
2034,"Controversial Role of GPOs in Healthcare-Product Supply Chains","Hu, Qiaohai (Joice) and Schwarz, Leroy B.","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","1-15","2011","JAN-FEB","Healthcare Product Supply Chain;Gpos;Cafs;On-Contract;Off-Contract","","This paper examines the controversial role that Group Purchasing Organizations (GPOs) play in the supply chains for healthcare products. Among the controversies, perhaps the most fundamental one is whether or not GPOs reduce purchasing costs for their members. However, the fiercest controversy is around the contract administration fees (CAFs) that GPOs charge to manufacturers. We examine these and other controversies using a Hotelling duopoly model. Among our conclusions: GPOs increase competition between manufacturers and lower prices for healthcare providers. However, GPOs reduce manufacturers' incentives to introduce innovations to existing products. We also demonstrate that the existence of lower off-contract prices is not, per se, evidence of anticompetitive behavior on the part of GPOs. Indeed, we demonstrate that, under certain circumstances, the presence of a GPO lowers off-contract prices. We also examine the consequences of eliminating the safe harbor provisions that permit healthcare GPOs to charge CAFs to manufacturers, and conclude that it would not affect any party's profits or costs."
2035,"Matching Product Architecture and Supply Chain Configuration","Uelkue, Sezer and Schmidt, Glen M.","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","16-31","2011","JAN-FEB","Product Architecture;Modularity;Product Quality;Outsourcing;Collaborative Product Development","","In this paper, we examine the suggested link between product architecture (i.e., the extent to which a product is modular vs. integral) and supply chain configuration (i.e., whether the product development is done internally by the manufacturer in an integrated supply chain or in collaboration with a supplier in a decentralized supply chain). Our model suggests that the choice of product architecture depends on firm, market, and product characteristics in addition to supply chain structure. In contrast to other studies, we find that the optimal mapping from architecture to supply chain structure is not always one-to-one. A decentralized supply chain may be associated with a more integral product when the technical collaboration penalty is not excessive and suppliers have significantly superior product development capabilities. Furthermore, in a decentralized supply chain, the nature of the relationship between the original equipment manufacturer and its supplier (adversarial or collaborative) plays a role in the choice of product architecture: modular architectures are more likely when the parties have adversarial relationships, while long-term trust-based relationships facilitate more integral product architectures."
2036,"Competing for Shelf Space","Martinez-de-Albeniz, Victor and Roels, Guillaume","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","32-46","2011","JAN-FEB","Game Theory;Supply Chain Competition;Price Of Anarchy;Pricing;Supply Contracts","","In recent years, the competition for shelf space has intensified, as more products now compete for a retail space that has remained roughly constant. In this paper, we analyze the dynamics of this competition in a multi-supplier retail point. Assuming that sales are shelf space dependent, we consider a retailer that optimizes its shelf space allocation among different products based on their sales level and profit margins. In this context, product manufacturers set their wholesale prices so as to obtain larger shelf space allocations but at the same time keep margins as high as possible. We analyze the equilibrium situation in the supply chain, and find that generally the retailer's and the suppliers' incentives are misaligned, resulting in suboptimal retail prices and shelf space allocations. We however find that the inefficiencies induced by suboptimal shelf space allocation decisions are small relative to those induced by suboptimal pricing decisions."
2037,"Category Captainship vs. Retailer Category Management under Limited Retail Shelf Space","Kurtulus, Muemin and Toktay, L. Beril","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","47-56","2011","JAN-FEB","Category Management;Category Captainship;Limited Shelf Space;Retailing;Supply Chain Collaboration","","Shelf-space scarcity is a predominant aspect of the consumer goods industry. This paper analyzes its implications for category management. We consider a model where two competing manufacturers sell their differentiated products through a single retailer who determines the shelf space allocated to the category. The scope of category management is pricing. We consider two category management mechanisms: retailer category management (RCM), where the retailer determines product prices and category captainship (CC), where a manufacturer in the category determines them. Our analysis reveals that the retailer can use the form of category management and the category shelf space to control the intensity of competition between manufacturers to his benefit. We also show that the emergence of CC depends on the degree of product differentiation, the opportunity cost of shelf space, and the profit sharing arrangement in the alliance. The equilibrium category shelf space under CC may be higher than under RCM if the value to the retailer of eliminating double marginalization and putting price pressure on the non-captain manufacturer dominates the loss from sharing the profit with the category captain. CC has been criticized for disadvantaging non-captain manufacturers. While we provide some support for this claim, we also find that CC may benefit non-captain manufacturers when implemented by a powerful retailer in categories with sufficiently differentiated products, because the shelf space allocated to the category increases in this case."
2038,"Inventory Control when the Lead-time Changes","Axsater, Sven","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","72-80","2011","JAN-FEB","Inventory Management;Stochastic;Jit;Transient","","A single-echelon inventory system with continuous review and Poisson demand is considered. There are standard linear holding and backorder costs but no ordering or set-up costs. We study a change in the lead-time, which is rather typical in connection with application of a Just-In-Time philosophy. Our main focus is a lead-time decrease but we also consider a lead-time increase. Due to the lead-time change, the optimal steady state solution will also, in general, change. We consider the transient problem of minimizing the costs when bringing the system from its original steady state to the new steady state."
2039,"Price, Rebate, and Returns Supply Contracts for Coordinating Supply Chains with Price-Dependent Demands","Chiu, Chun-Hung and Choi, Tsan-Ming and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","81-91","2011","JAN-FEB","Supply Chain Management;Channel Coordination;Sales Rebates;Returns Policy","","Channel rebates and returns policies are common mechanisms for manufacturers to entice retailers to increase their order quantities and sales ultimately. However, when the underlying demand depends on the retail price, it has been known that channel coordination cannot be achieved if only one of these mechanisms is deployed. In this article, we show that a policy that combines the use of wholesale price, channel rebate, and returns can coordinate a channel with both additive and multiplicative price-dependent demands. In addition to determining the sufficient conditions for the contract parameters associated with the equilibrium policy, we show that multiple equilibrium policies for channel coordination exist. We further explore how the equilibrium policy can be adjusted to achieve Pareto improvement. Other issues such as the maximum amount of expected profit that the manufacturer can share under the coordinated channel, the structural properties of the contracts under both the additive and multiplicative price-dependent demand functions are also discussed."
2040,"Supply Chain Sourcing Under Asymmetric Information","Oezer, Oezalp and Raz, Gal","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","92-115","2011","JAN-FEB","Sourcing;Supply Contracts;Cost Information;Game Theory;Mechanism Design","","We study a supply chain with two suppliers competing over a contract to supply components to a manufacturer. One of the suppliers is a big company for whom the manufacturer's business constitutes a small part of his business. The other supplier is a small company for whom the manufacturer's business constitutes a large portion of his business. We analyze the problem from the perspective of the big supplier and address the following questions: What is the optimal contracting strategy that the big supplier should follow? How does the information about the small supplier's production cost affect the profits and contracting decision? How does the existence of the small supplier affect profits? By studying various information scenarios regarding the small supplier's and the manufacturer's production cost, we show, for example, that the big supplier benefits when the small supplier keeps its production cost private. We quantify the value of information for the big supplier and the manufacturer. We also quantify the cost (value) of the alternative-sourcing option for the big supplier (the manufacturer). We determine when an alternative-sourcing option has more impact on profits than information. We conclude with extensions and numerical examples to shed light on how system parameters affect this supply chain."
2041,"Effect of Learning and Forgetting on Batch Sizes","Teyarachakul, Sunantha and Chand, Suresh and Ward, James","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","116-128","2011","JAN-FEB","Learning And Forgetting;Production Scheduling;Small Batches","","This paper investigates the effect of learning and forgetting on production scheduling decisions. Numerous papers have appeared on this topic in the last four decades; they show that firms are better off producing in larger batches in the presence of learning and forgetting. However, these papers fail to consider one or more of realistic features of learning and forgetting; factors such as (1) the amount forgotten increases with break length between two batches and (2) the forgetting could be slow over an initial short interval followed by fast forgetting. Our paper contributes by demonstrating that a consideration of these realistic features leads to a different conclusion-firms may be better off producing in smaller batches in the presence of learning and forgetting. This is a new insight that provides one more justification for producing in small batches."
2042,"Advance Selling by a Newsvendor Retailer","Prasad, Ashutosh and Stecke, Kathryn E. and Zhao, Xuying","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","129-142","2011","JAN-FEB","Advance Selling;Newsvendor;Consumer Valuation;Uncertainty;Pricing","","Retailers often face a newsvendor problem. Advance selling helps retailers to reduce demand uncertainty. Consumers, however, may prefer not to purchase in advance unless given a discount because they are uncertain about their valuation for the product in advance. It is then unclear whether or when advance selling to pass some uncertainty risk to consumers is optimal for the retailer. This paper examines the advance selling price and inventory decisions in a two-period setting, where the first period is the advance selling period and the second is the selling (and consumption) period. We find that an advance selling strategy is not always optimal, but is contingent on parameters of the market (e.g., market potential and uncertainty) and the consumers (e.g., valuation, risk aversion, and heterogeneity). For example, we find that retailers should sell in advance if the consumers' expected valuation exceeds consumers' expected surplus when not buying early by a certain threshold. This threshold increases with the degree of risk aversion but decreases with stock out risk. If the degree of risk aversion varies across consumers, then a retailer should sell in advance if the probability for a consumer to spot buy is less than a critical fractile."
2043,"A Note on the Relationship Among Capacity, Pricing, and Inventory in a Make-to-Stock System","Allon, Gad and Zeevi, Assaf","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","143-151","2011","JAN-FEB","Capacity Investment;Pricing;Inventory;Stochastic Demand","","We address the simultaneous determination of pricing, production, and capacity investment decisions by a monopolistic firm in a multi-period setting under demand uncertainty. We analyze the optimal decision with particular emphasis on the relationship between price and capacity. We consider models that allow for either bi-directional price changes or models with markdowns only, and in the latter case we prove that capacity and price are strategic substitutes."
2044,"A Note on Air-Cargo Capacity Contracts","Amaruchkul, Kannapha and Cooper, William L. and Gupta, Diwakar","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","152-162","2011","JAN-FEB","Capacity Contracts;Asymmetric Information;Informational Rents","","Carriers (airlines) use medium-term contracts to allot bulk cargo capacity to forwarders who deliver consolidated loads for each flight in the contractual period (season). Carriers also sell capacity to direct-ship customers on each flight. We study capacity contracts between a carrier and a forwarder when certain parameters such as the forwarder's demand, operating cost to the carrier, margin, and reservation profit are its private information. We propose contracts in which the forwarder pays a lump sum in exchange for a guaranteed capacity allotment and receives a refund for each unit of unused capacity according to a pre-announced refund rate. We obtain an upper bound on the informational rent paid by the carrier for a menu of arbitrary allotments and identify conditions under which it can eliminate the informational rent and induce the forwarder to choose the overall optimal capacity allotment (i.e., one that maximizes the combined profits of the carrier and the forwarder)."
2045,"On the Benefits of Risk Pooling in Inventory Management","Berman, Oded and Krass, Dmitry and Tajbakhsh, M. Mahdi","PRODUCTION AND OPERATIONS MANAGEMENT","20","1","57-71","2011","JAN-FEB","Risk Pooling;Stochastic Inventory Models;High Demand Variability;Distribution-Free Approach","","We analyze the benefits of inventory pooling in a multi-location newsvendor framework. Using a number of common demand distributions, as well as the distribution-free approximation, we compare the centralized (pooled) system with the decentralized (non-pooled) system. We investigate the sensitivity of the absolute and relative reduction in costs to the variability of demand and to the number of locations (facilities) being pooled. We show that for the distributions considered, the absolute benefit of risk pooling increases with variability, and the relative benefit stays fairly constant, as long as the coefficient of variation of demand stays in the low range. However, under high-variability conditions, both measures decrease to zero as the demand variability is increased. We show, through analytical results and computational experiments, that these effects are due to the different operating regimes exhibited by the system under different levels of variability: as the variability is increased, the system switches from the normal operation to the effective and then complete shutdown regimes; the decrease in the benefits of risk pooling is associated with the two latter stages. The centralization allows the system to remain in the normal operation regime under higher levels of variability compared to the decentralized system."
2046,"The Maximum Throughput on a Golf Course","Whitt, Ward","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","685-703","2015","MAY","Pace Of Play In Golf;The Capacity Of A Golf Course;Queueing Models Of Golf;Throughput;Production Lines;Queues In Series","","We develop stochastic models to help manage the pace of play on a conventional 18-hole golf course. These models are for group play on each of the standard hole types: par-3, par-4, and par-5. These models include the realistic feature that k-2 groups can be playing at the same time on a par-k hole, but with precedence constraints. We also consider par-3 holes with a wave-up rule, which allows two groups to be playing simultaneously. We mathematically determine the maximum possible throughput on each hole under natural conditions. To do so, we analyze the associated fully loaded holes, in which new groups are always available to start when the opportunity arises. We characterize the stationary interval between the times successive groups clear the green on a fully loaded hole, showing how it depends on the stage playing times. The structure of that stationary interval evidently can be exploited to help manage the pace of play. The mean of that stationary interval is the reciprocal of the capacity. The bottleneck holes are the holes with the least capacity. The bottleneck capacity is then the capacity of the golf course as a whole."
2047,"Recent Developments in Dynamic Pricing Research: Multiple Products, Competition, and Limited Demand Information","Chen, Ming and Chen, Zhi-Long","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","704-731","2015","MAY","Survey;Dynamic Pricing;Multiple Products;Competition;Limited Demand Information","","Dynamic pricing enables a firm to increase revenue by better matching supply with demand, responding to shifting demand patterns, and achieving customer segmentation. In the last 20years, numerous success stories of dynamic pricing applications have motivated a rapidly growing research interest in a variety of dynamic pricing problems in the academic literature. A large class of problems that arise in various revenue management applications involve selling a given amount of inventory over a finite time horizon without inventory replenishment. In this study, we identify most recent trends in dynamic pricing research involving such problems. We review existing research on three new classes of problems that have attracted a rapidly growing interest in the last several years, namely, problems with multiple products, problems with competition, and problems with limited demand information. We also identify a number of possible directions for future research."
2048,"Inventory-Based Dynamic Pricing with Costly Price Adjustment","Chen, Wen and Feng, Qi and Seshadri, Sridhar","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","732-749","2015","MAY","Inventory Control;Dynamic Pricing;Costly Price Adjustment","","We study an average-cost stochastic inventory control problem in which the firm can replenish inventory and adjust the price at anytime. We establish the optimality to change the price from low to high in each replenishment cycle as inventory is depleted. With costly price adjustment, scale economies of inventory replenishment are reflected in the cycle time instead of lot sizeAn increased fixed ordering cost leads to an extended replenishment cycle but does not necessarily increase the order quantity. A reduced marginal cost of ordering calls for an increased order quantity, as well as speeding up product selling within a cycle. We derive useful properties of the profit function that allows for reducing computational complexity of the problem. For systems requiring short replenishment cycles, the optimal solution can be easily computed by applying these properties. For systems requiring long replenishment cycles, we further consider a relaxed problem that is computational tractable. Under this relaxation, the sum of fixed ordering cost and price adjustment cost is equal to (greater than, less than) the total inventory holding cost within a replenishment cycle when the inventory holding cost is linear (convex, concave) in the stock level. Moreover, under the optimal solution, the time-average profit is the same across all price segments when the inventory holding cost is accounted properly. Through a numerical study, we demonstrate that inventory-based dynamic pricing can lead to significant profit improvement compared with static pricing and limited price adjustment can yield a benefit that is close to unlimited price adjustment. To be able to enjoy the benefit of dynamic pricing, however, it is important to appropriately choose inventory levels at which the price is revised."
2049,"Revenue Management vs. Newsvendor Decisions: Does Behavioral Response Mirror Normative Equivalence?","Kocabiyikoglu, Ayse and Gogus, Celile Itir and Gonul, M. Sinan","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","750-761","2015","MAY","Behavioral Operations Management;Revenue Management;Newsvendor Problem","","We study and compare decision-making behavior under the newsvendor and the two-class revenue management models, in an experimental setting. We observe that, under both problems, decision makers deviate significantly from normative benchmarks. Furthermore, revenue management decisions are consistently higher compared to the newsvendor order quantities. In the face of increasing demand variability, revenue managers increase allocations; this behavior is consistent with normative patterns when the ratio of the selling prices of the two customer segments is less than 1/2, but is its exact opposite when this ratio is greater than 1/2. Newsvendors' behavior with respect to changing demand variability, on the other hand, is consistent with normative trends. We also observe that losses due to leftovers weigh more in newsvendor decisions compared to the revenue management model; we argue that overage cost is more salient in the newsvendor problem because it is perceived as a direct loss, and propose this as the driver of the differences in behavior observed under the two problems."
2050,"Coping with Gray Markets: The Impact of Market Conditions and Product Characteristics","Ahmadi, Reza and Iravani, Foad and Mamani, Hamed","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","762-777","2015","MAY","Gray Markets;Parallel Importation;Parallel Markets;Strategic Pricing;Demand Uncertainty;Uniform Pricing","","Gray markets, also known as parallel imports, have created fierce competition for manufacturers in many industries. We analyze the impact of parallel importation on a price-setting manufacturer that serves two markets with uncertain demand, and characterize her policy against parallel importation. We show that ignoring demand uncertainty can take a significant toll on the manufacturer's profit, highlighting the value of making price and quantity decisions jointly. We find that adjusting prices is more effective in controlling gray market activity than reducing product availability, and that parallel importation forces the manufacturer to reduce her price gap while demand uncertainty forces her to lower prices. Furthermore, we explore the impact of market conditions (such as market base, price sensitivity, and demand uncertainty) and product characteristics (fashion vs. commodity) on the manufacturer's policy towards parallel importation. We also provide managerial insights about the value of strategic decision-making by comparing the optimal policy to the uniform pricing policy that has been adopted by some companies to eliminate gray markets entirely. The comparison indicates that the value of making price and quantity decisions strategically is highest for moderately different market conditions and non-commodity products."
2051,"Service Systems with Experience-Based Anecdotal Reasoning Customers","Huang, Tingliang and Chen, Ying-Ju","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","778-790","2015","MAY","Queueing;Service Systems;Pricing;Anecdotal Reasoning;Capacity Management","","The existing queueing literature typically assumes that customers either perfectly know the expected waiting time or are able to form rational expectations about it. In contrast, in this article, we study canonical service models where customers do not have such full information or capability. We assume that customers lack full capability or ample opportunities to perfectly infer the service rate or estimate the expected waiting time, and thus can only rely on past experiences and anecdotal reasoning to make their joining decisions. We fully characterize the steady-state equilibrium in this service system. Compared with the fully rational benchmark, we find that customers with anecdotal reasoning are less price-sensitive. Consequently, with a higher market potential (higher arrival rate), a revenue-maximizing firm may increase the price if the service rate is exogenous, and it may decrease the price if the service rate is at the firm's discretion. Both results go against the commonly accepted pricing recommendations in the fully rational benchmark. We also show that revenue maximization and welfare maximization lead to fundamentally different pricing strategies with anecdotal reasoning, whereas they are equivalent in the fully rational benchmark."
2052,"Supply Contract Design for Competing Heterogeneous Suppliers under Asymmetric Information","Li, Zhaolin and Ryan, Jennifer K. and Shao, Lusheng and Sun, Daewon","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","791-807","2015","MAY","Supply Chain Management;Supply Contracts;Competition;Asymmetric Information;Stochastic Inventory Model","","This study considers a supply chain with two heterogeneous suppliers and a common retailer whose type is either low-volume or high-volume. The retailer's type is unknown to the suppliers. The flexible supplier has a high variable cost and a low fixed cost, while the efficient supplier has a low variable cost and a high fixed cost. Each supplier offers the retailer a menu of contracts. The retailer chooses the contract that maximizes its expected profit. For this setting, we characterize the equilibrium contract menus offered by the suppliers to the retailer. We find that the equilibrium contract menus depend on which supplier-retailer match can generate the highest supply chain profit and on how much information rent the supplier may need to pay. An important feature of the equilibrium contract menus is that the contract assigned to the more profitable retailer will coordinate the supply chain, while the contract assigned to the less profitable retailer may not. In addition, in some circumstances, the flexible supplier may choose not to serve the high-volume retailer, in order to avoid excessive information rent."
2053,"Managing Supply Disruptions when Sourcing from Reliable and Unreliable Suppliers","Hu, Bin and Kostamis, Dimitris","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","808-820","2015","MAY","Multiple Sourcing;Guaranteed Delivery;Supplier Ranking","","We study a manufacturer's optimal multiple-sourcing strategies when some but not all suppliers face risks of complete supply disruptions. Using an approximate model, we show that the optimal unreliable orders are ranked by a simple and intuitive criterion, and are invariant of minor market size changes. Furthermore, when ordering from one reliable and one unreliable supplier, we show that the total order quantity and its allocation between the two suppliers are independent decisions. We then test and confirm the robustness of the insights without the approximation, as well as when we relax various assumptions."
2054,"Efficiency or Competition? A Structural Econometric Analysis of Canada's AWS Auction and the Set-Aside Provision","Hyndman, Kyle and Parmeter, Christopher F.","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","821-839","2015","MAY","Spectrum Auction;Set-Aside;Structural Matching;Pairwise Stability;Maximum Score","","In 2008, Industry Canada auctioned 105MHz of spectrum to a group of bidders that included incumbents and potential new entrants into the Canadian mobile phone market, raising $4.25billion. In an effort to promote new entry, 40MHz of spectrum was set-aside for new entrants. In order to estimate the implicit cost of the set-aside provision, we estimate the parameters of the bidders' profit function via a maximum match estimator based on the notion of pairwise stability in matches. We find that all telecommunications firms valued both geographic complementarities across auction licenses as well as absolute spectrum. Under a reasonable alternative scenario, our results indicate that the set-aside led to a total profit loss of approximately 10%."
2055,"A New Two-Bin Policy for Inventory Systems with Differentiated Demand Classes","Ghosh, Sugoutam and Piplani, Rajesh and Viswanathan, S.","PRODUCTION AND OPERATIONS MANAGEMENT","24","5","840-850","2015","MAY","Inventory;Service Differentiation;Demand Classes;Two-Bin Policy;Rationing","","We consider an inventory system under continuous review with two demand classes that are different in terms of service level required (or penalty cost incurred for backordering of demand). Prior literature has proposed the critical level rationing (CLR) policy under which the demand from the lower priority class is backordered once inventory falls below the critical level. While this reduces the penalty cost for the higher demand class, the fill rate achieved for the lower priority demand class gets compromised. In this study, we propose a new class of two-bin (2B) policy for the problem. The proposed 2B policy assigns separate bins of inventory for the two demand classes. The demand for each class is fulfilled from its assigned bin. However, when the bin intended for the higher demand class is empty, the demand from the higher class can still be fulfilled with the inventory from the other bin. The advantage of the 2B policy is that better fill rates are achieved, especially for the lower demand class. Computational results show that the proposed policy is able to provide a much higher service level for the lower priority class demand without increasing the total cost too much and without affecting the service level for the higher priority class. When a service level constrained optimization problem is considered, the 2B policy dominates the CLR policy when the service level difference for the two classes is not too high or the service levels required for both the classes are relatively lower."
2056,"Research Constituents and Authorship Patterns in the Production and Operations Management Journal","Saladin, Brooke A. and Shang, Guangzhi and Fry, Timothy D. and Donohue, Joan M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","523-534","2015","APR","Production And Operations Management;Author Affiliations;Research Constituents","","The Production and Operations Management Society is the largest professional society dedicated to creating and disseminating knowledge in product and process design, operations, and supply chains for the management of manufacturing and services. Its research journal, Production and Operations Management (POM), covers all topics in the discipline and all research paradigms to serve the entire community. Since its inception in 1992, POM has become recognized as a top tier outlet for operations management research. We identify research institutions in the operations management community that have played major roles in developing the journal based on the research of their faculty members and doctoral graduates. Our findings show that the constituency of the journal reflects the constituency of the society."
2057,"The Failure of Practical Intuition: How Forward-Coverage Inventory Targets Cause the Landslide Effect","Neale, John J. and Willems, Sean P.","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","535-546","2015","APR","Seasonal Demand;Days Of Supply;Safety Stock Targets;Production And Inventory Management;Industry Practice","","Seasonal demand for products is common at many companies including Kraft Foods, Case New Holland, and Elmer's Products. This study documents how these, and many other companies, experience bloated inventories as they transition from a low season to a high season and a severe drop in service levels as they transition from a high season to a low season. Kraft has termed this latter phenomenon the landslide effect. In this study, we present real examples of the landslide effect and attribute its root cause to a common industry practice employing forward days of coverage when setting inventory targets. While inventory textbooks and academic articles prescribe correct ways to set inventory targets, forward coverage is the dominant method employed in practice. We investigate the magnitude and drivers of the landslide effect through both an analytical model and a case study. We find that the effect increases with seasonality, lead time, and demand uncertainty and can lower service by an average of ten points at a representative company. While the logic is initially counterintuitive to many practitioners, companies can avoid the landslide effect by using demand forecasts over the preceding lead time to calculate safety stock targets."
2058,"When Gray is Good: Gray Markets and Market-Creating Investments","Autrey, Romana L. and Bova, Francesco and Soberman, David A.","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","547-559","2015","APR","Gray Markets;Unauthorized Distribution;Emerging Markets;Investment Spillovers;Management Control Systems","","Gray markets arise when an intermediary buys a product in a lower-priced, often emerging market and resells it to compete with the product's original manufacturer in a higher priced, more developed market. Evidence suggests that gray markets make the original manufacturer worse off globally by eroding profit margins in developed markets. Thus, it is interesting that many firms do not implement control systems to curb gray market activity. Our analysis suggests that one possible explanation lies at the intersection of two economic phenomena: firms investing to build emerging market demand, and investments conferring positive externalities (spillovers) on a rival's demand. We find that gray markets amplify the incentives to invest in emerging markets, because investments increase both emerging market consumption and the gray market's cost base. Moreover, when market-creating investments confer positive spillovers, each firm builds its own market more efficiently. Thus, firms can be better off with gray markets when investments confer spillovers, provided the spillover effect is sufficiently large. These results provide a perspective on why firms might not implement control systems to prevent gray market distribution in sectors where investment spillovers are common (e.g., the technology sector) and, more broadly, why gray markets persist in the economy."
2059,"The Role of Project and Organizational Context in Managing High-tech R&D Projects","Chandrasekaran, Aravind and Linderman, Kevin and Schroeder, Roger","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","560-586","2015","APR","Exploration;Exploitation;R&D Projects;Innovation;Team Effectiveness;High-Tech Organizations;Qualitative Data;Survey","","High-tech organizations often struggle to manage different types of R&D projects. Evidence from research and practice suggests that managers frequently categorize and manage projects based on the extent of change triggered in product, process, technology, and market dimensions. However, this can create challenges in high-tech organizations. This study investigates how high-tech organizations manage R&D projects based on their learning goals. First, we argue for the benefits of categorizing R&D projects based on the degree of exploration and exploitation learning goals. A qualitative case study from four high-tech business units involving 10 R&D projects helps understand the different types of projects based on their learning goals. The case study shows that R&D projects in high-tech organizations typically fall into three categories based on their learning goals: Radical innovation projects, Incremental innovation projects, and Hybrid projects. Second, we iterate between literature and evidence from our qualitative data to theorize how project context and organizational context affect project performance depending on the type of project. The data for the empirical analysis come from a multilevel survey of 110 R&D projects across 34 high-tech business units. Results show the importance of designing project and organizational context differently for the three types of R&D projects. Collectively, this study offers a new perspective on how to manage high-tech R&D projects."
2060,"Call Center Delay Announcement Using a Newsvendor-Like Performance Criterion","Jouini, Oualid and Aksin, O. Zeynep and Karaesmen, Fikri and Aguir, M. Salah and Dallery, Yves","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","587-604","2015","APR","Call Center Applications;Real-Time Delay Approximations;Priority;Simulation;Newsvendor Model","","The problem of estimating delays experienced by customers with different priorities, and the determination of the appropriate delay announcement to these customers, in a multi-class call center with time varying parameters, abandonments, and retrials is considered. The system is approximately modeled as an M(t)/M/s(t) queue with priorities, thus ignoring some of the real features like abandonments and retrials. Two delay estimators are proposed and tested in a series of simulation experiments. Making use of actual state-dependent waiting time data from this call center, the delay announcements from the estimated delay distributions that minimize a newsvendor-like cost function are considered. The performance of these announcements is also compared to announcing the mean delay. We find that an Erlang distribution-based estimator performs well for a range of different under-announcement penalty to over-announcement penalty ratios."
2061,"Would Allowing Privately Funded Health Care Reduce Public Waiting Time? Theory and Empirical Evidence from Canadian Joint Replacement Surgery Data","Chen, Hong and Qian, Qu and Zhang, Anming","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","605-618","2015","APR","Health Care Waiting Time;Elective Surgery;Health Policy;Privately Funded Health Service","","This study develops a theoretical model and then, using Canadian joint replacement surgery data, empirically tests the relationship between government policies that promote privately funded health care and patients' waiting time in the public health care system. Two policies are tested: one policy allows opt-out physicians to extra-bill private patients, and the other provides public subsidies to private patients. We find that both policies are associated with shorter public waiting time, and that the subsidy policy appears to be more effective in waiting time reduction than the extra-billing policy. Our findings are consistent with a dominant demand-side effect in that these policies would provide patients an option, and some incentive, to opt out of the public health system, shifting the demand from the public health system to the private care market."
2062,"Information Sharing in a Manufacturer-Supplier Relationship: Suppliers' Incentive and Production Efficiency","Chen, Ying-Ju and Deng, Mingcherng","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","619-633","2015","APR","Toyota Experience;Information Sharing;Dynamic Incentives;Mechanism Design","","While there have been vast discussions on the materialistic benefits of continuous improvement from the Toyota and Honda experiences, the academic literature pays little attention to information sharing. In this study, we construct a dynamic adverse selection model in which the supplier privately observes her production efficiency, and in the contractual duration the manufacturer obtains an informative but imprecise signal regarding this private efficiency. We show that despite the disclosure of proprietary information, information sharing may benefit the supplier; the supplier's voluntary participation is more likely to occur when the shared information is rather imprecise. On the other hand, our analysis also reveals that this information sharing unambiguously gives rise to an upward push of the production quantity, and may sometimes lead to an upward distortion that ultimately hurts the supply chain. We also document the non-trivial impact of the timing of information sharing on the supplier's incentive to participate."
2063,"Decision Bias in Capacity Allocation Games with Uncertain Demand","Chen, Yefen and Zhao, Xiaobo","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","634-646","2015","APR","Behavioral Operations;Capacity Allocation;Experiments;Mental Accounts;Quantal Response Equilibrium","","Existing studies on capacity allocation games have demonstrated that the standard Nash theory exaggerates retailers' tendency of ordering more than they need in the situation of supply shortage. Adding to the results in the literature, our experimental study with consideration of demand uncertainty demonstrates that the standard Nash theory also exaggerates retailers' tendency of telling the truth in their ordering strategy. To account for these systematic biases, based on the quantal response equilibrium framework, we develop a behavioral model with different mental weights on the underage and overage costs to characterize a retailer's perception bias regarding a critical fractile. Based on the parameter estimates, we show that retailers perceive the critical fractile as being closer to 0.5 than it is, and the perceived critical fractile increases over time. Such empirical evidence of retailers' behavior in capacity allocation games can be valuable, for example, in the mechanism design of coordination and in improving supply chain performance."
2064,"Replenishment Policies for Multi-Product Stochastic Inventory Systems with Correlated Demand and Joint-Replenishment Costs","Feng, Haolin and Wu, Qi and Muthuraman, Kumar and Deshpande, Vinayak","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","647-664","2015","APR","Multi-Item Inventory Management;Joint Replenishment;Stochastic Inventory Control;Correlated Demand;Fixed Ordering Cost","","This study analyzes optimal replenishment policies that minimize expected discounted cost of multi-product stochastic inventory systems. The distinguishing feature of the multi-product inventory system that we analyze is the existence of correlated demand and joint-replenishment costs across multiple products. Our objective is to understand the structure of the optimal policy and use this structure to construct a heuristic method that can solve problems set in real-world sizes/dimensions. Using an MDP formulation we first compute the optimal policy. The optimal policy can only be computed for problems with a small number of product types due to the curse of dimensionality. Hence, using the insight gained from the optimal policy, we propose a class of policies that captures the impact of demand correlation on the structure of the optimal policy. We call this class (s,c,d,S)-policies, and also develop an algorithm to compute good policies in this class, for large multi-product problems. Finally using an exhaustive set of computational examples we show that policies in this class very closely approximate the optimal policy and can outperform policies analyzed in prior literature which assume independent demand. We have also included examples that illustrate performance under the average cost objective."
2065,"The Role of Discount Vouchers in Market with Customer Valuation Uncertainty","Gao, Fei and Chen, Jian","PRODUCTION AND OPERATIONS MANAGEMENT","24","4","665-679","2015","APR","Customer Valuation Uncertainty;Discount Vouchers;Revenue Management;Marketing-Operations Interface","","Online discount voucher market In the discount voucher market, customers usually face two types of valuation uncertainty, namely, preference uncertainty and consumption state uncertainty. Preference uncertainty is related to the customer's lack of relevant experience with the merchant, whereas consumption state uncertainty is related to the advance selling nature of the discount voucher mechanism. By taking a comprehensive perspective (i.e., considering revenue management and promotion effect at the same time), we find (i) no show of voucher buyers may not be a good thing for the merchant, especially for those large or start-up ones; (ii) offering refund may always hurt the merchant's profit and the PayPal model may not be optimal in terms of maximizing social welfare; and (iii) market segmentation is not necessary for the profitability of promotion."
2066,"The Influence of ISO 9000 Certification on Process Compliance","Gray, John V. and Anand, Gopesh and Roth, Aleda V.","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","369-382","2015","MAR","Certifications;Decay;Diffusion;Management Standards;Quality Control","","This article examines the influence of ISO 9000 certification on plant-level process compliance, which arguably is its first-order, targeted performance dimension. The empirical setting is the medical device manufacturing industry. Process compliance is measured through Food and Drug Administration inspections of manufacturing plants. We control for several observable factors that possibly affect process compliance by matching certified plants with non-certified plants. Using longitudinal data, we find plants that obtained certification in the earlier diffusion period (early-certified plants) tend to have significantly better process compliance than a matched, non-certified control group of plants. The compliance difference between early-certified plants and their matched control group is greater than the compliance difference between late-certified plants and their matched control group. We also find deterioration in process compliance over time after certification. Because we capture longitudinally the first-order effects of ISO 9000 on process compliance, this study provides a useful baseline for assessing causality in ISO 9000-performance linkages. Also, we explain, in part, the inconsistencies observed in related ISO 9000 literature examining the performance effects of certification. Further, this research offers managerial insights on the dynamics of certification and process compliance with time, and highlights the need for continued vigilance post certification."
2067,"Signaling to Partially Informed Investors in the Newsvendor Model","Schmidt, William and Gaur, Vishal and Lai, Richard and Raman, Ananth","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","383-401","2015","MAR","Capacity Investment;Newsvendor Model;Game Theory;Information Asymmetry","","We analyze a signaling game between the manager of a firm and an investor in the firm. The manager has private information about the firm's demand and cares about the short-term stock price assigned by the investor. Previous research has shown that under continuous decision choices and the Intuitive Criterion refinement, the least-cost separating equilibrium will result, in which a low-quality firm chooses its optimal capacity and a high-quality firm over-invests in order to signal its quality to investors. We build on this research by showing the existence of pooling outcomes in which low-quality firms over-invest and high-quality firms under-invest so as to provide identical signals to investors. The pooling equilibrium is practically appealing because it yields a Pareto improvement compared to the least-cost separating equilibrium. Distinguishing features of our analysis are that: (i) we allow the capacity decision to have either discrete or continuous support, and (ii) we allow beliefs to be refined based on either the Undefeated refinement or the Intuitive Criterion refinement. We find that the newsvendor model parameters impact the likelihood of a pooling outcome, and this impact changes in both sign and magnitude depending on which refinement is used."
2068,"Lower Cost Arrivals for Airlines: Optimal Policies for Managing Runway Operations under Optimized Profile Descent","Chen, Heng and Solak, Senay","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","402-420","2015","MAR","Airline Industry;Aviation;Runway Operations;Sustainable Operations;Air Traffic Management","","Optimized profile descent (OPD) is an operating procedure being used by airlines to improve fuel and environmental efficiency during arrival operations at airports. In this study, we develop a stochastic dynamic programming framework to manage the sequencing and separation of flights during OPD operations. We find that simple calculation based measures can be used as optimal decision rules, and that the expected annual savings can be around $29 million if such implementations are adapted by major airports in the United States. Of these savings, $24 million are direct savings for airlines due to reduced fuel usage, corresponding to a potential savings of 10%-15% in fuel consumption over current practice. We also find that most of these savings will be due to the optimal spacing of OPD flights, as opposed to the optimal sequencing policies which contribute only 14% to the total savings. Hence, optimal spacing of OPD flights is much more important than optimal sequencing of these flights. We also conclude that there is not much difference between the environmental costs of fuel-optimal and sustainably-optimal spacing policies. Hence, an airline-centric approach in improving OPD operations is likely to be not in conflict with objectives that might be prioritized by other stakeholders."
2069,"The Impact of Costliness, Competitive Importance, and Modularity of Investments on Outsourcing","Grahovac, Jovan and Parker, Geoffrey and Shittu, Ekundayo","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","421-437","2015","MAR","Outsourcing;Vertical Integration;Modularity;Supply Chain Design","","This study is motivated by examples of outsourcing that are not readily explained by widely established economic theories. We extend recent literature that develops the idea that outsourcing can help firms avoid overinvestment by specifying more precisely the conditions under which this thesis is likely to apply. Our extension is realized through a two-period game theoretic model in which the outsourcing and in-house investments are driven by (1) the cost required to develop a product or process module, (2) competitive relevance, defined as the module's share in the production cost or the module's importance to the customer, and (3) modularity, defined as the extent to which generic investments in the module can approach firm-specific investments in terms of the overall product/process performance. The analysis generates predictions about what types of insourcing, outsourcing, and non-sourcing behaviors are likely to emerge in different parts of the parameter space. Outsourcing to a more concentrated industry upstream emerges at equilibrium when modularity is high, relevance low to medium, and development cost high enough that none or only a subset of focal firms wants to invest. While firms are forced to insource and overinvest due to a prisoner's dilemma when the development cost is sufficiently high relative to the module's relevance, we do not find outsourcing equilibria that solve this problem in a two-period game with no commitment. This result implies that some form of tacit coordination in a multi-period game may be necessary. We conclude the study with a discussion of empirical implications."
2070,"A Maximum Entropy Joint Demand Estimation and Capacity Control Policy","Maglaras, Costis and Eren, Serkan","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","438-450","2015","MAR","Revenue Management;Censored Demand;Uncensoring;Maximum Entropy Distributions","","We propose a tractable, data-driven demand estimation procedure based on the use of maximum entropy (ME) distributions, and apply it to a stochastic capacity control problem motivated from airline revenue management. Specifically, we study the two fare class Littlewood problem in a setting where the firm has access to only potentially censored sales observations; this is also known as the repeated newsvendor problem. We propose a heuristic that iteratively fits an ME distribution to all observed sales data, and in each iteration selects a protection level based on the estimated distribution. When the underlying demand distribution is discrete, we show that the sequence of protection levels converges to the optimal one almost surely, and that the ME demand forecast converges to the true demand distribution for all values below the optimal protection level. That is, the proposed heuristic avoids the spiral down effect, making it attractive for problems of joint forecasting and revenue optimization problems in the presence of censored observations."
2071,"Strategic Design Responsiveness: An Empirical Analysis of US Retail Store Networks","Shockley, Jeff and Plummer, Lawrence A. and Roth, Aleda V. and Fredendall, Lawrence D.","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","451-468","2015","MAR","Retail Operations;Design Strategy;Responsiveness;Customer Contact","","This study uses a service operations management (SOM) strategy lens to investigate chain store retailers' strategic design responsiveness (SDR)-a term that captures the degree to which retailers dynamically coordinate investments in human and structural capital with the complexity of their service and product offerings. Labor force and physical capital are respectively used as proxies for investments in human capital and structural capital, whereas gross margins are proxies for product/service offering complexity. Consequently, SDR broadly reflects three salient complementary choices of SOM design strategy. We test the effects of brick and mortar chain store retailers' SDR on current and future firm performance using publically available panel data collected from Compustat and the University of Michigan American Customer Satisfaction Index databases for the period 1996-2011. We find that retailers that fail to keep pace with investments in both structural and human capital exhibit short-term financial benefits, but have worse ongoing operational performance. These findings corroborate the importance of managers strategically maintaining the complementarity of design-related choices for improving and maintaining business performance."
2072,"A Dynamic Disaggregation Approach to Approximate Linear Programs for Network Revenue Management","Vossen, Thomas W. M. and Zhang, Dan","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","469-487","2015","MAR","Network Revenue Management;Choice Behavior;Dynamic Programming;Linear Programming","","The linear programming approach to approximate dynamic programming has received considerable attention in the recent network revenue management (RM) literature. A major challenge of the approach lies in solving the resulting approximate linear programs (ALPs), which often have a huge number of constraints and/or variables. Starting from a recently developed compact affine ALP for network RM, we develop a novel dynamic disaggregation algorithm to solve the problem, which combines column and constraint generation and exploits the structure of the underlying problem. We show that the formulation can be further tightened by considering structural properties satisfied by an optimal solution. We prove that the sum of dynamic bid-prices across resources is concave over time. We also give a counterexample to demonstrate that the dynamic bid-prices of individual resources are not concave in general. Numerical experiments demonstrate that dynamic disaggregation is often orders of magnitude faster than existing algorithms in the literature for problem instances with and without choice. In addition, adding the concavity constraints can further speed up the algorithm, often by an order of magnitude, for problem instances with choice."
2073,"Remanufactured Products in Closed-Loop Supply Chains for Consumer Goods","Abbey, James D. and Meloy, Margaret G. and Guide, Jr., V. Daniel R. and Atalay, Selin","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","488-503","2015","MAR","Closed-Loop Supply Chains;Sustainability;Remanufacturing;Consumer Products","","This study empirically investigates consumer perceptions of remanufactured consumer products in closed-loop supply chains. A multi-study approach led to increasing levels of measure refinement and facilitated examination of various assumptions researchers have made about the consumer market for remanufactured products. Based in part on the measure building studies, an experimental study examined remanufactured product perceptions from a national panel of consumers. The consumers responded to remanufactured product descriptions that manipulated price discount and brand equity. The results indicate that discounting had a consistently positive, linear effect on remanufactured product attractiveness. Curiously, the brand equity manipulation proved less important to consumers than specific remanufactured product quality perceptions. The results also show that green consumers and consumers who consider remanufactured products green typically found remanufactured products significantly more attractive. Finally, the findings introduce the concept of negative attribute perceptions, such as disgust, that had a significantly detrimental effect on remanufactured product attractiveness."
2074,"Optimal Software Free Trial Strategy: Limited Version, Time-locked, or Hybrid?","Cheng, Hsing Kenneth and Li, Shengli and Liu, Yipeng","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","504-517","2015","MAR","Software Free Trial;Network Effects;Hybrid Free Trial","","Limited version, time-locked, and hybrid are three software free trial strategies employed by software firms to exploit increased installed base and/or reduction of consumers' uncertainty about software quality. We develop an analytical model to examine these three software free trial strategies. We find that the hybrid strategy weakly dominates the limited and time-locked versions, and the intensity of the network effects is a key factor determining which strategy is optimal."
2075,"All You Need Is Trust? An Examination of Inter-organizational Supply Chain Projects","Brinkhoff, Andreas and Oezer, Oezalp and Sargut, Goekce","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","181-200","2015","FEB","Trust;Asymmetric Dependence;Supply Chain Projects;Project Management;Performance","","This study examines the antecedents of supply chain project success. We first propose and test a model that describes the role of relationship-level factors (trust and asymmetric dependence) and project-level factors (between-firm communication and within-firm commitment) in determining supply chain project success. We find that project-level factors completely mediate the effect of trust on project success. We conclude that trust, despite being a stronger predictor compared to asymmetric dependence, is necessary but not sufficient for supply chain project success. We then proceed to further explore the role of these factors by introducing a categorical scheme that differentiates supply chain projects based on the decision rights configuration of each project. This categorization enables us to explore how relationship-level and project-level factors can have different impact on performance based on the characteristics of a supply chain project. The findings offer insights into how to effectively manage supply chain projects and inter-firm alliances."
2076,"Estimating the Impact of Understaffing on Sales and Profitability in Retail Stores","Mani, Vidya and Kesavan, Saravanan and Swaminathan, Jayashankar M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","201-218","2015","FEB","Data Analytics;Retail Staffing;Store Performance","","In this study, we use hourly data on store traffic, sales, and labor from 41 stores of a large retail chain to identify the extent of understaffing in retail stores and quantify its impact on sales and profitability. Using an empirical model motivated from queueing theory, we calculate the benchmark staffing level for each store, and establish the presence of systematic understaffing during peak hours. We find that all 41 stores in our sample are systematically understaffed during a 3-hour peak period. Eliminating understaffing in these stores can result in a significant increase in sales and profitability in these stores. Also, we examine the extent to which forecasting errors and scheduling constraints drive understaffing in retail stores and quantify their relative impacts on store profits for the retailer in our study."
2077,"Promotion Planning and Supply Chain Contracting in a High-Low Pricing Environment","Breiter, Andreas and Huchzermeier, Arnd","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","219-236","2015","FEB","Supply Chain Management;Risk Management;Price Promotions;Retailing","","Demand forecast errors threaten the profitability of high-low price promotion strategies. This article shows how to match demand and supply effectively by means of two-segment demand forecasting and supply contracts. We find that demand depends on the path of past retail prices, which leads to only a limited number of reachable demand states. However, forecast errors cannot be entirely eliminated because competitive promotions entail some degree of random (i.e., last-minute) pricing. A hedging approach can be deployed to distribute demand risk efficiently over multiple promotional campaigns and within the supply chain. A retailer that employs a portfolio of forward, option, and spot contracts can avoid both stockouts and excess inventories while achieving the first-best solution and Pareto improvements. We provide an improved forecasting method as well as stochastic programs to solve for optimal production and purchasing policies such that the right amount of inventory is available at the right time. By connecting a stockpiling model of demand with the supply side, we derive insights on optimal risk management strategies for both manufacturers and retailers in a market environment characterized by frequent price promotions and multiple discount levels. We employ a data set of the German retail market for a key generator of store trafficnamely, diapers."
2078,"Contracting for Capacity under Renegotiation: Partner Preferences and the Value of Anticipating Renegotiation","Kemahlioglu-Ziya, Eda","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","237-252","2015","FEB","Supply Chain Management;Fixed-Quantity Contract;Contract Renegotiation;Cooperative Game Theory;Egalitarian Rule","","This paper studies contract renegotiation in a stylized supply chain model. Two original equipment manufacturers (OEMs) sign fixed-quantity contracts with a contract manufacturer (CM) prior to demand realization. Contract renegotiation after demand realization allows the OEMs to use capacity that is more or less than what they contracted for. We assume that the extra profit due to efficient allocation of capacity is allocated to the supply chain parties according to the egalitarian rule and investigate when an OEM's expected post-renegotiation profit is maximized. We aim to understand how an OEM's expected post-renegotiation profit is affected by her ability to negotiate a low wholesale price in the initial contract as well as the ability of the other OEM to do the same. Regardless of whether renegotiation is anticipated or not at the time of the initial contract, we find that an OEM, who had weak buyer power vis-a-vis the CM and was unable to negotiate a low wholesale price in the initial contract, may benefit more from renegotiation than a stronger OEM. In addition, we show that how the expected post-renegotiation profit of an OEM changes with demand variance or anticipating renegotiation depends on the strength of the OEM's buyer power. Finally, we numerically test the robustness of our results in a supply chain with three OEMs and also identify when the OEMs prefer to leave the CM out of the renegotiation."
2079,"The Effectiveness of Management-By-Walking-Around: A Randomized Field Study","Tucker, Anita L. and Singer, Sara J.","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","253-271","2015","FEB","Health Care;Implementation Research;Patient Safety;Quality Improvement;Survey Research","","Management-by-walking-around (MBWA) is a widely adopted technique in hospitals that involves senior managers directly observing frontline work. However, few studies have rigorously examined its impact on organizational outcomes. This study examines an improvement program based on MBWA in which senior managers observe frontline employees, solicit ideas about improvement opportunities, and work with staff to resolve the issues. We randomly selected hospitals to implement the 18-month-long, MBWA-based improvement program; 56 work areas participated. We find that the program, on average, had a negative impact on performance. To explain this surprising finding, we use mixed methods to examine the impact of the work area's problem-solving approach. Results suggest that prioritizing easy-to-solve problems was associated with improved performance. We believe this was because it resulted in greater action-taking. A different approach was characterized by prioritizing high-value problems, which was not successful in our study. We also find that assigning to senior managers responsibility for ensuring that identified problems get resolved resulted in better performance. Overall, our study suggests that senior managers' physical presence in their organizations' front lines was not helpful unless it enabled active problem solving."
2080,"Does a Store Brand Always Hurt the Manufacturer of a Competing National Brand?","Ru, Jun and Shi, Ruixia and Zhang, Jun","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","272-286","2015","FEB","Store Brand;Supply Chain;Power Retailer;Vertical Strategic Interaction","","It is generally believed that store brands hurt the manufacturers of competing national brands while benefiting retailers. In this study, we challenge this notion by studying the impacts of a store brand when it is introduced by a power retailer. We show that a store brand may benefit the manufacturer when the interaction between the manufacturer and retailer is modeled as a retailer-led Stackelberg game. This phenomenon occurs because the store brand changes the nature of the strategic interaction between the manufacturer and retailer in our model. In particular, while the interaction is always vertical strategic substitutability without a store brand, it may become vertical strategic independence with one. With the store brand, the demand for the national brand becomes larger, and the wholesale price for the national brand may increase, both of which benefit the manufacturer. Finally, the store brand may lessen the double marginalization problem of the supply chain for the national brand in the retailer-led Stackelberg game, but does so in an unconventional way: The reduction in the double marginalization effect may come from a lowered retail markup instead of a lowered wholesale price. Our results reconcile some discrepancies between theoretical predictions and empirical findings regarding the impacts of store brands on manufacturers."
2081,"Managing Supplier Competition and Sourcing Sequence for Component Manufacturing","Jiang, Li","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","287-310","2015","FEB","Supplier Competition;Sequential Decision;Sourcing;Reverse Auction","","We consider a setting in which a manufacturer sequentially sources two components and uses reverse auction to select a supplier with the lowest bidding price for each component. The manufacturer chooses a quantity to order from each supplier and a price for selling the final product. We show that the interplay between the direct competition faced by suppliers in providing their respective components and the sequence whereby the manufacturer sources components influence system performance in a subtle, and sometimes dramatic, way. As the direct competition for the early sourced component intensifies, the profit of its supplier will deteriorate while the profits of the other firms will improve. As the direct competition for the late sourced component intensifies, however, the profit of its supplier may improve, and the profits of the other supplier, the manufacturer, and the system can all decrease. Compared with when the manufacturer simultaneously sources the components, sequentially sourcing the components can benefit the manufacturer and every supplier. Furthermore, all the channel parties can unanimously agree on a specific sourcing sequence. All of these signify the importance for manufacturers to take appropriate measures to manage their sourcing procedures and the competition environments faced by their suppliers."
2082,"Benefits of Hybrid Lateral Transshipments in Multi-Item Inventory Systems under Periodic Replenishment","Glazebrook, Kevin and Paterson, Colin and Rauscher, Sandra and Archibald, Thomas","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","311-324","2015","FEB","Inventory Control;Multi-Item;Lateral Transshipments;Dynamic Programming","","Lateral transshipments are a method of responding to shortages of stock in a network of inventory-holding locations. Conventional reactive approaches only seek to meet immediate shortages. The study proposes hybrid transshipments which exploit economies of scale by moving additional stock between locations to prevent future shortages in addition to meeting immediate ones. The setting considered is motivated by retailers who operate networks of outlets supplying car parts via a system of periodic replenishment. It is novel in allowing non-stationary stochastic demand and general patterns of dependence between multiple item types. The generality of our work makes it widely applicable. We develop an easy-to-compute quasi-myopic heuristic for determining how hybrid transshipments should be made. We obtain simple characterizations of the heuristic and demonstrate its strong cost performance in both small and large networks in an extensive numerical study."
2083,"An Experimental Investigation of Pull Contracts in Supply Chains","Davis, Andrew M.","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","325-340","2015","FEB","Behavioral Operations Management;Pull Contracts;Supply Chain Management;Loss Aversion And Reference Dependence","","In this study, I investigate supply chain contracts in a setting where a supplier uses its inventory to directly satisfy a retailer's demand. These pull contracts have increased in popularity in practice but have not been studied experimentally. In a controlled laboratory setting, I evaluate a wholesale price contract and two coordinating contracts. The data suggest that the benefit of the two coordinating contracts over the wholesale price contract is less than the standard theory predicts, and that retailers, in the two coordinating contracts, exhibit a systematic bias of setting the coordinating parameter too low, and the wholesale price too high, relative to the normative benchmarks. In an effort to explain this deviation, I explore three behavioral models and find that loss aversion and reference dependence fit the data well. I empirically test this result in a follow-up experiment, which directly controls for loss aversion and reference dependence, and observe that retailers make significantly better decisions. Lastly, I administer a number of experiments which reduce the complexity of the problem, curtail the amount of risk, and increase the level of decision support, and find that none improve decisions relative to the treatment that controls for loss aversion and reference dependence."
2084,"The Pursuit of Productivity","Schmenner, Roger W.","PRODUCTION AND OPERATIONS MANAGEMENT","24","2","341-350","2015","FEB","Productivity;Business History;Theory Of Swift;Even Flow;Automation;Economies Of Scale","","This study names a pantheon of entrepreneurs and managers who have introduced a range of far-reaching productivity innovations throughout modern history. The thread tying together all of the innovations, in whatever sector of the economy one examines, is the theory of swift, even flow. The study argues why swift, even flow explains the power and long-lasting nature of these innovations and why other factors thought by some to affect productivity fall short."
2085,"Preventing and Diagnosing Colorectal Cancer with a Limited Colonoscopy Resource","Gunes, Evrim Didem and Ormeci, Egemen Lerzan and Kunduzcu, Derya","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","1-20","2015","JAN","Colorectal Cancer;Screening;Colonoscopy;Resource Allocation;Compartmental Model","","This paper explores how the capacity of colonoscopy services should be allocated for screening and diagnosis of colorectal cancer to improve health outcomes. Both of these services are important since screening prevents cancer by removing polyps, while diagnosis is required to start treatment for cancer. This paper first presents a basic compartmental model to illustrate the trade-off between these two analytically. Further, a more realistic population dynamics model with resource constraints is introduced for colorectal cancer screening and analyzed numerically. The best resource allocation decisions are investigated with the objectives of minimizing mortality or incidence rates. We provide a sensitivity analysis with respect to policy and disease-related parameters. We conclude that to minimize mortality, the capacity should be rationed to ensure that the wait for diagnosis is at reasonable levels. When the relevant performance measure is the incidence rate, screening is allocated more capacity compared to the case with mortality rate measure. We also show that benefits from increasing compliance to screening programs can only be realized if there is sufficient service capacity."
2086,"The Timing of Capacity Investment with Lead Times: When Do Firms Act in Unison?","Anderson, Edward James and Yang, Shu-Jung Sunny","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","21-41","2015","JAN","Capacity Investment Timing;Lead Time;Volume Flexibility;Existing Capacity;Operations Strategy","","We study competitive capacity investment for the emergence of a new market. Firms may invest either in capacity leading demand or in capacity lagging demand at different costs. We show how the lead time and other operational factors including volume flexibility, existing capacity, and demand uncertainty impact equilibrium outcomes. Our results indicate that a type of bandwagon behavior is the most likely equilibrium outcome: if both firms are going to invest, then they are most likely to act in unison. Contrary to much received wisdom, we show that leader-follower behavior is very uncommon in equilibrium where firms do not have volume flexibility, and will not occur at all if lead times are sufficiently short. On the other hand, if there is volume flexibility in production, then the likelihood of this sequential investment behavior increases. Our findings underscore the importance of operational characteristics in determining the competitive dynamics of capacity investment timing."
2087,"Production and Sales Planning in Capacitated New Product Introductions","Bilginer, Oezlem and Erhun, Feryal","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","42-53","2015","JAN","Product Introductions;Bass Diffusion Model;Capacity;Myopic Policy;Build-Up Policy","","How should a firm with limited capacity introduce a new product? Should it introduce the product as soon as possible or delay introduction to build up inventory? How do the product and market characteristics affect the firm's decisions? To answer such questions, we analyze new product introductions under capacity restrictions using a two-period model with diffusion-type demand. Combining marketing and operations management decisions in a stylized model, we optimize the production and sales plans of the firm for a single product. We identify four different introduction policies and show that when the holding cost is low and the capacity is low to moderate, a (partial) build-up policy is indeed optimal if consumers are sensitive to delay. Under such a policy, the firm (partially) delays the introduction of its product and incurs short-term backlog costs to manage its future demand and total costs more effectively. However, as either the holding cost or the capacity increases, or consumer sensitivity to delay decreases, the build-up policy starts to lose its appeal, and instead, the firm prefers an immediate product introduction. We extend our analysis by studying the optimal capacity decision of the firm and show that capacity shortages may be intentional."
2088,"Managing Perishables with Time and Temperature History","Ketzenberg, Michael and Bloemhof, Jacqueline and Gaukler, Gary","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","54-70","2015","JAN","Perishable Inventory;Value Of Information;Rfid;Simulation","","We address the use and value of time and temperature information to manage perishables in the context of a retailer that sells a random lifetime product subject to stochastic demand and lost sales. The product's lifetime is largely determined by the temperature history and the flow time through the supply chain. We compare the case in which information on flow time and temperature history is available and used for inventory management to a base case in which such information is not available. We formulate the two cases as Markov Decision Processes and evaluate the value of information through an extensive simulation using representative, real world supply chain parameters."
2089,"A Comparison of Product Take-Back Compliance Schemes","Esenduran, Goekce and Kemahlioglu-Ziya, Eda","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","71-88","2015","JAN","Take-Back Regulation;Recycling;Environment;Sequential Game;Nash Equilibrium","","Product take-back regulation, under which firms finance the collection and treatment of their end-of-life products, is a widely used environmental program. One of the most common compliance schemes is collectively with cost allocation by market share. As an alternative, individual compliance scheme is considered. Assuming that firms can choose their compliance scheme, we compare these two schemes with respect to the costs they impose on firms and environmental benefits. We show that high collection targets and large market shares among firms in a collective compliance scheme make it more cost-effective. From an environmental benefits perspective, the prevailing intuition is that collection rates will be higher under collective schemes but individual compliance will provide more incentive for higher recyclability levels. Our results challenge both of these premises. We identify conditions under which collection rates are higher when firms comply individually and recyclability levels are higher when firms comply collectively and allocate costs with respect to market shares."
2090,"Supplier Encroachment as an Enhancement or a Hindrance to Nonlinear Pricing","Li, Zhuoxin and Gilbert, Stephen M. and Lai, Guoming","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","89-109","2015","JAN","Supplier Encroachment;Information Asymmetry;Nonlinear Pricing","","The objective of this study was to extend existing understanding of supplier encroachment to contexts in which there is information asymmetry and the supplier can use nonlinear pricing. Prior research has shown that supplier encroachment can mitigate double marginalization and thus benefit both the supplier and the reseller. However, under symmetric information, this benefit disappears if the supplier can use nonlinear pricing. In our model, the reseller observes the true market size while the supplier knows only the prior distribution, that is, a seemingly ideal setting for implementing mechanism design through nonlinear pricing. We first show that, because encroachment capability enables the supplier to make an ex post output decision, it fundamentally alters the structure of the optimal nonlinear pricing policy. In addition to the usual downward distortion effect, where the reseller may purchase less than the efficient quantity, we also have the possibility for upward distortion. Thus, under asymmetric information and nonlinear pricing, supplier encroachment has two opposing effects. On one hand, the ability to shift sales to the direct channel allows the supplier to reduce information rents with less sacrifice of efficiency; but on the other hand, by introducing the possibility of her own opportunistic behavior, it can result in upward distortion of the quantities sold through the reselling channel, which is a new source of inefficiency. Depending upon the relative efficiency of the reselling channel and the demand distribution, either of these two effects may dominate and the supplier's ability to encroach may either benefit or hurt both the supplier and the reseller."
2091,"A Newsvendor Who Chooses Informational Effort","Marschak, Thomas and Shanthikumar, J. George and Zhou, Junjie","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","110-133","2015","JAN","Newsvendor;Inventory Management;Information Gathering;Demand Forecasting","","We study a newsvendor who can acquire the services of a forecaster, or, more generally, an information gatherer (IG) to improve his information about demand. When the IG's effort increases, does the average ex ante order quantity rise or fall? Do average ex post sales rise or fall? Improvements in information technology and in the services offered by forecasters provide motivation for the study of these questions. Much depends on our model of the IG and his efforts. We study an IG who sends a signal to a classic single-period newsvendor. The signal defines the newsvendor's posterior probability distribution on the possible demands and the newsvendor uses that posterior to calculate the optimal order. Each of the possible posteriors is a scale/location transform of the same base distribution. When the IG works harder, the average scale parameter drops. Higher IG effort is always useful to the newsvendor. We show that there is a critical value of order cost. For costs on one side of this value more IG effort leads to a higher average ex ante order and for costs on the other side to a lower average order. But for all costs, more IG effort leads to higher average ex post sales. We obtain analogous results for a regret-averse newsvendor who suffers a penalty that is a nonlinear function of the discrepancy between quantity ordered and true demand."
2092,"The Impact of Contracts and Competition on Upstream Innovation in a Supply Chain","Wang, Jingqi and Shin, Hyoduk","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","134-146","2015","JAN","Supply Chain Management;Innovation;Quality;Contracts;Competition","","We consider a supply chain with an upstream supplier who invests in innovation and a downstream manufacturer who sells to consumers. We study the impact of supply chain contracts with endogenous upstream innovation, focusing on three different contract scenarios: (i) a wholesale price contract, (ii) a quality-dependent wholesale price contract, and (iii) a revenue-sharing contract. We confirm that the revenue-sharing contract can coordinate supply chain decisions including the innovation investment, whereas the other two contracts may result in underinvestment in innovation. However, the downstream manufacturer does not always prefer the revenue-sharing contract; the manufacturer's profit can be higher with a quality-dependent wholesale price contract than with a revenue-sharing contract, specifically when the upstream supplier's innovation cost is low. We then extend our model to incorporate upstream competition between suppliers. By inviting upstream competition, with the wholesale price contract, the manufacturer can increase his profit substantially. Furthermore, under upstream competition, the revenue-sharing contract coordinates the supply chain, and results in an optimal contract form for the manufacturer when suppliers are symmetric. We also analyze the case of complementary components suppliers, and show that most of our results are robust."
2093,"An Analysis of Scoring and Buyer-Determined Procurement Auctions","Santamaria, Natalia","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","147-158","2015","JAN","Procurement Auctions;Buyer-Determined Auctions;Bidding Strategies","","In procurement auctions, the object for sale is a contract, bidders are suppliers, and the bid taker is a buyer. The suppliers bidding for the contract are usually the current supplier (the incumbent) and a group of potential new suppliers (the entrants). As the buyer has an ongoing relationship with the incumbent, he needs to adjust the bids of the entrants to include non-price attributes, such as the switching costs. The buyer can run a scoring auction, in which suppliers compete on the adjusted bids or scores, or, he can run a buyer-determined auction, in which suppliers compete on the price, and the buyer adjusts a certain number of the bids with the non-price attributes after the auction to determine the winner. Unless the incumbent has a significant cost advantage over the entrants, I find that the scoring auction yields a lower average cost for the buyer, if the non-price attributes are available. If the non-price attributes are difficult or expensive to obtain, the buyer could run a buyer-determined auction adjusting only the lowest price bid."
2094,"Contractors' and Agency Decisions and Policy Implications in A plus B Bidding","Gupta, Diwakar and Snir, Eli M. and Chen, Yibin","PRODUCTION AND OPERATIONS MANAGEMENT","24","1","159-177","2015","JAN","Auctions;Time-Based Incentives;A Plus B Bidding;Procurement Policy","","The focus of this study is on the A+B transportation procurement mechanism, which uses the proposed cost (A component) and the proposed time (B component) to score contractors' bids. Empirical studies have shown that this mechanism shortens project durations. We use normative models to study the effect of certain discretionary parameters set by state transportation agencies on contractors' equilibrium bidding strategies, winner selection, and actual completion times. We model the bidding environment in detail including multi-dimensional bids, contractors' uncertainty about completion times, and reputation cost. The latter refers to a private penalty that accrues to tardy contractors from increased cost of posting bonds and reduced prospects of winning future projects. Our model explains why contractors may skew line-item bids and why winners frequently finish earlier than bid. It has several policy implications as well. For example, we recommend that agencies set the daily incentive, disincentive, and road user cost to be equal and not cap incentives. This is a departure from current practice, where incentives are often capped and weaker than penalties. Furthermore, we show that agencies may be justified in setting daily road user cost strictly smaller than the true cost of traffic disruption during construction."
2095,"Transfer Pricing and Sourcing Strategies for Multinational Firms","Shunko, Masha and Debo, Laurens and Gavirneni, Srinagesh","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2043-2057","2014","DEC","Transfer Pricing;International Tax;Multinational Firms;Global Sourcing","","Taking advantage of low tax rates using transfer pricing and taking advantage of low production costs using offshoring are two strategies multinational firms (MNFs) use to increase profits. We identify an important trade-off that MNFs face in setting their transfer prices: the conflict between (i) the incentive role and (ii) the tax role of the transfer price. For MNFs, we find the profit-maximizing transfer-pricing strategies that motivate divisional management to (i) make good sourcing decisions and (ii) take advantage of favorable tax rates. We quantify the absolute and relative maximum inefficiency in terms of the after-tax MNF's profit change from using a single transfer-pricing system as compared to the dual transfer-pricing system. We show that the highest relative loss is attained when the average sourcing cost and the tax differential are high. We demonstrate that the highest absolute loss is attained when the average outsourcing cost is approximately equal to the offshoring cost. We extend our results to two practical variations in MNF structures: an MNF that faces operational constraints on its offshoring capacity and an MNF that uses compensation contracts linked to after-tax firm-wide profits. Our insights help MNFs' managers identify when to use single and dual transfer-pricing systems."
2096,"Dynamic Pricing and Inventory Management with Dual Suppliers of Different Lead Times and Disruption Risks","Gong, Xiting and Chao, Xiuli and Zheng, Shaohui","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2058-2074","2014","DEC","Inventory Control;Source Diversification;Optimal Pricing;Supplier Disruption;List-Price With Markdown Policy","","It is common for a firm to make use of multiple suppliers of different delivery lead times, reliabilities, and costs. In this study, we are concerned with the joint pricing and inventory control problem for such a firm that has a quick-response supplier and a regular supplier that both suffer random disruptions, and faces price-sensitive random demands. We aim at characterizing the optimal ordering and pricing policies in each period over a planning horizon, and analyzing the impacts of supply source diversification. We show that, when both suppliers are unreliable, the optimal inventory policy in each period is a reorder point policy and the optimal price is decreasing in the starting inventory level in that period. In addition, we show that having supply source diversification or higher supplier reliability increases the firm's optimal profit and lowers the optimal selling price. We also demonstrate that, with the selling price as a decision, a supplier may receive even more orders from the firm after an additional supplier is introduced. For the special case where the quick-response supplier is perfectly reliable, we further show that the optimal inventory policy is of a base-stock type and the optimal pricing policy is a list-price policy with markdowns."
2097,"Optimal Procurement Design of an Assembly Supply Chain with Information Asymmetry","Fang, Xiang and Ru, Jun and Wang, Yunzeng","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2075-2088","2014","DEC","Mechanism Design;Private Cost Information;Decentralized Assembly Systems;Demand Uncertainty","","We study a decentralized assembly supply chain in which an assembler (she) assembles a set of n components, each produced by a different supplier (he), into a final product to satisfy an uncertain market demand. Each supplier holds private cost information to himself, for which the assembler only has a subjective estimate. Furthermore, the assembler believes that the suppliers' costs follow a joint discrete probability distribution. The assembler aims to design an optimal menu of contracts to maximize her own expected profit. The assembler's problem is a complex multi-dimensional constrained optimization problem. We prove that there exists a unique optimal menu of contracts for the assembler, and we further develop an efficient algorithm with a complexity of O(n) to compute the optimal contract. In addition, we conduct a comprehensive sensitivity analysis to analyze how environmental parameters affect individual firm's performance and the value of information to the assembler, to each supplier, and to the supply chain. Our results suggest that each supplier's private cost information becomes more valuable to the assembler and each supplier when the average market demand increases or when the final product unit revenue increases. Surprisingly, when a supplier's cost volatility increases and its mean remains the same, the value of information to the assembler or to each supplier does not necessarily increase. Furthermore, we show that when the suppliers' cost distributions become more positively correlated, the suppliers are always worse off, but the assembler is better off. However, the value of information for the assembler might increase or decrease."
2098,"Pay-Back-Revenue-Sharing Contract in Coordinating Supply Chains with Random Yield","Tang, Sammi Y. and Kouvelis, Panos","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2089-2102","2014","DEC","Supply Chain Coordination;Yield Uncertainty;Demand Uncertainty","","We consider coordination issues in supply chains where supplier's production process is subject to random yield losses. For a simple supply chain with a single supplier and retailer facing deterministic demand, a pay back contract which has the retailer paying a discount price for the supplier's excess units can provide the right incentive for the supplier to increase his production size and achieve coordination. Building upon this result, we consider coordination issues for two other supply chains: one with competing retailers, the other with stochastic demand. When retailers compete for both demand and supply, they tend to over-order. We show that a combination of a pay back and revenue sharing mechanism can coordinate the supply chain, with the pay back mechanism correcting the supplier's under-producing problem and the revenue sharing mechanism correcting the retailers' over-ordering problem. When demand is stochastic, we consider a modified pay-back-revenue-sharing contract under which the retailer agrees to not only purchase the supplier's excess output (beyond the retailer's order), but also share with the supplier a portion of the revenue made from the sales of the excess output. We show that this contract, by giving the supplier additional incentives in the form of revenue share, can achieve coordination."
2099,"Optimal Sourcing and Lead-Time Reduction under Evolutionary Demand Risk","de Treville, Suzanne and Schuerhoff, Norman and Trigeorgis, Lenos and Avanzi, Benjamin","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2103-2117","2014","DEC","Forecast Evolution;Lead-Time Reduction;Production Location Decision;Demand Volatility","","We develop a real-options model for optimizing production and sourcing choices under evolutionary supply-chain risk. We model lead time as an endogenous decision and calculate the cost differential required to compensate for the risk exposure coming from lead time. The shape of the resulting cost-differential frontier reveals the term structure of supply-chain risk premiums and provides guidance as to the potential value of lead-time reduction. Under constant demand volatility, the break-even cost differential increases in volatility and lead time at a decreasing rate, making incremental lead-time reduction less valuable than full lead-time reduction. Stochastic demand volatility increases the relative value of incremental lead-time reduction. When demand has a heavy right tail, the value of lead-time reduction depends on how extreme values of demand are incorporated into the forecasting process. The cost-differential frontier is invariant to discount rates, making the cost of capital irrelevant for choosing between lead times. We demonstrate the managerial implications of the model by applying it first to the classic Sport-Obermeyer case and then to a supplier-selection problem faced by a global manufacturer."
2100,"Differences in Retail Inventory Investment Behavior During Macroeconomic Shocks: Role of Service Level","Kesavan, Saravanan and Kushwaha, Tarun","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2118-2136","2014","DEC","Inventory Investment;Macroeconomic Shocks;Expansion;Contraction;Inventory Holding Cost;Stockout Cost;Service Level","","In this article, we analyze how retailers change their inventory investment behavior in response to macroeconomic shocks. We examine if service level, as measured by the ratio of stockout to inventory holding costs, can explain the differences in observed behavior across retailers. We use data on macroeconomic indicators and quarterly filings of US public retailers from 1985 to 2009 to estimate a dynamic model of short- and long-term impact of macroeconomic shocks on inventory investment. Our results show that retailers with a high service level increase their inventory investment significantly more than those with a low service level during expansion shocks. Conversely, retailers with a low service level curtail their inventory investment significantly more than those with a high service level during periods of economic contractions. Thus, we show that the aggregate change in inventory investment documented in prior macroeconomics research is driven by different sets of retailers, as predicted by newsvendor logic. We draw implications of our findings to retailers as well as their suppliers."
2101,"The Effect of Demand-Supply Mismatches on Firm Risk","Hendricks, Kevin B. and Singhal, Vinod R.","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2137-2151","2014","DEC","Demand-Supply Mismatch;Empirical Research;Equity Volatility;Information Asymmetry;Operating And Financial Leverage","","A supply chain management (SCM) system comprises many subsystems, including forecasting, order management, supplier management, procurement, production planning and control, warehousing and distribution, and product development. Demand-supply mismatches (DSMs) could indicate that some or all of these subsystems are not working as expected, creating uncertainties about the overall capabilities and effectiveness of the SCM system, which can increase firm risk. This article documents the effect of DSMs on firm risk as measured by equity volatility. Our sample consists of three different types of DSMs announced by publicly traded firms: production disruptions, excess inventory, and product introduction delays. We find that all three types of DSMs result in equity volatility increases. Over a 2-year period around the announcement date, we observe mean abnormal equity volatility increases of 5.62% for production disruptions, 11.19% for excess inventory, and 6.28% for product introduction delays. Volatility increases associated with excess inventory are significantly higher than the increases associated with production disruptions and product introduction delays. Across all three types of DSMs, volatility changes are positively correlated with changes in information asymmetry. The results provide some support that volatility changes are also correlated with changes in financial and operating leverage."
2102,"Quality Risk Ratings in Global Supply Chains","Zhou, Zach Zhizhong and Johnson, M. Eric","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2152-2162","2014","DEC","Quality Risk;Vendor Rating;Supplier Rating And Evaluation;Global Supply Chain;Analytical Modeling","","Extended enterprises face many challenges in managing the product quality of their suppliers. Consequently characterizing the quality risk posed by value-chain partners has become increasingly important. There have been several recent efforts to develop frameworks for rating the quality risk posed by suppliers. We develop an analytical model to examine the impact of such quality ratings on suppliers, manufacturers, and social welfare. While it might seem that quality ratings would benefit high-quality suppliers and hurt low-quality suppliers, we show that this is not always the case. We find that such quality ratings can hurt both types of suppliers or benefit both, depending on the market conditions. We also find that quality ratings do not always benefit the most demanding manufacturers who desire high-quality suppliers. Finally, we find that social welfare is not always improved by risk ratings. These results suggest that public policy initiatives addressing risk ratings must be carefully considered."
2103,"Linking Process Quality and Resource Usage: An Empirical Analysis","Andritsos, Dimitrios A. and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2163-2177","2014","DEC","Healthcare Operations;Healthcare Policy;Pay-For-Performance","","Motivated by an increasing adoption of evidence-based medical guidelines in the delivery of medical care, we examine whether increased adherence to such guidelines (typically referred to as higher process quality) is associated with reduced resource usage in the course of patient treatment. In this study, we develop a sample of US hospitals and use cardiac care as our context to empirically examine our questions. To measure a patient's resource usage, we use the total length of stay, which includes any additional inpatient stay necessitated by unplanned readmissions within thirty days after initial hospitalization. We find evidence that higher process quality, and more specifically its clinical (as opposed to its administrative) dimensions, are associated with a reduction in resource usage. Moreover, the standardization of care that is achieved via the implementation of medical guidelines, makes this effect more pronounced in less focused environments: higher process quality is more beneficial when the cardiac department's patient population is distributed across a wider range of medical conditions. We explore the implications of these findings for process-oriented pay-for-performance programs, which tie the reimbursement of hospitals to their adherence to evidence-based medical guidelines."
2104,"Life Is All about Timing: An Examination of Differences in Treatment Quality for Trauma Patients Based on Hospital Arrival Time","Anderson, David and Gao, Guodong (Gordon) and Golden, Bruce","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2178-2190","2014","DEC","Health Care;Service Quality;Time Of Day;Trauma Center","","In health care, most quality transparency and improvement programs focus on the quality variation across hospitals, while we know much less about within-hospital quality variation. This study examines one important factor that is associated with the fluctuation of quality of care in the same hospitalthe timing of patient arrival. We analyze data from the National Trauma Data Bank and find that patients arriving at the hospital during off-hours (6PM-6AM) receive significantly lower quality care than those who arrive during the daytime, as reflected in higher mortality rates, among other measures. More importantly, we try to uncover the mechanism for the quality variation. Interestingly, we find consistent evidence that the inferior care received during off-hours is not likely due to unobserved heterogeneity, disruptions in circadian rhythms, or delays in receiving treatment. Instead, it is more likely due to the limited availability of high-quality resources. This leads to a higher surgical complication rate, a higher likelihood of multiple surgeries, and longer patient length of stay in the intensive care unit. These findings have important implications for optimal resource allocation in hospitals to improve the quality-of-care delivery."
2105,"Measuring the Contribution of Workers' Health and Psychosocial Work-Environment on Production Efficiency","Odegaard, Fredrik and Roos, Pontus","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2191-2208","2014","DEC","Production Efficiency;Dea;Health Status;Psychosocial Work-Environment;Ordinal Data","","Increasingly many firms have started to implement programs intended to improve the workers' health and the psychosocial work-environment, as well as other attributes of labor quality. Motivated by the need for evaluating to what extent the programs affect a firm's productivity performance, this study discusses a model for analyzing the contribution of labor quality attributes toward firm productivity. To assess the contribution from the labor quality attributes, we model firm productivity as the outcome of two separate processes within a firm: the physical production process and the labor quality process. Firm productivity is measured by a Malmquist-like productivity index and is computed by Data Envelopment Analysis. Based on bootstrap methods we analyze potential statistical bias and provide bias-corrected productivity estimates. The labor quality attributes are first modeled at an individual worker level as latent variables using Item Response Theory, and then aggregated to a firm-level. The model is empirically validated using data from three manufacturing plants that participated in a coordinated worksite health promotion program. Over a 4-year period (2000-2003), we observed a general improvement in efficiency of 2-5%, half of which could be attributed to an improvement in workers' health and psychosocial work-environment. A key benefit with the model is that it is practical, easy to implement, and very fast to compute. The model also constructively contributes to the discourse on sustainability by providing a framework for deriving meaningful metrics and providing tangible measurements on the effect of sustainability-related issues."
2106,"Panel Size and Overbooking Decisions for Appointment-Based Services under Patient No-Shows","Liu, Nan and Ziya, Serhan","PRODUCTION AND OPERATIONS MANAGEMENT","23","12","2209-2223","2014","DEC","Service Operations;Health Care Management;Queueing Theory;Appointment Scheduling","","Many service systems that work with appointments, particularly those in healthcare, suffer from high no-show rates. While there are many reasons why patients become no-shows, empirical studies found that the probability of a patient being a no-show typically increases with the patient's appointment delay, i.e., the time between the call for the appointment and the appointment date. This paper investigates how demand and capacity control decisions should be made while taking this relationship into account. We use stylized single server queueing models to model the appointments scheduled for a provider, and consider two different problems. In the first problem, the service capacity is fixed and the decision variable is the panel size; in the second problem, both the panel size and the service capacity (i.e., overbooking level) are decision variables. The objective in both cases is to maximize some net reward function, which reduces to system throughput for the first problem. We give partial or complete characterizations for the optimal decisions, and use these characterizations to provide insights into how optimal decisions depend on patient's no-show behavior in regards to their appointment delay. These insights especially provide guidance to service providers who are already engaged in or considering interventions such as sending reminders in order to decrease no-show probabilities. We find that in addition to the magnitudes of patient show-up probabilities, patients' sensitivity to incremental delays is an important determinant of how demand and capacity decisions should be adjusted in response to anticipated changes in patients' no-show behavior."
2107,"Quality Testing and Product Rationing by Input Suppliers","Arya, Anil and Gong, Ning and Ramanan, Ram N. V.","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1835-1844","2014","NOV","Voluntary Disclosure;Quality Testing;Perceived Quality;Product Rationing","","Quality testing by suppliers has significant ramifications for downstream supply chain participants and retail consumers. This article focuses on such implications accounting for the fact that suppliers often enjoy discretion in quality testing and reporting. Under a discretionary testing and reporting environment, we show that a supplier can improve the market's perception of product quality by engaging in self-imposed production cuts. Production cuts dampen supplier incentives to engage in excessive quality testing, putting the supplier and the market on a more equal information footing. This reduces the market's need to skeptically discount product quality to protect itself. The improved market perception, then, reduces quality testing demand, introducing cost savings. The result that costly production cuts can improve quality perceptions indicates that the groundwork for influencing market perceptions may have to be laid upfront, even prior to acquiring private information, providing a contrast to routine signaling models."
2108,"Advertising in Asymmetric Competing Supply Chains","Liu, Bin and Cai, Gangshu (George) and Tsay, Andy A.","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1845-1858","2014","NOV","Manufacturer Advertising;Retailer Advertising;Cost Sharing;Supply Chain Competition;Game Theory;Co-Op Advertising","","Advertising is a crucial tool for demand creation and market expansion. When a manufacturer uses a retailer as a channel for reaching end customers, the advertising strategy takes on an additional dimension: which party will perform the advertising to end customers. Cost sharing (co-operative advertising) arrangements proliferate the option by decoupling the execution of the advertising from its funding. We examine the efficacy of cost sharing in a model of two competing manufacturer-retailer supply chains who sell partially substitutable products that may differ in market size. Some counterintuitive findings suggest that the firms performing the advertising would rather bear the costs entirely if this protects their unit profit margin. We also evaluate the implications of advertising strategy for overall supply chain efficiency and consumer welfare."
2109,"Shareholder Value Effects of Voluntary Emissions Reduction","Jacobs, Brian W.","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1859-1874","2014","NOV","Environmental Performance;Emissions Reduction;Stock Market Reaction","","The relationship between emissions reduction and firm financial performance has been studied with mixed results. We consider potential sources of this ambiguity by examining announcements of voluntary emissions reduction (VER) from 1990 to 2009. We measure the stock market reaction associated with VER announcements to estimate the effects of time, emissions type, and whether the reduction was announced ex ante or ex post. We find that the market reaction to VER significantly decreased over time. The changing nature of the market reaction to VER over time highlights the importance of evaluating the financial impact of any VER in the current context rather than relying on past findings. We also find that the market reaction is more positive if the reduction is for greenhouse gas (GHG) rather than other emissions types. In light of the increasing concern with GHGs, this finding should be welcome news for managers. Last, we find a more positive market reaction for VER announcements that are pledges or statements of intent rather than realized achievements of VER. Managers contemplating VER might find benefit (and at least no harm) in announcing their intent to reduce emissions rather than waiting until they have achieved the reduction."
2110,"Of Physics and Factory Physics","Spearman, Mark L.","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1875-1885","2014","NOV","Production-Inventory Models;Brownian Motion;Uncertainty","","The Principle of Least Action is the foundational principle of fundamental physics. Application of this principle to the supply chain naturally results in an uncertainty principle linking variation in production to variation in net-inventory. The model also provides an easy means of determining the stationary distribution of net-inventory for a variety of control strategies. The formalism results in a control strategy that outperforms commonly used control methods."
2111,"The Impact of Complexity on Knowledge Transfer in Manufacturing Networks","Lang, Markus and Deflorin, Patricia and Dietl, Helmut and Lucas, Eric","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1886-1898","2014","NOV","Manufacturing Network;Knowledge Transfer;Lead Factory;Complexity;Nk Model","","Coordinating knowledge transfer within multi-plant manufacturing networks is a challenging task. Using a computational model, we examine when it is beneficial to create production knowledge within a central unit, the lead factory, and transfer it to geographically dispersed plants. We demonstrate that the knowledge transfer generates a trade-off between a positive cost-saving effect due to fewer adaptations in each plant, and a negative transfer cost effect due to the costly knowledge transfer itself. The complexity of the production process moderates the performance implications of the knowledge transfer because it determines the relative strength of these two effects. For production processes with low complexity, knowledge transfer can engender superior network performance. Here, an optimal extent of knowledge transfer exists, and thus, a complete knowledge transfer is not performance maximizing. For production processes with medium and high levels of complexity, performance is reduced rather than enhanced through knowledge transfer so that it is optimal not to transfer any knowledge from the lead factory to the plants. While we analyze knowledge transfer within a manufacturing network, our results are transferable to other settings that consist of a knowledge sending and receiving unit."
2112,"Balancing Revenues and Repair Costs under Partial Information about Product Reliability","Ding, Chao and Rusmevichientong, Paat and Topaloglu, Huseyin","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1899-1918","2014","NOV","Revenue Management;Reliability;Marketing;Optimal Stopping;Bayesian Learning","","We consider the problem faced by a company selling a product with warranty and under partial information about the product reliability. The product can fail from multiple failure types, each of which is associated with an inherently different repair cost. If the product fails within the warranty duration, then the company is required to pay the repair cost. The company does not know the probabilities associated with different failure types, but it learns the failure probabilities as sales occur and failure information is accumulated. If the failure probabilities turn out to be too high and it becomes costly to fulfill the warranty coverage, then the company may decide to stop selling the product, possibly replacing it with a more reliable alternative. The objective is to decide if and when to stop. By formulating the problem as a dynamic program with Bayesian learning, we establish structural properties of the optimal policy. Since computing the optimal policy is intractable due to the high dimensional state space, we propose two approximation methods. The first method is based on decomposing the problem by failure types and it provides upper bounds on the value functions. The second method provides lower bounds on the value functions and it is based on a deterministic approximation. Computational experiments indicate that the policy from the first method provides noticeable benefits, especially when it is difficult to form good estimates of the failure probabilities quickly."
2113,"Committed Versus Contingent Pricing Under Competition","Wang, Zizhuo and Hu, Ming","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1919-1936","2014","NOV","Competition;Contingent Pricing;Committed Pricing;Revenue Management;Demand Uncertainty","","Should capacitated firms set prices responsively to uncertain market conditions in a competitive environment? We study a duopoly selling differentiated substitutable products with fixed capacities under demand uncertainty, where firms can either commit to a fixed price ex ante, or elect to price contingently ex post, e.g., to charge high prices in booming markets, and low prices in slack markets. Interestingly, we analytically show that even for completely symmetric model primitives, asymmetric equilibria of strategic pricing decisions may arise, in which one firm commits statically and the other firm prices contingently; in this case, there also exists a unique mixed strategy equilibrium. Such equilibrium behavior tends to emerge, when capacity is ampler, and products are less differentiated or demand uncertainty is lower. With asymmetric fixed capacities, if demand uncertainty is low, a unique asymmetric equilibrium emerges, in which the firm with more capacity chooses committed pricing and the firm with less capacity chooses contingent pricing. We identify two countervailing profit effects of contingent pricing under competition: gains from responsively charging high price under high demand, and losses from intensified price competition under low demand. It is the latter detrimental effect that may prevent both firms from choosing a contingent pricing strategy in equilibrium. We show that the insights remain valid when capacity decisions are endogenized. We caution that responsive price changes under aggressive competition of less differentiated products can result in profit-killing discounting."
2114,"The Strategic Role of Third-Party Marketplaces in Retailing","Mantin, Benny and Krishnan, Harish and Dhar, Tirtha","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1937-1949","2014","NOV","Marketing Channels;Dual-Format Retailing;Third-Party Marketplaces;Internet Retailing;Bargaining","","Retailers are increasingly adopting a dual-format model. In addition to acting as traditional merchants (buying and reselling goods), these retailers provide a platform for third-party (3P) sellers to access and compete for the same customers. We investigate the strategic rationale for a retailer to introduce a 3P marketplace. Our analysis provides insights into the growing prevalence of 3P marketplaces. We show that by committing to having an active 3P marketplace, the retailer creates an outside option that improves its bargaining position in negotiations with the manufacturer. This can explain the increasing prevalence of such marketplaces. On the other hand, the manufacturer would prefer to eliminate the retailer's outside option and should seek to limit or prevent sales through 3P marketplaces. This is consistent with actions that several manufacturers have taken to limit such sales. Interestingly, if the manufacturer fails to eliminate sales of competing products through the 3P marketplace, then the best strategy for the manufacturer is to allow the retailer to dictate the terms of their contract. This is because a powerful retailer will rely less on its outside option in generating profit, and therefore it will increase the fees charged to 3P sellers and soften the competition between 3P sellers and the manufacturer. The decrease in competition will lead to an increase in the value of outside option of the manufacturer and improve its profit. Additionally, we find that the presence of a 3P marketplace benefits consumers, but this benefit diminishes as the retailer becomes more powerful."
2115,"Vehicle Supply Chains in Humanitarian Operations: Decentralization, Operational Mix, and Earmarked Funding","Besiou, Maria and Pedraza-Martinez, Alfonso J. and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1950-1965","2014","NOV","Disaster Management;Humanitarian Operations;Humanitarian Logistics;Supply Chain Management;System Dynamics","","The work of international humanitarian organizations (IHOs) frequently involves operating in remote locations, decentralized decision-making, and the simultaneous implementation of development and disaster response programs. A large proportion of this work is funded by earmarked donations, since donors often exhibit a preference for the programs they are willing to fund. From extensive research involving qualitative descriptions and quantitative data, and applying system dynamics methodology, we model vehicle supply chains (VSCs) in support of humanitarian field operations. Our efforts encompass the often-overlooked decentralized environment by incorporating the three different VSC structures that IHOs operate, as well as examining the entire mix of development and disaster response programs, and the specific (and virtually unexplored) effects of earmarked funding. Our results suggest that earmarked funding causes a realand negativeoperational impact on humanitarian disaster response programs in a decentralized setting."
2116,"Inventory Control with a Fixed Cost and a Piecewise Linear Convex Cost","Lu, Ye and Song, Miao","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1966-1984","2014","NOV","Inventory Control;Fixed Cost;Convex Cost;Heuristic Policy","","This paper studies the optimal policy for a periodic-review inventory system in which the production costs consist of a fixed cost and a piecewise linear convex variable cost. Such a cost function can arise from alternate sources of supply or from the use of overtime production. We fully characterize the structure of the optimal policy for the single-period problem. For the multi-period problem, the optimal policy can have disconnected production regions and complicated optimal produce-up-to levels, which implies that implementation of the optimal policy may not be practical. Fortunately, careful investigation shows that the optimal policy has some interesting properties. The structure of the optimal policy outlined by these properties leads to a practical and close-to-optimal heuristic policy. In an extensive numerical study, the average gap is only 0.02% and the worst gap is 1.37%."
2117,"The Impact of Modular Assembly on Supply Chain Efficiency","Feng, Tianjun and Zhang, Fuqiang","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","1985-2001","2014","NOV","Modular Assembly;Supply Chains;Inventory Management;Game Theory","","This article studies the impact of modular assembly on supply chain efficiency. In the modular assembly approach, a manufacturer acquires pre-assembled modules from its suppliers, rather than the individual components, as in the traditional assembly approach. We analyze the competitive behavior of a two-stage modular assembly system consisting of a manufacturer, and a supplier who pre-assembles two components into a module. The firms can choose their own inventory policies and we show the existence of Nash equilibrium in the inventory game. Moving from the traditional to the modular approach has a twofold effect on the supply chain. First, we investigate the effect of centralizing the component suppliers. It can be shown that when there is no production time shift, the module supplier always holds more component inventories than suppliers do in the traditional approach, which yields a lower cost for the manufacturer. However, the suppliers, and therefore the supply chain may incur a higher cost in the modular approach. Second, we study the effect of a shift in production time from the manufacturing stage to the supplier stage. From numerical studies, it has been found that such a lead time shift always benefits a centralized supply chain, but not necessarily so for a decentralized system. Combining the two effects, we find that the modular approach generally reduces the cost to the manufacturer and the supply chain, which explains the prevalence of modular assembly from the perspective of inventory management. These results also provide some insight into how firms can improve supply chain efficiency by choosing the right decision structure and lead time configuration."
2118,"Fairness in Selling to the Newsvendor","Wu, Xiaole and Niederhoff, Julie A.","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","2002-2022","2014","NOV","Supply Chain Management;Modeling Behavioral Preferences;Incentives And Contracts;Fairness;Supply Chain Efficiency","","This paper studies the impact of fairness concerns on supply chain performance (SCP) in the two-party newsvendor setting. We extend prior fairness analysis to a wide range of demand distributions, and also allow the degree and definition of fairness to assume a broader range of preferences than those in prior literature. Contrary to prior literature, we find that if the retailer's ideal allocation to the supplier is not sufficiently large, regardless of demand variability, a fair-minded retailer makes no difference to system efficiency when facing a traditional profit-maximizing supplier. Only when the retailer's ideal allocation to the supplier is above a threshold can the retailer's fairness concern improve the system efficiency for sufficiently high demand uncertainty. In order for the retailer's fairness concern to improve expected profits of both parties compared to the traditional supply chain case (win-win), the demand uncertainty cannot be too low, the retailer is not very averse to disadvantageous inequity, and his ideal allocation to the supplier is within a specific range. If only the supplier is concerned for fairness, the results range from worsening to improving (but not coordinating) the system and a win-win situation is impossible. Finally, when both the supplier and retailer are fair-minded, SCP is improved unless both parties prefer to allocate small portions of system profit to the other. Again, win-win will be achieved only when the demand uncertainty is sufficiently high, the retailer's ideal allocation is within a certain range, and he is not very averse to disadvantageous inequity."
2119,"Assortment Optimization under the Multinomial Logit Model with Random Choice Parameters","Rusmevichientong, Paat and Shmoys, David and Tong, Chaoxu and Topaloglu, Huseyin","PRODUCTION AND OPERATIONS MANAGEMENT","23","11","2023-2039","2014","NOV","Logit;Assortment Optimization;Revenue Management;Capacity Control","","We consider assortment optimization problems under the multinomial logit model, where the parameters of the choice model are random. The randomness in the choice model parameters is motivated by the fact that there are multiple customer segments, each with different preferences for the products, and the segment of each customer is unknown to the firm when the customer makes a purchase. This choice model is also called the mixture-of-logits model. The goal of the firm is to choose an assortment of products to offer that maximizes the expected revenue per customer, across all customer segments. We establish that the problem is NP complete even when there are just two customer segments. Motivated by this complexity result, we focus on assortments consisting of products with the highest revenues, which we refer to as revenue-ordered assortments. We identify specially structured cases of the problem where revenue-ordered assortments are optimal. When the randomness in the choice model parameters does not follow a special structure, we derive tight approximation guarantees for revenue-ordered assortments. We extend our model to the multi-period capacity allocation problem, and prove that, when restricted to the revenue-ordered assortments, the mixture-of-logits model possesses the nesting-by-fare-order property. This result implies that revenue-ordered assortments can be incorporated into existing revenue management systems through nested protection levels. Numerical experiments show that revenue-ordered assortments perform remarkably well, generally yielding profits that are within a fraction of a percent of the optimal."
2120,"Optimal Policies for Recovering the Value of Consumer Returns","Crocker, Keith J. and Letizia, Paolo","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1667-1680","2014","OCT","Consumer Returns;Returns Policy;Preponement;Hidden Action;Hidden Information","","This study characterizes the class of Pareto optimal returns policies between a manufacturer and a retailer who receives consumer returns. The manufacturer may take a costly hidden action that reduces the expected number of products returned by consumers, which when realized is hidden information known only to the retailer. When faced with consumer returns, the retailer must decide whether to send the product back to the manufacturer, who harvests a low salvage value, or to engage in costly refurbishment that permits the returned product to be resold to consumers. We find that the optimal returns policies may be implemented through the payment by the manufacturer of a full refund to the retailer of the wholesale price for any returns as well as a bonus paid to the retailer that is decreasing in the number of returns to the manufacturer."
2121,"Stimulating Early Adoption of New Products through Channel Disintegration","Ramanan, Ram N. V. and Bhargava, Hemant K.","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1681-1689","2014","OCT","Supply Chains;Channel Disintegration;Double Marginalization","","Conventional wisdom holds that adding layers to a distribution channel is detrimental to the interests of consumers and the channel that serves them. In contrast, our study indicates that a disintegrated channel structure can be desirable in some instances. When consumers have valuation uncertainty prior to consuming a product, having an independent retailer may boost both channel profits and consumer surplus relative to direct selling by an integrated firm. The quandary in selling such products is that after early adopters make their purchase decisions, the seller may alter prices in such a way that makes early adopters' decisions appear suboptimal in hindsight. Since the seller cannot credibly commit to future prices, customers are reluctant to adopt early, choosing instead to delay their purchase decisions. This delay is certainly detrimental to the interest of the distribution channel, but the rejection of the early adoption discount can equally reduce consumer surplus. This problem can be mitigated by introducing an independent retailer. The familiar double marginalization problem from channel disintegration can credibly assure customers of unfavorable future prices for late adoption. This assurance attracts more customers to seek early adoption, leading to lower overall retail prices, increased supply, and higher consumer and producer surpluses."
2122,"Customers' Capital Market Information Quality and Suppliers' Performance","Radhakrishnan, Suresh and Wang, Zheng and Zhang, Yue","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1690-1705","2014","OCT","Information Sharing;Earnings Guidance And Quality;Analysts;Credit Rating;Dupont Profitability Ratios","","We empirically examine the association between downstream firms', i.e., customers' capital market information quality, and the operating performance of upstream firms, i.e., suppliers. Customers' capital market information quality is measured by the customers' provision of earnings forecasts, the customers' reported earnings quality, and the customers' coverage by financial analysts and credit rating agencies. We hypothesize and find a positive association between customers' capital market information quality and suppliers' operating performance measured by the DuPont profitability ratios. The association is stronger for suppliers with higher sales volatility, no order backlogs, customers who are less dependent on their input, and shorter business relation with customers. Collectively, the results suggest that the quality of information provided by the customers to the capital market has a spillover effect in the input market, i.e., helps the suppliers improve their performance."
2123,"Outsourcing Competition and Information Sharing with Asymmetrically Informed Suppliers","Zhao, Xia and Xue, Ling and Zhang, Fuqiang","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1706-1718","2014","OCT","Service Outsourcing;Asymmetric Information;Information Sharing;Common Value Auction","","This paper studies an outsourcing problem where two service providers (suppliers) compete for the service contract from a client. The suppliers face uncertain cost for providing the service because they do not have perfect information about the client's type. The suppliers receive differential private signals about the client type and thus compete under asymmetric information. We first characterize the equilibrium of the supplier competition. Then we investigate two of the client's information sharing decisions. It is shown that less information asymmetry between the suppliers may dampen their competition. Therefore, the client does not necessarily have the incentive to reduce information asymmetry between the suppliers. We characterize the conditions under which leveling the informational ground is beneficial to the client. We also find that under the presence of information asymmetry (e.g., when the suppliers have different learning abilities), sharing more information with both suppliers may enhance the advantage of one supplier over the other and at the same time increase the upper bound of the suppliers' quotes in equilibrium. Consequently, the suppliers compete less aggressively and the client's payoff decreases in the amount of shared information. The findings from this study provide useful managerial implications on information management for outsourcing firms."
2124,"Strategic Information Sharing in Competing Channels","Guo, Liang and Li, Tian and Zhang, Hongtao","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1719-1731","2014","OCT","Competition;Disclosure;Supply Chain;Strategic Information Sharing;Channel","","We investigate strategic information sharing in two competing channels. The retailer in a channel can ex post decide whether to share private demand information with his upstream manufacturer after the content of information becomes known. We find that a retailer discloses low demand and withholds high demand to induce lower wholesale prices from his manufacturer. We show that a retailer should share less information when the retail market becomes more competitive, but should disclose more information when his capability to acquire information improves. When a decentralized supply chain competes with an integrated channel, we show that firms in the supply chain benefit from the rival channel's effort to improve information capability, that the incentive for the retailer in the supply chain to improve his information capability increases with the intensity of competition and with the rival channel's information capability, and that the retailer may not want to pursue perfect information acquisition even when doing so is costless. Extensive numerical studies demonstrate that similar results also hold for two decentralized supply chains competing with each other."
2125,"With or Without Forecast Sharing: Competition and Credibility under Information Asymmetry","Gumus, Mehmet","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1732-1747","2014","OCT","Forecast Sharing;Competition;Credibility;Asymmetric Information;Signalling","","Forecast sharing among trading partners lies at the heart of many collaborative and contractual supply chain management efforts. Even though it has been praised in both academic and practitioner circles for its critical role in increasing demand visibility, some concerns remain: The first one is related to the credibility of forecast sharing, and the second is the fear that it may turn into a competitive disadvantage and induce suppliers to increase their price offerings. In this study, we explore the validity of these concerns under a supply chain with a competitive upstream structure, focusing specifically on (i) when and how a credible forecast sharing can be sustainable, and (ii) how it impacts on the intensity of price competition. To address these issues, we develop a supply chain model with a buyer facing a demand risk and two heterogeneous suppliers competing for order allocation from the buyer. The extent of demand is known only to the buyer. The buyer submits a buying request to the suppliers via a commonly used procurement mechanism called request for quotation (RFQ). We consider two variants of RFQ. In the first type, the buyer simply shares the estimated order quantity with no further specifications. In the second one, in addition to this, the buyer also specifies minimum and/or maximum order quantities. We fully characterize equilibrium decisions and profits associated with them under symmetric and asymmetric information scenarios. Our main findings are that the buyer can use a RFQ with quantity restrictions as a credible signal for forecast sharing as long as the degree of demand information asymmetry is not too high, and that, contrary to above concerns, the equilibrium prices that emerge between competing suppliers under asymmetric information may indeed increase if the buyer cannot share forecast information credibly with its upstream partners."
2126,"Strategic Sourcing in the Presence of Uncertain Supply and Retail Competition","Chen, Jianqing and Guo, Zhiling","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1748-1760","2014","OCT","Dual Sourcing;Supply Uncertainty;Uniform Allocation;Price Competition;Supply Chain","","This study develops an analytical model to evaluate competing retail firms' sourcing strategies in the presence of supply uncertainty. We consider a common supplier that sells its uncertain supply to two downstream retail firms engaging in price competition in a horizontally differentiated product market. The focal firm has a dual-sourcing option, while the rival firm can only source from the common supplier. We assess the system-wide effects of supply uncertainty on the focal firm's incentive to pursue the dual-sourcing strategy. We find that the focal firm's dual-sourcing strategy can create a win-win situation that leads to increased retail prices and expected profits for both firms. Furthermore, under certain conditions, we show that it is beneficial for the focal firm to strategically source from the common supplier, even if its alternative supplier offers a lower wholesale price. Overall, we identify two types of incentives for adopting the dual-sourcing strategy: the incentive of mitigating supply risk through supplier diversification and the incentive of strategic sourcing for more effective retail competition."
2127,"Optimal Inventory Control with Retail Pre-Packs","Gao, Long and Thomas, Douglas J. and Freimer, Michael B.","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1761-1778","2014","OCT","Periodic Review Policies;Pre-Pack;Batch-Ordering;Steady-State Distribution;Demand Correlation;Markov Decision Process","","A pre-pack is a collection of items used in retail distribution. By grouping multiple units of one or more stock keeping units (SKU), distribution and handling costs can be reduced; however, ordering flexibility at the retail outlet is limited. This paper studies an inventory system at a retail level where both pre-packs and individual items (at additional handling cost) can be ordered. For a single-SKU, single-period problem, we show that the optimal policy is to order into a band with as few individual units as possible. For the multi-period problem with modular demand, the band policy is still optimal, and the steady-state distribution of the target inventory position possesses a semi-uniform structure, which greatly facilitates the computation of optimal policies and approximations under general demand. For the multi-SKU case, the optimal policy has a generalized band structure. Our numerical results show that pre-pack use is beneficial when facing stable and complementary demands, and substantial handling savings at the distribution center. The cost premium of using simple policies, such as strict base-stock and batch-ordering (pre-packs only), can be substantial for medium parameter ranges."
2128,"Inventory Sharing with Transshipment: Impacts of Demand Distribution Shapes and Setup Costs","Liang, Chao and Sethi, Suresh P. and Shi, Ruixia and Zhang, Jun","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1779-1794","2014","OCT","Transshipment;Inventory Sharing;Demand Shapes;Three-Point Distribution","","We study a firm's optimal transshipment problem considering the impacts of setup costs for transshipment and demand distribution shapes. We assume that the demand follows a three-point distribution, which changes from a degenerate distribution, to a unimodal distribution, and to a bimodal distribution as the demand shape parameter increases. We find that as the demand shape parameter increases, the optimal transshipment strategy changes from no transshipment to transshipment, and finally to no transshipment. The firm would use two-way transshipment when the shape parameter is relatively small, while it would use one-way transshipment when the shape parameter is relatively large. When the optimal strategy is one-way transshipment, the transshipment direction depends on the contribution margin as well as the demand shape, when the difference between the two demand uncertainties is small. Our study of a dual-channel retail system shows that the additional benefit of two-way transshipment is negligible when there are many retail stores."
2129,"Integrated Procurement Planning in Multi-division Firms","Balakrishnan, Anantaram and Natarajan, Harihara Prasad","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1795-1810","2014","OCT","Procurement;Volume Discounts;Multi-Division Firms;Optimization;Cutting Planes","","For large multi-division firms, coordinating procurement policies across multiple divisions to leverage volume discounts from suppliers based on firm-wide purchasing power can yield millions of dollars of savings in procurement costs. Coordinated procurement entails deciding which suppliers to use to meet each division's purchasing needs and sourcing preferences so as to minimize overall purchasing, logistics, and operational costs. Motivated by this tactical procurement planning problem facing a large industrial products manufacturer, we propose an integrated optimization model that simultaneously considers both firm-wide volume discounts and divisional ordering and inventory costs. To effectively solve this large-scale integer program, we develop and apply a tailored solution approach that exploits the problem structure to generate tight bounds. We identify several classes of valid inequalities to strengthen the linear programming relaxation, establish polyhedral properties of these inequalities, and develop both a cutting-plane method and a sequential rounding heuristic procedure. Extensive computational tests for realistic problems demonstrate that our integrated sourcing model and solution method are effective and can provide significant economic benefits. The integrated approach yields average savings of 7.5% in total procurement costs compared to autonomous divisional policies, and our algorithm generates near-optimal solutions (within 0.75% of optimality) within reasonable computational time."
2130,"Bounds of Relative Regret Limit in p-Robust Supply Chain Network Design","Tian, Junfeng and Yue, Jinfeng","PRODUCTION AND OPERATIONS MANAGEMENT","23","10","1811-1831","2014","OCT","Supply Chain Design;Robust Optimization;Stochastic Programming;Regret","","This research studies the p-robust supply chain network design with uncertain demand and cost scenarios. The optimal design integrates the supplier selection together with the facility location and capacity problem. We provide a new framework to obtain the relative regret limit, which is critical in the robust supply chain design but is assumed to be a known value in the existing literature. We obtain lower and upper bounds for relative regret limit and obtain a sequence of optimal solutions for series relative regret limits between the upper and lower bounds. An algorithm for p-robust supply chain network design is provided. A series of numerical examples are designed to find the properties of the bottleneck scenarios. A scenario with low probability and a low optimal objective function value for the scenario has a greater chance of being a bottleneck. To focus only on the influence from the relative regret, we also introduce three separate new objective functions in p-robust design. The proposed new theories and approaches provide a sequence of options for decision makers to reduce the marketing risks effectively in supply chain network design."
2131,"Supply-Chain Research Opportunities with the Poor as Suppliers or Distributors in Developing Countries","Sodhi, ManMohan S. and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1483-1494","2014","SEP","Micro-Entrepreneurs;Social Business;Social Enterprise;Socially Responsible Operations;Supply Chain Management;Supply Chain Surplus;Value Creation","","Many social enterprises and some companies have developed supply chains with the poor as suppliers or distributors to alleviate poverty and to create revenues for themselves. Such supply chains have created new research opportunities because they raise issues fundamentally different from those examined in the existing operations management literature. We report this phenomenon of supply chains with the poor as suppliers or distributors in developing countries and identify operations management (OM) research opportunities. We also provide some stylized models to serve as potential seeds for modeling-based research in this area."
2132,"Capacity Planning with Financial and Operational Hedging in Low-Cost Countries","Chen, Lijian and Li, Shanling and Wang, Letian","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1495-1510","2014","SEP","Operational Hedging;Financial Hedging;Risk Management;Capacity Planning","","The authors of this article outline a capacity planning problem in which a risk-averse firm reserves capacities with potential suppliers that are located in multiple low-cost countries. While demand is uncertain, the firm also faces multi-country foreign currency exposures. This study develops a mean-variance model that maximizes the firm's optimal utility and derives optimal utility and optimal decisions in capacity and financial hedging size. The authors show that when demand and exchange rate risks are perfectly correlated, a risk-averse firm, by using financial hedging, will achieve the same optimal utility as a risk-neutral firm. In this study as well, a special case is examined regarding two suppliers in China and Vietnam. The results show that if a single supplier is contracted, financial hedging most benefits the highly risk-averse firm when the demand and exchange rate are highly negatively related. When only one hedge is used, financial hedging dominates operational hedging only when the firm is very risk averse and the correlation between the two exchange rates have become positive. With both theoretical and numerical results, this study concludes that the two hedges are strategic tools and interact each other to maximize the optimal utility."
2133,"Designing Efficient Infrastructural Investment and Asset Transfer Mechanisms in Humanitarian Supply Chains","Bhattacharya, Shantanu and Hasija, Sameer and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1511-1521","2014","SEP","Asset Transfer;Humanitarian Logistics;Supply Chain Design","","We analyze the efficacy of different asset transfer mechanisms and provide policy recommendations for the design of humanitarian supply chains. As a part of their preparedness effort, humanitarian organizations often make decisions on resource investments ex ante because doing so allows for rapid response if an adverse event occurs. However, programs typically operate under funding constraints and donor earmarks with autonomous decision-making authority resting with the local entities, which makes the design of efficient humanitarian supply chains a challenging problem. We formulate this problem in an agency setting with two independent aid programs, where different asset transfer mechanisms are considered and where investments in resources are of two types: primary resources that are needed for providing the aid and infrastructural investments that improve the operation of the aid program in using the primary resources. The primary resources are acquired from earmarked donations. We show that allowing aid programs the flexibility of transferring primary resources improves the efficiency of the system by yielding greater social welfare than when this flexibility does not exist. More importantly, we show that a central entity that can acquire primary resources from one program and sell them to the other program can further improve system efficiency by providing a mechanism that facilitates the transfer of primary resources and eliminates losses from gaming. This outcome is achieved without depriving the individual aid programs of their decision-making autonomy while maintaining the constraints under which they operate. We find that outcomes with centralized resource transfer but decentralized infrastructural investments by the aid programs are the same as with a completely centralized system (where both resource transfer and infrastructural investments are centralized)."
2134,"Sequencing and Scheduling Appointments with Potential Call-In Patients","Chen, Rachel R. and Robinson, Lawrence W.","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1522-1538","2014","SEP","Appointment Scheduling;Sequencing;No-Shows;Same-Day Patients;Healthcare","","This paper studies appointment scheduling for a combination of routine patients who book well in advance and last-minute patients who call for an appointment later that same day. We determine when these same-day patients should be scheduled throughout the day, and how the prospect of their arrivals affects the appointment times of the routine patients. By formulating the problem as a stochastic linear program, we are able to incorporate random and heterogeneous service times and no-show rates, ancillary physician tasks, and appointment delay costs for same-day patients who prefer to see the doctor as early as possible. We find that the optimal patient sequence is quite sensitive to the no-show probabilities and the expected number of same-day patients. We also develop two simple heuristic solutions to this combinatorial sequencing problem."
2135,"The Design and Introduction of Product Lines When Consumer Valuations are Uncertain","Biyalogorsky, Eyal and Koenigsberg, Oded","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1539-1548","2014","SEP","Product Line;Product Introduction;Introduction Strategy;Demand Uncertainty","","This article presents a model of the design and introduction of a product line when the firm is uncertain about consumer valuations for the products. We find that product line introduction strategy depends on this uncertainty. Specifically, under low levels of uncertainty the firm introduces both models during the first period; under higher levels of uncertainty, the firm prefers sequential introduction and delays design of the second product until the second period. Under intermediate levels of uncertainty the firm's first product should be of lower quality than one produced by a myopic firm that does not take product line effects into consideration. We find that when the firm introduces a product sequentially, the strategy might depend on realized demand. For example, if realized demand is high, the firm's second product should be a higher-end model; if demand turns out to be low, the firm's second product should be a lower-end model or replace the first product with a lower-end model."
2136,"Benefactors and Beneficiaries: The Effects of Giving and Receiving on Cost-Coalitional Problems","Meca, Ana and Sosic, Greys","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1549-1560","2014","SEP","Cost-Coalitional Problems;Benefactors;Beneficiaries;K-Norm Cost Games","","Motivated by supply chain collaborations in practice, we introduce a class of cost-coalitional problems, which are based on a priori information about the cost faced by each agent in each set that it could belong to. Our focus is on problems with decreasingly monotonic coalitional costs. In this class of problems, we study the effects of giving and receiving when there exist players whose participation in an alliance always contributes to the savings of all alliance members (we refer to these players as benefactors), and there also exist players whose cost decreases in such an alliance (we call them beneficiaries). We use linear and quadratic norm cost games to analyze the role played by benefactors and beneficiaries in achieving stability of different cooperating alliances. We consider different notions of stability (the core and the bargaining set) and provide conditions for stability of an all-inclusive alliance of agents which leads to minimum value of total cost incurred by all agents."
2137,"End-of-Life Inventory Problem with Phaseout Returns","Pourakbar, M. and van der Laan, E. and Dekker, R.","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1561-1576","2014","SEP","End-Of-Life Inventory Management;Spare Parts;Phaseout Returns","","We consider the service parts end-of-life inventory problem of a capital goods manufacturer in the final phase of its life cycle. The final phase starts as soon as the production of parts terminates and continues until the last service contract expires. Final order quantities are considered a popular tactic to sustain service fulfillment obligations and to mitigate the effect of obsolescence. In addition to the final order quantity, other sources to obtain serviceable parts are repairing returned defective items and retrieving parts from phaseout returns. Phaseout returns happen when a customer replaces an old system platform with a next-generation one and returns the old product to the original equipment manufacturer (OEM). These returns can well serve the demand for service parts of other customers still using the old generation of the product. In this study, we study the decision-making complications as well as cost-saving opportunities stemming from phaseout occurrence. We use a finite-horizon Markov decision process to characterize the structure of the optimal inventory control policy. We show that the optimal policy consists of a time-varying threshold level for item repair. Furthermore, we study the value of phaseout information by extending the results to cases with an uncertain phaseout quantity or an uncertain schedule. Numerical analysis sheds light on the advantages of the optimal policy compared to some heuristic policies."
2138,"Managing Supply Risk for Vertically Differentiated Co-Products","Bansal, Saurabh and Transchel, Sandra","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1577-1598","2014","SEP","Operations Strategy;Product Substitution;Co-Production Systems;Product Line","","The manufacturing complexity of many high-tech products results in a substantial variation in the quality of the units produced. After manufacturing, the units are classified into vertically differentiated products. These products are typically obtained in uncontrollable fractions, leading to mismatches between their demand and supply. We focus on product stockouts due to the supply-demand mismatches. Existing literature suggests that when faced with product stockouts, firms should satisfy all unmet demand of a low-end product by downgrading excess units of a high-end product (downward substitution). However, this policy may be suboptimal if it is likely that low-end customers will substitute with a higher quality product and pay the higher price (upward substitution). In this study, we investigate whether and how much downward substitution firms should perform. We also investigate whether and how much low-end inventory firms should withhold to strategically divert some low-end demand to the high-end product. We first establish the existence of regions of co-production technology and willingness of customers to substitute upward where firms adopt different substitution/withholding strategies. Then, we develop a managerial framework to determine the optimal selling strategy during the life cycle of technology products as profit margins shrink, manufacturing technology improves, and more capacity becomes available. Consistent trends exist for exogenous and endogenous prices."
2139,"Power Structure and Profitability in Assembly Supply Chains","Chen, Lucy Gongtao and Ding, Ding and Ou, Jihong","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1599-1616","2014","SEP","Assembly System;Supply Chain Power Structure;Profitability","","This paper studies the impact of supply chain power structure on firms' profitability in an assembly system with one assembler and two suppliers. Two power regimes are investigated-in a Single Power Regime, a more powerful firm acts as the Stackelberg leader to decide the wholesale price but not the quantity whereas in a Dual Power Regime, both the price and quantity decisions are granted to the more powerful firm. Tallying the power positions of the three firms, for each power regime we study three power structures and investigate the system's as well as the firms' preference of power. We find that when the assembler is the most powerful firm among the three, the system-wide profit is the highest and so is the assembler's profit. The more interesting finding is that, if the assembler is not the most powerful player in the system, more power does not necessarily guarantee her a higher profit. Similarly, a supplier's profit can also decrease with the power he has. These results contrast with the conclusion for serial systems, where a firm always prefers more power. We also find that when both suppliers are more (less) powerful than the assembler, it can be beneficial (indifferent) for everyone if the two suppliers merge into a mega supplier to make decisions jointly. When the assembler is more powerful than one supplier and less so than the other, it is always better for the system to have the two suppliers merge, and for each individual firm, merging is preferred if the firm becomes the more powerful party after merging."
2140,"Randomization Approaches for Network Revenue Management with Customer Choice Behavior","Kunnumkal, Sumit","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1617-1633","2014","SEP","Network Revenue Management;Customer Choice;Dynamic Programming;Simulation","","In this study, we present new approximation methods for the network revenue management problem with customer choice behavior. Our methods are sampling-based and so can handle fairly general customer choice models. The starting point for our methods is a dynamic program that allows randomization. An attractive feature of this dynamic program is that the size of its action space is linear in the number of itineraries, as opposed to exponential. It turns out that this dynamic program has a structure that is similar to the dynamic program for the network revenue management problem under the so called independent demand setting. Our approximation methods exploit this similarity and build on ideas developed for the independent demand setting. We present two approximation methods. The first one is based on relaxing the flight leg capacity constraints using Lagrange multipliers, whereas the second method involves solving a perfect hindsight relaxation problem. We show that both methods yield upper bounds on the optimal expected total revenue. Computational experiments demonstrate the tractability of our methods and indicate that they can generate tighter upper bounds and higher expected revenues when compared with the standard deterministic linear program that appears in the literature."
2141,"Enabling Opportunism: Revenue Sharing when Sales Revenues are Unobservable","Heese, H. Sebastian and Kemahlioglu-Ziya, Eda","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1634-1645","2014","SEP","Supply Chain Management;Revenue-Sharing Contracts;Noncooperative Game Theory","","We consider a supply chain with a supplier that sells to a retailer under a revenue-sharing arrangement. Demand is uncertain and unobservable to the supplier. We assume that the retailer is rational, that is, the retailer behaves opportunistically and underreports sales revenues to the supplier whenever such underreporting is profitable. Assuming the supplier has the ability to audit the retailer and learn about the actual sales revenues, we show that the supplier will never find it optimal to audit to the point that ensures truthful reporting for all demand realizations. By committing to an auditing policy, the supplier can exploit retailer opportunism and derive profits that at times even exceed those that could be obtained when dealing with a retailer that always strictly adheres to the agreed-upon contract terms. We also show that the retailer's opportunistic behavior can increase total supply chain profits."
2142,"Integrality in Stochastic Inventory Models","Chen, Wei and Dawande, Milind and Janakiraman, Ganesh","PRODUCTION AND OPERATIONS MANAGEMENT","23","9","1646-1663","2014","SEP","Integrality;Stochastic Inventory Control;Total Unimodularity;Multi-Dimensional Piecewise Linearity","","We study several finite-horizon, discrete-time, dynamic, stochastic inventory control models with integer demands: the newsvendor model, its multi-period extension, and a single-product, multi-echelon assembly model. Equivalent linear programs are formulated for the corresponding stochastic dynamic programs, and integrality results are derived based on the total unimodularity of the constraint matrices. Specifically, for all these models, starting with integer inventory levels, we show that there exist optimal policies that are integral. For the most general single-product, multi-echelon assembly system model, integrality results are also derived for a practical alternative to stochastic dynamic programming, namely, rolling-horizon optimization by a similar argument. We also present a different approach to prove integrality results for stochastic inventory models. This new approach is based on a generalization we propose for the one-dimensional notion of piecewise linearity with integer breakpoints to higher dimensions. The usefulness of this new approach is illustrated by establishing the integrality of both the dynamic programming and rolling-horizon optimization models of a two-product capacitated stochastic inventory control system."
2143,"10-year Anniversary of the New Product Development, R&D, and Project Management Department in Production and Operations Management-Progress, Thoughts, and Perspectives","Kavadias, Stylianos (Stelios)","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1259-1264","2014","AUG","R&D;New Product Development;Project Management;Anniversary Reflections;Future Perspectives","","The issue you are about to browse offers an opportunity to share many thanks, some observations, and a few forward-looking thoughts about the department I have had the honor to edit over the last 4 years. It also offers an opportunity to expand the discussion beyond the boundaries of the particular department of Production and Operations Management (POM), and to take stock of the evolution path of the academic community that has formed around the department and its research topics over the past 10 years."
2144,"Tolerance for Failure and Incentives for Collaborative Innovation","Hutchison-Krupat, Jeremy and Chao, Raul O.","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1265-1285","2014","AUG","Innovation;New Product Development;Organization Control;Rewards And Penalties;Project Management;Project Risk;Behavioral Operations","","Most organizations employ collaborative teams to manage innovation projects. Although the use of collaborative innovation teams is a good starting point, an organization's ability to innovate can be enhanced by managing risk-taking behavior through monetary incentive schemes and through an organizational culture that tolerates failure. This article reports the results of two controlled experiments aimed at understanding how tolerance for failure and incentives impact the decisions of individuals engaged in a collaborative innovation initiative. A key element of our experiments is the notion of endogenous project risk, which we define as the explicit link between resources allocated to a project and the likelihood of project success. We observe that when penalties are low, the amount of risk an individual assumes is fairly insensitive to the rewards that are offered. In an analogous result, when individuals make decisions alone (rather than collaboratively), higher tolerance for failure does little to increase the amount of risk an individual is willing to take. Taken together, these results highlight the importance of implicit incentives that are created as a result of project and organizational characteristics."
2145,"Incentives in a Stage-Gate Process","Chao, Raul O. and Lichtendahl, Jr., Kenneth C. and Grushka-Cockayne, Yael","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1286-1298","2014","AUG","Innovation;New Product Development;Principal-Agent Analysis;Search;Complex Performance Landscapes","","Many large organizations use a stage-gate process to manage new product development projects. In a typical stage-gate process project managers learn about potential ideas from research and exert effort in development while senior executives make intervening go/no-go decisions. This decentralized decision making results in an agency problem because the idea quality in early stages is unknown to the executive and the project manager must exert unobservable development effort in later stages. In light of these challenges, how should the firm structure incentives to ensure that project managers reveal relevant information and invest the appropriate effort to create value? In this study, we develop a model of adverse selection in research and moral hazard in development with a go/no-go decision at the intervening gate. Our results show that the principal's uncertainty regarding early-stage idea quality-a term we refer to as idea risk-alters the effect of late-stage development risk. The presence of idea risk can alter the incentives offered to the agent and may lead the principal to reject projects that otherwise seem favorable in terms of positive net present value. A simulation of early-stage ideas, found through search on a complex landscape, shows that the firm can mitigate the negative effects of idea risk by encouraging breadth of search and high tolerance for failure."
2146,"Managing Cost Salience and Procrastination in Projects: Compensation and Team Composition","Wu, Yaozhong and Ramachandran, Karthik and Krishnan, Vish","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1299-1311","2014","AUG","Project Management;Procrastination;Cost Salience;Behavioral Operations Management","","The rising trend of projects with high-skilled and autonomous contributors increasingly exposes managers to the risk of idiosyncratic individual behaviors. In this article, we examine the effects of an important behavioral factor, an individual's cost salience. Cost salience leads individuals to perceive the cost of immediate effort to be larger than the cost of future effort. This leads to procrastination in early stages and back-loaded effort over the course of the project. We model the problem confronting the manager of a project whose quality is adversely impacted by such distortion of individual effort over time. Complementary to prior works focused on the planning and scheduling tasks of project management in the absence of human behavior, we find that managers should reward contributions made in earlier stages of a project. Our analysis also yields interesting insights on the project team performance: teams with diverse levels of cost salience will perform better than homogeneous teams. We also address another important facet of team composition, namely, the choice between stable and fluid teams, and find that the practice of creating fluid teams might have previously unrecognized benefits when behavioral aspects of projects are considered. We conclude with insights and organizational implications for project managers."
2147,"Realizing the Need for Rework: From Task Interdependence to Social Networks","Sosa, Manuel E.","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1312-1331","2014","AUG","New Product Development;Rework;Social Networks;Hierarchies;Expertise","","Design rework is a core phenomenon in new product development (NPD). Yet carrying out design rework presupposes recognizing the need for it. I characterize the types of interpersonal knowledge transfer that help developers realize the need for design rework in NPD. As predicted by the NPD literature, I find that individuals who interact frequently with colleagues to address their task interdependences are more likely to realize the need for rework. I also learn that interacting with colleagues who have different expertise in process-related knowledge (as opposed to product-related knowledge) facilitates realizing the need for rework. However, to develop a deeper understanding of how individuals recognize the need for rework when interacting with others, we must expand our views beyond task interdependence and expertise-related factors. In particular, organizational variables-both formal and informal-play a significant role. With respect to formal hierarchical structures, actors of superior rank are less likely to realize the need for rework regardless of whether or not their interacting partner is of superior rank; however, actors of superior rank are more likely to trigger realizing the need for rework when interacting with partners of subordinate rank. By examining an organization's informal structure, I discover that the social embeddedness of developers (i.e., the energy and attention invested in a dyadic relationship) significantly influences their propensity to realize the need for rework. Several hypotheses are tested in a sociometric study conducted within the development department of a software company, and I discuss the implications for behavioral operations in NPD."
2148,"Knowledge Diversity, Turnover, and Organizational-Unit Productivity: An Empirical Analysis in a Knowledge-Intensive Context","Narayanan, Sriram and Swaminathan, Jayashankar M. and Talluri, Srinivas","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1332-1351","2014","AUG","Data Envelopment Analysis;Employee Turnover;Knowledge Diversity;Organizational-Unit Productivity;Tobit Regression","","We examine the role of knowledge diversity among unit members on an organizational unit's productivity. Utilizing a proprietary data set of corrective maintenance tasks from a large software-services firm, we investigate the impact of two key within-unit diversity metrics: interpersonal diversity and intrapersonal diversity. We analyze the independent influence of interpersonal diversity and the interactive influence of interpersonal diversity and intrapersonal diversity on organizational unit's productivity. Finally, we examine how diversity moderates productivity of an organizational unit when employee turnover occurs. Our analysis reveals the following key insights: (a) interpersonal diversity has an inverted U-shaped effect on organizational unit's productivity; (b) intrapersonal diversity moderates the influence of interpersonal diversity on organizational-unit productivity; (c) at higher levels of interpersonal diversity, rate of decrease in productivity of the organizational unit due to turnover is higher. We discuss the resulting theoretical and managerial insights associated with these findings."
2149,"System Dynamics Understanding in Projects: Information Sharing, Psychological Safety, and Performance Effects","Bendoly, Elliot","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1352-1369","2014","AUG","Project Management;Systems Thinking","","Systems thinking has proven useful in project management planning activities and has been suggested as a critical driver of a range of beneficial organizational behaviors. Yet, empirical evidence on the myriad of ways in which systems thinking can impact internal project dynamics and performance remains limited. This study focuses on one aspect of systems thinking in particular: the ability to recognize and understand the dynamics of systems and their features (e.g., feedback and delay). It makes use of a unique, large-scale interview data set along with objective and structured survey data drawn from multiple sources associated with supply chain system implementation projects. Analysis suggests that an individual's understanding of system dynamics as well as the similarity of such understanding to that typical of their team is, in fact, a strong predictor of both perceptions of psychological safety and information sharing quality in project work. These outcomes appear to mediate the relationship between system dynamics understanding and performance."
2150,"Opt-Out Options in New Product Co-development Partnerships","Savva, Nicos and Scholtes, Stefan","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1370-1386","2014","AUG","New Product Co-Development;Pharmaceutical R&D;Real Options;Financial Constraints","","We study three contractual arrangements-co-development, licensing, and co-development with opt-out options-for the joint development of new products between a small and financially constrained innovator firm and a large technology company, as in the case of a biotech innovator and a major pharma company. We formulate our arguments in the context of a two-stage model, characterized by technical risk and stochastically changing cost and revenue projections. The model captures the main disadvantages of traditional co-development and licensing arrangements: in co-development the small firm runs a risk of running out of capital as future costs rise, while licensing for milestone and royalty (M&R) payments, which eliminates the latter risk, introduces inefficiency, as profitable projects might be abandoned. Counter to intuition we show that the biotech's payoff in a licensing contract is not monotonically increasing in the M&R terms. We also show that an option clause in a co-development contract that gives the small firm the right but not the obligation to opt out of co-development and into a pre-agreed licensing arrangement avoids the problems associated with fully committed co-development or licensing: the probability that the small firm will run out of capital is greatly reduced or completely eliminated and profitable projects are never abandoned."
2151,"Getting What You Pay For-Strategic Process Improvement Compensation and Profitability Impact","Veldman, Jasper and Klingenberg, Warse and Gaalman, Gerard J. C. and Teunter, Ruud H.","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1387-1400","2014","AUG","Strategic Compensation;Process Improvement;Cost Reduction;Firm Heterogeneity;Non-Cooperative Game Theory","","Profit-maximizing firm owners who incentivize their managers with a bonus for process improvement create an intentional misalignment of their own objective and management attention. From the viewpoint of a single firm, such a local misalignment can never be profitable, but in this study we take a wider strategic perspective by investigating cost-reducing process improvements of two firms competing in a Cournot market. We find that the use of a process improvement bonus (by firm A) can be profitable, by affecting the competitor's decision making. Informed about the reward structure at firm A, which provides an incentive for process improvement and thereby for increased production at that firm, the manager of the competing firm (B) is inclined to produce less if the owner of firm B only rewards profit. This leads to a higher profit for firm A. However, we also show that firm B's best strategy is to also offer a process improvement bonus, even if that firm is a cost laggard (with higher costs for process improvement), and that this leads to reduced profit for both firms in many situations unless one of them is sufficiently superior in its ability to improve processes. These results are robust for uncertain process improvement outcomes, multidimensional process improvement decisions, and information asymmetry in the owner-manager relationship."
2152,"The Payback of Effective Innovation Programs: Empirical Evidence from Firms that Have Won Innovation Awards","Zhang, Guoqiang Peter and Yu, Jifeng and Xia, Yusen","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1401-1420","2014","AUG","Innovation Awards;Effective Innovation Programs;Operational And Financial Performance;Empirical Analysis","","Despite the widely held belief of the importance of innovation, the connection between innovation and firm performance is empirically inconclusive, partially owing to the limitations of existing innovation measures, which tend to ignore the effectiveness of innovation programs. In this study, we use the winning of innovation awards as a proxy for the effective execution of innovation. We conducted event-study analyses based on data from more than 1000 publicly traded firms that won innovation awards between 1998 and 2003. Our statistical tests provide strong evidence that the performance of award-winning firms is significantly higher as compared with several sets of control firms. Over an 8-year period, starting from 4 years before to 3 years after the year of winning the first innovation award, the test sample's mean (median) change in return on assets is nearly 33% (24%) higher than that of a control sample. The evidence also suggests that effective innovation programs can increase firms' revenue, cost efficiency, and market valuation. Over the period, the control-adjusted mean (median) change in sales, cost per dollar of sales, and Tobin's Q are 39.28% (20.71%), -5.52% (-3.80%), and 23.70% (3.16%), respectively. Panel data regression analysis provides additional insights on the performance impact of effective innovation programs. The results show that award winners are not only financially more successful but also enjoy an indirect benefit through better R&D execution, which increases firm profitability in both the short term and long term."
2153,"Collaborative Product Development: The Effect of Project Complexity on the Use of Information Technology Tools and New Product Development Practices","Peng, David Xiaosong and Heim, Gregory R. and Mallick, Debasish N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1421-1438","2014","AUG","Collaboration;Product Development;Information Technology;Npd Practices;Project Complexity","","Collaboration is an essential element of new product development (NPD). This research examines the associations between four types of information technology (IT) tools and NPD collaboration. The relationships between NPD practices and NPD collaboration are also examined. Drawing on organizational information processing theory, we propose that the relationships between IT tools and NPD collaboration will be moderated differently by three project complexity dimensions, namely, product size, project novelty, and task interdependence, due to the differing nature of information processing necessitated by each project complexity dimension. Likewise, the moderation effects of the project complexity dimensions on the relationship between NPD practices and NPD collaboration will also be different. We test our hypotheses using data from a sample of NPD projects in three manufacturing industries. We find that IT tools are associated with collaboration to a greater extent when product size is relatively large. In contrast, IT tools exhibit a smaller association with collaboration when project novelty or task interdependence is relatively high. NPD practices are found to be more significantly associated with NPD collaboration under the contingency of high project novelty or high task interdependence. The findings provide insights about circumstances where several popular IT tools are more likely to facilitate collaboration, thus informing an NPD team's IT adoption and use decisions."
2154,"The Effect of Competition on R&D Portfolio Investments","Zschocke, Mark S. and Mantin, Benny and Jewkes, Elizabeth M.","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1439-1449","2014","AUG","Project Portfolio Management;Resource Allocation;R&D Investments;Game Theory;Competition","","Although project portfolio management has been an active research area over the past 50 years, budget allocation models that consider competition are sparse. Faced with the competition, firms contemplating budget allocation for their project portfolio cannot limit their attention to the returns from their projects' target markets, as is the case for monopoly firms, but must also anticipate the competitive effects on these returns. Assuming firms allocate their budgets between projects offering incremental innovation targeting a mature market and projects offering radical innovation targeting an emerging market, we show that while the monopoly firm bases its budget allocation decision solely on the marginal returns of the markets, competing firms-as they take into account their counterparts' investment decisions-need to also consider the projects' average returns from their respective markets. This drives competing firms into incrementalism: faced with competition, firms invest larger portions of their budgets into projects targeting mature markets. This effect is amplified as the number of competing firms increases and firms allocate an even greater share of their budget into projects targeting a mature market. We further demonstrate the effects that changes to firms' individual budgets, as well as to market characteristics, have on firms' budget allocation decision."
2155,"The Path-Dependent Nature of R&D Search: Implications for (and from) Competition","Oraiopoulos, Nektarios and Kavadias, Stylianos","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1450-1461","2014","AUG","R&D Search;Technological Landscape;Knowledge Spillovers;Competition","","We formalize R&D as a search process for technology improvements across different technological domains. Technology improvements from a specific domain draw upon a common knowledge base, and as such they share technological content. Moreover, different domains may rely on similar scientific principles, and therefore, knowledge about the technology improvements by one domain might be transferable to another. We analyze how such a technological relatedness shapes the direction of R&D search when knowledge generated from past search efforts disseminates to rival firms. We show that firms optimally diversify their search efforts, even toward domains that are riskier and less promising on expectation. This is amplified for higher competition intensity, i.e., higher cross-product substitutability. Our work also suggests that different sources of learning about the domains may have opposite effects on the direction of search. Higher ability to infer the potential of an explored domain prompts the clustering of searches, whereas the ability to learn across domains prompts diversification. Finally, we discuss the technological landscape properties that prompt firms to engage in a sequential R&D search, instead of a parallel competitive search."
2156,"Defining Problems Fast and Slow: The U-shaped Effect of Problem Definition Time on Project Duration","Choo, Adrian S.","PRODUCTION AND OPERATIONS MANAGEMENT","23","8","1462-1479","2014","AUG","Group Problem Solving;Problem Definition;Prior Project Experience;Project Complexity;Six Sigma Projects","","This study examines how time spent in problem definition affects problem solving in projects such as Six Sigma projects. Our hypotheses are tested using data collected from 1558 Six Sigma projects in a company. The results show evidence of a U-shaped relationship between the amount of time spent in the Define phase and project duration. This finding suggests that spending too little time on problem definition potentially causes poor problem formulation, which leads to deficient problem solving and lengthens overall project time. On the other hand, too much time spent on problem definition can lead to unneeded delays in project completion due to diminishing returns on problem definition efforts. Furthermore, the optimal balance between spending too little and too much time depends on prior project experience and project complexity. Prior project experience reduced project completion time and weakened the U-shaped effect. Conversely, complex projects took longer and appeared to show some evidence of a stronger U-shaped effect; this suggests balancing the time spent in the Define phase was more challenging for complex projects. Our study also underscores the importance of managing project duration, as projects that were completed faster tended to be associated with higher project savings."
2157,"Improving Voting Systems through Service-Operations Management","Yang, Muer and Fry, Michael J. and Kelton, W. David and Allen, Theodore T.","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1083-1097","2014","JUL","Government;Elections;Simulation;Applications;Service Operations;Queueing","","We apply service-operations-management concepts to improve the efficiency and equity of voting systems. Recent elections in the United States and elsewhere have been plagued by long lines, excessive waiting times, and perceptions of unfairness. We build models for the waiting lines at voting precincts using both traditional steady-state queueing methods and simulation models. We develop solution methods to allocate voting machines optimally to precincts. Our objective functions consider both the efficiency and the equity of the voting system. We compare our allocation algorithm to several competing methods, including those used in practice. We examine several different strategies for improving voting operations on both the demand and the capacity side of voting systems, and we present a complete case study of applying our method to data from the 2008 election for Franklin County, Ohio. We conclude that our method is superior to existing polices in terms of efficiency and equity and that it is robust in terms of uncertainties regarding turnout rates on Election Day. We also suggest several operational improvements to the voting process drawn from the service-operations literature."
2158,"Improving the Milk Supply Chain in Developing Countries: Analysis, Insights, and Recommendations","Mu, Liying and Dawande, Milind and Mookerjee, Vijay","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1098-1112","2014","JUL","Milk Supply Chain;Non-Cooperative Games;Quality Testing;Free Riding","","Quality issues in milk-arising primarily from deliberate adulteration by producers-have been reported in several developing countries. In the milk supply chain, a station buys raw milk from a number of producers, mixes the milk and sells it to a firm (that then sells the processed milk to end consumers). We study a non-cooperative game between a station and a population of producers. Apart from penalties on proven low-quality producers, two types of incentives are analyzed: confessor rewards for low-quality producers who confess and quality rewards for producers of high-quality milk. Contrary to our expectations, whereas (small) confessor rewards can help increase both the quality of milk and the station's profit, quality rewards can be detrimental. We examine two structures based on the ordering of individual and mixed testing of milk: pre-mixed individual testing (first test a fraction of producers individually and then [possibly] perform a mixed test on the remaining producers) and post-mixed individual testing (first test the mixed milk from all producers and then test a fraction of producers individually). Whereas pre-mixed individual testing can be socially harmful, a combination of post-mixed individual testing and other incentives achieves a desirable outcome: all producers supply high-quality milk with only one mixed test and no further testing by the station."
2159,"Cellular Bucket Brigades on U-Lines with Discrete Work Stations","Lim, Yun Fong and Wu, Yue","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1113-1128","2014","JUL","Bucket Brigades;U-Lines;Cross-Training;Work Sharing;Self-Organization","","It is challenging to maximize and maintain productivity of a U-line with discrete stations under the impact of variability. This is because maximizing productivity requires assigning workers to suitable tasks and maintaining productivity requires sufficient flexibility in task assignment to absorb the impact of variability. To achieve this goal, we propose an operating protocol to coordinate workers on the U-line. Under the protocol the system can be configured such that its productivity is maximized. Workers are allowed to dynamically share work so that the system can effectively absorb the impact of variability. Analysis based on a deterministic model shows that the system always converges to a fixed point or a period-2 orbit. We identify a sufficient condition for the system to converge to the fixed point. Increasing the number of stations improves productivity only under certain circumstances. The improvement is most significant when the number of stations in each stage increases from one to two, but further dividing the U-line into more stations has diminishing return. Simulations based on random work velocities suggest that our approach significantly outperforms an optimized, static work allocation policy if variability in velocity is large."
2160,"Browse-and-Switch: Retail-Online Competition under Value Uncertainty","Balakrishnan, Anantaram and Sundaresan, Shankar and Zhang, Bo","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1129-1145","2014","JUL","Showrooming;Channel Switching;Retail Pricing;Multi-Channel Competition","","Although online shopping is becoming popular, consumers who are unsure about whether to buy a product may find it advantageous to visit a brick-and-mortar retail store to first examine the product before purchasing it. But, after browsing at the store, consumers have the option of switching to an e-tailer to purchase the item at a cheaper price rather than buying at the store. Recent business press refers to this browse-and-switch behavior as showrooming, and attributes to it the declining profits of brick-and-mortar retailers. To study the effect of the browse-and-switch option on retail and online pricing strategies and profits, we analyze a stylized economic model that incorporates uncertainty in consumers' valuation of the product, captures the heterogeneity among consumers in their inclination to purchase online, and permits product returns. We consider various equilibrium scenarios for different combinations of consumer shopping behaviors, characterize the parameter ranges for each scenario, and demonstrate that browse-and-switch behavior can indeed occur under equilibrium. Our analysis further shows that the option for consumers to browse-and-switch intensifies competition, reducing the profits for both firms."
2161,"Judgmental Forecasting: Cognitive Reflection and Decision Speed","Moritz, Brent and Siemsen, Enno and Kremer, Mirko","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1146-1160","2014","JUL","Forecasting;Behavioral Operations;Decision Speed;Cognitive Reflection","","This research analyzes how individual differences affect performance in judgmental time-series forecasting. Decision makers with the ability to balance intuitive judgment with cognitive deliberation, as measured by the cognitive reflection test, tend to have lower forecast errors. This relationship holds when controlling for intelligence. Furthermore, forecast errors increase for very fast or very slow decisions. We provide evidence that forecast performance can be improved by manipulating decision speed."
2162,"Is Safe Production an Oxymoron?","Pagell, Mark and Johnston, David and Veltri, Anthony and Klassen, Robert and Biehl, Markus","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1161-1175","2014","JUL","Operational Safety;Human Resources;Practices;Qualitative Research","","This research examines how organizations simultaneously manage their operations and occupational health and safety. Although both safety and operations scholars conduct research in the same operational settings, they have reached different, yet untested, conclusions about the relationship between creating a safe workplace and creating a productive workplace. The results from a series of 10 case studies show that it is possible to create safe and productive workplaces, but that many facilities fail at this task because of problems associated with the culture management creates and the practices management adopts."
2163,"Uniform vs. Retailer-Specific Pricing: Incentive Alignment to Enhance Supply Chain Efficiency","Vakharia, Asoo J. and Wang, Lan","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1176-1182","2014","JUL","Wholesale Pricing;Incentive Alignment;Supply Chains","","We consider a supplier selling to multiple retailers using one of two constant wholesale pricing strategies: a uniform wholesale price (UWP) vs. a retailer-specific wholesale price (RSWP). In line with the prior literature in economics, our initial finding is that as long as retailers are asymmetric, then (a) the supplier and less efficient retailer would prefer the RSWP strategy and (b) the more efficient retailer would prefer the UWP strategy. By examining the total profits of the supply chain under each pricing strategy, we present a new result: the UWP strategy results in a greater degree of supply chain efficiency as compared to the RSWP strategy. The key intuition driving this result is that by charging a UWP, the supplier signals a fair treatment for downstream retailers, which leads to the more efficient retailer being able to reduce market prices and hence capture a larger share of market demand. Noting that the supplier prefers the RSWP scheme as compared to the UWP scheme, we propose a contract which comprises two components: a UWP per unit complemented with a slotting allowance or side payment. The contract is always preferred by the supplier and also leads to greater supply chain efficiency."
2164,"Impeding the Juggernaut of Innovation Diffusion: A Production-Constrained Model","Balakrishnan, P. V. (Sundar) and Pathak, Surya","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1183-1197","2014","JUL","Bass Model;Marketing;Industrial Production Policy;Waiting Customers;Service Quality","","Models of innovation diffusion typically depict an inexorable momentum once the process begins to roll. Limited production capacity, however, can place a cap on this process, leading to waiting lines of potential customers, thus diminishing overall service quality and the speed of diffusion. Identifying the minimum production capacity needed for unimpeded and unimpaired diffusion can ensure that there are no customers waiting to adopt the product. We propose a production-capacity-constrained diffusion model that considers an exogenous industry production capacity and accounts for word-of-mouth effects from adopters as well as waiting customers. We derive analytical expressions for minimum capacity needed under multiple production scenarios. We present a dual-objective non-linear least squares procedure with large-scale grid search for estimating the parameters. We apply our model to several new product innovation data sets, ranging from vacuum cleaners to sports utility vehicles in the United States to iPhones globally. Our estimates show that product shortages exist, ranging from mild to severe, in all of these product markets. We are able to corroborate some of our findings with independent external sources of evidence. We find that information on industry capacity can be recovered with as few as 5 years of sales data. Our model has practical implications for policy makers and can help equity analysts triangulate industry capacity better, particularly when such information is closely held."
2165,"Managing Disruptions in Decentralized Supply Chains with Endogenous Supply Process Reliability","Tang, Sammi Y. and Gurnani, Haresh and Gupta, Diwakar","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1198-1211","2014","JUL","Supply Disruption;Process Improvement;Incentive Mechanism;Dual Sourcing","","Supply disruptions are all too common in supply chains. To mitigate delivery risk, buyers may either source from multiple suppliers or offer incentives to their preferred supplier to improve its process reliability. These incentives can be either direct (investment subsidy) or indirect (inflated order quantity). In this study, we present a series of models to highlight buyers' and suppliers' optimal parameter choices. Our base-case model has deterministic buyer demand and two possibilities for the supplier yield outcomes: all-or-nothing supply or partial disruption. For the all-or-nothing model, we show that the buyer prefers to only use the subsidy option, which obviates the need to inflate order quantity. However, in the partial disruption model, both incentives-subsidy and order inflation-may be used at the same time. Although single sourcing provides greater indirect incentive to the selected supplier because that avoids order splitting, we show that the buyer may prefer the diversification strategy under certain circumstances. We also quantify the amount by which the wholesale price needs to be discounted (if at all) to ensure that dual sourcing strategy dominates sole sourcing. Finally, we extend the model to the case of stochastic demand. Structural properties of ordering/subsidy decisions are derived for the all-or-nothing model, and in contrast to the deterministic demand case, we establish that the buyer may increase use of subsidy and order quantity at the same time."
2166,"Operational Hedging and Diversification under Correlated Supply and Demand Uncertainty","Sting, Fabian J. and Huchzermeier, Arnd","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1212-1226","2014","JUL","Supply And Demand Risk;Operational Hedging;Diversification;Concordance Order;Trivariate Correlation","","When facing supply uncertainty caused by exogenous factors such as adverse weather conditions, firms diversify their supply sources following the wisdom of not holding all eggs in one basket. We study a firm that decides on investment and production levels of two unreliable but substitutable resources. Applying real options thinking, production decisions account for actual supply capabilities, whereas investment decisions are made in advance. To model triangular supply and demand correlations, we adapt the concepts of random capacity and stochastic proportional yield while using concordant ordered random variables. Optimal profit decreases monotonically in supply correlation and increases monotonically in supply-demand correlation. Optimal resource selection, however, depends on the trivariate interplay of supply and demand and responds non-monotonically to changing correlations. Moreover, supply hedges (i.e., excess capacity at alternative sources) can be optimal even if supply resources are perfectly positively correlated. To accommodate changing degrees of correlation, the firm adjusts the lower margin capacities under random capacity; but under stochastic proportional production capability, it uses either low-or high-margin capacities"
2167,"Inventory Commitment and Prioritized Backlogging Clearance with Alternative Delivery Lead Times","Wang, Haifeng and Liang, Xiaoying and Sethi, Suresh and Yan, Houmin","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1227-1242","2014","JUL","Flexible Delivery;Backlog Models;Priority Rules;Inventory Management","","We propose a model where customers are classified into two groups: short lead-time customers who require the product immediately and long lead-time customers to whom the supplier may deliver either immediately or in the next cycle. Unmet orders are backlogged with associated costs. Specifically, the supplier faces two problems: how the on-hand inventories should be allocated between the two classes of customers and how the backlogged orders should be cleared when replenishments arrive. We treat the former as an inventory commitment problem and handle the latter with priority rules. We characterize and compare the inventory commitment policies with three priority rules in clearing back-logs. We also explore the optimal inventory replenishment decision and evaluate the performance of each priority"
2168,"Inventory Rationing in a Make-to-Stock System with Batch Production and Lost Sales","Pang, Zhan and Shen, Houcai and Cheng, T. C. E.","PRODUCTION AND OPERATIONS MANAGEMENT","23","7","1243-1257","2014","JUL","Production And Inventory Control;Inventory Rationing;Batch Production;Make-To-Stock","","We address an inventory rationing problem in a lost sales make-to-stock (MTS) production system with batch ordering and multiple demand classes. Each production order contains a single batch of a fixed lot size and the processing time of each batch is random. Assuming that there is at most one order outstanding at any point in time, we first address the case with the general production time distribution. We show that the optimal order policy is characterized by a reorder point and the optimal rationing policy is characterized by time-dependent rationing levels. We then approximate the production time distribution with a phase-type distribution and show that the optimal policy can be characterized by a reorder point and state-dependent rationing levels. Using the Erlang production time distribution, we generalize the model to a tandem MTS system in which there may be multiple outstanding orders. We introduce a state-transformation approach to perform the structural analysis and show that both the reorder point and rationing levels are state dependent. We show the monotonicity of the optimal reorder point and rationing levels for the outstanding orders, and generate new theoretical and managerial insights from the research findings."
2169,"Buttressing Supply Chains against Floods in Asia for Humanitarian Relief and Economic Recovery","Sodhi, ManMohan S. and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","938-950","2014","JUN","Supply Chain Design;Floods;Natural Disasters;Humanitarian Relief;Social Enterprise;Buttressed Supply Chains;Disaster Relief","","Floods are the most frequent category of disasters worldwide. Among all geographic regions, Asia has suffered the most. While there are several ongoing humanitarian efforts and initiatives, we believe there is a new opportunity to coordinate last mile humanitarian efforts in the event of a flood using micro-retailers. Because micro-retailers are the last mile nodes in traditional retail supply chains in many Asian countries, we propose the use of social enterprise to buttress these supply chains for distribution of essential goods by coordinating with micro-retailers before and after floods. We also present a stylized model to quantify the benefits of doing so."
2170,"Vehicle Procurement Policy for Humanitarian Development Programs","Eftekhar, Mahyar and Masini, Andrea and Robotis, Andreas and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","951-964","2014","JUN","Fleet Management;Humanitarian Logistics;Development Programs;Procurement","","This article aims to identify optimal vehicle procurement policies for organizations engaged in humanitarian development programs and to derive general insights on the characteristics of these policies. Toward that end, we follow an inductive approach. First, we study the operations of the International Committee of the Red Cross (ICRC) in three representative countries: Sudan, Afghanistan, and Ethiopia. Using a linear programming (LP) model primed with field data provided by the ICRC, we calculate the optimal vehicle fleet size and compare it with the policies actually implemented. Second, drawing from results of the LP model, we develop a stylized quadratic control model and use it to characterize the general structure of the optimal policy under different demand scenarios and operational constraints. After demonstrating that the results of the control model are consistent with those of the LP model in the specific context analyzed, we discuss the optimal policies and the applicability of the former as a practical tool for strategic asset planning."
2171,"Using Fairness Models to Improve Equity in Health Delivery Fleet Management","McCoy, Jessica H. and Lee, Hau L.","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","965-977","2014","JUN","Health Care;Public Policy;Humanitarian Operations;Capacity Planning","","Inefficiency and inequity are two challenges that plague humanitarian operations and health delivery in resource-limited regions. Increasing capacity in humanitarian and health delivery supply chains is one option that has the potential to improve equity while maintaining efficiency. For example, the nonprofit organization Riders for Health has worked to increase capacity by providing reliable transportation to health workers in rural parts of sub-Saharan Africa; with more motorcycle hours at their disposal, health workers can perform more outreach to outlying communities. We develop a model using a family of fairness function to quantify the efficiency and equity of health delivery as capacity is increased via development programs. We present optimal resource allocations under utilitarian, proportionally fair, and egalitarian objectives and extend the model to include dual modes of transport and diminishing returns of subsequent outreach visits. Finally, we demonstrate how to apply our model at a regional level to provide support for humanitarian decision makers such as Riders for Health. We use data from the baseline phase of our evaluation trial of Riders for Health in Zambia to quantify efficiency and equity for one real-world scenario."
2172,"Assessing Trade-offs among Multiple Objectives for Humanitarian Aid Delivery Using Expert Preferences","Gralla, Erica and Goentzel, Jarrod and Fine, Charles","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","978-989","2014","JUN","Humanitarian Logistics;Aid Delivery;Expert Preferences;Objectives","","Humanitarian aid agencies deliver emergency supplies and services to people affected by disasters. Scholars and practitioners have developed modeling approaches to support aid delivery planning, but they have used objective functions with little validation as to the trade-offs among the multiple goals of aid delivery. We develop a method to value the performance of aid delivery plans based on expert preferences over five key attributes: the amount of cargo delivered, the prioritization of aid by commodity type, the prioritization of aid by delivery location, the speed of delivery, and the operational cost. Through a conjoint analysis survey, we measure the preferences of 18 experienced humanitarian logisticians. The survey results quantify the importance of each attribute and enable the development of a piecewise linear utility function that can be used as an objective function in optimization models. The results show that the amount of cargo delivered is the most valued objective and cost the least important. In addition, experts prioritize more vulnerable communities and more critical commodities, but not to the exclusion of others. With these insights and the experts' utility functions, better humanitarian objective functions can be developed to enable better aid delivery in emergency response."
2173,"A School Feeding Supply Chain Framework: Critical Factors for Sustainable Program Design","Kretschmer, Andreas and Spinler, Stefan and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","990-1001","2014","JUN","Humanitarian Supply Chain;School Feeding;Sustainability;Framework","","School feeding is an established development aid intervention with multiple objectives including education, nutrition, and value transfer. Traditionally run by international organizations in low-income settings, school feeding programs have had a substantial impact in many less-developed countries. However, recent rethinking by the World Bank and the World Food Programme has prompted a shift toward long-term, sustainable solutions that rely more upon local resources, local capacity, and community participation. Supply chain management, which is critical to program delivery, is vital to developing a sustainable approach to school feeding. We propose a theoretical framework that identifies the internal and external factors that shape the supply chain and connects them to the objectives and performance measures of sustainable programs. Drawing upon supply chain management theory, current school feeding practices, and expert feedback, this article contributes to development aid logistics and program transitioning with a focus on sustainable program design. It aims to provide a comprehensive introduction to school feeding and relevant supply chain issues, a framework to identify sustainability problems in school feeding supply chains, and a starting point for further research on program design."
2174,"Improving Humanitarian Operations through Technology-Enabled Collaboration","Ergun, Oezlem and Gui, Luyi and Heier Stamm, Jessica L. and Keskinocak, Pinar and Swann, Julie","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","1002-1014","2014","JUN","Humanitarian Operations;Coordination;Cooperative Game Theory;Cost-Allocation Mechanisms","","Humanitarian supply chains involve many different entities, such as government, military, private, and non-governmental organizations and individuals. Well-coordinated interactions between entities can lead to synergies and improved humanitarian outcomes. Information technology (IT) tools can help facilitate collaboration, but cost and other barriers have limited their use. We document the use of an IT tool to improve last-mile supply distribution and data management in one of many camps for internally displaced persons after the January 2010 earthquake in Haiti, and we describe other current uses of technology in camp management. Motivated by these examples and the interest among humanitarian organizations in expanding the use of such tools to facilitate coordination, we introduce a cooperative game theory model and explore insights about the conditions under which multi-agency coordination is feasible and desirable. We also outline an agenda for future research in the area of technology-enabled collaboration in the humanitarian sector."
2175,"Information Diffusion among Agents: Implications for Humanitarian Operations","Altay, Nezih and Pal, Raktim","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","1015-1027","2014","JUN","Humanitarian Logistics;Cluster Approach;Disaster Response;Coordination;Information Flows","","The basis for this article is an information-processing view of the UN's cluster approach. We use agent-based modeling and simulations to show that clusters, if properly utilized, encourage better information flow and thus facilitate effective response to disasters. The article intends to turn the attention of the humanitarian community to the importance of sharing information and the role of cluster leads in facilitating humanitarian aid. Our results indicate that if cluster leads act as information hubs, information reaches its target faster, enabling a prompt humanitarian response. In addition, we show that information quality is critical for effective resource utilization-if cluster leads filter information, it moves faster. We also found evidence that the willingness to exchange information plays a larger role in transmitting information than that of an information hub, particularly during later stages of response operations."
2176,"Supplier Selection for Framework Agreements in Humanitarian Relief","Balcik, Burcu and Ak, Deniz","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","1028-1041","2014","JUN","Supplier Selection;Framework Agreements;Humanitarian Relief;Procurement;Stochastic Programming","","In this study, we consider the supplier selection problem of a relief organization that wants to establish framework agreements (FAs) with a number of suppliers to ensure quick and cost-effective procurement of relief supplies in responding to sudden-onset disasters. Motivated by the FAs in relief practice, we focus on a quantity flexibility contract in which the relief organization commits to purchase a minimum total quantity from each framework supplier over a fixed agreement horizon, and, in return, the suppliers reserve capacity for the organization and promise to deliver items according to pre-specified agreement terms. Due to the uncertainties in demand locations and amounts, it may be challenging for relief organizations to assess candidate suppliers and the offered agreement terms. We use a scenario-based approach to represent demand uncertainty and develop a stochastic programming model that selects framework suppliers to minimize expected procurement and agreement costs while meeting service requirements. We perform numerical experiments to understand the implications of agreement terms in different settings. The results show that supplier selection decisions and costs are generally more sensitive to the changes in agreement terms in settings with high-impact disasters. Finally, we illustrate the applicability of our model on a case study."
2177,"The Effect of Language Differences and National Culture on Operational Process Compliance","Gray, John V. and Massimino, Brett","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","1042-1056","2014","JUN","Routines;Knowledge Transfer;Offshoring;International;Manufacturing","","With increasing frequency, firms are locating their operations in disparate countries with distinct national cultures and languages. This study develops and empirically tests hypotheses relating an operation's process compliance performance to (1) the presence of a language difference between the location of the operation and that of headquarters and (2) the national culture of the location of the operation and that of headquarters. Employing an international sample of pharmaceutical manufacturing plants located primarily in Western nations, the analysis reveals that a language difference between the location of a plant and the firm's headquarters is consistently related to decreased process compliance at the plant level. Regarding national culture, only limited evidence of a direct relationship between national cultural dimensions (at either the plant or headquarters location) and process compliance exists. However, the analysis does suggest that cultural congruence between the location of the plant and that of headquarters can relate to improved compliance performance. Such a relationship depends on the specific national cultural dimension studied. While these results are obtained in a specific manufacturing setting, they potentially have implications for process compliance in any global operation."
2178,"Distributed Development and Product Line Decisions","Bala, Ram and Krishnan, V. and Zhu, Wenge","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","1057-1066","2014","JUN","Distributed Development;Product Line Design;Global Operations Management;Operations-Marketing Interface","","Distributed product development is becoming increasingly prevalent in a number of industries. We study how the global distribution of product development impacts the profit-maximizing product line that a firm offers. Specifically, we formulate a model to understand the linkage between cost arbitrage as a driver of distributed development and consequent market implications such as customer perceived quality loss to remotely developed products. Analysis of the model reveals that a firm should expand the product line for a development-intensive good only at intermediate values of cost advantage and quality loss. We modify the base model to include development capacity constraints as a driver of distributed development and find that the results are robust to this change. Our analysis affirms the need for product managers to incorporate the implications of distributed development in making their product line design decision."
2179,"Monopoly Versioning of Information Goods When Consumers Have Group Tastes","Wei, Xueqi (David) and Nault, Barrie R.","PRODUCTION AND OPERATIONS MANAGEMENT","23","6","1067-1081","2014","JUN","Information Goods;Market Segmentation;Product Differentiation;Versioning Strategies;Pricing Strategies","","Large sunk costs of development, negligible costs of reproduction, and distribution resulting in economies of scale distinguish information goods from physical goods. Versioning is a way firms may take advantage of these properties. However, in a baseline model where consumers differ in their tastes for quality, an information goods monopolist only offers one version, and this differs from what we observe in practice. We explore formulations that add features to the baseline model that result in a monopolist offering multiple versions. We examine versioning where consumers differ in individual tastes for quality, and groups of consumers that share the same group taste are delineated by segments of individual tastes. We find that if groups have mutually exclusive characteristics-a horizontal dimension-that they value relative to the shared characteristics, then versioning is optimal. Consequently, any horizontal differentiation in product line design favors versioning. In addition, when group tastes are hierarchical such that higher taste groups value characteristics that lower taste groups value but not vice versa-a vertical dimension-as long as the valuations of the higher and adjacent lower taste group are sufficiently close, then versioning is also optimal. Our conditions, which also help determine how many versions are optimal, are based on exogenously defined parameters so that it is feasible to check them in practice."
2180,"POMS Initiatives for Promoting Practice- Driven Research and Research- Influenced Practice","Singhal, Kalyan and Sodhi, ManMohan S. and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","725-727","2014","MAY","Research And Practice;Interactions Between Academics And Practitioners;Dissemination Of Academic Research To Practitioners","","The Production and Operations Management Society (POMS) and Production and Operations Management (POM) have developed new initiatives with these objectives: (1) to disseminate managerial insights of articles published in POM to practitioners, MBA students, and participants in executive development programs; (2) to solicit descriptions of current and emerging problems from practitioners and share them with academics; and (3) to recognize academic research based on direct work with practitioners."
2181,"The Effect of Product Development Restructuring on Shareholder Value","Jacobs, Brian W. and Singhal, Vinod R.","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","728-743","2014","MAY","Product Development;Empirical Research;Stock Market Reaction;Restructuring","","This article examines the effect of product development restructuring (PDR) on shareholder value. The results are based on a sample of 165 announcements made during 2002-2011. PDR announcements are associated with an economically and statistically significant positive stock market reaction. Over a two-day period (the day of the announcement and the day preceding the announcement), the mean (median) market reaction is 1.63% (0.87%). The market reaction is generally positive regardless of the PDR purpose or action. Although the market reaction is more positive for higher R&D intensity firms, it is not directly affected by the firm's prior financial performance or whether the firm's primary PDR objective is to increase revenues or cut costs. However, the interaction between the firm's prior financial performance and its primary PDR objective is significant. For firms that are financial outperformers, the market reaction is more positive if the firm's primary PDR objective is to increase revenues. For financial underperformers, the market reaction is more positive if the firm's primary PDR objective is to cut costs."
2182,"Economic and Environmental Assessment of Remanufacturing Strategies for Product plus Service Firms","Ovchinnikov, Anton and Blass, Vered and Raz, Gal","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","744-761","2014","MAY","Remanufacturing;Demand Cannibalization;Product Plus Service Firms;Environmental Impact","","This article provides a data-driven assessment of economic and environmental aspects of remanufacturing for product+service firms. A critical component of such an assessment is the issue of demand cannibalization. We therefore present an analytical model and a behavioral study which together incorporate demand cannibalization from multiple customer segments across the firm's product line. We then perform a series of numerical simulations with realistic problem parameters obtained from both the literature and discussions with industry executives. Our findings show that remanufacturing frequently aligns firms' economic and environmental goals by increasing profits and decreasing the total environmental impact. We show that in some cases, an introduction of a remanufactured product leads to no changes in the new products' prices (positioning within the product line), implying a positive demand cannibalization and a decrease in the environmental impact; this provides support for a heuristic approach commonly used in practice. Yet in other cases, the firm can increase profits by decreasing the new product's prices and increasing salesa negative effective cannibalization. With negative cannibalization the firm's total environmental impact often increases due to the growth in new production. However, we illustrate that this growth is nearly always sustainable, as the relative environmental impacts per unit and per dollar rarely increase."
2183,"Analysis and Management of Periodic Review, Order-Up-To Level Inventory Systems with Order Crossover","Bischak, Diane P. and Robb, David J. and Silver, Edward A. and Blackburn, Joseph D.","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","762-772","2014","MAY","Periodic Review Inventory Models;Leadtime Variability;Order Crossover","","In this article, we investigate the (R, S) periodic review, order-up-to level inventory control system with stochastic demand and variable leadtimes. Variable leadtimes can lead to order crossover, in which some orders arrive out of sequence. Most theoretical studies of order-up-to inventory systems under variable leadtimes assume that crossovers do not occur and, in so doing, overestimate the standard deviation of the realized leadtime distribution and prescribe policies that can inflate inventory costs. We develop a new analytic model of the expected costs associated with this system, making use of a novel approximation of the realized (reduced) leadtime standard deviation resulting from order crossovers. Extensive experimentation through simulation shows that our model closely approximates the true expected cost and can be used to find values of R and S that provide an expected cost close to the minimum cost. Taking account of, as opposed to ignoring, crossovers leads, on average, to substantial improvements in accuracy and significant cost reductions. Our results are particularly useful for managers seeking to reduce inventory costs in supply chains with variable leadtimes."
2184,"On the Preference to Avoid Ex Post Inventory Errors","Kremer, Mirko and Minner, Stefan and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","773-787","2014","MAY","Newsvendor Decisions;Value Of Demand Information;Inventory Error Regret;Risk Aversion","","The value of demand information underlies many supply chain strategies that aim at better matching supply and demand. This study reports on the results of a laboratory experiment designed to estimate the behavioral value of demand information. Relative to the commonly assumed benchmark of a rational risk-neutral decision maker, we find that decision makers are consistently willing to pay too much for the option to eliminate the risk of supply not matching demand. Contrary to intuition, we show that risk aversion does not explain this result. We posit that demand information provides behavioral value because it mitigates regret from ex post inventory errors."
2185,"Appointment Scheduling with No-Shows and Overbooking","Zacharias, Christos and Pinedo, Michael","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","788-801","2014","MAY","Appointment Scheduling;No-Shows;Overbooking;Sequential Scheduling;Health Care","","We study an overbooking model for scheduling arrivals at a medical facility under no-show behavior, with patients having different no-show probabilities and different weights. The scheduler has to assign the patients to time slots in such a way that she minimizes the expected weighted sum of the patients' waiting times and the doctor's idle time and overtime. We first consider the static problem, where the set of patients to be scheduled and their characteristics are known in advance. We partially characterize the optimal schedule and introduce a new sequencing rule that schedules patients according to a single index that is a function of their characteristics. Then we apply our theoretical results and conclusions from numerical experiments to sequential scheduling procedures. We propose a heuristic solution to the sequential scheduling problem, where requests for appointments come in gradually over time and the scheduler has to assign each patient to one of the remaining slots that are available in the schedule for a given day. We find that the no-show rate and patients' heterogeneity have a significant impact on the optimal schedule and should be taken under consideration."
2186,"Information Acquisition and Voluntary Disclosure in an Export-Processing System","Gao, Long and Li, Zhaolin and Shou, Biying","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","802-816","2014","MAY","Supply Risk;Information Asymmetry;Signaling Game;Information Sharing;Random Yield;Export Processing","","We study a strategic information management problem in the export-processing trade, where the buyer controls the raw material input and sales and the producer is responsible for production. The production is vulnerable to random yield risk. The producer can exert a costly effort to acquire the private yield rate information and discretionarily share it with the buyer. We develop a sequential Bayesian game model that captures three key features of the systemendogenous information endowment, voluntary disclosure, and ex post information sharinga significant departure from the literature. The optimal disclosure strategy is driven by the trade-off between the gains from Pareto efficiency improvement and self-interested overproduction. It is specified by two thresholds on yield rate: only the middle-yield producers (with yield rate between these two thresholds) share private information to improve supply-demand match; the low- and high-yield producers withhold information to extract excess input from the buyer. The buyer in response penalizes nondisclosure with reduced input and rewards information sharing with a larger order. This strategic interaction is further exacerbated by the double marginalization effect from decentralization, resulting in severe efficiency loss. We examine the effectiveness of three corrective mechanismsvertical integration, mandatory disclosure, and production restrictionand reveal the costs of information suppressive effect and overinvestment incentive and the benefit from concessions on the processing fee. Our study endogenizes the asymmetric supply risk and provides the first attempt to rationalize the strategic interactions of informational and operational incentives in the export-processing system."
2187,"Beyond Information Sharing: An Empirical Analysis of Vendor-Managed Inventory","Dong, Yan and Dresner, Martin and Yao, Yuliang","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","817-828","2014","MAY","Vendor-Managed Inventory;Information Sharing;Empirical Analysis","","Using a unique, item-level data set, we examined benefits to downstream firms (distributors) from the decision-transfer component of vendor-managed inventory (VMI), the feature that distinguishes VMI from other information-sharing, collaborative supply chain programs. Our major findings are that the decision-transfer component of VMI adds significant benefits to the downstream firm in terms of inventory and stockout reductions above and beyond information sharing, and that these two benefits may be realized at different times following VMI implementation; that is, inventory reduction, initially, may be the major benefit to distributors from VMI, while the benefits of stockout reduction may more likely be realized after the first year of implementation. In addition, VMI provides benefits to the upstream firm (manufacturer) by reducing the downstream firm's inventory variability, a likely contributor to the bullwhip effect. Based on our empirical analysis, the decision-transfer component of VMI, on average, reduces inventory levels by 7%, stockouts by 31%, and inventory variability by 9%."
2188,"The Effect of Competition on the Efficient-Responsive Choice","Wang, Tong and Thomas, Douglas J. and Rudi, Nils","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","829-846","2014","MAY","Efficient-Responsive;Quick Response;Competition","","In determining their operations strategy, a firm chooses whether to be responsive or efficient. For firms competing in a market with uncertain demand and varying intensity of substitutability for the competitor's product, we characterize the responsive or efficient choice in equilibrium. To focus first on the competitive implications, we study a model where a firm can choose to be responsive at no additional fixed or marginal cost. We find that competing firms will choose the same configuration (responsive or efficient), and responsiveness tends to be favorable when demand uncertainty is high or when product competition is not too strong. Intense competition can drive firms to choose to be efficient rather than responsive even when there is no additional cost of being responsive. In such a case, both firms would be better off by choosing to be responsive but cannot credibly commit. We extend the basic model to study the impact of endogenized production timing, multiple productions and product holdback (or, equivalently, postponed production). For all these settings, we find structurally similar results; firms choose the same configuration, and the firms may miss Pareto-improvements. Furthermore, through extensions to the basic model, we find that greater operational flexibility can make responsiveness look less attractive in the presence of product competition. In contrast to our basic model and other extensions, we find it is possible for one firm to be responsive while the other is efficient when there is either a fixed cost or variable cost premium associated with responsive delivery."
2189,"Prioritizing and Monitoring Concurrent Project Work: Effects on Switching Behavior","Bendoly, Elliot and Swink, Morgan and Simpson, III, Wendell P.","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","847-860","2014","MAY","Project Management;Switching;Priorities;Monitoring;Experiment","","Project switching occurs when a multi-project worker shifts his/her attention from one project to another before completing the first project. In this study, we study the effects of two areas of management policy on project switching behavior, project prioritization, and work monitoring. We conduct a controlled experiment to evaluate direct and combined effects of prioritization, scheduled progress checks, and managerial progress checks on project switching behavior in a distributed, multi-project work environment. We use computerized tasks constituting multiple projects as a means of efficiently simulating a project work setting. Working professionals served as subjects for the experiment, thereby enabling us to control for experience and other individual differences that may vary across workers in real-world projects. We find that clarifying priorities has little overall effect on the prevalence of switching in our multi-project setting, while the presence of managerial progress checks has significant and distinct impacts, driving up switch tendencies. Interestingly, various attributes of the timing of these monitoring events also significantly impact the likelihood that workers will switch in response to these event triggers. We discuss the implications of these findings for managerial practice and for future research."
2190,"Flexible Capacity Investments and Product Mix: Optimal Decisions and Value of Postponement Options","Kouvelis, Panos and Tian, Zhongjun","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","861-876","2014","MAY","Flexible Capacity;Capacity Investment;Product Mix;Real Options;Postponement","","In this article, we study a firm's interdependent decisions in investing in flexible capacity, capacity allocation to individual products, and eventual production quantities and pricing in meeting uncertain demand. We propose a three-stage sequential decision model to analyze the firm's decisions, with the firm being a value maximizer owned by risk-averse investors. At the beginning of the time horizon, the firm sets the flexible capacity level using an aggregate demand forecast on the envelope of products its flexible resources can accommodate. The aggregate demand forecast evolves as a Geometric Brownian Motion process. The potential market share of each product is determined by the Multinomial Logit model. At a later time and before the end of the time horizon, the firm makes a capacity commitment decision on the allocation of the flexible capacity to each product. Finally, at the end of the time horizon, the firm observes the demand and makes the production quantity and pricing decisions for end products. We obtain the optimal solutions at each decision stage and investigate their optimal properties. Our numerical study investigates the value of the postponed capacity commitment option in supplying uncertain operation environments."
2191,"When to Carry Eccentric Products? Optimal Retail Assortment under Consumer Returns","Alptekinoglu, Aydin and Grasas, Alex","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","877-892","2014","MAY","Assortment Planning;Product Variety;Consumer Returns;Retail Operations;Nested Logit","","To understand whether retailers should consider consumer returns when merchandising, we study how the optimal assortment of a retailer is influenced by its return policy. The retailer selects its assortment from an exogenous set of horizontally differentiated products. Consumers make purchase and keep/return decisions in nested multinomial logit fashion. Our main finding is that the optimal assortment has a distinct structure for relatively strict return policies: it is optimal to offer a mix of the most popular and most eccentric products when the refund amount is sufficiently low, which can be viewed as a form of risk sharing between the retailer and consumers. In contrast, if the refund is sufficiently high or when returns are disallowed, the optimal assortment is composed of only the most popular products (a common finding in the literature). We provide preliminary empirical evidence for one of the key drivers of our results: more eccentric products have higher probability of returnconditional on purchase. In light of our analytical findings and managerial insights, we conclude that retailers should take returns into account when merchandising."
2192,"Shelf Loathing: Cross Docking at an Online Retailer","Cattani, Kyle D. and Souza, Gilvan C. and Ye, Shengqi","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","893-906","2014","MAY","Cross Docking;Online Retailing;Inventory;Markov Decision Processes","","Online customers expect to wait, sometimes for a delay of many days. At the fulfillment center, there might be an opportunity to fill customer orders earlier than the due date through a cross-docking transaction: rather than picking the item from inventory, the item moves directly from the receiving to the shipping dock, saving shelving and picking transactions. While cross docking reduces shelving and picking costs, it risks changing customer expectations for how soon a product will be delivered. Given customer order arrivals random in quantity and due dates, random replenishment arrivals, and costs (or benefits) for shipping a product early, we characterize the optimal decision as to whether to cross dock a replenishment item to fulfill demand that is not immediately due or to wait to (hopefully) cross dock in later periods. With multiple demands and due dates, the cross-docking decision depends on the number of unfulfilled demands in each period across the horizon, the number of units that have just arrived (available for cross docking), picking and shelving costs, and the delay cost (or benefit). We formulate the problem as a Markov decision process, determine the structure of the optimal policy, and propose a well-performing heuristic."
2193,"Optimal Policies for Perishable Products When Transportation to Export Market Is Disrupted","Cai, Xiaoqiang and Zhou, Xian","PRODUCTION AND OPERATIONS MANAGEMENT","23","5","907-923","2014","MAY","Food And Agricultural Industries;Production And Delivery Of Perishable Products;Random Demands;Transportation Disruptions;Disruption Management","","We consider a problem where a firm produces a variety of fresh products to supply two markets: an export market and a local market. A public transportation service is utilized to deliver the products to the export market, which is cheap, but its schedule is often disrupted severely. Each time this happens, the firm faces the following questions. (i) For a product that has been finished and is waiting for delivery to the export market, should it continue to wait, at an increasing risk of decay, and when should the waiting be terminated and the product be put to the local market? (ii) For a product that has not been finished, should its processing be postponed, so as to reduce the loss from decay after its completion? (iii) What is the best sequence to process the remaining products, according to the information available? We develop, in this study, a model to address these and other related questions. We find optimal policies that minimize the total expected loss in both the make-to-order and make-to-stock production systems, respectively. For each finished product, we reveal relationships among the desirable waiting time, the price at the local market, and the decaying cost. For unfinished products, we find the optimal start times and processing sequence. Numerical experiments are also conducted to evaluate the optimal policies."
2194,"Does International Economic Integration Lead to a Cleaner Production in China?","Lin, Liguo and Moon, Jon J. and Yin, Haitao","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","525-536","2014","APR","Trade-Up Hypothesis;Pollution Haven Hypothesis;International Integration;Environment;China","","In contrast to the Pollution Haven Hypothesis, the Trade-Up Hypothesis holds that international integration helps improve firms' environmental performance in developing countries. Using firm-level data from Shanghai, this article examines how international linkages, in the form of foreign direct investment or international trade, affect firms' environmental compliance and performance. We find that firms with international linkage via ownership exhibit better compliance with environmental regulation and emit less pollution than firms with no international linkage. We also find that firms with international linkage via market exposure are more likely to exhibit better compliance with environmental regulation than firms with no international linkage, but find no evidence that the former emit less pollution than the latter. This provides a piece of empirical evidence for the Trade-Up Hypothesis."
2195,"An Empirical Study of the Bullwhip Effect in China","Shan, Jun and Yang, Shitao and Yang, Shilei and Zhang, Jin","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","537-551","2014","APR","Bullwhip Effect;Empirical Study;China;Supply Chain Management","","In this study, we investigate the bullwhip effect in China using data on over 1200 companies listed on the Shanghai and Shenzhen stock exchanges from 2002 to 2009. Specifically, we estimate the ratio of the volatility of production to the volatility of demand as a proxy for the bullwhip effect. Our results show that more than two-thirds of the companies we studied exhibit the bullwhip effect. We also find that several hypotheses proposed in the existing literature are supported by firm-level data from China, and that the intensity of the bullwhip effect in China declined during the period from 2002 to 2009."
2196,"First Step in Social Media: Measuring the Influence of Online Management Responses on Customer Satisfaction","Gu, Bin and Ye, Qiang","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","570-582","2014","APR","Online Social Media;Management Response;Service Recovery;Customer Satisfaction;Peer-Induced Fairness","","With the growing influence of online social media, firms increasingly take an active role in interacting with consumers in social media. For many firms, their first step in online social media is management responses, where the management responds to customers' comments about the firm or its products and services. In this article, we measure the impact of management responses on customer satisfaction using data retrieved from a major online travel agency in China. Applying a panel data model that controls for regression toward the mean and heterogeneity in individual preference for hotels, we find that online management responses are highly effective among low satisfaction customers but have limited influence on other customers. Moreover, we show that the public nature of online management responses introduces a new dynamic among customers. Although online management responses increase future satisfaction of the complaining customers who receive the responses, they decrease future satisfaction of complaining customers who observe but do not receive management responses. The result is consistent with the peer-induced fairness theory."
2197,"The Roles of Bank and Trade Credits: Theoretical Analysis and Empirical Evidence","Cai, Gangshu (George) and Chen, Xiangfeng and Xiao, Zhiguo","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","583-598","2014","APR","Trade Credit;Bank Credit;Capital Constrained;Newsvendor;Moral Hazard","","This study investigates the roles of bank and trade credits in a supply chain with a capital-constrained retailer facing demand uncertainty. We evaluate the retailer's optimal order quantity and the creditors' optimal credit limits and interest rates in two scenarios. In the single-credit scenario, we find the retailer prefers trade credit, if the trade credit market is more competitive than the bank credit market; otherwise, the retailer's preference of a specific credit type depends on the risk levels that the retailer would divert trade credit and bank credit to other risky investments. In the dual-credit scenario, if the bank credit market is more competitive than the trade credit market, the retailer first borrows bank credit prior to trade credit, but then switches to borrowing trade credit prior to bank credit as the retailer's internal capital declines. In contrast, if the trade credit market is more competitive, the retailer borrows only trade credit. We further analytically prove that the two credits are complementary if the retailer's internal capital is substantially low but become substitutable as the internal capital grows, and then empirically validate this prediction based on a panel of 674 firms in China over the period 2001-2007."
2198,"Firms' R& D Cooperation Behavior in a Supply Chain","Ge, Zehui and Hu, Qiying and Xia, Yusen","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","599-609","2014","APR","Supply Chain;R&D Cooperation Behavior;Cartelization;Spillover;Cooperation Path","","This study investigates firms' R&D cooperation behavior in a supply chain where two firms first cooperate in R&D investments and then decide the production quantity according to a wholesale price contract. By using a concept named contribution level that measures a firm's technological contribution to the R&D cooperation in the supply chain, we show that both firms can achieve win-win via cartelization only if their contribution levels are Pareto matched, i.e., when each firm's contribution level is comparable to its partner's. When spillovers are endogenized, we further establish that an increasing spillover always benefits both firms without any R&D cooperation, but only benefits the firm whose contribution level is relatively low when under R&D cartels. Finally, we show that the path of first increasing spillovers to be perfect and then forming a cartel has a higher chance of achieving the best mode in terms of profitability."
2199,"The Comparison of Two Vertical Outsourcing Structures under Push and Pull Contracts","Wang, Yulan and Niu, Baozhuang and Guo, Pengfei","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","610-625","2014","APR","Pull;Push;Control;Delegation;Three-Tier Supply Chain","","In a three-tier supply chain comprising an original equipment manufacturer (OEM), a contract manufacturer (CM), and a supplier, there exist two typical outsourcing structures: control and delegation. Under the control structure, the OEM contracts with the CM and the supplier respectively. Under the delegation structure, the OEM contracts with the CM only and the CM subcontracts with the supplier. We compare the two outsourcing structures under a push contract (whereby orders are placed before demand is realized) and a pull contract (whereby orders are placed after demand is realized). For all combinations of outsourcing structures and contracts, we derive the corresponding equilibrium wholesale prices, order quantities, and capacities. We find that the equilibrium production quantity is higher under control than under delegation for the push contract whereas the reverse holds for the pull contract. Both the OEM and the CM prefer control over delegation under the push contract. However, under the pull contract, the OEM prefers control over delegation whereas the CM and the supplier prefer delegation over control. We also show that for a given outsourcing structure, the OEM prefers the pull contract over the push contract. In extending our settings to a general two-wholesale-price (TWP) contract, we find that when wholesale prices are endogenized decision variables, the TWP contract under our setting degenerates to either a push or a pull contract."
2200,"Scheduling of Multi-skilled Staff Across Multiple Locations","Kuo, Yong-Hong and Leung, Janny M. Y. and Yano, Candace A.","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","626-644","2014","APR","Workforce Scheduling;Skill Compatibility;Multi-Location Scheduling;Scheduling Flexibility","","We address the problem of assigning airline customer service agents (CSAs) to tasks related to departing flights, such as selling tickets and collecting boarding cards, at an international terminal of a large airport. The airline specifies minimum and target levels of staff and required (or desired) types and levels of skills for each location in each time period. The assignment problem is complicated by staff heterogeneity, time required for moves between locations, and lunch and rest-break requirements. We present a mixed-integer formulation that considers both staffing shortages and skills mismatches and show that the problem is NP-hard. We derive valid inequalities that tighten the bounds within a branch-and-cut procedure, enabling us to obtain near-optimal solutions for problems of realistic size very quickly. We also present a generalization to simultaneously optimize shift starting times and task assignments, which can aid in longer term workforce planning. Finally, we utilize our procedure to obtain managerial insights regarding the benefits of flexibility derived from more highly skilled staff, allowing more frequent moves, and choices of shift starting times. We also demonstrate the benefits of our procedure vs. a heuristic that mimics what an experienced scheduler might choose."
2201,"Flexible-Duration Extended Warranties with Dynamic Reliability Learning","Gallego, Guillermo and Wang, Ruxian and Ward, Julie and Hu, Ming and Beltran, Jose Luis","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","645-659","2014","APR","Post-Sales Service;Flexible Warranty;Reliability Learning;Heterogeneous Market;Threshold Policy","","Frequent technological innovations and price declines adversely affect sales of extended warranties (EWs) as product replacement upon failure becomes an increasingly attractive alternative. To increase sales and profitability, we propose offering flexible-duration EWs. These warranties can appeal to customers who are uncertain about how long they will keep the product as well as to customers who are uncertain about the product's reliability. Flexibility may be added to existing services in the form of monthly billing with month-by-month commitments or by making existing warranties easier to cancel with pro-rated refunds. This paper studies flexible warranties from perspectives of both customers and the provider under customers' reliability learning. We present a model of customers' optimal coverage decisions and show that customers' optimal coverage policy has a threshold structure under some mild conditions. We further show that flexible warranties can result in higher profits and higher attach rates in a homogeneous market as well as in a heterogeneous market with multiple segments differing in various dimensions."
2202,"Service Completion Estimates for Cross-trained Workforce Schedules under Uncertain Attendance and Demand","Easton, Fred F.","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","660-675","2014","APR","Workforce Scheduling;Cross-Training;Allocation;Absenteeism","","Although cross-trained workers offer numerous operational advantages for extended-hour service businesses, they must first be scheduled for duty. The outcome from those decisions, usually made a week or more in advance, varies with realized service demand, worker attendance, and the way available cross-trained workers are deployed once the demands for service are known. By ignoring the joint variability of attendance and demand, we show that existing workforce scheduling models tend to overstate expected schedule performance and systematically undervalue the benefits of cross-training. We propose a two-stage stochastic program for profit-oriented cross-trained workforce scheduling and allocation decisions that is driven by service completion estimates obtained from the convolution of the employee attendance and service demand distributions. Those estimates, reflecting optimal worker allocation decisions over all plausible realizations of attendance and demand, provide the gradient information used to guide workforce scheduling decisions. Comparing the performance of workforce scheduling decisions for hundreds of different hypothetical service environments, we find that solutions based on convolution estimates are more profitable, favor proportionately more cross-trained workers and fewer specialists, and tend to recommend significantly larger (smaller) staffing levels for services under high (low) contribution margins than workforce schedules developed with independent expectations of attendance and demand."
2203,"Optimal Uniform Pricing Strategy of a Service Firm When Facing Two Classes of Customers","Zhou, Wenhui and Chao, Xiuli and Gong, Xiting","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","676-688","2014","APR","Service System;Queueing Delays;Delay-Sensitive Customers;Optimal Pricing","","When facing heterogeneous customers, how should a service firm make its pricing decision to maximize revenue? If discrimination is allowed, then priority schemes and differentiated pricing are often used to achieve that. In many applications, however, the firm cannot or is not allowed to set discriminatory prices, for example, list price in retail stores, online shopping, and gas stations; thus a uniform price must be applied to all customers. This study addresses the optimal uniform pricing problem of a service firm using a queueing system with two classes of customers. Our result shows that the potential pool of customers plays a central role in the firm's optimal decision. Depending on the range of system parameters, which are determined explicitly by the primitive data, the firm's optimal strategy may choose to serve only one class of customers, a subset of a class of customers, or a combination of different classes of customers. In addition, the optimal price is in general not monotonic with respect to the potential market sizes because their changes may lead to a major shift in the firm's decision on which customer class to serve. However, unless such a shift occurs, the optimal price is weakly decreasing in the potential market sizes."
2204,"Pricing and Operational Performance in Discretionary Services","Tong, Chunyang and Rajagopalan, Sampath","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","689-703","2014","APR","Discretionary Service;Pricing Scheme;Service Performance;Queuing","","In many services, for example, website or landscape design, the value or quality derived by a customer depends upon the service time, and this valuation differs across customers. Customers procure the service based on the expected value to be delivered, prices charged, and the timeliness of service. We investigate the performance of the optimal pricing scheme as well as two commonly used pricing schemes (fixed fee and time-based pricing) for such services on important dimensions such as revenue, demand served, and utilization. We propose a novel model that captures the above features and wherein both service rate and demand are endogenous and functions of the pricing scheme. In particular, service time is an outcome of the pricing scheme adopted and the heterogeneous valuations of customers, unlike in the queueing-based pricing literature. We find that the service system may benefit from a greater variance in consumer valuations, and the performance of pricing schemes is impacted by the shape of the distribution of customers' valuation of service time and the responsiveness desired by customers. Both the fixed fee and time-based schemes do well relative to the optimal pricing scheme in terms of revenue in many plausible scenarios, but there are substantial differences between the pricing schemes in some important operational metrics. For instance, the fixed fee scheme serves more customers and has higher utilization than the time-based scheme. We also explore variants of the fixed and time-based schemes that have better revenue performance and show that the two-part tariff which is a combination of fixed and time-based pricing can do as well as the optimal scheme in terms of revenue."
2205,"Interruption and Forgetting in Knowledge-Intensive Service Environments","Froehle, Craig M. and White, Denise L.","PRODUCTION AND OPERATIONS MANAGEMENT","23","4","704-722","2014","APR","Health Care;Services;Interruptions;Simulation","","An increasing barrier to productivity in knowledge-intensive work environments is interruptions. Interruptions stop the current job and can induce forgetting in the worker. The induced forgetting can cause re-work; to complete the interrupted job, additional effort and time is required to return to the same level of job-specific knowledge the worker had attained prior to the interruption. This research employs primary observational and process data gathered from a hospital radiology department as inputs into a discrete-event simulation model to estimate the effect of interruptions, forgetting, and re-work. To help mitigate the effects of interruption-induced re-work, we introduce and test the operational policy of sequestering, where some service resources are protected from interruptions. We find that sequestering can improve the overall productivity and cost performance of the system under certain circumstances. We conclude that research examining knowledge-intensive operations should explicitly consider interruptions and the forgetting rate of the system's human workers or models will overestimate the system's productivity and underestimate its costs."
2206,"Clickstream Data and Inventory Management: Model and Empirical Analysis","Huang, Tingliang and Van Mieghem, Jan A.","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","333-347","2014","MAR","Click Tracking;Advance Demand Information;Inventory Theory And Control;Empirical Research;Dynamic Programming;Econometric Analysis;Big Data","","We consider firms that feature their products on the Internet but take orders offline. Click and order data are disjoint on such non-transactional websites, and their matching is error-prone. Yet, their time separation may allow the firm to react and improve its tactical planning. We introduce a dynamic decision support model that augments the classic inventory planning model with additional clickstream state variables. Using a novel data set of matched online clickstream and offline purchasing data, we identify statistically significant clickstream variables and empirically investigate the value of clickstream tracking on non-transactional websites to improve inventory management. We show that the noisy clickstream data is statistically significant to predict the propensity, amount, and timing of offline orders. A counterfactual analysis shows that using the demand information extracted from the clickstream data can reduce the inventory holding and backordering cost by 3% to 5% in our data set."
2207,"Management of Energy Technology for Sustainability: How to Fund Energy Technology Research and Development","Baker, Erin and Solak, Senay","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","348-365","2014","MAR","Energy Technology;R&D Portfolio;Climate Change;Public Policy;Stochastic Progamming","","Operations management methods have been applied profitably to a wide range of technology portfolio management problems, but have been slow to be adopted by governments and policy makers. We develop a framework that allows us to apply such techniques to a large and important public policy problem: energy technology R&D portfolio management under climate change. We apply a multi-model approach, implementing probabilistic data derived from expert elicitations into a novel stochastic programming version of a dynamic integrated assessment model. We note that while the unifying framework we present can be applied to a range of models and data sets, the specific results depend on the data and assumptions used and therefore may not be generalizable. Nevertheless, the results are suggestive, and we find that the optimal technology portfolio for the set of projects considered is fairly robust to different specifications of climate uncertainty, to different policy environments, and to assumptions about the opportunity cost of investing. We also conclude that policy makers would do better to over-invest in R&D rather than under-invest. Finally, we show that R&D can play different roles in different types of policy environments, sometimes leading primarily to cost reduction, other times leading to better environmental outcomes."
2208,"Product Life-Cycle Management of Packaged Software","Mehra, Amit and Seidmann, Abraham and Mojumder, Probal","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","366-378","2014","MAR","Software Upgrades;Software Life Cycle;Upgrade Timing;Network Externalities","","A software product becomes less valuable for its consumers over time due to technological and economic obsolescence. As a result, firms have an opportunity to introduce and sell upgrades that provide higher utility to consumers compared to an older and out-of-date software product. In a market that is growing and consists of homogeneous customers, we prove that the optimal upgrade intervals are monotonically increasing throughout the product's life cycle solely because of demand and cost considerations. This finding is in conformity with empirical evidence, thus validating our theoretical model. We then present comparative statics results to show that increase in the rate of obsolescence or network externalities may sometimes increase upgrade intervals for early upgrades and decrease these for later upgrades in the product's life cycle, but increase in market growth rate always decreases these intervals. Further, when successive software upgrades are forward compatible, upgrade intervals are longer than when they are not. Finally, we present three separate extensions of our model to showcase the robustness of our results. Since upgrade development costs depend on upgrade intervals, these insights help managers understand how costing for upgrades changes over the product's life cycle."
2209,"Stable and Coordinating Contracts for a Supply Chain with Multiple Risk-Averse Suppliers","Chen, Xin and Shum, Stephen and Simchi-Levi, David","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","379-392","2014","MAR","Supply Chain Contracts;Risk Aversion;Quantity Discount;Consignment","","We analyze a decentralized supply chain with a single risk-averse retailer and multiple risk-averse suppliers under a Conditional Value at Risk objective. We define coordinating contracts and show that the supply chain is coordinated only when the least risk-averse agent bears the entire risk and the lowest-cost supplier handles all production. However, due to competition, not all coordinating contracts are stable. Thus, we introduce the notion of contract core, which reflects the agents' bargaining power and restricts the set of coordinating contracts to a subset which is credible. We also study the concept of contract equilibrium, which helps to characterize contracts that are immune to opportunistic renegotiation. We show that, the concept of contract core imposes conditions on the share of profit among different agents, while the concept of contract equilibrium provide conditions on how the payment changes with the order quantity."
2210,"Optimal Per-Use Rentals and Sales of Durable Products and Their Distinct Roles in Price Discrimination","Gilbert, Stephen M. and Randhawa, Ramandeep S. and Sun, Haoying","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","393-404","2014","MAR","Revenue Management;Per-Use Rental;Price Discrinimation;Market Segmentation","","We consider a setting in which consumers experience distinct instances of need for a durable product at random intervals. Each instance of need is associated with a random utility and the consumers are differentiated according to the frequency with which they experience such instances of need. We use our model of consumer utility to characterize the firm's optimal strategy of whether to sell, rent, or do a combination of both in terms of the transaction costs and consumers' usage characteristics. We find that the two modes of operation serve different roles in allowing the firm to price discriminate. While sales allow the firm to discriminate among consumers of different usage frequencies, rentals allow it to discriminate according to consumers' realized valuations. Consequently, even when transaction costs are negligible, it is often optimal for the firm to simultaneously rent and sell its product. In addition, we find that although sales and rentals are substitutes and that the offering of sales weakly increases rental prices, it is possible that the introduction of rentals to a pure selling operation can either increase or decrease the optimal sales prices."
2211,"Hierarchical Screening for Capacity Allocation in Supply Chains: The Role of Distributors","Chen, Ying-Ju and Deng, Mingcherng and Huang, Ke-Wei","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","405-419","2014","MAR","Capacity Allocation;Supply Chains;Hierarchy;Mechanism Design","","We consider a two-stage principal-agent screening environment in a decentralized supply chain with retailers, distributors, and a supplier. The retailers possess private information regarding their local market profitabilities. The distributors can partially observe the retailers' profitabilities and are heterogeneous with regard to the precision of that information. The supplier determines the level of production, but knows neither the local market profitabilities nor the precision of the distributors' information. The supplier first allocates finished products to distributors, and the distributors then contract with local retailers with a capacity constraint. We find that due to the distributors' superior information, the quantity distortion on the retailers' side is mitigated, and the upstream information asymmetry subsequently affects the quantity allocation among the downstream retailers. The supplier may not benefit from contracting with the distributors. In addition, no distributor is excluded based on the heterogeneity of the information precision, even though some distributors do not have better information than the supplier. In the numerical examples, we further analyze how the local market heterogeneity and inventory costs affect the capacity allocation, the retailers' payoffs, and the supply chain profits. We document some counter-intuitive quantity allocation rules that arise from the distributors' information advantage."
2212,"The Value of Category Captainship in the Presence of Manufacturer Competition","Kurtulus, Muemin and Nakkas, Alper and Uelkue, Sezer","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","420-430","2014","MAR","Retail Supply Chain Management;Supply Chain Collaboration;Category Management;Category Captainship;Auctions With Externalities","","This research investigates the value of category captainship (a management practice in which a retailer relies on a manufacturer for recommendations regarding strategic category management decisions) in retail supply chains. We consider a setting where the scope of category management is limited to assortment decisions and demand enhancing activities. We assume that the retailer selects a category captain among multiple competing manufacturers with privately known capabilities for driving category traffic. First, we consider a benchmark scenario where the retailer is responsible for category management. Then, we consider the category captainship scenario where the retailer selects one of the manufacturers as a captain to manage the category. We find that captainship is more likely to emerge in categories where the cost of managing variety, the retail margins, and the competition for captainship are moderate and the captain is more capable of driving traffic compared to the retailer. In such categories the collaboration between the retailer and the captain ensures sufficient surplus for both parties. Finally, we show that captainship can also benefit the non-captain manufacturers."
2213,"Coordinating Production and Marketing with Dynamic Transfer Prices","Dockner, Engelbert J. and Fruchter, Gila E.","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","431-445","2014","MAR","Coordinating Decentralized Divisions;Dynamic Transfer Price;Production And Marketing Interface;Price Production Differential Game","","Decentralized decision making is a fact in the modern business world accompanied by extensive research that looks into its consequences for overall firm profits. We study the interactions of decentralized marketing and operations divisions in a corporation and explore their impact on overall firm profits in the case with and without coordination of the two decentralized units. We assume that the marketing department is responsible for the price that influences the demand (sales), and the operations department is responsible for the production rate. We allow for backlogging over time. We model the interdependence involving marketing and operations decisions as a non-cooperative differential game, with the two divisions as strategically interacting players. We find that, without coordination, strategic interactions of marketing and production result in inefficiencies that can quantitatively be substantial. Next, we introduce a dynamic transfer pricing scheme as a coordination device and evaluate if it establishes efficient (first best and fully coordinated) outcomes. We show that if production and marketing play a game with pre-commitment strategies, there exists a dynamic transfer price that efficiently (fully) coordinates decentralized decision making and hence results in Pareto-efficient company profits. If the two decentralized divisions play a game without pre-commitment, dynamic transfer prices can partially coordinate decentralized decision making but fail to fully eliminate overall inefficiencies arising from strategic interactions among decentralized divisions."
2214,"A Capacitated Multi-echelon Inventory Placement Model under Lead Time Constraints","Hammami, Ramzi and Frein, Yannick","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","446-462","2014","MAR","Inventory Placement;Generic Multi-Echelon Supply Chain;Delivery Lead Time;Finite Capacity","","We develop an inventory placement model in the context of general multi-echelon supply chains where the delivery lead time promised to the customer must be respected. The delivery lead time is calculated based on the available stocks of the different input and output products in the different facilities and takes into account the purchasing lead times, the manufacturing lead times, and the transportation lead times. We assume finite manufacturing capacities and consider the interactions of manufacturing orders between time periods. Each facility manages the stocks of its input and output products. The size of customer orders and their arrival dates and due dates are assumed to be known as in many B2B situations. We perform extensive computational experiments to derive managerial insights. We also derive analytical insights regarding the manufacturing capacities to be installed and the impacts of the frequency of orders on the system cost."
2215,"Lean Control for Make-to-Order Companies: Integrating Customer Enquiry Management and Order Release","Thuerer, Matthias and Stevenson, Mark and Silva, Cristovao and Land, Martin J. and Fredendall, Lawrence D. and Melnyk, Steven A.","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","463-476","2014","MAR","Workload Control;Lean;Make-To-Order;Customer Enquiry Management;Order Review And Release","","A lead time that is short, predictable, and reliable is an increasingly important criterion in supplier selection. Although many companies may achieve this through lean implementation, high-variety manufacturers, for example, small and medium-sized make-to-order companies, have found that lean's planning and control techniques do not apply. This article outlines a planning and control concept known as workload control (WLC) that integrates customer enquiry management, including a due-date setting rule, with order release control. Simulation is then used to assess its impact on shop performance. Results demonstrate that an integrated WLC concept can reduce the percentage of tardy jobsso short lead times can be realistically quotedwhile also reducing and stabilizing workloads. WLC can level demand and production over time when work is not standardized and it is not possible to synchronize flows on the shop floor. Results are shown to be robust to changes in routing characteristics, the mix of orders with due dates specified by the customer and proposed internally, and the strike rate (or order-winning probability). Hence, an integrated approach to WLC represents an important step toward achieving lean in make-to-order companies."
2216,"Updating Inventories of Substitutable Resources in Response to Forecast Updates","Bansal, Saurabh and Dyer, James S.","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","477-488","2014","MAR","Substitutable Resources;Forecast Updates;Inventory Updates;Structural Properties Of Multi-Product Newsvendor Problems","","We show simple yet optimal results to update the inventory/capacity levels, expected profit, fill rates, and service levels of substitutable resources in response to an updating of the mean demand forecasts for the resources. We find that a change in the mean demand of one resource does not affect the optimal inventory level of any other resource. The results are obtained for demands with location-scale distribution, and for a revenue structure satisfying a triangle property such that the manager will always use the inventory of a resource to meet her own demand first before using it for substitution. The results for updating the performance measures also extend to managers who maintain non-optimal inventory/capacity levels. Implications for procurement, sales and operational planning, and multi-store operations are discussed."
2217,"Hierarchical Multi-skill Resource Assignment in the Telecommunications Industry","Barz, Christiane and Kolisch, Rainer","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","489-503","2014","MAR","Markov Decision Process;Approximate Linear Programming;Multi-Skilled Resources;Admission Control;Queueing","","We formulate a discrete time Markov decision process for a resource assignment problem for multi-skilled resources with a hierarchical skill structure to minimize the average penalty and waiting costs for jobs with different waiting costs and uncertain service times. In contrast to most queueing models, our application leads to service times that are known before the job is actually served but only after it is accepted and assigned to a server. We formulate the corresponding Markov decision process, which is intractable for problems of realistic size due to the curse of dimensionality. Using an affine approximation of the bias function, we develop a simple linear program that yields a lower bound for the minimum average costs. We suggest how the solution of the linear program can be used in a simple heuristic and illustrate its performance in numerical examples and a case study."
2218,"Peakedness-Based Staffing for Call Center Outsourcing","Van den Schrieck, Jean-Christophe and Aksin, Zeynep and Chevalier, Philippe","PRODUCTION AND OPERATIONS MANAGEMENT","23","3","504-524","2014","MAR","Bursty Arrivals;Peakedness Measurement;Call Center;Outsourcing","","This study considers the staffing problem of a vendor call center in a co-sourcing setting. The aim is to take short-term variability and correlations in time for call arrivals at such a vendor call center into account. To do so, peakedness is proposed as a useful measure of the burstiness in the arrival stream. The study empirically demonstrates the presence of bursty arrivals at a call center and proposes an approach to the measurement of the peakedness of the arrival stream making use of standard call center data. The problematic nature of bursty arrivals in the context of call center co-sourcing is demonstrated along with an asymptotic result establishing that the problem persists in large call centers. The study then analyzes two peakedness-based staffing methods: one which is a well known extension of the square root staffing rule and another which makes use of the Hayward approximation principles. Both approaches are simple and enable the vendor to improve its staffing procedure with good accuracy."
2219,"Distributional and Peer-Induced Fairness in Supply Chain Contract Design","Ho, Teck-Hua and Su, Xuanming and Wu, Yaozhong","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","161-175","2014","FEB","","","Members of a supply chain often make profit comparisons. A retailer exhibits peer-induced fairness concerns when his own profit is behind that of a peer retailer interacting with the same supplier. In addition, a retailer exhibits distributional fairness when his supplier's share of total profit is larger than his own. While existing research focuses exclusively on distributional fairness concerns, this study investigates how both types of fairness might interact and influence economic outcomes in a supply chain. We consider a one-supplier and two-retailer supply chain setting, and we show that (i) in the presence of distributional fairness alone, the wholesale price offer is lower than the standard wholesale price offer; (ii) in the presence of both types of fairness, the second wholesale price is higher than the first wholesale price; and (iii) in the presence of both types of fairness, the second retailer makes a lower profit and has a lower share of the total supply chain profit than the first retailer. We run controlled experiments with subjects motivated by substantial monetary incentives and show that subject behaviors are consistent with the model predictions. Structural estimation on the data suggests that peer-induced fairness is more salient than distributional fairness."
2220,"Order Stability in Supply Chains: Coordination Risk and the Role of Coordination Stock","Croson, Rachel and Donohue, Karen and Katok, Elena and Sterman, John","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","176-196","2014","FEB","","","The bullwhip effect describes the tendency for the variance of orders in supply chains to increase as one moves upstream from consumer demand. We report on a set of laboratory experiments with a serial supply chain that tests behavioral causes of this phenomenon, in particular the possible influence of coordination risk. Coordination risk exists when individuals' decisions contribute to a collective outcome and the decision rules followed by each individual are not known with certainty, for example, where managers cannot be sure how their supply chain partners will behave. We conjecture that the existence of coordination risk may contribute to bullwhip behavior. We test this conjecture by controlling for environmental factors that lead to coordination risk and find these controls lead to a significant reduction in order oscillations and amplification. Next, we investigate a managerial intervention to reduce the bullwhip effect, inspired by our conjecture that coordination risk contributes to bullwhip behavior. Although the intervention, holding additional on-hand inventory, does not change the existence of coordination risk, it reduces order oscillation and amplification by providing a buffer against the endogenous risk of coordination failure. We conclude that the magnitude of the bullwhip can be mitigated, but that its behavioral causes appear robust."
2221,"Does Higher Transparency Lead to More Search in Online Auctions?","Haruvy, Ernan and Leszczyc, Peter T. L. Popkowski and Ma, Yu","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","197-209","2014","FEB","","","In a controlled field experiment, we examine pairs of auctions for identical items under different conditions. We find that auction design features that are under the control of the auctioneerincluding information transparency, number of simultaneous auctions, and the degree of overlap between simultaneous auctionsaffect bidder search and choice. Clickstream data show that a significant relationship between information transparency and price dispersion can be linked to search. Specifically, the effect of information transparency on price dispersion is fully mediated by lookup behavior. Combining these findings, we make auction design recommendations regarding the provision of product and value information."
2222,"Reputation and Mechanism Choice in Procurement Auctions: An Experiment","Brosig-Koch, Jeannette and Heinrich, Timo","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","210-220","2014","FEB","","","We experimentally study the role of reputation in procurement using two common mechanisms: price-based and buyer-determined auctions. While buyers are bound to buy from the lowest bidder in price-based auctions, they can choose between bidders in buyer-determined auctions. Only the latter buyers can consider the reputation of bidders. We find that bidders supply higher quality in buyer-determined auctions leading to higher market efficiencies in these auctions. Accordingly, buyers prefer the buyer-determined auction over the price-based auction, while only half of the bidders do so. A more detailed analysis of buyers' and bidders' behavior and profits provides insights into their mechanism choice."
2223,"Coordination in Games with Strategic Complementarities: An Experiment on Fixed vs. Random Matching","Hyndman, Kyle and Kraiselburd, Santiago and Watson, Noel","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","221-238","2014","FEB","","","In this article, we study behavior in a series of two-player supply chain game experiments. Each player simultaneously chooses a capacity before demand is realized, and sales are given by the minimum of realized demand and chosen capacities. We focus on the differences in behavior under fixed pairs and random rematching. Intuition suggests that long-run relations should lead to more profitable outcomes. However, our results go against this intuition. While subjects' capacity choices are better aligned (i.e., closer together) under fixed pairs, average profits are more variable. Moreover, learning is slower under fixed pairsso much so that over the last five periods, average profits are actually higher under random rematching. The underlying cause for this finding appears to be a first-impressions bias, present only under fixed matching, in which the greater the misalignment in initial choices, the lower are average profits."
2224,"Willingness to Pay for Shifting Inventory Risk: The Role of Contractual Form","Kremer, Mirko and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","239-252","2014","FEB","","","In order to reduce their inventory risk, firms can attempt to contract with their suppliers for shorter supply lead-times, with their buyers for longer demand lead-times, or both. We designed a controlled laboratory experiment to study contracts that shift a focal firm's inventory risk to its supply chain partners and address two questions. First, is it more effective if the cost of shifting inventory risk is framed as a fixed fee or in per-unit cost terms? We find that, generally, our participants are willing to pay more to avoid supplydemand mismatches than the expected costs from such mismatches. This tendency to overpay is mitigated under fixed fee schemes. Second, does it matter whether the option to reduce inventory risk is the outcome of either increased responsiveness from the upstream supplier or advanced demand information from the downstream buyer? Our results suggest that this difference, when only a matter of framing, has no significant effect on willingness-to-pay."
2225,"Supply Chain Contract Design: Impact of Bounded Rationality and Individual Heterogeneity","Wu, Diana Yan and Chen, Kay-Yut","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","253-268","2014","FEB","","","In this article, we model various forms of non-optimizing behavior in a newsvendor setting, including biases such as recency, reinforcement, demand chasing, and anchoring, as well as unsystematic decision errors. We assume that a newsvendor may evaluate decisions by examining both past outcomes and future expected payoffs. Our model is motivated by laboratory observations under several types of supply chain contracts. Ordering decisions are found to follow multi-modal distributions that are dependent on contract structures and incentives. We differ from previous research by using statistics to determine which behavioral factors are applicable to each decision maker. A great deal of heterogeneity was discovered, indicating the importance of calibrating a contract to the individual. Our analysis also shows that the profit performance and the effectiveness of co-ordinating contracts can be affected by non-optimizing behaviors significantly. We conclude that, in addition to the aggregate order quantities, the decision distributions should be considered in designing contracts."
2226,"Complexity as a Contract Design Factor: A Human-to-Human Experimental Study","Kalkanci, Basak and Chen, Kay-Yut and Erhun, Feryal","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","269-284","2014","FEB","","","Despite being theoretically suboptimal, simpler contracts (such as price-only contracts and quantity discount contracts with limited number of price blocks) are commonly preferred in practice. Thus, exploring the tension between theory and practice regarding complexity and performance in contract design is especially relevant. Using human subject experiments, Kalkanc et al. (2011) showed that such simpler contracts perform effectively for a supplier interacting with a computerized buyer under asymmetric demand information. We use a similar set of experiments with the modification that a human supplier interacts with a human buyer. We show that human interactions strengthen the supplier's preference for simpler contracts. We find that suppliers have fairness concerns even when they interact with computerized buyers. These fairness concerns tend to be even stronger when suppliers interact with human buyers, particularly when the complexity of the contract is low. We also find that suppliers are more prone to random decision errors (i.e., bounded rationality) when interacting with human buyers. In the absence of social preferences, Kalkanc et al. identified reinforcement and bounded rationality as key biases that impact suppliers' decisions. In human-to-human experiments, we find evidence for social preference effects. However, these effects may be secondary to bounded rationality."
2227,"Wholesale Pricing under Mild and Privately Known Concerns for Fairness","Katok, Elena and Olsen, Tava and Pavlov, Valery","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","285-302","2014","FEB","","","This article studies the performance of wholesale pricing when the supply chain partners' fairness concerns are private information. We find that some properties of wholesale pricing established under complete information hold under incomplete information as well. First, wholesale pricing can coordinate the supply chain, despite the information asymmetry, when fairness concerns are strong enough. Second, in the case when an equitable profit split does not imply that the retailers profit must be higher than that of the supplier, the suppliers' equilibrium offer is never rejected. Overall, the study makes two primary contributions. First, it provides a partial characterization of the equilibrium when the conditions required for coordination do not hold, that is, when fairness concerns are mild. In this case, the model predicts that the expected market price must be exactly the same as under complete information. The channel efficiency, nevertheless, is strictly lower than under complete information. The distribution-free lower bound on channel efficiency suggests that this efficiency loss should be quite small, though. Second, it provides an experimental test of the models' predictions as well as a direct validation of the assumptions of preferences heterogeneity and mildness by obtaining the empirical distribution of the preferences."
2228,"Comparison as Incentive: Newsvendor Decisions in a Social Context","Avci, Buket and Loutfi, Zeina and Mihm, Juergen and Belavina, Elena and Keck, Steffen","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","303-313","2014","FEB","","","Explicit formal mechanisms dominate the discussion about incentives in Operations Management, yet many other mechanisms exist. Social comparison between peers may provide strong implicit incentives for individuals. Social comparison arises naturally in all social settings and may thus be unintended; however, many companies deliberately use it to motivate employees. In this study, we model a social context in which purchasers evaluate their performance relative to their peers; a feeling of inferiority results in a negative contribution to utility, whereas a feeling of superiority results in a positive contribution. We find that social comparison induces characteristic deviations from the newsvendor optimum ordering decision: if fear of inferiority outweighs anticipation of superiority, then purchasers herd together; the converse scenario incites actors to polarize away from each other. In both cases, actors will deviate from ordering the newsvendor optimum in order to satisfy social goals. Demand correlation and profit margins moderate the extent of the deviation."
2229,"Distributed Decisions in Networks: Laboratory Study of Routing Splittable Flow","Rapoport, Amnon and Gisches, Eyran J. and Mak, Vincent","PRODUCTION AND OPERATIONS MANAGEMENT","23","2","314-331","2014","FEB","","","We study network games in which users choose routes in computerized networks susceptible to congestion. In the unsplittable condition, route choices are completely unregulated, players are symmetric, each player controls a single unit of flow and chooses a single origindestination (OD) path. In the splittable condition, which is the main focus of this study, route choices are partly regulated, players are asymmetric, each player controls multiple units of flow and chooses multiple OD paths to distribute her fleet. In each condition, users choose routes in two types of network: a basic network with three parallel routes and an augmented network with five routes sharing joint links. We construct and subsequently test equilibrium solutions for each combination of condition and network type, and then propose a Markov revision protocol to account for the dynamics of play. In both conditions, route choice behavior approaches equilibrium and the Braess Paradox is clearly manifested."
2230,"Clinic Capacity Management: Planning Treatment Programs that Incorporate Adherence","McCoy, Jessica H. and Johnson, M. Eric","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","1-18","2014","JAN","Health Care Management;Public Policy;Humanitarian Operations;Clinic Capacity Planning And Investment;Math Programming","","For infectious diseases like tuberculosis and HIV, treatment adherence plays an important role in treatment effectiveness and epidemic control. Studies of some infectious diseases indicate that patients who live closer to their health facilities maintain higher adherence; however, most models ignore the heterogeneity of patients' adherence. Clinics must balance knowledge about adherence with epidemic growth when creating successful treatment programs. We develop an optimization model that integrates a clinic's capacity decisions with population health outcomes. We find that incorporating adherence into clinic planning models can lead to decisions that significantly improve outcomes. For example, in a realistic case study of the HIV epidemic in Zambia, we find that decision makers who ignore decreasing adherence make suboptimal decisions and overestimate the effectiveness of their treatment programs by as much as 94%. Our model is a first step toward understanding the relationship between adherence and health delivery."
2231,"Vertical Integration under Competition: Forward, Backward, or No Integration?","Lin, Yen-Ting and Parlaktuerk, Ali K. and Swaminathan, Jayashankar M.","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","19-35","2014","JAN","Vertical Integration;Competition;Supply Chain;Quality;Pricing","","We consider two competing supply chains, each consisting of supplier, a manufacturer, and a retailer. The suppliers exert effort to improve product quality, and the retailers sell products competitively. Each manufacturer chooses one of the three strategies: forward integration, backward integration, or no vertical integration. We seek for a subgame perfect Nash equilibrium and study the resulting market structure. Moreover, we characterize the effect of vertical integration on profitability, product price, and quality in a competitive setting. Existing literature has shown that, when manufacturers consider only forward integration, they may choose not to vertically integrate in equilibrium. In contrast, we find that, when both forward and backward integration options are considered, disintegration cannot be an equilibrium outcome. In this case, both manufacturers either forward or backward integrate, and the degree of product perishability, cost of quality, and how much consumers value quality are critical for the chosen direction of integration. Furthermore, competition increases attractiveness of backward integration relative to forward integration. We show that, while integrating backward unilaterally is always beneficial, unilateral forward integration can harm a manufacturer's profitability. Finally, vertical integration can result in a better quality product sold at a lower price."
2232,"Strategic Motive for Introducing Internet Channels in a Supply Chain","Hsiao, Lu and Chen, Ying-Ju","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","36-47","2014","JAN","Multi-Channel Management;Retail Operations;Electronic Commerce;Game Theory","","Rapid advances of information technology in recent years have enabled both the manufacturers and the retailers to operate their own Internet channels. In this study, we investigate the interaction between the capabilities of introducing the Internet channels, the pricing strategies, and the channel structure. We classify consumers into two segments: grocery shoppers attach a higher utility from purchasing through the physical channel, whereas a priori Internet shoppers prefer purchasing online. We find that when the Internet shoppers are either highly profitable or fairly unimportant, the manufacturer prefers to facilitate the channel separation either through his own Internet channel or the retailer's. In the intermediate region, however, the manufacturer encroaches the grocery shoppers and steals the demand from the retailer's physical channel. With horizontal competition between retailers, a priori symmetric retailers may adopt different channel strategies as a stable market equilibrium. The manufacturer may willingly give up his Internet channel and leverage on the retailer competition. When the manufacturer sells through an online e-tailer, Internet shoppers may be induced to purchase through the physical channel. This reverse encroachment strategy emerges because selling through the e-tailer leads to a more severe double marginalization problem."
2233,"Competitive Quality Choice and Remanufacturing","Oersdemir, Adem and Kemahlioglu-Ziya, Eda and Parlaktuerk, Ali K.","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","48-64","2014","JAN","Product Quality;Remanufacturing;Competition;Environmental Impact;Social Welfare","","We consider an original equipment manufacturer (OEM) who faces competition from an independent remanufacturer (IR). The OEM decides the quality of the new product, which also determines the quality of the competing remanufactured product. The OEM and the IR then competitively determine their production quantities. We explicitly characterize how the OEM competes with the IR in equilibrium. Specifically, we show that the OEM relies more on quality as a strategic lever when it has a stronger competitive position (determined by the relative cost and value of new and remanufactured products), and in contrast it relies more heavily on limiting quantity of cores when it has a weaker competitive position. The IR's entry threat as well as its successful entry can decrease the consumer surplus. Furthermore, our results illustrate that ignoring the competition or the OEM's quality choice leads to overestimating benefits of remanufacturing for consumer and social welfare. In addition, we show an IR with either a sufficiently weak competitive position (so the OEM deters entry) or a sufficiently strong one (so the OEM is forced to limit quantity of cores) is desirable for reducing the environmental impact. Comparing our results with the benchmark in which the OEM remanufactures suggests that encouraging IRs to remanufacture in lieu of the OEMs may not benefit the environment. Furthermore, the benchmark illustrates that making remanufacturing more attractive improves the environmental impact when the remanufacturer is the OEM, while worsening it when remanufacturing is done by the IR."
2234,"Dynamic Pricing and Inventory Management with Regular and Expedited Supplies","Zhou, Sean X. and Chao, Xiuli","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","65-80","2014","JAN","Optimal Policy;Pricing;Inventory Control;Supply Diversification;Lead Time","","We consider a periodic-review inventory system with regular and expedited supply modes. The expedited supply is faster than the regular supply but incurs a higher cost. Demand for the product in each period is random and sensitive to its selling price. The firm determines its order quantity from each supply in each period as well as its selling price to maximize the expected total discounted profit over a finite or an infinite planning horizon. We show that, in each period if it is optimal to order from both supplies, the optimal inventory policy is determined by two state-independent thresholds, one for each supply mode, and a list price is set for the product; if only the regular supply is used, the optimal policy is a state-dependent base-stock policy, that is, the optimal base-stock level depends on the starting inventory level, and the optimal selling price is a markdown price that decreases with the starting inventory level. We further study the operational impact of such supply diversification and show that it increases the firm's expected profit, reduces the optimal safety-stock levels, and lowers the optimal selling price. Thus that diversification is beneficial to both the firm and its customers. Building upon these results, we conduct a numerical study to assess and compare the respective benefit of dynamic pricing and supply diversification."
2235,"An Auction Mechanism for Pricing and Capacity Allocation with Multiple Products","Karabati, Selcuk and Yalcin, Zehra Bilginturk","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","81-94","2014","JAN","Auctions;Pricing;Scheduling;Capacity Allocation","","We consider a pricing and short-term capacity allocation problem in the presence of buyers with orders for bundles of products. The supplier's objective is to maximize her net profit, computed as the difference between the revenue generated through sales of products and the production and inventory holding costs. The objective of each buyer is similarly profit maximization, where a buyer's profit is computed as the difference between the time-dependent utility of the product bundle he plans to buy, expressed in monetary terms, and the price of the bundle. We assume that bundles' utilities are buyers' private information and address the problem of allocating the facility's output. We directly consider the products that constitute the supplier's output as market goods. We study the case where the supplier follows an anonymous and linear pricing strategy, with extensions that include quantity discounts and time-dependent product and delivery prices. In this setting, the winner determination problem integrates the capacity allocation and scheduling decisions. We propose an iterative auction mechanism with non-decreasing prices to solve this complex problem, and present a computational analysis to investigate the efficiency of the proposed method under supplier's different pricing strategies. Our analysis shows that the problem with private information can be effectively solved with the proposed auction mechanism. Furthermore, the results indicate that the auction mechanism achieves more than 80% of the system's profit, and the supplier receives a higher percentage of profit especially when the ratio of demand to available capacity is high."
2236,"Lead Time Management through Expediting in a Continuous Review Inventory System","Mamani, Hamed and Moinzadeh, Kamran","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","95-109","2014","JAN","Expediting;Inventory Management;Continuous-Review Inventory Systems;Shipment Network Design","","We consider a continuous review inventory system where delivery lead times can be managed by expediting in-transit orders shipped from the supplier. First, we propose an ordering/expediting policy and derive expressions for evaluating the operating characteristics of such systems. Second, using extensive numerical experiments, we quantify the benefits of such an expediting policy. Third, we investigate a number of managerial issues. Specifically, we analyze the impact of the number of expediting hubs and their locations along the shipment network on the performance of such systems and offer insights into the design of the shipment network. We show (i) a single expediting hub that is optimally located in a shipment network can capture the majority of cost savings achieved by a multi-hub system, especially when expediting cost is not low or demand variability is not high; (ii) when expediting time is proportional to the time to destination, for small-enough or large-enough demand variations, a single expediting hub located in the middle of the shipment network can capture the majority of cost savings of an optimally located hub; and (iii) in general, hubs close to the retailer significantly drive down costs, whereas hubs close to the supplier may not offer much cost savings."
2237,"Coordinated Logistics: Joint Replenishment with Capacitated Transportation for a Supply Chain","Buyukkaramikli, Nasuh C. and Gurler, Ulku and Alp, Osman","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","110-126","2014","JAN","Joint Replenishment;Transportation;Inventory;Logistics","","In this study, we consider the integrated inventory replenishment and transportation operations in a supply chain where the orders placed by the downstream retailer are dispatched by the upstream warehouse via an in-house fleet of limited size. We first consider the single-item single-echelon case where the retailer operates with a quantity based replenishment policy, (r,Q), and the warehouse is an ample supplier. We model the transportation operations as a queueing system and derive the operating characteristics of the system in exact terms. We extend this basic model to a two-echelon supply chain where the warehouse employs a base-stock policy. The departure process of the warehouse is characterized in distribution, which is then approximated by an Erlang arrival process by matching the first two moments for the analysis of the transportation queueing system. The operating characteristics and the expected cost rate are derived. An extension of this system to multiple retailers is also discussed. Numerical results are presented to illustrate the performance and the sensitivity of the models and the value of coordinating inventory and transportation operations."
2238,"Supply Disruptions, Heterogeneous Beliefs, and Production Efficiencies","Chen, Ying-Ju","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","127-137","2014","JAN","Supply Disruptions;Heterogeneous Beliefs;Information Asymmetry;Backup Production","","Recent years have witnessed the pervasive supply disruptions and their impacts on supply chain performance. In this study, we investigate the optimal procurement design with supply disruptions and heterogeneous beliefs between the buyer and the supplier. We examine the impact of information asymmetry on the supplier's belief, the control right of the backup production, and the verifiability of supply disruption. The belief heterogeneity creates speculative gains and losses because the buyer and the supplier hold different estimates of the disruption probability. We demonstrate that the buyer's incentive to exploit this belief heterogeneity leads to real production inefficiencies in different scenarios. The production efficiency is not necessarily improved with more transparent information. Moreover, a very pessimistic supplier may have no incentive to invest in improving the reliability even if this is costless, and the supplier may produce more when the expected production cost becomes higher. When the buyer sees some value in using the supplier's estimate to update his own belief, we find that the main results hold unless the buyer completely abandons his belief."
2239,"Dedicated Transportation Subnetworks: Design, Analysis, and Insights","Rajapakshe, Tharanga and Dawande, Milind and Gavirneni, Srinagesh and Sriskandarajah, Chelliah and Panchalavarapu, P. Rao","PRODUCTION AND OPERATIONS MANAGEMENT","23","1","138-159","2014","JAN","Transportation Network;Dedicated Subnetwork;Deadheading;Lane-Sharing;Heuristics","","A dedicated subnetwork (DSN) refers to a subset of lanes, with associated loads, in a shipper's transportation network, for which resourcestrucks, drivers, and other equipmentare exclusively assigned to accomplish shipping requirements. The resources assigned to a DSN are not shared with the rest of the shipper's network. Thus, a DSN is an autonomously operated subnetwork and, hence, can be subcontracted. We address a novel problem of extracting a DSN for outsourcing to one or more subcontractors, with the objective of maximizing the shipper's savings. In their pure form, the defining conditions of a DSN are often too restrictive to enable the extraction of a sizable subnetwork. We consider two notionsdeadheading and lane-sharingthat aid in improving the size of the DSN. We show that all the optimization problems involved are both strongly NP-hard and APX-hard, and demonstrate several polynomially solvable special cases arising from topological properties of the network and parametric relationships. Next, we develop a network-flow-based heuristic that provides near-optimal solutions to practical instances in reasonable time. Finally, using a test bed based on data obtained from a national 3PL company, we demonstrate the substantial monetary impact of subcontracting a DSN and offer useful managerial insights."
2240,"The Role of Operations Management Across the Entrepreneurial Value Chain","Joglekar, Nitin and Levesque, Moren","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1321-1335","2013","NOV","Operations Management;Entrepreneurship;Technology Commercialization;Discovery;Commitment;Organization;Growth","","This special issue contains articles that exemplify the role of operations management across the entrepreneurial value chain. This value chain encompasses all stages of the entrepreneurial phenomenon, including technology commercialization, where discovery, commitment, organization, and growth must take place. We report on a literature search that identifies research questions categorized with respect to topics crucial to operations management scholars and classify these questions under each stage of this value chain. The search guides the development of an evolutionary path for the use of resources, routines, and reputation (3Rs), often lacking in this process, and enables us to propose modeling and topical gaps in the literature. We offer a framework to set up exemplars for operational tradeoffs uniquely associated with the entrepreneurial value chain. We also articulate how five contributed articles in this issue tackle some of these tradeoffs, prior to introducing four perspective pieces. We hope this discussion motivates follow-on work and triggers a significant increase in the flow of articles that make it to both entrepreneurship and operations management top-tier academic and practitioner publications."
2241,"Cooperating to Commercialize Technology: A Dynamic Model of Fairness Perceptions, Experience, and Cooperation","van Burg, Elco and van Oorschot, Kim E.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1336-1355","2013","NOV","Technology Commercialization;Cooperation;System Dynamics;Fairness;Spin-Offs","","Technology entrepreneurship is an important driver of economic growth, although entrepreneurs must maintain cooperative ties with the owners of any technology they hope to bring to market. Existing studies show that fairness perceptions have a great influence on this cooperation, but no research investigates its precise mechanisms or dynamic patterns. This study explores the development of 17 ventures that cooperated with a university-owner of technology and thereby identifies different cooperation patterns in which fairness perceptions influence the degree of cooperation. These perceptions also change over time, partly as a function of accumulated experience and learning. A system dynamics model integrates insights from existing literature with the empirical findings to reveal which cooperation mechanisms relate to venture development over time; the combinations of individual experience, fairness perceptions, and market circumstances lead to four different patterns. This model can explain changes in entrepreneurial cooperation as a result of changes in fairness perceptions, which depend on learning effects and entrepreneurial experience. Each identified cooperation pattern has implications for research and offers insights for practitioners who need to manage relationships in practice."
2242,"Integration and Cospecialization of Emerging Complementary Technologies by Startups","Anderson, Jr., Edward G. and Parker, Geoffrey G.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1356-1373","2013","NOV","Startups;Complementary Technologies;Integration;Renewable Energy;System Dynamics","","We analyze the market entry problem faced by startups that must integrate their service or product with one or more complementary technologies. The problem is especially challenging when the complementary technologies have uncertain cost reduction potentials. The entrepreneurship literature suggests that startups should pursue focused strategies for various reasons, including bounded rationality and budget constraints, but generally overlooks startups entering markets with complementary technologies. The advice for mature firms investing in complementary technologies is often to diversify investment across multiple complements to manage technological uncertainty. Given competing guidance, we seek to extend the entrepreneurship literature by modeling startups' entry decisions for markets in which complementary technologies exhibit strong learning effects. We find that, consistent with the extant entrepreneurship literature, startups generally achieve higher expected returns by channeling their integration investment to only one complementary technology. However, the mechanisms driving our results differ significantly by hinging on nonlinear feedback effects that occur when firms concentrate integration investment in only one complementary technology. Interestingly, this focused strategy often does not yield the highest market share or the lowest likelihood of bankruptcy. We characterize the situations under which each finding holds and describe the implications of these findings for theory, practice, and policy."
2243,"Commercialization of Platform Technologies: Launch Timing and Versioning Strategy","Bhargava, Hemant K. and Kim, Byung Cho and Sun, Daewon","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1374-1388","2013","NOV","Technology Commercialization;Product Launch Strategy;Platform Technology;Versioning;Uncertainty","","Many emerging entrepreneurial applications and services connect two or more groups of users over Internet-based information technologies. Commercial success of such technology products requires astute business practices related to product line design, price discrimination, and launch timing. We examine these issues for a platform firm that serves two marketslabeled as user and developer marketssuch that the size of each market positively impacts participation in the other. In addition, our model allows for sequential unfolding of consumer and developer participation, and for uncertainty regarding developer participation. We demonstrate that product versioning is an especially attractive strategy for platform firms, that is, the trade-off between market size and margins is tilted in the direction of more versions. However, when expanding the product line carries substantial fixed costs (e.g., marketing cost, cost of additional plant, increased distribution cost), then the uncertainty in developer participation adversely impacts the firm's ability to offer multiple versions. We show that for established firms with lower uncertainty about developer participation, the choice is essentially between an expanded or minimal product line. Startups and firms that are entering a new product category are more likely to benefit from a wait and see deferred expansion strategy."
2244,"Entrepreneurial Firms and Downstream Alliance Partnerships: Impact of Portfolio Depth and Scope on Technology Innovation and Commercialization Success","Hora, Manpreet and Dutta, Dev K.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1389-1400","2013","NOV","Technology Commercialization Success;Alliance Portfolio;Depth And Scope;Biotech Industry","","To achieve technology innovation and commercialization (TIC) success under complex, protracted, and uncertain product development cycles, entrepreneurial firms engage in downstream alliance partnerships with mainstream industry players. In this study, we examine two specific characteristics of the entrepreneurial firm's downstream alliance portfolio (depth and scope) and their impact on TIC success. Employing a sample of 728 biotech firms and their partnerships with pharmaceutical companies, we find that while portfolio depth and scope separately have positive impact on success, the relationship between portfolio scope and success is additionally moderated by portfolio depth. Further, insights from post hoc interviews also suggest that though it is challenging for entrepreneurial firms to incorporate both depth and scope in alliance partnerships, those that optimally combine both can achieve higher TIC success."
2245,"The Role of Operational Capabilities in Enhancing New Venture Survival: A Longitudinal Study","Tatikonda, Mohan V. and Terjesen, Siri A. and Patel, Pankaj C. and Parida, Vinit","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1401-1415","2013","NOV","Firm Survival;Working Capital;Labor Productivity;Start-Ups;Longitudinal Methods;Performance Measurement","","We investigate relationships between operational capabilities and new venture survival. On the basis of operations management and entrepreneurship literature, we develop a contingency framework of operational capabilities especially appropriate at different life phases of a new venture's evolution. We expect that in the first years of a new venture's life, entrepreneurs should emphasize high inventory turnover to preserve working capital, support customer responsiveness, and aid firm adaptability. As new ventures grow, entrepreneurs should emphasize internal working capital generation via larger gross margins to support production ramp-up. Later, new venture entrepreneurs should emphasize employee productivity to buttress sustainable volume production. We analyze a 6-year longitudinal sample of 812 Swedish manufacturing new ventures using a gamma frailty-based Cox regression. The findings show that specific operational capabilities, while always supporting new venture survival, have exceptional influence in specific new venture life phases. The three hypotheses are confirmed, suggesting that higher inventory turnover, gross margin, and employee productivity further increase new venture survival likelihoods, respectively, in the venture's start-up, growth, and stability phases. This suggests a phased-capabilities approach to new venture survival. This study contributes to operations management and entrepreneurship theory and practice, and sets a foundation for future research on operations strategy for new ventures."
2246,"Operational Entrepreneurship: How Operations Management Research Can Advance Entrepreneurship","Shepherd, Dean A. and Patzelt, Holger","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1416-1422","2013","NOV","Opportunity Recognition;Opportunity Evaluation;Opportunity Exploitation;Operational Entrepreneurship;Entrepreneurial Operations","","In this article, we introduce the notion of operational entrepreneurshipthe selection and management of transformation processes for recognizing, evaluating, and exploiting opportunities for potential value creationto offer examples of research opportunities at the interface of entrepreneurship and operations management. Specifically, we believe that operations management has been under-utilized for gaining a deeper understanding of (i) the knowledge and motivation required for opportunity recognition, (ii) evaluations of a recognized opportunity to determine if it represents an opportunity for the specific entrepreneur, and (iii) the role that feedback from an exploitation of a current opportunity plays in the recognition and evaluation of subsequent opportunities. We also introduce (but not develop) the notion of entrepreneurial operations."
2247,"Advancing Theory in Entrepreneurship from the Lens of Operations Management","Phan, Phillip and Chambers, Chester","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1423-1428","2013","NOV","Entrepreneurship;Om Research","","Early writings in economics describe the entrepreneur's role in terms of bearing the uncertainty inherent in new undertakings. Much of the research published in the pages of Production and Operations Management deals with management under uncertainty. The shared concerns over the impacts of multiple types of uncertainty suggest that research on Operations Management (OM) can play a role in the development of theory in entrepreneurship. We discuss aspects of such a role from two perspectives. First, we consider several topics in the OM literature that have clear applications or parallels in entrepreneurship. These topics include innovation, the management of technology, new product development, flexibility, and hedging strategies. Understanding these topical connections should aid in the development of tools and applications central to the practice of entrepreneurship. On another level, when we consider how the approaches to many of these topics in OM are grounded in theory adapted from Operations Research and Economics we argue that these same roots can be used as starting points for the development of theory in entrepreneurship. As examples, we will argue that the theoretical bases supporting robust optimization, stochastic dynamic programming, and even Total Quality Management can also serve as foundations of theories about the roles, practice, and behaviors of entrepreneurs."
2248,"Knowledge Management for the Entrepreneurial Venture","Gaimon, Cheryl and Bailey, Jennifer","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1429-1438","2013","NOV","Entrepreneurship;Knowledge Management;Venture Life Cycle","","We synthesize research from operations management, entrepreneurship, organizational science, and strategy to investigate the performance-enhancing benefits of knowledge management activities throughout the entrepreneurial process of a high-tech venture from idea conception to commercialization. We adopt a dynamic learning perspective of entrepreneurship to understand how knowledge management activities change throughout four phases of the venture's life cycle. We introduce a framework that identifies a set of knowledge-based capabilities that enhance the entrepreneurial venture's success. In the context of the first phase, we discuss knowledge as a key driver of entrepreneurial alertness and creativity, both of which impact the quality and quantity of opportunities and innovations discovered. Second, we describe how knowledge enables the entrepreneur to make decisions under uncertainty such as determining which opportunity to pursue. For Phase 3 of the life cycle, we explore the challenges of managing knowledge during the development of the product or technology including the trade-off between exploration and exploitation. In the final phase, we explore how knowledge impacts the market entry decision, survival, and the value captured at commercialization. We conclude the article with suggestions for future research."
2249,"Operations Management Opportunities in Technology Commercialization and Entrepreneurship","Krishnan, Viswanathan","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1439-1445","2013","NOV","Technology Commercialization;Innovation;Entrepreneurship","","The field of Production and Operations Management (POM) is increasingly perceived as a rigorous but narrow field, antiquated and not very relevant to the current challenges and concerns of managers in job-creating growth companies vital to our economies. I argue that a narrower positioning of POM in the past is responsible for its perceived limited utility to growth firms and global economies. POM at its core is about doing more with less, which is very well aligned with the context and needs of resource-constrained entrepreneurial companies. My discussion is focused on how the research paradigm of POM is and can be relevant to meeting the emerging challenges of growth companies of tomorrow. Specifically, I examine how POM can help meet the needs of these organizations to become scalable and sustainable. The objective is to stimulate thought and discussion and encourage early-stage POM scholars to seriously consider the contexts of technology commercialization, entrepreneurship, and growth companies as avenues for future research."
2250,"Integration of Global Knowledge Networks","Anderson, Jr., Edward G. and Parker, Geoffrey G.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1446-1463","2013","NOV","Supply Chain Integration;Outsourcing;Project Management;Product Development;Software Development","","This article surveys the literature and develops a framework for research into the integration of distributed knowledge work (DKW). Knowledge work is considered to be distributed whenever key decisions for execution of the project cut across organizational boundaries, as occurs under outsourcing, offshoring, or open-source arrangements. The growth of such arrangements in recent years is well documented. Nonetheless, research into maintaining the coherence of a DKW project from initiation to customer delivery, often referred to as supply chain integration, project or systems integration, or simply integration, is relatively new. We first review the relevant literature from operations, service, and information management, organizational theory, and engineering design, focusing on the key decisions identified by this literature in relation to the contracting, organization, work, and information infrastructure design of a knowledge work project. We then attempt to open the black box of integration by inductively organizing these key decisions. Finally, we contrast this approach with prior research frameworks and identify key topics for future study."
2251,"Leveraging Open Innovation Using Intermediary Networks","Billington, Corey and Davidson, Rhoda","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1464-1477","2013","NOV","Open Innovation;Intermediary Networks;Procurement;Supply Chain Management","","Open innovation, fuelled by the rise of the Internet, has made it feasible and cheaper for firms to open themselves up to a wide range of external sources of innovative ideas. The explosive growth of open innovation intermediary networks, such as InnoCentive or Linked-in, enables the rapid pairing of firms seeking knowledge to address a wide range of business challenges (seekers) with other firms or individuals who already have relevant knowledge (solvers or knowledge brokers). These intermediary networks allow procurement departments to source codified and un-codified knowledge from firms or individuals outside their traditional supplier networks using one-off transactional relationships. Although sourcing ideas in this way theoretically poses problems for knowledge search and transfer, we have found that companies can draw on processes and integration mechanisms developed by procurement and design engineering to develop effective organizational learning routines. These routines are strategically vital to source new ideas through open innovation using intermediary networks and create competitive advantage."
2252,"Team Dispersion, Information Technology, and Project Performance","Bardhan, Indranil and Krishnan, Vish V. and Lin, Shu","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1478-1493","2013","NOV","Team Dispersion;Information Technology;Project Performance;Moderation;Project Management","","The impact of information technology (IT) on the performance of distributed projects is not well understood. Although prior research has documented that dispersion among project teams has an adverse effect on project performance, the role of IT as an enabler of communication to bridge the spatial distance among team members in distributed networks has not been empirically studied. We focus on the role of IT as a moderator of the relationship between team dispersion and project performance using projects as the unit of analysis. We find that IT mitigates the negative effect of team dispersion on project performance, especially in high information volume projects. Our central contribution is the development of an empirically tested model to improve the understanding of the operational impact of IT as a vehicle to bridge spatial dispersion among distributed teams that are engaged in knowledge-intensive work."
2253,"Supply Chain Integration, Product Modularity, and Market Valuation: Evidence from the Solar Energy Industry","Davies, Jane and Joglekar, Nitin","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1494-1508","2013","NOV","Product Modularity;Supply Chain Integration;Network;Market Valuation","","Supply chain integration is increasingly seen as a method to obtain flexibility and, consequently, to provide competitive advantage for firms within a supply chain. Product modularity, either in concert with or independent of such integration, can also produce flexibility for firms within a supply chain. In this proof-of-concept research, we explore whether the supply chain network affects each constituent firm's market valuation and how decisions regarding the level of supply chain integration and the usage of product modularity are associated with the value of the supply chain. We develop a method to identify and measure the supply chain's effect on each constituent firm's market valuation. Results indicate that greater integration is associated with a higher supply chain valuation, whereas increasing aggregated product modularity across the supply chain relates to a lower supply chain value. However, when combined, the interaction of aggregated product modularity and supply chain integration is positively associated with the supply chain's valuation."
2254,"In-House Globalization: The Role of Globally Distributed Design and Product Architecture on Product Development Performance","Gokpinar, Bilal and Hopp, Wallace J. and Iravani, Seyed M. R.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1509-1523","2013","NOV","Distributed Work;Global Product Development;Networked Design;Product Architecture","","Changes in the global economy and technological advances are stimulating increased geographic distribution of new product design and development efforts. For large organizations that design and develop complex products, this geographic distribution has added a new layer of complexity to product development operations. In this empirical study of a large auto manufacturer, we examine the operational performance implications of splitting the design of vehicle subsystems across multiple geographic locations. Our results indicate that global distribution diminishes the chance of completing tasks on time and degrades subsystem design quality. Finally, by examining the interplay between subsystem centrality and global distribution, we found that higher centrality in the product architecture amplifies the impact of global distribution on subsystem error rates."
2255,"Failure Modes and Effects Analysis: An Evaluation of Group versus Individual Performance","Guerrero, Hector H. and Bradley, James R.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1524-1539","2013","NOV","Fmea;Risk Analysis;Virtual Groups;Product Design;Distributed Product Development","","Failure modes and effects analysis (FMEA) is one of the most frequently used tools in process and product design: it is used in quality and reliability planning, and event and failure mode analysis. It has a long history of use and is a formally prescribed procedure by a number of prominent standards organizations. In addition, it's popular use has evolved as a less formal and widely interpreted tool in the area of Lean/Six Sigma (LSS) process improvement. This paper investigates one of the most important issues related to FMEA practicethe quality of individual vs. group performance in ranking failure modes. In particular, we compare FMEA rankings generated by: (i) individuals, (ii) group consensus, and (iii) non-collaborative aggregation of group input (a synthesized group ranking). We find that groups outperform individuals and that synthetic groups perform as well as group consensus. We explain the implications of this result on the coordination of the design of products and processes amongst distributed organizations. The increasing distribution of product design efforts, both in terms of geography and different organizations, presents an opportunity to improve coordination using distributed synthetic group-based FMEA."
2256,"Inter-organizational Quality Management: The Use of Contractual Incentives and Monitoring Mechanisms with Outsourced Manufacturing","Handley, Sean M. and Gray, John V.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1540-1556","2013","NOV","Quality Management;Outsourcing;Supply Chain Management;Agency Theory","","Quality-related incidents involving contract manufacturers (CMs) are becoming increasingly prevalent. The quality management (QM) literature, however, has focused mostly on QM within a single firm. Thus, the need for data-driven research on managing quality with outsourced production is evident. We investigate the use and effectiveness of external failure penalties and audits of CMs' facilities to manage inter-firm quality. Building on agency theory and extant QM literature, this study addresses two research questions: (i) whether the control mechanisms of quality audits and contractual external quality failure penalties are substitutes or complements in use and (ii) whether they are substitutes or complements in their effectiveness at aligning the quality interests of customers and their CMs. Our analysis uses dyadic data gathered from brand-owning firms and their CMs representing 95 contract manufacturing relationships in Food and Drug Administration (FDA)-regulated industries. The results indicate that more severe external failure penalties correspond to a lower use of facility audits (i.e., they are substitutes-in-use). We also find that both external failure penalties and facility audits have a unique positive effect on the CM's perception of relative quality importance. Finally, some evidence supports the hypothesis that each mechanism is more effective in the presence of the other (i.e., they are complements-in-effectiveness)."
2257,"Structuring Work Distribution for Global Product Development Organizations","Tripathy, Anshuman and Eppinger, Steven D.","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1557-1575","2013","NOV","Distributed Product Development;Complex Engineered Systems;System Architecture;Design Structure Matrix","","This study describes (through an application) a novel approach toward organizing work distribution across globally distributed design and development centers of a product development (PD) organization. While there exist several studies (and modeling applications) for work distribution and allocation for manufacturing and supply chain networks, those related to product development organizations are limited to qualitative suggestions such as offshoring of modular tasks. However, most PD efforts are characterized by significant complexity in information sharing and information dependency among PD tasks (represented by coupling in the system architecture of the firm), thus preventing the identification of modular tasks. Also, redesigning the architecture to introduce modularity has associated risks of costs and product integrity. We demonstrate a methodology to organize work distribution globally in an industrial setting, utilizing the design structure matrix to quantify the system architecture of the firm. Our optimization results show significant cost savings through a restructured PD organization. On analysis of the results, we make two significant observations: (a) while offshoring based on modularity is generally appropriate, it is not the whole answer, as there exists a trade-off between the efficiency of performing specific PD tasks at the offshore location and the modularity of the task; and (b) firms should successively increase work allocation to the offshore location, benefiting from capability improvements through learning effects."
2258,"The Effect of Learning and Integration Investment on Manufacturing Outsourcing Decisions: A Game Theoretic Approach","Xiao, Wenli and Gaimon, Cheryl","PRODUCTION AND OPERATIONS MANAGEMENT","22","6","1576-1592","2013","NOV","Buyer-Supplier Problem;Integration Process Improvement;Partial Outsourcing;Stackelberg Game;Volume-Based Learning","","We introduce a two-period Stackelberg game of a supplier and buyer. We recognize that learning from manufacturing experience has many advantages. Consistent with the literature, we assume both the buyer and supplier realize reductions in their respective production costs in period 2 due to volume-based learning from period 1 production. In addition, we introduce another learning concept, the future value, to capture the buyer's benefits of transferring current manufacturing experience for the design and development of future products and technologies. In contrast to the literature, we allow the supplier two mechanisms to impact the buyer's outsourcing decision: price and the investment in integration process improvement (IPI) that reduces the buyer's unit cost of integration. IPI may include the investment in new materials, specialized technology, or the re-design of the integration process. Conditions are given whereby the buyer partially outsources component demand as opposed to fully outsourcing or fully producing in-house. Furthermore, conditions are given characterizing when the supplier's price and investment in IPI are substitute strategies versus complements. Both analytic and numerical results are presented."
2259,"Environmental Taxes and the Choice of Green Technology","Krass, Dmitry and Nedorezov, Timur and Ovchinnikov, Anton","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1035-1055","2013","SEP","Green Technologies;Sustainability;Environmental Policy;Environmental Taxes;Subsidies And Rebates","","We study several important aspects of using environmental taxes to motivate the choice of innovative and green emissions-reducing technologies as well as the role of fixed cost subsidies and consumer rebates in this process. In our model, a profit-maximizing monopolistic firm facing price-dependent demand selects emissions control technology, production quantity, and price in response to the tax, subsidy, and rebate levels set by the regulator. The available technologies vary in environmental efficiency as well as in the fixed and variable costs. Both the optimal policy for the firm and the social-welfare maximizing policy for the regulator are analyzed. We find that the firm's reaction to an increase in taxes may be non-monotone: while an initial increase in taxes may motivate a switch to a greener technology, further tax increases may motivate a reverse switch. For the regulator, we compare the social welfare achievable in the centralized system (which serves as an upper bound) to the highest level achievable under different classes of environmental policies. If the regulator is limited to a tax-only policy, then when the regulator is moderately concerned with environmental impacts, the tax level that maximizes social welfare simultaneously motivates the choice of clean technology and closes the gap to the upper bound; however, both low and high levels of societal environmental concerns may lead to the choice of dirty technology and significant welfare losses as compared to the centralized case. Supplementing the environmental taxation with fixed cost subsidies and consumer rebates can eliminate this effect, expanding the range of parameters over which the green technology is chosen and often closing the welfare gap to the centralized solution."
2260,"Sales Forecasting with Financial Indicators and Experts' Input","Osadchiy, Nikolay and Gaur, Vishal and Seshadri, Sridhar","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1056-1076","2013","SEP","Retail Operations;Sales Forecasting;Operational Hedging;Martingale Modulated Forecast Evolution;Operations;Finance Interface","","We present a method for forecasting sales using financial market information and test this method on annual data for US public retailers. Our method is motivated by the permanent income hypothesis in economics, which states that the amount of consumer spending and the mix of spending between discretionary and necessity items depend on the returns achieved on equity portfolios held by consumers. Taking as input forecasts from other sources, such as equity analysts or time-series models, we construct a market-based forecast by augmenting the input forecast with one additional variable, lagged return on an aggregate financial market index. For this, we develop and estimate a martingale model of joint evolution of sales forecasts and the market index. We show that the market-based forecast achieves an average 15% reduction in mean absolute percentage error compared with forecasts given by equity analysts at the same time instant on out-of-sample data. We extensively analyze the performance improvement using alternative model specifications and statistics. We also show that equity analysts do not incorporate lagged financial market returns in their forecasts. Our model yields correlation coefficients between retail sales and market returns for all firms in the data set. Besides forecasting, these results can be applied in risk management and hedging."
2261,"The Changing Face of Distribution Channels: Partial Forward Integration and Strategic Investments","Arya, Anil and Mittendorf, Brian","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1077-1088","2013","SEP","Dual Distribution;Forward Integration;Investments;Supply Chains","","Recent years have seen a drastic transformation in the organization of wholesale and retail markets. Where once clear distinctions between wholesale suppliers and retail competitors existed, now an era of blurring boundaries has emerged. This transformation has been marked by the introduction of online channels for suppliers to provide products directly to consumers while, at the same time, traditional retailers too persist. Thus, retailers are both wholesale customers and retail competitors of many manufacturers. The consequences of the rapid emergence of instances of such partial forward integration by suppliers are not yet fully known. To this end, we study how partial forward integration can affect competing firms' strategic investments. We find that integration shifts the environment from being one in which firms invest to undercut retail rivals to one in which firms invest more in boosting demand, even that of their competitors. A case in point is the tendency for a manufacturer to invest broadly in brand promotion (benefiting both itself and its retail competitor), rather than heavy promotion of its own sales channel. The shift in the nature of strategic investments arising from partial forward integration implies that such integration can benefit firms and consumers alike, even the firm which finds itself reliant on a competitor for supplies."
2262,"How Collection Cost Structure Drives a Manufacturer's Reverse Channel Choice","Atasu, Atalay and Toktay, L. Beril and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1089-1102","2013","SEP","Closed-Loop Supply Chain;Reverse Logistics;Remanufacturing;Channel Choice","","This note discusses the impact of collection cost structure on the optimal reverse channel choice of manufacturers who remanufacture their own products. Using collection cost functions that capture collection rate and collection volume dependency, we show that the optimal reverse channel choice (retailer- vs. manufacturer-managed collection) is driven by how the cost structure moderates the manufacturer's ability to shape the retailer's sales and collection quantity decisions."
2263,"Designing Service Level Agreements for Inventory Management","Liang, Liping and Atkins, Derek","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1103-1117","2013","SEP","Service Level Agreement;Performance-Based Contract;Inventory Management;Strategic Behavior;Moral Hazard","","Service level agreements (SLAs) are widely employed forms of performance-based contracts in operations management. They compare performance during a period against a contracted service level and penalize outcomes exceeding some allowed deviation. SLAs have a number of design characteristics that need careful tuning to ensure that incentives are properly aligned. However, there is little theoretical research in this area. Using an example of an SLA for outsourcing inventory management, we make a number of recommendations. First it is preferable, if possible, that penalties be proportional to the underperformance rather than lump-sum ones. This goes a long way towards mitigating strategic (gaming) behavior by the supplier. Second, it might be thought that giving bonuses for good performance rather than penalties for bad performance are essentially identical apart from the former being a more positive approach to management. This turns out to be incorrect in the case of large percentage service rate targets and that penalties will normally be preferred by the buying firm. Third, in order not to incorrectly penalize underperformance resulting purely from noise rather than supplier efforts, management might think it best to make allowed deviations from the target generous. Again intuition is not a helpful guide here: for proportional penalties, acceptable performance deviations should be close to the target. Although these results come from a particular inventory application, it is likely that the lessons are applicable to SLAs in general."
2264,"A Note on Optimal Selling to Asymmetric Retailers","Kostamis, Dimitris","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1118-1125","2013","SEP","Optimal Contracts;Competition;Retail Channels;Asymmetric Retailers","","I consider a channel with one manufacturer selling the same product to two retailers engaged in imperfect competition. The retailers are asymmetric because one has a lower marginal selling cost (or a higher demand potential) than the other. I design the manufacturer's optimal selling mechanism, whereby the manufacturer must offer the same contract options to both retailers. I fully characterize the manufacturer's optimal selling mechanism for varying degrees of retailer asymmetry and competition intensity. I find that under certain conditions, the manufacturer is better off selling a larger quantity through the high-cost (or low-demand potential) retailer. I also show how the optimal mechanism can be implemented using a menu of two-part tariffs with quantity controls."
2265,"Optimal Crop Choice, Irrigation Allocation, and the Impact of Contract Farming","Huh, Woonghee Tim and Lall, Upmanu","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1126-1143","2013","SEP","Crop Planning;Contract Farming;Irrigation;Agriculture;India","","The changing climate and concerns over food security are prompting a new look at the supply chain reliability of products derived from agriculture, and the potential role of contract farming as a mechanism to address climate and price risk while contributing toward crop diversification and water use efficiency is also emerging. In this study, the decision problem of a farmer associated with allocating his land among different crops with varying water requirements is considered, given that a subset of the crops may be associated with a forward contract that is being offered by a buyer. The problem includes a decision to acquire a certain amount of irrigation water capacity prior to the season and to allocate this capacity as irrigation water to be applied during the season to each of the crops selected. Rainfall in the growing season and the market price of each crop at the end of the season are considered to be random variables. Two stochastic programming models are developed to consider facets of this problem and to understand how contracts that reduce market price uncertainty from the problem may change the farmer's decision. The structural properties of these models are discussed, and selected implications are illustrated through an application to data from the Ganganagar district in Rajasthan, India."
2266,"Design Principles for Flexible Systems","Andradottir, Sigrun and Ayhan, Hayriye and Down, Douglas G.","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1144-1156","2013","SEP","Cross-Trained Servers;System Bottleneck;Chaining;Desirable Flexibility Structures","","A fundamental aspect of designing systems with dedicated servers is identifying and improving the system bottlenecks. We extend the concept of a bottleneck to networks with heterogeneous, flexible servers. In contrast with a network with dedicated servers, the bottlenecks are not a priori obvious, but can be determined by solving a number of linear programming problems. Unlike the dedicated server case, we find that a bottleneck may span several nodes in the network. We then identify some characteristics of desirable flexibility structures. In particular, the chosen flexibility structure should not only achieve the maximal possible capacity (corresponding to full server flexibility), but should also have the feature that the entire network is the (unique) system bottleneck. The reason is that it is then possible to shift capacity between arbitrary nodes in the network, allowing the network to cope with demand fluctuations. Finally, we specify when certain flexibility structures (in particular chaining, targeted flexibility, and the N and W structures from the call center literature) possess these desirable characteristics."
2267,"Pricing and Replenishment of Competing Perishable Product Variants under Dynamic Demand Substitution","Sainathan, Arvind","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1157-1181","2013","SEP","Joint Pricing And Inventory Decisions;Perishable;Vertical Differentiation;Lost Sales;Dynamic Demand Substitution","","I consider pricing and ordering decisions faced by a retailer selling a perishable product with a two-period shelf life over an infinite horizon. In the first period, the product is new; in the next, it becomes old. The new product is perceived by customers to have a higher quality than the old product. Every period, the retailer makes three decisions: prices for the new and old products and how much new product to order. I first show, with some simple cases, that demand uncertainty can make the sale of the old product profitable. I then consider a more realistic case with dynamic demand substitution among customers. I recognize that the retailer's decisions may be constant or may vary across different periods, under different contexts. For instance, varying the price of the new product can sometimes be difficult due to the negative impact it generates among customers. I find that (i) the benefit obtained from selling the old product with constant decisions is much higher than the benefit from allowing all the decisions to vary; (ii) the former benefit increases with a higher procurement cost, a higher quality of the new product, and higher demand volatility; however, the latter benefit is non-monotone in these parameters; (iii) most of the latter benefit can be obtained by just changing the order quantity; and (iv) as the inventory of the old product increases, when all the decisions vary, the optimal price of the new product may increase or decrease."
2268,"Joint Stocking and Product Offer Decisions Under the Multinomial Logit Model","Topaloglu, Huseyin","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1182-1199","2013","SEP","Product Variety;Customer Choice;Assortment;Multinomial Logit","","This article studies a joint stocking and product offer problem. We have access to a number of products to satisfy the demand over a finite selling horizon. Given that customers choose among the set of offered products according to the multinomial logit model, we need to decide which sets of products to offer over the selling horizon and how many units of each product to stock so as to maximize the expected profit. We formulate the problem as a nonlinear program, where the decision variables correspond to the stocking quantity for each product and the duration of time that each set of products is offered. This nonlinear program is intractable due to its large number of decision variables and its nonseparable and nonconcave objective function. We use the structure of the multinomial logit model to formulate an equivalent nonlinear program, where the number of decision variables is manageable and the objective function is separable. Exploiting separability, we solve the equivalent nonlinear program through a dynamic program with a two dimensional and continuous state variable. As the solution of the dynamic program requires discretizing the state variable, we study other approximate solution methods. Our equivalent nonlinear program and approximate solution methods yield insights for good offer sets."
2269,"The Retail Planning Problem Under Demand Uncertainty","Georgiadis, George and Rajaram, Kumar","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1200-1213","2013","SEP","Retailing;Facility Location;Inventory Management;Stochastic Demand;Nonlinear Integer Programming","","We consider the retail planning problem in which the retailer chooses suppliers and determines the production, distribution, and inventory planning for products with uncertain demand to minimize total expected costs. This problem is often faced by large retail chains that carry private-label products. We formulate this problem as a convex-mixed integer program and show that it is strongly NP-hard. We determine a lower bound by applying a Lagrangian relaxation and show that this bound outperforms the standard convex programming relaxation while being computationally efficient. We also establish a worst-case error bound for the Lagrangian relaxation. We then develop heuristics to generate feasible solutions. Our computational results indicate that our convex programming heuristic yields feasible solutions that are close to optimal with an average suboptimality gap at 3.4%. We also develop managerial insights for practitioners who choose suppliers and make production, distribution, and inventory decisions in the supply chain."
2270,"How Inventory Cost Influences Introduction Timing of Product Line Extensions","Ke, Te Tony and Shen, Zuo-Jun Max and Li, Shan","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1214-1231","2013","SEP","New-Product Introduction;Inventory Management;Marketing And Operations Coordination;Innovation Diffusion","","In the industry with radical technology push or rapidly changing customer preference, it is firms' common wisdom to introduce high-end product first, and follow by low-end product-line extensions. A key decision in this down-market stretch strategy is the introduction time. High inventory cost is pervasive in such industries, but its impact has long been ignored during the presale planning stage. This study takes a first step toward filling this gap. We propose an integrated inventory (supply) and diffusion (demand) framework and analyze how inventory cost influences the introduction timing of product-line extensions, considering substitution effect among successive generations. We show that under low inventory cost or frequent replenishment ordering policy, the optimal introduction time indeed follows the well-known now or never rule. However, sequential introduction becomes optimal as the inventory holding gets more substantial or the product life cycle gets shorter. The optimal introduction timing can increase or decrease with the inventory cost depending on the marketplace setting, requiring a careful analysis."
2271,"Impacts of Power Structure on Supply Chains with Uncertain Demand","Shi, Ruixia and Zhang, Jun and Ru, Jun","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1232-1249","2013","SEP","Supply Chain;Power Structure;Demand Uncertainty;Pricing;Game Theory","","In this study, we use a game-theory-based framework to model power in a supply chain with random and price-dependent demand and examine how power structure and demand models (expected demand and demand shock) affect supply chain members' performance. We demonstrate that whether a firm benefits from its power depends on the expected demand model but not on demand shock model. A firm benefits from its power only for linear but not for constant elasticity expected demand. The impact of power structure on supply chain efficiency depends on the models of both expected demand and demand shock. With additive shock, supply chain efficiency is highest (lowest) when neither firm dominates for linear (constant elasticity) expected demand. With multiplicative shock, the supply chain efficiency is highest with a power retailer (manufacturer) for linear (constant elasticity) expected demand. The manufacturer always benefits from a reduction in demand uncertainty. However, the retailer loses (benefits) from demand uncertainty reduction for linear (constant elasticity) expected demand. With a power retailer, the retail price is always on the higher end for linear expected demand, and the customer service level is the lowest for constant elasticity expected demand. Consequently, consumers do not necessarily benefit from a power retailer."
2272,"Managing Production and Distribution for Supply Chains in the Processed Food Industry","Azoury, Katy S. and Miyaoka, Julia","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1250-1268","2013","SEP","Inventory;Production;Distribution","","We develop and evaluate a modeling approach for making periodic review production and distribution decisions for a supply chain in the processed food industry. The supply chain faces several factors, including multiple products, multiple warehouses, production constraints, high transportation costs, and limited storage at the production facility. This problem is motivated by the supply chain structure at Amy's Kitchen, one of the leading producers of natural and organic foods in the United States. We develop an enhanced myopic two-stage approach for this problem. The first stage determines the production plan and uses a heuristic, and the second stage determines the warehouse allocation plan and uses a non-linear optimization model. This two-stage approach is repeated every period and incorporates look-ahead features to improve its performance in future periods. We validate our model using actual data from one factory at Amy's Kitchen and compare the performance of our model to that of the actual operation. We find that our model significantly reduces both inventory levels and stockouts relative to those of the actual operation. In addition, we identify a lower bound on the total costs for all feasible solutions to the problem and measure the effectiveness of our model against this lower bound. We perform sensitivity analysis on some key parameters and assumptions of our modeling approach."
2273,"Pricing and Capacity Rationing with Customer Disappointment Aversion","Liu, Qian and Shum, Stephen","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1269-1286","2013","SEP","Strategic Customer Behavior;Disappointment Aversion;Pricing;Capacity Rationing","","Customers are averse to disappointment that arises when economic outcomes fall short of expectations. In this study, we study a two-period model in which the firm may create rationing in either period. In the anticipation of possible disappointment due to stock-outs, strategic customers decide when to purchase and the firm determines the prices and rationing levels in each period. We explore the impact of disappointment aversion on customers' strategic purchasing behavior and the firm's pricing and rationing decisions. Without disappointment aversion, it is optimal for the firm to adopt a uniform pricing policy without rationing. However, when strategic customers are averse to disappointment, a firm may be able to increase profits with an appropriate level of rationing. We analyze both the mark-up and mark-down policies. We show that, in a mark-down scenario, the firm always benefits from disappointment aversion behavior by using an appropriate level of rationing in a low-price period. However, in a mark-up scenario, whether it is beneficial for the firm to induce disappointment aversion behavior depends on how customers frame payoffs in different periods when forming utilities. Particularly, when customers compartmentalize payoffs in different periods to form utilities, the firm should not induce disappointment aversion behavior."
2274,"Broadband Network Management and the Net Neutrality Debate","Guo, Hong and Cheng, Hsing Kenneth and Bandyopadhyay, Subhajyoti","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1287-1298","2013","SEP","Net Neutrality;Broadband Network Management;Traffic Prioritization;Public Policy","","The debate of net neutrality and the potential regulation of net neutrality may fundamentally change the dynamics of data consumption and transmission through the Internet. The existing literature on economics of net neutrality focuses only on the supply side of the market, that is, a broadband service provider (BSP) may charge content providers for priority delivery of their content to consumers. In this article, we explore a complete spectrum of broadband network management options based on both the supply and demand sides of the market. We find that although the BSP always prefers the non-neutral network management options, it does not always discriminate both sides of the market. From the social planner's perspective, we find that some network management options maximize the social welfare under certain market conditions while other options reduce the social welfare. Using the terminology from a recent Federal Communications Commission report and order, we categorize the social welfare maximizing options as reasonable network management and the social welfare reducing options as unreasonable discrimination. We also identify conditions under which the BSP's network management choices deviate from the social optimum. These conditions help establish the criteria under which the social planner might wish to regulate the BSP's actions."
2275,"The Role of Contract Negotiation and Industry Structure in Production Outsourcing","Feng, Qi and Lu, Lauren Xiaoyuan","PRODUCTION AND OPERATIONS MANAGEMENT","22","5","1299-1319","2013","SEP","Outsourcing;Wholesale-Price Contract;Common Vs;Exclusive Supplier;Two-Part Tariff;Multiunit Bilateral Bargaining","","Despite the spread of cost-driven outsourcing practices, academic research cautions that suppliers' cost advantage may weaken manufacturers' bargaining positions in negotiating outsourcing agreements, thereby hurting their profitability. In this study, we attempt to further understand the strategic impact of low-cost outsourcing on manufacturers' profitability by investigating the contractual form of outsourcing agreements and the industry structure of the upstream supply market. We consider a two-tier supply chain system, consisting of two competing manufacturers, who have the option to produce in-house or to outsource to an upstream supplier with lower cost. To reach an outsourcing agreement, each manufacturer engages in bilateral negotiation with her supplier, who may be an exclusive supplier or a common supplier serving both manufacturers. Our analysis shows that wholesale-price contracts always mitigate the competition between manufacturers regardless of whether they compete with price or quantity. In contrast, two-part tariffs intensify the competition when the manufacturers compete with quantity, but soften it when they compete with price. As a result, when outsourcing with two-part tariffs, the manufacturers may earn lower profits than they would from in-house production, although the suppliers are more cost efficient. This suggests that managers have to be wary about the downside of using coordinating contracts such as two-part tariffs when pursuing low-cost outsourcing strategies. Our analysis also sheds some light on the profitability of using an exclusive supplier for outsourcing. When outsourcing with wholesale-price contracts, the competing manufacturers are better off outsourcing to an exclusive supplier. However, when outsourcing with two-part tariffs, the manufacturers may earn higher profits by outsourcing to a common supplier than to an exclusive one when the manufacturers' bargaining power is sufficiently strong (weak) under quantity (price) competition."
2276,"Shipping Fees or Shipping Free? A Tale of Two Price Partitioning Strategies in Online Retailing","Guemues, Mehmet and Li, Shanling and Oh, Wonseok and Ray, Saibal","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","758-776","2013","JUL","Retail;E-Commerce Pricing Strategy;Price Partitioning;Free Shipping;Shipping And Handling Costs","","In this article, we study the price partitioning decisions of online retailers regarding shipping and handling (S&H) fees. Specifically, we analyze two partitioning formats used by retailers in this context. In the first scenario, retailers present customers with a price that is partitioned into a product price and a separate S&H surcharge (the PS strategy); in the second, customers are offered free shipping through a non-partitioned format where the product price already includes the shipping cost (the ZS strategy). We first develop a stylized game-theoretic model that captures the competitive dynamics between (and within) these two formats. Analysis of the model provides insights into how both firm and product level characteristics drive a retailer's strategic choice regarding which partitioning format to adopt and, hence, determines the equilibrium market structure in terms of proportion of ZS and PS retailers. Subsequently, we conduct empirical analyses, based on product and S&H prices data for two different product categories (digital cameras and printers) collected from online retailers, to validate all the results of our theoretical model. We establish that PS retailers charge lower product prices than ZS ones, but the total price (product + S&H) charged is higher for the first group. The S&H charge for PS retailers can be significantit is, on average, 5.4% (printers) and 3.0% (digital cameras) for our two product categories. Furthermore, retailers which are popular and/or face risky cost environment are more likely to opt for the ZS strategy, while retailers whose portfolio mostly includes large or heavy products with high cost (S&H)-to-price ratios usually choose the PS strategy. Lastly, our empirical study also illustrates that the price adjustment behavior of retailers is affected by their shipping-fee policiesfor example, ZS retailers change their product prices almost 1.5 times more frequently than PS ones."
2277,"Selling with Money-Back Guarantees: The Impact on Prices, Quantities, and Retail Profitability","Akcay, Yalcin and Boyaci, Tamer and Zhang, Dan","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","777-791","2013","JUL","Money-Back Guarantees;Consumer Returns;Open-Box Sales;Pricing;Ordering","","In this paper, we consider a retailer adopting a money-back-guaranteed (MBG) sales policy, which allows customers to return products that do not meet their expectations to the retailer for a full or partial refund. The retailer either salvages returned products or resells them as open-box items at a discount. We develop a model in which the retailer decides on the quantity to procure, the price for new products, the refund amount, as well as the price of returned products when they are sold as open-box. Our model captures important features of MBG sales including demand uncertainty, consumer valuation uncertainty, consumer returns, the sale of returned products as open-box items, and consumer choice between new and returned products and possibility of exchanges when restocking is considered. We show that selling with MBGs increases retail sales and profit. Furthermore, the second-sale opportunity created by restocking returned products enables the retailer to generate additional revenues. Our analysis identifies the ideal conditions under which this practice is most beneficial to the retailer. Offering an MBG without restocking increases the new product price. We show that if the retailer decides to resell the returned items as open-box, the price of the new product further increases, while open-box items are sold at a discount. On the other hand, customers enjoy more generous refunds along with lower restocking fees. The opportunity to resell returned products also generally decreases the initial stocking levels of the retailer. Our extensive numerical study substantiates the analytical results and sharpens our insights into the drivers of performance of MBG policies and their impact on retail decisions."
2278,"Information-Sensitive Replenishment when Inventory Records Are Inaccurate","Mersereau, Adam J.","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","792-810","2013","JUL","Retail Operations;Inventory Management;Record Inaccuracy;Dynamic Programming","","Inspired by recent empirical work on inventory record inaccuracy, we consider a periodic review inventory system with imperfect inventory records and unobserved lost sales. Record inaccuracies are assumed to arrive via an error process that perturbs physical inventory but is unobserved by the inventory manager. The inventory manager maintains a probability distribution around the physical inventory level that he updates based on sales observations using Bayes Theorem. The focus of this study is on understanding, approximating, and evaluating optimal forward-looking replenishment in this environment. By analyzing one- and two-period versions of the problem, we demonstrate several mechanisms by which the error process and associated record inaccuracy can impact optimal replenishment. Record inaccuracy generally brings an incentive for a myopic manager to increase stock to buffer the added uncertainty. On the other hand, a forward-looking manager will stock less than a myopic manager, in part to improve information content for future decisions. Using an approximate partially observed dynamic programming policy and associated bound, we numerically corroborate our analytical findings and measure the effectiveness of an intelligent myopic heuristic. We find that the myopic heuristic is likely sufficiently good in practical settings targeting high service levels."
2279,"The Value of Information for Managing Retail Inventory Remotely","Ketzenberg, Michael E. and Geismar, Neil and Metters, Richard and van der Laan, Erwin","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","811-825","2013","JUL","Retail;Value Of Information;Vending Machines;Inventory Management","","An important difference between both manufacturing and wholesaling vs. retail is the information available concerning inventory. Typically, far less information characterizes retail. Here, an extreme environment of information shortfall is examined. The environment is technically termed unattended points of sale, but colloquially called vending machines. Once inventory is loaded into a machine, information on demand and inventory level is not observed until the scheduled reloading date. Technological advances and business process changes have drawn attention to the value of information (VOI) in retail inventory in many venues. Moreover, technology is now available that allows unattended points of sale to report inventory information. Capturing the value of this information requires changes in current business practice. We demonstrate the value of capturing information analytically in an environment with restrictive demand assumptions. Experiments in an environment with realistic demand assumptions and parameter values show that the VOI depends greatly on operating characteristics and can range from negligible effects to increasing profitability 30% or more in actual practice."
2280,"Durability, Transit Lags, and Optimality of Inventory Management Decisions","Bloomfield, Robert J. and Kulp, Susan L.","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","826-842","2013","JUL","Behavioral Operations;Newsvendor Problem;Single-Echelon Inventory Problem;Decision Biases;Ordering Decisions;Inventory Management;Supply Chain Management","","Two laboratory experiments on a single-echelon inventory task show that inventory durability interacts with transit lags to create order volatility that exceeds demand volatility. Thus, inventory durability and transit lags cause managers to deviate from inventory decision optimality. Durability creates a large increase in order volatility because players adjust orders insufficiently to reflect current inventory and backlogs, much as they adjust orders insufficiently to reflect holding and backlog costs in newsvendor studies (e.g., Schweitzer and Cachon 2000). Transit lags exacerbate non-optimal ordering by interfering with players' ability to correct prior errors. Our results suggest that non-optimal inventory decisions can be driven by inventory and supply chain characteristics, even in the absence of the coordination and information sharing problems studied by Croson etal. (2005) and Sterman (1989a,b). We also examine the influence of features related to personality. We find little evidence that the interactive effects of durability and transit lags are altered by need for cognition, impulsiveness, or locus of control, suggesting that these features make supply chain management extremely difficult. These results imply that retailers and their upstream partners must consider the characteristics of their product and supply chains when interpreting demand signals received from downstream partners."
2281,"RFID-Enabled Visibility and Retail Inventory Record Inaccuracy: Experiments in the Field","Hardgrave, Bill C. and Aloysius, John A. and Goyal, Sandeep","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","843-856","2013","JUL","Supply Chain Management;Inventory Record Inaccuracy (Iri);Radio Frequency Identification (Rfid);Inventory Visibility;Field Experiment","","Accurate inventory records are key to effective store execution, affecting forecasting, ordering, and replenishment. Prior empirical research, however, shows that retailer inventory records are inherently inaccurate. Radio Frequency Identification (RFID) enables visibility into the movement of inventories in the supply chain. Using two different field experiments, the current research investigates the effectiveness of this visibility in reducing retail store inventory record inaccuracy (IRI). Study 1 used an interrupted time-series design and involved daily physical counts of all products in one category in 13 stores (8 treatments and 5 controls) of a major global retailer over 23weeks. Results indicate a significant decrease in IRI of approximately 26% due to RFID-enabled visibility. Using an untreated control group design with pre-test and post-test, Study 2 expands the number of categories to five and the number of stores to 62 (31 treatment and 31 control stores). Results show that the effectiveness of RFID in reducing IRI varies by category (ranging from no statistically significant improvement to 81%). Results also suggest that RFID ameliorates the effects of known determinants of IRI and provide the key insight that the technology is most effective for product categories characterized by these determinants."
2282,"Improving Valuation Under Consumer Search:Implications for Pricing and Profits","Perdikaki, Olga and Swaminathan, Jayashankar","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","857-874","2013","JUL","Retail Operations;Consumer Valuation;Consumer Search;Free Riding","","There is a growing trend in the retail industry to improve customer experience. In this article, we study retailer-initiated strategies to increase consumer valuation for a product under duopoly. In such a setting, it is possible that a consumer's valuation may be increased by one retailer; however, the consumer may decide to buy the product from the competitor. We consider a two-stage game where retailers first decide whether to invest in improvements in customer valuation and then engage in price competition. We computationally explore the Nash equilibria in terms of both investment and pricing. We find that in the majority of cases retailers price in a manner to discourage their local customers to buy from the competitor. Next, we focus on the pricing game and theoretically characterize the pricing Nash equilibrium. We find that a retailer could overcome competitive effects by improving consumer valuation beyond a certain threshold. We also find that a retailer who does not invest could benefit from competition in situations where his competitor increases consumer valuation beyond a threshold. Finally, we explore through a computational study the Nash equilibria of the two-stage game using an alternate model to establish the robustness of our findings."
2283,"Sequence Matters: Shelf-Space Allocation under Dynamic Customer-Driven Substitution","Gilland, Wendell G. and Heese, H. Sebastian","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","875-887","2013","JUL","Product Substitution;Dynamic Customer Arrivals;Shelf-Space Allocation;Retail Sales","","Customers who face a stockout situation often decide to purchase a different product in the same category. We analyze the resulting dynamic substitution problem in a retail environment, where customers serve themselves from the store shelves, such that the sequence of customer arrivals affects how scarce products are allocated to customers. We consider a setting with constrained shelf space, and we study how a retailer should optimally allocate such space between substitute products. We characterize environments where the sequence of customer arrivals can have a substantial impact on profitability."
2284,"The Backroom Effect in Retail Operations","Eroglu, Cuneyt and Williams, Brent D. and Waller, Matthew A.","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","915-923","2013","JUL","Backroom Effect;Case Pack Quantity;Reorder Point;Inventory Management;Retail Operations","","Traditional inventory models fail to take into account the dynamics between the retail sales floor and the backroom, commonly used by retailers for extra storage. When a replenishment order for a given item arrives at a retail store, it may not fit on the allocated shelf space, making backroom storage necessary. In this article, we introduce the backroom effect (BRE) as a consequence of misalignment of case pack size, shelf space, and reorder point. This misalignment results from the fragmented nature of inventory policy decision making in the retail industry and affects basic trade-offs in inventory models. We specify conditions under which the BRE exists, quantify the expected amount of backroom inventory, derive an optimal short-term inventory policy, and assess the impact of the BRE on the optimal inventory policy and total costs. Our results indicate that ignoring the BRE leads to artificially high reorder points and higher total costs. The paper concludes with a discussion of theoretical and managerial implications."
2285,"Analyzing the Efficient Execution of In-Store Logistics Processes in Grocery Retailing-The Case of Dairy Products","Reiner, Gerald and Teller, Christoph and Kotzab, Herbert","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","924-939","2013","JUL","In-Store Logistics;Data Envelopment Analysis;Process Simulation;Grocery Retailing","","In this article, we examine in-store logistics processes for handling dairy products, from the incoming dock to the shelves of supermarkets and hypermarkets. The efficient execution of the in-store logistics related to such fast-moving, sensitive, and essential items is challenging and crucial for grocery retailers' sales, profits, and image. In our empirical study, we survey in-store logistics processes in 202 grocery supermarkets and hypermarkets belonging to a major retail chain in central Europe. Using a data envelopment analysis (DEA) and simulation, we facilitate process benchmarking. In particular, we identify ways of improving in-store logistics processes by showing the performance impacts of different managerial strategies and tactics. The DEA results indicate different efficiency levels for different store formats; the hybrid store format of the small hypermarket exhibits a comparatively worse performance in the analyzed execution of in-store logistics processes. The process simulation analysis reveals that the strategic and tactical design of in-store logistics processes (such as store locations/layouts, capacity management, reorder time, order period, and safety stock factors) lead to substantial service performance improvements (such as higher on-shelf availability combined with reduced inventory obsolescence costs). The results also show marginal improvements in the performance figures when delivery delays and damage to products are reduced."
2286,"Design for the Environment: Life-Cycle Approach Using a Newsvendor Model","Raz, Gal and Druehl, Cheryl T. and Blass, Vered","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","940-957","2013","JUL","Newsvendor;Life-Cycle Assessment;Design For The Environment;Functional And Innovative Products;Decoupling","","Introducing environmental innovations in product and process design can affect the product's cost and demand, as well as the environmental impact in different stages of its life cycle (such as manufacturing and use stages). In this article, we advance understanding on where such design changes can be most effective economically to the firm and examine their corresponding environmental consequences. We consider a profit maximizing firm (newsvendor) deciding on the production quantity as well as its environmentally focused design efforts. We focus our results along the two dimensions of demand characteristics and life-cycle environmental impact levels, specifically functional vs. innovative products, and higher manufacturing stage environmental impact vs. higher use stage environmental impact. We also discuss the environmental impact of overproduction and how it relates to the different types of products and their salvage options. We find that although the environmental impact per unit always improves when firms use eco-efficient or demand-enhancing innovations, the total environmental impact can either increase or decrease due to increased production quantities. We identify the conditions for such cases by looking at the environmentally focused design efforts needed to compensate for the increase in production. We also show that the environmental impact of overproduction plays an important role in the overall environmental impact of the firm. We conclude by applying our model to different product categories."
2287,"Replacement Decisions for Potentially Hazardous Substances","Kraft, Tim and Erhun, Feryal and Carlson, Robert C. and Rafinejad, Dariush","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","958-975","2013","JUL","Environmental Investments And Regulation;Hazardous Substance Uncertainty;Product Strategy;Two-Stage Dynamic Programming","","As public awareness of environmental hazards increases, a growing concern for corporations is the potential negative environmental impact of their products and the chemicals these products contain. In this study, we analyze the optimal decisions of a firm when a substance within its product is identified as potentially hazardous. Although the substance is not currently regulated, regulation may occur in the future. Therefore, the firm must devise a strategy for the development and implementation of a replacement substance. In an environment where replacement costs can be millions of dollars, regulation is uncertain, and both consumer and non-governmental organization pressures exist, a carefully developed plan that balances costs and risks is critical for a firm. Our results demonstrate that as long as a threat of regulation exists, a firm should always dedicate resources toward developing a replacement substance. However, it is not always optimal for a firm to implement a developed replacement. Regarding competitive dynamics, we find that competition between firms can offset a low chance of a shift in consumer perception about a substance and compel firms to replace; however, competition can lead to inefficient outcomes in which firms incur avoidable costs to implement ahead of potential regulation."
2288,"Stock Market Reaction to Green Vehicle Innovation","Ba, Sulin and Lisic, Ling Lei and Liu, Qindong and Stallaert, Jan","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","976-990","2013","JUL","Automobile Industry;Corporate Sustainability;Event Study;Green Innovation;New Product Development","","We study the stock market reaction to announcements of global green vehicle innovation over a 14-year time span (1996-2009) using the event study methodology. We document that the stock market generally reacts positively to automakers' announcements of environmental innovations, consistent with prior research on the wealth effects of innovation announcements. Our results indicate that crucial green product development decisions such as innovation type and market segment choices exert direct influence on a firm's market value. These results hold after controlling for firm size, leverage, profitability, R&D intensity, and oil price changes."
2289,"How Does Product Recovery Affect Quality Choice?","Atasu, Atalay and Souza, Gilvan C.","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","991-1010","2013","JUL","Quality Choice;Remanufacturing;Recycling;Take-Back Legislation","","We study the impact of product recovery on a firm's product quality choice, where quality is defined as an observable performance measure that increases a consumer's valuation for the product. We consider three general forms of product recovery: (i) when product recovery reuses (after reprocessing) quality inducing components or material (e.g., remanufacturing), (ii) when product recovery does not reuse quality inducing components or material but it is overall profitable (e.g., cell phone recycling), and (iii) when product recovery is costly (but mandated by legislation, e.g., recycling of small appliances in the European Union). Using a stylized economic model, we show that the form of product recovery, recovery cost structure, and the presence of product take-back legislation play an important role in quality choice. Generally speaking, product recovery increases the firm's quality choice, except for some instances of recovery form (ii). In addition, we find that product take-back legislation can lead to higher quality choice as opposed to voluntary take-back. We further demonstrate that both the firm and the consumers benefit from recovery form (ii), while both are worse off with recovery form (iii). However, environmental implications of the three recovery modes differ from their impact on consumer surplus and firm profit. While recovery forms (i) and (iii) reduce consumption and increase environmental benefits, the same is not true with recovery form (ii), which can increase consumption, potentially resulting in higher environmental impact."
2290,"Product Reuse in Innovative Industries","Galbreth, Michael R. and Boyaci, Tamer and Verter, Vedat","PRODUCTION AND OPERATIONS MANAGEMENT","22","4","1011-1033","2013","JUL","Innovation;Reusability;Product Design;Remanufacturing;Upgrading","","Most models of product reuse do not consider the fact that firms might be required to innovate their products over time in order to continue to appeal to the tastes of customers. We consider how the rate of this required innovation, which might be fast or slow depending on the product, affects reuse decisions. We consider two types of reuseremanufacturing to original specifications, and upgrading used items by replacing components that have experienced innovation since the item was originally produced. We find that optimal reuse decreases with the rate of innovation, implying that models that ignore innovation overestimate the optimal amount of reuse that a company should pursue. Furthermore, we show that reuse can be encouraged in two waysthe intuitive approach of increasing end-of-life costs, and the less intuitive approach of raising the cost to make items reusable. We also examine the environmental impact of reuse, measured in terms of virgin material usage, finding that reuse can actually increase total virgin material usage in some cases. In an extension, we show how the results and insights change when the rate of innovation is uncertain."
2291,"Competing on Time: An Integrated Framework to Optimize Dynamic Time-to-Market and Production Decisions","Oezer, Oezalp and Uncu, Onur","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","473-488","2013","MAY-JUN","New Product Introduction;Time-To-Market;Learning;Stochastic Production Systems;Optimal Stopping","","This study develops a comprehensive framework to optimize new product introduction timing and subsequent production decisions faced by a component supplier. Prior to market entry, the supplier performs process design activities, which improve manufacturing yield and the chances of getting qualified for the customer's product. However, a long delay in market entry allows competitors to enter the market and pass the customer's qualification process before the supplier, reducing the supplier's share of the customer's business. After entering the market and if qualified, the supplier also needs to decide how much to produce for a finite planning horizon by considering several factors such as manufacturing yield and stochastic demand, both of which depend on the earlier time-to-market decision. To capture this dependency, we develop a sequential, nested, two-stage decision framework to optimize the time-to-market and production decisions in relation to each other. We show that the supplier's optimal market entry and qualification timing decision need to be revised in real time based on the number of qualified competitors at the time of market-entry decision. We establish the optimality of a threshold policy. Following this policy, at the beginning of each decision epoch, the supplier should optimally stop preparing for qualification and decide whether to enter the market if her order among qualified competitors exceeds a predetermined threshold. We also prove that the supplier's optimal production policy is a state-dependent, base-stock policy, which depends on the time-to-market and qualification decisions. The proposed framework also enables a firm to quantify how market conditions (such as price and competitor entry behavior) and operating conditions (such as the rate of learning and inventory/production-related costs) affect time-to-market strategy and post-entry production decisions."
2292,"The Promise of Strategic Customer Behavior: On the Value of Click Tracking","Huang, Tingliang and Van Mieghem, Jan A.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","489-502","2013","MAY-JUN","Click Tracking;Customer Behavior;Advance Demand Information;Game Theory","","Click tracking is gaining in popularity, and the practice of web analytics is growing fast. Whether strategic customers are willing to visit a website when they know their clicks may be tracked is an important yet complex problem, which depends on various factors. Using a newsvendor framework, we examine this problem by focusing on the operational factor: how product availability induces strategic customers to voluntarily provide advance demand information. We find that a strong Nash equilibrium exists where every customer is willing to click, and customer incentives to click are robust to noise. Hence, we demonstrate the promise of strategic customer behavior in the context of click tracking, contrary to the conventional wisdom that it is typically a peril for the firm. Notably, click tracking is typically advantageous to both the firm and its customers, compared with other strategies such as advance selling, quantity commitment, availability guarantees, and quick response. Lastly, we extend to two settings by including marketing decisions, price-sensitive demand and markdown pricing, and discuss how operations and marketing decisions interact in influencing the value of click tracking."
2293,"Finding and Implementing Energy Efficiency Projects in Industrial Facilities","Aflaki, Sam and Kleindorfer, Paul R. and de Miera Polvorinos, Victor Saenz","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","503-517","2013","MAY-JUN","Sustainable Operations;Energy Efficiency;Kaizen;Carbon Footprinting","","This study addresses the challenges of finding and implementing profitable energy efficiency (EE) projects, a critical foundation for sustainable operations. We focus on manufacturing enterprises, but many of our findings apply also to the back office of service operations. Our starting point is that, in nearly every industrial enterprise, there are many profitable EE projects that could be implemented but are not. An oft-cited hindrance to implementation is the lack of an internal management framework in which to find, value, and execute these projects. Using a conceptual approach, we rely on proven sustainable operations tools to develop such a framework. We identify three major value drivers of EE projects: savings intensity, green image, and project complexity. We then describe a framework for understanding the context of EE projects in industry, with an underlying analytic foundation in optimal portfolio analysis. A case study of a large manufacturing site is used to illustrate emerging best practicesbased on Kaizen management principlesfor integrating EE project management with operations, engineering, and strategy."
2294,"Script Usage in Standardized and Customized Service Encounters: Implications for Perceived Service Quality","Victorino, Liana and Verma, Rohit and Wardell, Don G.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","518-534","2013","MAY-JUN","Service Script;Service Design;Service Quality;Service Encounter;Video Experiment","","This study examines the effect that verbal scripts have on customer perceived service quality for two distinct service process types. We designed a video experiment that varied the level of verbal scripting for standardized and customized service encounters. We found that in standardized service encounters, an increase in the level of verbal scripting had no effect on perceived service quality. However, for customized encounters, perceived service quality was impacted. More specifically, a predominantly scripted encounter for customized service processes, on average, resulted in the lowest perception of service quality by respondents. Since verbal scripting was shown to impact customer perceptions of service quality, we suggest that a service provider's decision regarding the degree of verbal scripting is an important service design consideration."
2295,"Robust Structural Equations for Designing and Monitoring Strategic International Facility Networks","Kouvelis, Panos and Munson, Charles L. and Yang, Shilei","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","535-554","2013","MAY-JUN","Global Network Design;Plant Location;Structural Equations Modeling;Supply Chain Management","","Using predictive global sensitivity analysis, we develop a structural equations model to abstract from the details of a large-scale mixed integer program (MIP) to capture essential design trade-offs of global manufacturing and distribution networks. We provide a conceptual framework that describes a firm's network structure along three dimensions: market focus, plant focus, and network dispersion. Normalized dependent variables are specified that act as proxies for a company's placement into our conceptual network classification via the calculation of just a few key independent variables. We provide robust equation sets for eight cost structure clusters. Many different product types could be classified into one of these groups, which would allow managers to use the equations directly without needing to run the MIP for themselves. Our numerical tests suggest that the formulas representing the network structure driverseconomies of scale, complexity costs, transportation costs, and tariffsmay be sufficient for managers to design their strategic network structures, and perhaps more importantly, to monitor them over time to detect potential need for adjustment."
2296,"Increasing the Revenue of Self-Storage Warehouses by Facility Design","Gong, Yeming (Yale) and de Koster, Rene B. M. and Frenk, J. B. G. (Hans) and Gabor, Adriana F.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","555-570","2013","MAY-JUN","Logistics And Transportation;Facility Design And Planning;Self Storage;Warehouse Management","","Self-storage is a booming industry. Both private customers and companies can rent temporary space from such facilities. The design of self-storage warehouses differs from other facility designs in its focus on revenue maximization. A major question is how to design self-storage facilities to fit market segments and accommodate volatile demand to maximize revenue. Customers that cannot be accommodated with a space size of their choice can be either rejected or upscaled to a larger space. Based on data of 54 warehouses in America, Europe, and Asia, we propose a new facility design approach with models for three different cases: an overflow customer rejection model and two models with customer upscale possibilities, one with reservation and another without reservation. We solve the models for several real warehouse cases, and our results show that the existing self-storage warehouses can be redesigned to generate larger revenues for all cases. Finally, we show that the upscaling policy without reservation generally outperforms the upscaling policy with reservation."
2297,"Advance Selling in the Presence of Speculators and Forward-Looking Consumers","Lim, Wei Shi and Tang, Christoper S.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","571-587","2013","MAY-JUN","Advance Selling;Speculators;Forward-Looking Consumers;Capacity Constraint","","This article examines the pricing policy of a monopolist seller who may sell in advance of consumption in a market that comprises of myopic consumers, forward-looking consumers, and speculators. The latter group has no consumption value for the goods and is in the market with the sole objective of making a profit by reselling the purchased goods shortly after. Consumers, although homogeneous in terms of their valuations, are different with respect to their perspectives. We show that in an upward market where the expected valuation increases over time, the optimal pricing policy is an ex ante static one where the seller prices into the future and prices the myopic consumers out of the advance market. However, in a downward market where the expected valuation decreases over time, the seller adopts a dynamic pricing strategy except for the case when higher initial sales can trigger more demand subsequently and when the downward trend is not too high. In this case, the seller prefers an ex ante static pricing strategy and deliberately prices lower initially to sell to speculators. We identify the conditions under which the seller benefits from the existence of speculators in the market. Moreover, although the presence of entry costs is ineffective as an entry deterrence, we determine the conditions under which exit costs can rein in speculative purchase."
2298,"Delayed Differentiation for Multiple Lifecycle Products","Abbey, James D. and Guide, Jr., V. Daniel R. and Souza, Gilvan C.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","588-602","2013","MAY-JUN","Multiple Lifecycle;Delayed Differentiation;Clsc;Modular Design;Remanufacturing","","Modular design allows several generations of products to co-exist in the installed base as product designs change to take advantage of improved performance via modular upgrades. Use of a common base platform and modular design approach allows a firm to offer updates for improved performance and flexibility via remanufacturing when products have multiple lifecycles. However, as the product evolves through multiple lifecycles, the large pool of product variants leads to the curse of product proliferation. In practice, product proliferation causes high levels of line congestion and results in longer lead times, higher inventory levels, and lower levels of customer service. To offer insights into the product proliferation problem, the authors employ a delayed differentiation model in a multiple lifecycle context. The delayed differentiation model gives flexibility to balance trade-offs between disassembly and reassembly costs by adaptively changing the push-pull boundary. An adaptive, evolving push-pull boundary provides flexibility for a remanufacturing firm to meet changing customer demands. The delayed differentiation model includes both a mixed-integer linear program and an analytical investigation of the evolutionary nature of the push-pull boundary. Both field observations and experimental results show that the nature of product proliferation and changing demand structures play significant roles in the cost and flexibility of the evolving delayed differentiation system."
2299,"Multi-Product Quality Competition: Impact of Resource Constraints","Yayla-Kuellue, H. Muege and Parlaktuerk, Ali K. and Swaminathan, Jayashankar M.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","603-614","2013","MAY-JUN","Product-Line;Limited Capacity;Competition;Quality Differentiation;Om-Marketing Interface","","We study a multi-product firm with limited capacity where the products are vertically (quality) differentiated and the customer base is heterogeneous in their valuation of quality. While the demand structure creates opportunities through proliferation, the firm should avoid cannibalization between its own products. Moreover, the oligopolistic market structure puts competitive pressure and limits the firm's market share. On the other hand, the firm has limited resources that cause a supply-side fight for adequate and profitable production. We explicitly characterize the conditions where each force dominates. Our focus is on understanding how capacity constraints and competition affect a firm's product-mix decisions. We find that considering capacity constraints could significantly change traditional insights (that ignore capacity) related to product-line design and the role of competition therein. In particular, we show that when the resources are limited, the firm should offer only the product that has the highest margin per unit capacity. We find that this product could be the diametrically opposite product suggested by the existing literature. In addition, we show that for intermediate capacity levels, whereas the margin per unit capacity effect dominates in a less competitive market, proliferation and cannibalization effects dominate in a more competitive market."
2300,"On the Unimodality of the Profit Function of the Pricing Newsvendor","Lu, Ye and Simchi-Levi, David","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","615-625","2013","MAY-JUN","Newsvendor With Price Effect;Log-Concavity;Pricing Game","","In this note, we study the price-setting newsvendor problem. We use three conditions, the log-convexity of the coefficient of variation, the log-concavity of the deterministic profit function, and the log-convexity of the random noise's expectation conditional on having leftover inventory to establish the log-concavity of the retailer's expected profit function. This new result is complementary to existing results and removes some assumptions in the pricing and inventory coordination literature. It also addresses the conjecture made by Petruzzi and Dada (1999), and can be applied in the pricing game."
2301,"Pricing Policy in a Supply Chain: Negotiation or Posted Pricing","Kuo, Chia-Wei and Ahn, Hyun-Soo and Aydin, Goker","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","626-641","2013","MAY-JUN","Supply-Chain Management;Pricing;Negotiation;Retailing","","This article examines the choice of pricing policy (posted pricing or negotiation) toward end customers in a supply chain. Many retailers actively decide whether or not to encourage negotiation on the shop floor. Of course, the retailer's pricing policy influences not only the retailer's profit, but also the profits of the manufacturers who sell through the retailer. However, little is known about the forces that shape the pricing policy when two self-interested parties interact in a supply chain. We consider two alternative models depending on who has the power to decide the pricing policy: the manufacturer or the retailer. We find that an increase in the wholesale price weakens the retailer's ability to price discriminate through negotiation. Therefore, the retailer prefers negotiation at lower wholesale prices and posted pricing at higher wholesale prices. We also find that whenever the retailer prefers negotiation, the manufacturer does too. Therefore, the retailer's discretion over the pricing policy causes friction only when the retailer wants to use posted pricing, while the manufacturer wishes the retailer to use negotiation. We show that such friction arises only when product availability or the cost of negotiation is moderate. In this case, we show that the manufacturer may offer a substantial discount to persuade the retailer to negotiate. Surprisingly, in this region of friction, a decrease in the supply chain's capacity or an increase in negotiation costs (both of which are typically considered as worsening the retailer's business environment) translates into higher profit for the retailer."
2302,"Coordinated Contract Decisions in a Make-to-Order Manufacturing Supply Chain: A Stochastic Programming Approach","Feng, Yan and Martel, Alain and D'Amours, Sophie and Beauregard, Robert","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","642-660","2013","MAY-JUN","Contract Design;Supply Chain Coordination;Make-To-Order Manufacturing;Stochastic Programming;Sample Average Approximation","","One of the important objectives of supply chain S&OP (Sales and Operations Planning) is the profitable alignment of customer demand with supply chain capabilities through the coordinated planning of sales, production, distribution, and procurement. In the make-to-order manufacturing context considered in this paper, sales plans cover both contract and spot sales, and procurement plans require the selection of supplier contracts. S&OP decisions also involve the allocation of capacity to support sales plans. This article studies the coordinated contract selection and capacity allocation problem, in a three-tier manufacturing supply chain, with the objective to maximize the manufacturer's profitability. Using a modeling approach based on stochastic programming with recourse, we show how these S&OP decisions can be made taking into account economic, market, supply, and system uncertainties. The research is based on a real business case in the Oriented Strand Board (OSB) industry. The computational results show that the proposed approach provides realistic and robust solutions. For the case considered, the planning method elaborated yields significant performance improvements over the solutions obtained from the mixed integer programming model previously suggested for S&OP."
2303,"Supply Chain Contracting Under Competition: Bilateral Bargaining vs. Stackelberg","Feng, Qi and Lu, Lauren Xiaoyuan","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","661-675","2013","MAY-JUN","Bilateral Bargaining;Stackelberg Game;Competition;Contracting","","We analyze contracting behaviors in a two-tier supply chain system consisting of competing manufacturers and competing retailers. We contrast the contracting outcome of a Stackelberg game, in which the manufacturers offer take-it-or-leave-it contracts to the retailers, with that of a bargaining game, in which the firms bilaterally negotiate contract terms via a process of alternating offers. The manufacturers in the Stackelberg game possess a Stackelberg-leader advantage in that the retailers are not entitled to make counteroffers. Our analysis suggests that whether this advantage would benefit the manufacturers depends on the contractual form. With simple contracts such as wholesale-price contracts, which generally do not allow one party to fully extract the trade surplus, the Stackelberg game replicates the boundary case of the bargaining game with the manufacturers possessing all the bargaining power. In contrast, with sophisticated contracts such as two-part tariffs, which enable full surplus extraction, the two games lead to distinct outcomes. We further show that the game structure being Stackelberg or bargaining critically affects firms' preferences over contract types and thus their equilibrium contract choices. These observations suggest that the Stackelberg game may not be a sufficient device to predict contracting behaviors in reality where bargaining is commonly observed."
2304,"On the Effects of Capacity Agent on Market Equilibrium","Jiang, Li","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","676-690","2013","MAY-JUN","Supply Chain Management;Capacity Agent;Market Equilibrium;Contract Design","","I consider a setting of two firms and one capacity agent. Each firm serves a primary market, and the capacity agent sustains a common market to draw demand for capacity from the external firms. The firms can partner with the capacity agent under her contract to serve the common market. When they use the common market mainly as an outlet for their unused capacities, the capacity agent will only specify a variable fee for each capacity unit deployed through her, and prefer to partner with one firm in most circumstances. When the firms adjust capacities to accommodate the businesses created by serving the common market, the capacity agent will specify a lump-sum payment and a variable fee, and will be more likely to incentivize only one firm to partner with her, when the common market is sufficiently large or the demands in the common and primary markets are strongly correlated. She will always use a fixed fee to extract, while not necessarily all, the profit gains to the firms serving the common market, but will use a variable fee only when partnering with both firms. The key results are robust with respect to market configuration and contract type."
2305,"Robust Stochastic Lot-Sizing by Means of Histograms","Klabjan, Diego and Simchi-Levi, David and Song, Miao","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","691-710","2013","MAY-JUN","Stochastic Inventory Control;Robust Optimization;Dynamic Programming;Optimal Policy","","Traditional approaches in inventory control first estimate the demand distribution among a predefined family of distributions based on data fitting of historical demand observations, and then optimize the inventory control using the estimated distributions. These approaches often lead to fragile solutions whenever the preselected family of distributions was inadequate. In this article, we propose a minimax robust model that integrates data fitting and inventory optimization for the single-item multi-period periodic review stochastic lot-sizing problem. In contrast with the standard assumption of given distributions, we assume that histograms are part of the input. The robust model generalizes the Bayesian model, and it can be interpreted as minimizing history-dependent risk measures. We prove that the optimal inventory control policies of the robust model share the same structure as the traditional stochastic dynamic programming counterpart. In particular, we analyze the robust model based on the chi-square goodness-of-fit test. If demand samples are obtained from a known distribution, the robust model converges to the stochastic model with true distribution under generous conditions. Its effectiveness is also validated by numerical experiments."
2306,"The Effect of Single Rater Bias in Multi-Stakeholder Research: A Methodological Evaluation of Buyer-Supplier Relationships","Roh, Joseph A. and Whipple, Judith M. and Boyer, Kenneth K.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","711-725","2013","MAY-JUN","Single Rater Bias;Multi-Stakeholder Constructs;Buyer-Supplier Relationships;Measurement Error;Social Capital;Dyadic Data;Cross-Prediction","","As the global competitive landscape intensifies, firms have looked to their supply chain organizations to improve cost, visibility, and cycle time performance across functions, products, and markets. As a result, the scope of supply chain related operations have increasingly cut across organizational boundaries. To understand and capture such cross-organizational activities, researchers have broadened the focus of their studies and included multiple stakeholders in their analysis (e.g., integration, sustainability, and buyer-supplier relationships). However, multi-stakeholder research has also increased the complexity and effort required to conduct studies across organizational boundaries. Unfortunately, many studies that use multi-stakeholder constructs fail to fully address their multi-sided nature during both construct conceptualization and data collection. Several studies suggest that neglecting the multi-sided nature of certain constructs can affect the research validity and reliability and may invalidate research inferences and results, although such concerns have not been empirically demonstrated. The current study addresses this gap by performing a series of tests using data from 105 matched pairs of buyers and their suppliers to illustrate key methodological considerations for conducting multi-stakeholder research. This study also offers practical guidance regarding assumptions routinely made in single rater research and proposes when single rater data may be appropriate for multi-stakeholder research."
2307,"A Performance Metric and Goal-Setting Procedure for Deadline-Oriented Processes","Doerr, Kenneth Howard and Gue, Kevin R.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","726-738","2013","MAY-JUN","Metrics;Goals;Warehousing;Deadlines;Motivation","","A performance metric and goal-setting procedure is defined for an order fulfillment operation. In this operation, order requests arrive continuously, and filled orders are shipped at a specific time each day. The metric links the continuous operation of order fulfillment to the scheduled shipment times. To prescribe goals against the metric, a performance model is developed that incorporates the motivational effect of a goal. Goal-Setting Theory is used to establish the performance goal and to show how to match arriving orders to deadlines based on their arrival times and expected processing times. Monte Carlo simulation on data from a large distribution center is used to demonstrate that setting these two parameters in the light of motivational research yields quite different results than doing so with an intuitive method. Moreover, a motivational goal leads to better operational performance; that is, correctly setting up the metric causes more customers to receive their orders sooner."
2308,"Non-dominated Time-Window Policies in City Distribution","Akyol, Derya Eren and De Koster, Rene B. M.","PRODUCTION AND OPERATIONS MANAGEMENT","22","3","739-751","2013","MAY-JUN","Urban Freight Transport;Sustainability;Time Windows;Data Envelopment Analysis","","Urban freight contributes significantly to pollution, noise disturbance, traffic congestion, and safety problems in city centers. In many cities, local governments have introduced policy measures, in particular time-access restrictions, to alleviate these problems. However, setting time windows is very challenging due to the conflicting interests and objectives of the stakeholders involved. In this article, we examine whether it is possible to develop time-window policies that enhance environmental sustainability and distribution efficiencies, while meeting the objectives of the municipalities. We develop a framework for balancing retailer (costs), municipality (satisfaction), and environmental (emissions) objectives, using data envelopment analysis, under different urban time-window policies. The approach is illustrated by a case study of three Dutch retail organizations, with a large number of stores affected by such time windows. On the basis of an evaluation of 99 different time-window policies, our results show that harmonizing time windows between neighboring cities leads to the best overall performance. The currently used time-window policy appears to perform reasonably well, but can be improved on all dimensions. However, harmonizing time-window policies may be difficult to realize in practice."
2309,"The Impact of Logistics Performance on Trade","Hausman, Warren H. and Lee, Hau L. and Subramanian, Uma","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","236-252","2013","MAR-APR","Logistics;Logistics Improvements;Global Trade","","This paper studies the impact of logistics performance on global bilateral trade. Taking a supply chain perspective, logistics performance refers to cost, time, and complexity in accomplishing import and export activities. We draw on a data set compiled by the World Bank containing specific quantitative metrics of logistics performance in terms of time, cost, and variability in time. Numerous researchers have shown that logistics performance is statistically significantly related to the volume of bilateral trade. Our research calibrates the impact of specific improvements in logistics performance (time, cost, and reliability) on increased trade. Our findings can spur public and private agencies that have direct or indirect influence over logistics performance to focus attention on altering the most relevant aspects of logistics performance to improve their country's ability to compete in today's global economy. Moreover, as our logistics metrics are directly related to operational performance, countries can use these metrics to target actions to improve logistics and monitor their progress."
2310,"The Critical Role of Ocean Container Transport in Global Supply Chain Performance","Fransoo, Jan C. and Lee, Chung-Yee","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","253-268","2013","MAR-APR","Supply Chain Management;Transport;Ocean Containers;Research Agenda","","With supply chains distributed across global markets, ocean container transport now is a critical element of any such supply chain. We identify key characteristics of ocean container transport from a supply chain perspective. We find that unlike continental (road) transport, service offerings tend to be consolidated in few service providers, and a strong focus exists on maximization of capital intensive resources. Based on the characteristics of ocean container transport as part of global supply chains, we list a number of relevant and challenging research areas and associated questions."
2311,"Profit Seeking vs. Survival Seeking: An Analytical Study of Supplier's Behavior and Buyer's Subsidy Strategy","Wei, Mike Mingcheng and Yao, Tao and Jiang, Bin and Young, Scott T.","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","269-282","2013","MAR-APR","Supplier Competition;Buyer Subsidy;Survival-Seeking Strategy;Profit-Seeking Strategy;Game Theory","","Supplier default is common in emerging markets. Suppliers under the threat of default have different objectives from profit-seeking companies. This paper analytically tests how profit-seeking or survival-seeking behavior, single-period or two-period consideration, and buyer's subsidy influence the supplier's and buyer's final utilities. The results show that under single-period consideration, the supplier's survival-seeking strategy in fact drives more start-ups or small suppliers out of business when the competition becomes severe; under two-period consideration, no matter which strategy (profit-seeking or survival-seeking) the supplier selects, the second-period price and profit are always higher than those of the first period. Furthermore, we find that providing subsidy is an effective way for buyer to keep suppliers' competition at a certain level on the behalf of buyer's interest. By numerically estimating the benefits associated with the cost of subsidy, we provide a basis for understanding the costbenefit analysis of buyer's subsidy strategy."
2312,"Effect of Quality Management Systems and Total Quality Management on Productivity Before and After: Empirical Evidence from the Indian Auto Component Industry","Iyer, Ananth and Saranga, Haritha and Seshadri, Sridhar","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","283-301","2013","MAR-APR","Productivity;Technical Change;Relative Efficiency;Qms;Tqm;Indian Auto Component Industry;Data Envelopment Analysis;Quality Certification;Quality Awards;Panel Data","","We study the linkages between firm-level quality initiatives such as quality management systems (QMS) and total quality management (TQM) and output productivity in the Indian auto component industry. We use externally validated quality certification and quality awards as proxies for QMS and TQM, respectively, as it is difficult to directly measure the QMS and TQM efforts of firms. We use an unbalanced panel of 220 firms and a balanced panel of 73 firms from the Indian auto component industry over the period 19932006 to study these links. Both parametric as well as non-parametric approaches are used, as appropriate, to measure the rate of change in productivity and the impact of quality initiatives on productivity change during this period. We determine the proportion of productivity resulting from technical change and relative efficiency change, thus providing insights into the structure of productivity improvements. We find that TQM efforts resulted in a high rate of productivity change (11%) in the award-winning firms after the award. On the other hand, pre-certification productivity change due to QMS was 5% and post-certification change was 3.6%. In the periods prior to certification, productivity change was driven mainly by technical change; whereas the source of productivity change after certification is mixed. However, prior to awards, productivity change was driven mainly by relative efficiency change, whereas post-award productivity change was due to technical change. The results suggest that management focus on attaining certification did generate conceptual learning (linked to technical change) during the period leading to certification, but these effects were not significant after certification. The results also suggest that the TQM programs generated significant productivity gains in the long run, although setting the associated systems in place did not result in significant productivity change prior to winning awards. Thus, the study provides direct but nuanced evidence linking quality certification as well as the adoption of TQM programs to the associated conceptual and operational learning processes and their impact on the change in productivity."
2313,"Inventory Management in China: An Empirical Study","Shan, Jun and Zhu, Kaijie","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","302-313","2013","MAR-APR","Inventory Performance;Empirical Study;Emerging Markets","","With the outsourcing of manufacturing activities from Western countries, China has gradually become the global manufacturing hub. In the presence of increased competition from both inside and outside of China, many Chinese manufacturers have turned to scientific management approaches and implemented various enterprise systems. In academia, there has been a growing interest in quantifying the impacts of such efforts on the corporate performance of Chinese firms, and research has been carried out in areas such as finance and accounting. However, due to limited visibility of operational decisions and data, there seems to be a lack of investigation into the impacts on the firms' operational performance in the literature. In this article, we apply an empirical method to investigate the inventories of 1286 firms listed on the two stock exchanges in China, the Shanghai Stock Exchange and the Shenzhen Stock Exchange. We find that on average the inventory levels have declined over time and that the firm-level data is consistent with several implications derived from classical inventory models."
2314,"Offshoring Business Process Services and Governance Control Mechanisms: An Examination of Service Providers from India","Jayaraman, Vaidyanathan and Narayanan, Sriram and Luo, Yadong and Swaminathan, Jayashankar M.","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","314-334","2013","MAR-APR","Business Process Outsourcing;Emerging Markets;Buyersupplier Relationships;Governance Control Mechanisms","","As emerging markets increasingly rely on service businesses through offshore outsourcing, we examine the role of governance control mechanisms in improving performance among business process outsourcing (BPO) service providers in India. Using data collected from 205 emerging market-based BPO service providers in India, we examine the antecedents and consequences of establishing governance control mechanisms in BPO service providers. Specifically, we examine how structural (use of contracts with the client), administrative (effective allocation and demarcation of responsibilities within the firm), and relational (collaboration and information sharing with the client) mechanisms drive the performance of a BPO service provider operating in an emerging market. We also examine how key task-related (task connectivity and task security) and client-related (end customer orientation and global control) antecedents influence the use of different governance control approaches in this environment. Our analysis finds that both task connectivity and task security significantly impact use of structural and administrative mechanisms, whereas end customer orientation is significantly associated with the strength of the relational mechanisms governing the emerging market-based BPO service provider and its client. Further global control significantly influences the strength of the structural mechanisms between the client and the BPO service provider. Finally, the three mechanisms have a complementary influence in driving the BPO service provider's performance."
2315,"Emerging Market Penetration, Inventory Supply, and Financial Performance","Han, Chaodong and Dong, Yan and Dresner, Martin","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","335-347","2013","MAR-APR","Emerging Markets;Inventory;Financial Performance;Multinational Firms;Manufacturing","","Realizing potential benefits from emerging market penetration requires firms to address inherent supply chain challenges. A major challenge is for firms to manage costly inventories to address demand and supply risks in emerging markets. However, emerging market penetration may offer opportunities for firms to lower inventory levels, reduce costs, and improve operating performance. Using data for 482 manufacturing firms over the 5-year period, 20032007, obtained from the COMPUSTAT Industrial and Segment Databases, this article examines the relationships between emerging market penetration, inventory supply, and financial performance. Our results show that a multinational firm's sales penetration into emerging markets is associated with fewer days of inventory supply and improved financial performance. As emerging market penetration may allow firms to operate with lower inventory supply, the positive effect from emerging market penetration, such as labor cost reductions, may be enhanced due to inventory cost savings."
2316,"Training, Production, and Channel Separation in ITC's E-Choupal Network","Chen, Ying-Ju and George, Shanthikumar J. and Max, Shen Zuo-Jun","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","348-364","2013","MAR-APR","E-Choupal;India Agriculture;Incentives;Socially And Environmentally Responsible Supply Chains","","In recent years, I.T.C. Limited (hereafter ITC) developed the e-Choupals for the rural areas of India. In this new business model, ITC reaches implicit agreements with some farmers (inside the network) that they can sell the products directly to ITC at the market price in the local market, but allow the farmers, both inside and outside the network, to access valuable information through the e-Choupals. In this study, we investigate ITC's incentive of offering such opportunities, especially to those farmers outside the network, and analyze the farmers' strategic quantity decisions. We show that the implicit agreement behaves as a formal contract, regardless of the price elasticity of the local market: Once reaching an agreement with ITC, the farmers always give priority to delivering directly to ITC. The e-Choupal network leads naturally to the complete separation of selling channels, provided that ITC's capacity constraint is not tight. Surprisingly, in a variety of scenarios, ITC finds it optimal to provide the best available training to the farmers outside the network. We further show that our results are not prone to potential cheating in the mandi system, the possible exploitation via postponed payments, and the stochastic effects on the market-clearing price."
2317,"Vehicle Replacement in the International Committee of the Red Cross","Pedraza-Martinez, Alfonso J. and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","365-376","2013","MAR-APR","Humanitarian Logistics;Vehicle Replacement;Transportation;Decentralized Supply Chains","","This article studies 4x4 vehicle replacement within the International Committee of the Red Cross (ICRC), one of the largest humanitarian organizations. ICRC policy sets the replacement of vehicles at 5 years or 150,000 km, whichever comes first. Using field data collected at the ICRC headquarters and national level we study the ICRC policy. Our results suggest that the organization can make considerable savings by adjusting its replacement policy. This study contributes to the area of logistics and transportation research in humanitarian operations."
2318,"Supply Chains and Global Health: An Imperative for Bringing Operations Management Scholarship into Action","Kraiselburd, Santiago and Yadav, Prashant","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","377-381","2013","MAR-APR","Global Health Supply Chain;Public Health;Vaccines;Essential Medicines","","Many people in developing countries do not have access to effective vaccines, medicines, and other life-saving health technologies. Shortage of health care workers, severe financial constraints, and lack of awareness are some of the major obstacles that prevent higher access. However, ineffective and poorly designed supply chains for purchasing and distributing the medicines, vaccines, and health technologies are one of the most important barriers to increasing access. We argue that the ineffectiveness of the global health supply chain can be attributed largely to: coordination problems across multiple stakeholders with widely divergent objectives, lack of careful supply chain design, and use of myopic operational objectives and metrics. The operations management research community can contribute to improving this by applying existing knowledge to the field of global health delivery and by researching new frameworks of analysis which would then become the cornerstones for policy advice to those who design, operate, or finance these supply chains."
2319,"Stakeholder Perspectives on E-Waste Take-Back Legislation","Atasu, Atalay and Ozdemir, Oznur and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","382-396","2013","MAR-APR","Product Take-Back;Weee;Legislation;Implementation;Social Welfare","","In this study, we compare two common forms of product take-back legislation implementation: (i) manufacturer-operated systems, where the state imposes certain take-back objectives on manufacturers, and (ii) state-operated systems, where manufacturers or consumers finance take-back through recovery fees. We show that their impacts on different stakeholders, that is, social welfare, manufacturers, consumers, and the environment, can be significantly different and stakeholder preferences for these models vary depending on the operating environments (e.g., production and take-back costs, and environmental externalities). We also consider the impact of operational externalities such as operating and monitoring costs, and show how they affect stakeholder preferences."
2320,"Supplier-Buyer Negotiation Games: Equilibrium Conditions and Supply Chain Efficiency","Martinez-de-Albeniz, Victor and Simchi-Levi, David","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","397-409","2013","MAR-APR","Multi-Period Inventory Management;Pricing;Subgame-Perfect Equilibrium;Strategic Inventory","","In a decentralized supply chain, supplierbuyer negotiations have a dynamic aspect that requires both players to consider the impact of their decisions on future decisions made by their counterpart. The interaction generally couples strongly the price decision of the supplier and the quantity decision of the buyer. We propose a basic model for a repeated supplierbuyer interaction, during several rounds. In each round, the supplier first quotes a price, and the buyer places an order at that price. We find conditions for existence and uniqueness of a well-behaved subgame-perfect equilibrium in the dynamic game. When costs are stationary and there are no holding costs, we identify some demand distributions for which these conditions are met, examine the efficiency of the equilibrium, and show that, as the number of rounds increases, the profits of the supply chain increase towards the supply chain optimum. In contrast, when costs vary over time or holding costs are present, the benefit from multi-period interactions is reduced and after a finite number of time periods, supply chain profits stay constant even when the number of rounds increases."
2321,"The Impact of Information Sharing on Supply Chain Performance under Asymmetric Information","Inderfurth, Karl and Sadrieh, Abdolkarim and Voigt, Guido","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","410-425","2013","MAR-APR","Cheap Talk;Experimental Economics;Principal-Agent Theory;Screening Contracts;Supply Chain Coordination","","The use of screening contracts is a common approach to solve supply chain coordination problems under asymmetric information. One main assumption in this context is that managers without specific incentives would rather use their private information strategically than reveal it truthfully. This harms supply chain performance. This study investigates the impact of information sharing in a principal-agent setting that is typical for many supply chain transactions. We conduct a laboratory experiment to test whether information sharing has an influence on supply chain coordination. We find that information sharing within the supply chain has two positive effects. First, information sharing reduces the inefficiencies resulting from information deficits if there is a certain amount of trust in the supply chain. Second, communication can limit out-of-equilibrium behavior with a small impact on the firm's own payoff, but a large impact on the supply chain partner. Furthermore, we find that both effects are amplified when communication takes place in an environment that allows the less informed supply chain party to punish or to reward the better informed party. Although our extended mechanisms substantially enhance the poor performance of the theoretically optimal coordination contract menu, we find no mechanism that implements supply chain performance superior to the theoretically predicted second-best level."
2322,"Managing Downstream Competition via Capacity Allocation","Chen, Fangruo and Li, Jianbin and Zhang, Hanqin","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","426-446","2013","MAR-APR","Supply Chains;Retail Competition;Capacity Allocation;Proportional Mechanism;Lexicographic Mechanism;Equilibrium Analysis;Wholesale Pricing","","Consider a supply chain with one supplier and multiple retailers. The supplier produces a single product and sells it to the retailers, who in turn sell the product to consumers. The supplier has limited production capacity, and the retailers are engaged in a Cournot competition at the consumer/market level. When the sum of the retailer orders exceeds the capacity, the supplier allocates her capacity according to a pre-announced allocation mechanism. Two mechanisms are considered: proportional allocation and lexicographic allocation. An extensive study of the two allocation mechanisms shows that the lexicographic mechanism has the ability to dampen the competition at the retail level, increasing the profits for both the supplier and the supply chain."
2323,"Supply Diversification with Responsive Pricing","Li, Tao and Sethi, Suresh P. and Zhang, Jun","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","447-458","2013","MAR-APR","Supply Diversification;Responsive Pricing","","We study sourcing and pricing decisions of a firm with correlated suppliers and a price-dependent demand. With two suppliers, the insightcost is the order qualifier while reliability is the order winnerderived in the literature for the case of exogenously determined price and independent suppliers, continues to hold when the suppliers' capacities are correlated. Moreover, a firm orders only from one supplier if the effective purchase cost from him, which includes the imputed cost of his unreliability, is lower than the wholesale price charged by his rival. Otherwise, the firm orders from both. Furthermore, the firm's diversification decision does not depend on the correlation between the two suppliers' random capacities. However, its order quantities do depend on the capacity correlation, and, if the firm's objective function is unimodal, the total order quantity decreases as the capacity correlation increases in the sense of the supermodular order. With more than two suppliers, the insight no longer holds. That is, when ordering from two or more suppliers, one is the lowest-cost supplier and the others are not selected on the basis of their costs. We conclude the paper by developing a solution algorithm for the firm's optimal diversification problem."
2324,"Market Good Flexibility in Capacity Auctions","Hall, Nicholas G. and Liu, Zhixin","PRODUCTION AND OPERATIONS MANAGEMENT","22","2","459-472","2013","MAR-APR","Noncooperative Game;Auction;Market Good Flexibility;Capacity Allocation","","We consider the allocation of limited production capacity among several competing agents through auctions. Our focus is on the contribution of flexibility in market good design to effective capacity allocation. The application studied is a capacity allocation problem involving several agents, each with a job, and a facility owner. Each agent generates revenue by purchasing capacity and scheduling its job at the facility. Ascending auctions with various market good designs are compared. We introduce a new market good that provides greater flexibility than those previously considered in the literature. We allow ask prices to depend both on agents' utility functions and on the number of bids at the previous round of the auction, in order to model and resolve resource conflicts. We develop both optimal and heuristic solution procedures for the winner determination problem. Our computational study shows that flexibility in market good design typically increases system value within auctions. A further increase is achieved if each agent is allowed to bid for multiple market goods at each round. On average, the multiple flexible market goods auction provides over 95% of the system value found by centralized planning."
2325,"Operational Slack and Venture Survival","Azadegan, Arash and Patel, Pankaj C. and Panda, Vinit","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","1-18","2013","JAN-FEB","Operational Slack;Uncertainty;Venture Survival;Gamma Frailty Weibull Regression","","Slack can act as a double-edged sword. While it can buffer against environmental threats to help ensure business continuity, slack can also be costly and reduce profitability. In this study we focus on operational slack, the form related to the firm's production processes. We investigate the role of operational slack on firm survival during its venture stage when its survival is significantly challenged by environmental threats. Specifically, we explore how change in three types of environmental uncertainty, namely dynamism, complexity, and lack of munificence, affect the relationship between operational slack and venture survival. Results suggest that with an increase in environmental uncertainty, operational slack lowers the likelihood of venture failure."
2326,"Increasing Revenue by Decreasing Information in Procurement Auctions","Haruvy, Ernan and Katok, Elena","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","19-35","2013","JAN-FEB","Bidding;Procurement Auctions;Reverse Auctions;Multi-Attribute Auctions;Behavioral Game Theory;Experimental Economics","","We report on results of several laboratory experiments that investigate on-line procurement auctions in which suppliers bid on price, but exogenous bidder quality affects winner determination. In procurement auctions, bidder quality may or may not be publicly known to all bidders, and the effect of this quality transparency on the auction outcome is one aspect of auction design that we examine. The second aspect of auction design that we examine is the effect of price visibility on the auction outcome, and the interaction between price visibility and quality transparency. In terms of price visibility, we consider two extreme cases: the sealed bid request for proposals (RFPs), and the open-bid dynamic auction event. In terms of bidder quality transparency, we also consider two extreme cases: a setting in which bidder qualities are publicly known and the case in which they are private. We find that in our laboratory experiments, the RFP format is consistent in generating higher buyer surplus levels than does the open-bid dynamic format. This advantage is independent of the quality transparency. In contrast, the open-bid format is highly sensitive to quality transparency, generating significantly lower buyer surplus levels when the information about bidder quality is public."
2327,"Remanufacturing and the Component Commonality Decision","Subramanian, Ravi and Ferguson, Mark E. and Toktay, L. Beril","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","36-53","2013","JAN-FEB","Component Commonality;Remanufacturing;Competition;Closed Loop Supply Chains","","Firms often determine whether or not to make components common across products by focusing on the manufacturing and sales of new products only. However, component commonality decisions that ignore remanufacturing can adversely affect the profitability of the firm. In this article we analyze how remanufacturing could reverse the OEM's commonality decision that is based on the manufacturing and sales of new products only. Specifically, we determine the conditions under which the OEM's optimal decision on commonality may be reversed and illustrate how her profit can be significantly higher if remanufacturing is taken into account ex ante. We illustrate the implementation of our model for two products in the Apple iPad (TM) family."
2328,"An Advanced Heuristic for Multiple-Option Spare Parts Procurement after End-of-Production","Inderfurth, Karl and Kleber, Rainer","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","54-70","2013","JAN-FEB","Spare Parts;Inventory Management;Reverse Logistics;Final Order","","After-sales service is a major source of profit for many original equipment manufacturers in industries with durable products. Successful engagement in after-sales service improves customer loyalty and allows for competitive differentiation through superior service like an extended service period during which customers are guaranteed to be provided with service parts. Inventory management during this period is challenging due to the substantial uncertainty concerning demand over a long time horizon. The traditional mechanism of spare parts acquisition is to place a large final order at the end of regular production of the parent product, causing major holding costs and a high level of obsolescence risk. With an increasing length of the service period, more flexibility is needed and can be provided by adding options like extra production and remanufacturing. However, coordinating all three options yields a complicated stochastic dynamic decision problem. For that problem type, we show that a quite simple decision rule with order-up-to levels for extra production and remanufacturing is very effective. We propose a heuristic procedure for parameter determination which accounts for the main stochastic and dynamic interactions in decision making, but still consists of relatively simple calculations that can be applied to practical problem sizes. A numerical study reveals that the heuristic performs extremely well under a wide range of conditions, and therefore can be strongly recommended as a decision support tool for the multi-option spare parts procurement problem. A comparison with decision rules adapted from practice demonstrates that our approach offers an opportunity for major cost reductions."
2329,"An Enhanced Concave Program Relaxation for Choice Network Revenue Management","Meissner, Joern and Strauss, Arne and Talluri, Kalyan","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","71-87","2013","JAN-FEB","Discrete-Choice Models;Network Revenue Management;Optimization;Cutting Planes","","The network choice revenue management problem models customers as choosing from an offer set, and the firm decides the best subset to offer at any given moment to maximize expected revenue. The resulting dynamic program for the firm is intractable and approximated by a deterministic linear program called the CDLP which has an exponential number of columns. However, under the choice-set paradigm when the segment consideration sets overlap, the CDLP is difficult to solve. Column generation has been proposed but finding an entering column has been shown to be NP-hard. In this study, starting with a concave program formulation called SDCP that is based on segment-level consideration sets, we add a class of constraints called product constraints (sigma PC), that project onto subsets of intersections. In addition, we propose a natural direct tightening of the SDCP called ESDC kappa, and compare the performance of both methods on the benchmark data sets in the literature. In our computational testing on the data sets, 2PC achieves the CDLP value at a fraction of the CPU time taken by column generation. For a large network our 2PC procedure runs under 70 seconds to come within 0.02% of the CDLP value, while column generation takes around 1 hour; for an even larger network with 68 legs, column generation does not converge even in 10 hours for most of the scenarios while 2PC runs under 9 minutes. Thus we believe our approach is very promising for quickly approximating CDLP when segment consideration sets overlap and the consideration sets themselves are relatively small."
2330,"A Nonatomic-Game Approach to Dynamic Pricing under Competition","Yang, Jian and Xia, Yusen","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","88-103","2013","JAN-FEB","Revenue Management;Nonatomic Games;Fixed Point;Competitive Firms;Dynamic Pricing","","We study a revenue management problem involving competing firms. We assume the presence of a continuum of infinitesimal firms where no individual firm has any discernable influence over the evolution of the overall market condition. Under this nonatomic-game approach, the unanimous adoption of an equilibrium pricing policy by all firms will yield a market-condition process that in turn will elicit the said policy as one of the best individual responses. For both deterministic- and stochastic-demand cases, we show the existence of equilibrium pricing policies that exhibit well-behaving monotone trends. Our computational study reveals many useful insights, including the fact that only a reasonable number of firms are needed for our approach to produce near-rational pricing policies."
2331,"On the Advantage of Quantity Leadership When Outsourcing Production to a Competitive Contract Manufacturer","Wang, Yulan and Niu, Baozhuang and Guo, Pengfei","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","104-119","2013","JAN-FEB","Outsourcing;Contract Manufacturing;Competitive Cm;Quantity Leadership;Cournot Competition","","This study investigates a supply chain comprising an original equipment manufacturer (OEM) and a contract manufacturer (CM), in which the CM acts as both upstream partner and downstream competitor to the OEM. The two parties can engage in one of three Cournot competition games: a simultaneous game, a sequential game with the OEM as the Stackelberg leader, and a sequential game with the CM as the Stackelberg leader. On the basis of these three basic games, this study investigates the two parties' Stackelberg leadership/followership decisions. When the outsourcing quantity and wholesale price are exogenously given, either party may prefer Stackelberg leadership or followership. For example, when the wholesale price or the proportion of production outsourced to the CM is lower than a threshold value, both parties prefer Stackelberg leadership and, consequently, play a simultaneous game in the consumer market. When the outsourcing quantity and wholesale price are decision variables, the competitive CM sets a wholesale price sufficiently low to allow both parties to coexist in the market, and the OEM outsources its entire production to this CM. This study also examines the impact of the supply chain parties' bargaining power on contract outcomes by considering a wholesale price that is determined via the generalized Nash bargaining scheme, finding a Stackelberg equilibrium to be sustained when the CM's degree of bargaining power is great and the non-competitive CM's wholesale price is high."
2332,"Does Quality Still Pay? A Reexamination of the Relationship Between Effective Quality Management and Firm Performance","Zhang, Guoqiang Peter and Xia, Yusen","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","120-136","2013","JAN-FEB","Quality;Total Quality Management;Award;Firm Performance;Event Study","","Because of the changing competitive environment, quality might have lost some of its luster and emphasis in business. The research question we aim to address in this paper is: Does quality still pay in the new competitive environment? Using replication research, we re-examine the impact of an effective total quality management (TQM) program on a firm's operating performance in the new competitive environment. We use publicly available data for award-winning firms and adopt several control-firm-selection approaches in our event study. Based on data from more than 500 firms, we find that over a 10-year period-6 years before to 3 years after winning their first quality award firms in our sample perform significantly better than control groups in various operating performance measures. Not only do award-winning firms have better results after receiving awards, they also have superior performance records before the award. Our results suggest that quality is still critical to achieving long-term competitive advantages, and firms who continuously improve their quality continue to reap rewards by way of sales and financial performances exceeding those of their competitors."
2333,"Managing Risk of Supply Disruptions: Incentives for Capacity Restoration","Hu, Xinxin and Gurnani, Haresh and Wang, Ling","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","137-150","2013","JAN-FEB","Supply Disruption;Capacity Restoration;Supply Diversification","","A supplier facing the prospect of disruption has to decide whether or not to invest in restoration capability. With restoration capability, if disruption occurs, additional costly effort can be exerted to rebuild capacity, although its outcome is uncertain. We study how a firm (buyer) can use incentive mechanisms to motivate a supplier's investment in capacity restoration, and compare this approach with the traditional approach of diversifying part of the order to an expensive but reliable supplier. Under a Restoration Enhancement (RE) strategy, the buyer uses price and/or order quantity incentives to encourage the supplier's restoration investment decision. Two different cases are considered when the incentive is committed to ex ante (prior to disruption) and when it is committed to ex post (after disruption). In contrast, under a Supplier Diversification (SD) strategy, the buyer splits orders between a reliable supplier and an unreliable supplier to hedge against the disruption risk. Here, the buyer does not provide any separate incentive to the unreliable supplier. Our analysis indicates that under the RE strategy, where the buyer offers incentives, both the buyer and the supplier (weakly) prefer the ex ante commitment over the ex post one. Furthermore, the RE strategy is preferred over the SD strategy when the unreliable supplier's restoration outcome is more predictable or when a high restoration outcome is more likely. However, the buyer's preference for the SD strategy increases as market demand increases."
2334,"Distributing a Product Line in a Decentralized Supply Chain","Shao, Jing and Krishnan, Harish and McCormick, S. Thomas","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","151-163","2013","JAN-FEB","Supply Chain Management;Coordinating Contracts;Product Line Distribution;Price And Inventory Competition","","Although there is a rich literature on single product distribution in decentralized supply chains, the incentive problems that arise in. distributing a product line have largely not been investigated. In practice, most manufacturers distribute a line of products with different features and qualities and not just a single product. Consider a manufacturer who distributes a product line through competing downstream retailers. In this setting, we investigate how and why the retailers' price and inventory decisions deviate from the centrally optimal decisions. Due to substitution between different product variants, as well as between different retailers, the incentive problems associated with distributing a product line are more complicated than that of distributing a single product. We characterize retailers' incentive distortions under a residual-claimancy contract, and construct contracts that achieve channel coordination. We show that retail price floors or inventory buybacks, appropriately tailored to each product variant, are among the contracts that can achieve coordination. Using numerical simulations, we demonstrate how the optimal contract terms (such as wholesale prices and buyback prices) for each variant are influenced by the parameters of an underlying consumer choice model."
2335,"Offshore Outsourcing, Yield Uncertainty, and Contingency Responses","Kouvelis, Panos and Li, Jian","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","164-177","2013","JAN-FEB","Yield Uncertainty;Contingency Response;Emergency Production;Delivery Option","","In this article, we study an offshore outsourcing arrangement for a buyer of a produced good in the presence of supply yield uncertainty. We analyze the performance of contingency responses to the realized yield information at the end of production and prior to its delivery to the destination market. The contingency responses considered are: (i) Emergency Production via which an emergency order is placed with another fast and perfectly reliable offshore supplier; (ii) Emergency Production and Delivery via which an expedited shipping of (partial or total) good units is used on top of Emergency Production. Within a periodic review inventory system with uncertain demand setting, we theoretically characterize the optimal decisions on the cycle order size, the emergency order size, and the way to split the available good units between the fast and slow shipping modes. We provide comparative statics on how the choices of these quantities are affected by each other and by the demand and yield uncertainties. We use numerical examples to illustrate the values of such contingency responses and the impact of other factors on the cost of meeting demand."
2336,"Analysis of the Market-Based Adjustable Outsourcing Contract under Uncertainties","Feng, Baichun and Yao, Tao and Jiang, Bin","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","178-188","2013","JAN-FEB","Outsourcing;Adjustable Contract;Share Ratio;Target Price","","The market-based adjustable contract for customized goods or services has emerged in outsourcing practices. Its objective is to minimize the operational risks inherent in today's volatile environment of operations. Our research reveals several important properties of this contract through a continuous-time analytical approach. Specifically, we consider the determination of this contract between two risk-averse firms through a Nash bargaining process. We derive the optimal adjusting mechanism analytically and extensively analyze the application boundary of the market-based adjustable outsourcing contract. We conclude by discussing implications for practice and research."
2337,"The Retail Space-Exchange Problem with Pricing and Space Allocation Decisions","Leng, Mingming and Parlar, Mahmut and Zhang, Dengfeng","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","189-202","2013","JAN-FEB","Retail Space-Exchange;Price;Space Allocation;Hotelling Model;Nash Equilibrium","","We consider retail space-exchange problems where two retailers exchange shelf space to increase accessibility to more of their consumers in more locations without opening new stores. Using the Hotelling model, we find two retailers' optimal prices, given their host and guest space in two stores under the space-exchange strategy. Next, using the optimal space-dependent prices, we analyze a non-cooperative game, where each retailer makes a space allocation decision for the retailer's own store. We show that the two retailers will implement such a strategy in the game, if and only if their stores are large enough to serve more than one-half of their consumers. Nash equilibrium for the game exists, and its value depends on consumers' utilities and trip costs as well as the total available space in each retailer's store. Moreover, as a result of the space-exchange strategy, each retailer's prices in two stores are both higher than the retailer's price before the space exchange, but they may or may not be identical."
2338,"Design of Stockless Production Systems","Arreola-Risa, Antonio and Keblis, Matthew F.","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","203-215","2013","JAN-FEB","Production System Design;Manufacturing Operations;Inventory Management;Stochastic Processes","","In make-to-stock production systems finished goods are produced in anticipation of demand. By contrast, in stockless I production systems finished goods are not produced until demand is observed. In this study we investigate the problem of designing a multi-item manufacturing system, where there is both demand- and production-related uncertainty, so that stockless operation will be optimal for all items. For the problem of interest, we focus on gaining an understanding of the effect of two design variables: (i) manufacturing speed measured by the average manufacturing rate or, equivalently, the average unit manufacturing time, and (ii) manufacturing consistency measured by the variation in unit manufacturing times. We establish conditions on these two variables that decision makers can use to design stockless production systems. Managerial implications of the conditions are also discussed."
2339,"A Markov Chain Model for an EMS System with Repositioning","Alanis, Ramon and Ingolfsson, Armann and Kolfal, Bora","PRODUCTION AND OPERATIONS MANAGEMENT","22","1","216-231","2013","JAN-FEB","Health Care;Ambulance Service;Repositioning;System Status Management;Fleet Management","","We propose and analyze a two-dimensional Markov chain model of an Emergency Medical Services system that repositions ambulances using a compliance table policy, which is commonly used in practice. The model is solved via a fixed-point iteration. We validate the model against a detailed simulation model for several scenarios. We demonstrate that the model provides accurate approximations to various system performance measures, such as the response time distribution and the distribution of the number of busy ambulances, and that it can be used to identify near-optimal compliance tables. Our numerical results show that performance depends strongly on the compliance table that is used, indicating the importance of choosing a well-designed compliance table."
2340,"Competition and Coordination in Online Marketplaces","Ryan, Jennifer K. and Sun, Daewon and Zhao, Xuying","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","997-1014","2012","NOV-DEC","E-Business;Online Marketplace;Coordination;Competition;Game Theory","","Online marketplaces, such as those operated by Amazon, have seen rapid growth in recent years. These marketplaces serve as an intermediary, matching buyers with sellers, whereas control of the good is left to the seller. In some cases, e.g., the Amazon marketplace system, the firm that owns and manages the marketplace system will also sell competing products through the marketplace system. This creates a new form of channel conflict, which is a focus of this article. We consider a setting in which a marketplace firm operates an online marketplace through which retailers can sell their products directly to consumers. We consider a single retailer, who currently sells its product only through its own website, but who may choose to contract with Amazon to sell its product through the marketplace system. Selling the product through the marketplace expands the available market for the retailer, but comes at some expense, e.g., a fixed participation fee or a revenue sharing requirement. Thus, a key question for the retailer is whether she should choose to sell through the marketplace system, and if so, at what price. We analyze the optimal decisions for both the retailer and the marketplace firm and characterize the system equilibrium."
2341,"Coalition Formation and Cost Allocation for Joint Replenishment Systems","Elomri, Adel and Ghaffari, Asma and Jemai, Zied and Dallery, Yves","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1015-1027","2012","NOV-DEC","Joint Replenishment;Cooperative Game Theory;Proportional Allocations;Coalition Formation;Coalition Structure Core;Fractional Programming","","This paper focuses on the issues of coalition formation and cost allocation in a joint replenishment system involving a set of independent and freely interacting retailers purchasing an item from one supplier to meet a deterministic demand. The papers dealing with this problem are mainly focused on supperadditive games, where the cost savings associated with a coalition increase with the number of players in the coalition. The most relevant question addressed then is how to allocate the savings to the players. In this paper, we propose to go further by dealing with a non-supperadditive game, where a set of independent retailers have the common understanding to share the cost savings according to the cost-based proportional rule. In this setting, the global cost optimization is no longer a relevant approach to identify appealing coalitions for any retailer. Here, we provide an iterative procedure to form the so-called efficient coalition structure and we show that this coalition structure has the nice properties of being (i) weakly stable in the sense of the coalition structure core and (ii) strongly stable under a given assumption. An exact fractional programming based solution is also given to generate such efficient coalitions."
2342,"A Multi-Supplier Sourcing Problem with a Preference Ordering of Suppliers","Honhon, Dorothee and Gaur, Vishal and Seshadri, Sridhar","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1028-1041","2012","NOV-DEC","Inventory Management;Procurement;Supplier Scorecard;Multi-Supplier Sourcing;Stockout-Based Substitution","","We study a sourcing problem faced by a firm that seeks to procure a product or a component from a pool of alternative suppliers. The firm has a preference ordering of the suppliers based on factors such as their past performance, quality, service, geographical location, and financial strength, which are commonly included in a supplier scorecard system. Thus, the firm first uses available inventory from supplier 1, if any, then supplier 2, if any, and so on. The suppliers differ in costs and prices. The buyer firm seeks to determine which suppliers to purchase from and in what quantities to maximize its total expected profit subject to the preference ordering constraint. We present the optimal solution to this problem, and show that it has a portfolio structure. It consists of a sub-set of suppliers that are ordered by their underage and overage costs. This portfolio achieves a substantial profit gain compared to sourcing from a unique supplier. We present an efficient algorithm to compute the optimal solution. Our model applies to component sourcing problems in manufacturing, merchandizing problems in retailing, and capacity reservation problems in services."
2343,"Extended Producer Responsibility for E-Waste: Individual or Collective Producer Responsibility?","Atasu, Atalay and Subramanian, Ravi","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1042-1059","2012","NOV-DEC","Product Take-Back;Extended Producer Responsibility;Weee;Competition","","We investigate the implications of collective and individual producer responsibility (CPR and IPR, respectively) models of product take-back laws for e-waste on manufacturers' design for product recovery (DfR) choices and profits, and on consumer surplus in the presence of product competition. We show that IPR offers superior DfR incentives as compared to CPR, and provides a level competitive ground. CPR may distort competition and allow free-riding on DfR efforts to reduce product recovery costs. Thus, manufacturer preferences for IPR or CPR may differ because of the free-riding implications under CPR, with even high-end manufacturers having incentives to free-ride under certain competitive conditions. The policy choice between IPR and CPR is not clear cut from an economic welfare perspective. This choice involves a comparison between the effects of superior recovery cost reduction through improved DfR under IPR and the operational cost-efficiency under CPR."
2344,"Analysis of Travel Times and CO2 Emissions in Time-Dependent Vehicle Routing","Jabali, O. and Van Woensel, T. and de Kok, A. G.","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1060-1074","2012","NOV-DEC","Vehicle Routing Problems;Time-Dependent Travel Times;Co2 Emissions;Green Logistics","","Due to the growing concern over environmental issues, regardless of whether companies are going to voluntarily incorporate green policies in practice, or will be forced to do so in the context of new legislation, change is foreseen in the future of transportation management. Assigning and scheduling vehicles to service a pre-determined set of clients is a common distribution problem. Accounting for time-dependent travel times between customers, we present a model that considers travel time, fuel, and CO2 emissions costs. Specifically, we propose a framework for modeling CO2 emissions in a time-dependent vehicle routing context. The model is solved via a tabu search procedure. As the amount of CO2 emissions is correlated with vehicle speed, our model considers limiting vehicle speed as part of the optimization. The emissions per kilometer as a function of speed are minimized at a unique speed. However, we show that in a time-dependent environment this speed is sub-optimal in terms of total emissions. This occurs if vehicles are able to avoid running into congestion periods where they incur high emissions. Clearly, considering this trade-off in the vehicle routing problem has great practical potential. In the same line, we construct bounds on the total amount of emissions to be saved by making use of the standard VRP solutions. As fuel consumption is correlated with CO2 emissions, we show that reducing emissions leads to reducing costs. For a number of experimental settings, we show that limiting vehicle speeds is desired from a total cost perspective. This namely stems from the trade-off between fuel and travel time costs."
2345,"Impact of Reseller's Forecasting Accuracy on Channel Member Performance","Chen, Ying-Ju and Xiao, Wenqiang","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1075-1089","2012","NOV-DEC","Forecasting Accuracy;Multi-Tier Channel;Mechanism Design;Salesforce Compensation","","This article studies a three-layer supply chain where a manufacturer sells a product through a reseller who then relies on its own salesperson to sell to the end market. The reseller has superior capability in demand forecasting relative to the manufacturer. We explore the main trade-offs between the risk-reduction effect and the information-asymmetry-aggravation effect of the improved forecasting accuracy. We show that under the optimal wholesale price contract, both the manufacturer and the reseller are always better off as the reseller's forecasting accuracy improves. Nevertheless, under the menu of two-part tariffs, the manufacturer prefers the reseller to be either uninformed or perfectly informed about the market condition. We further find that the improved forecasting accuracy is beneficial for the reseller if its current forecasting system is either very poor or very good."
2346,"Equilibrium Financing in a Distribution Channel with Capital Constraint","Jing, Bing and Chen, Xiangfeng and Cai, Gangshu (George)","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1090-1101","2012","NOV-DEC","Capital Constraint;Distribution Channel;Financing;Trade Credit","","There exist capital constraints in many distribution channels. We examine a channel consisting of one manufacturer and one retailer, where the retailer is capital constrained. The retailer may fund its business by borrowing credit either from a competitive bank market or from the manufacturer, provided the latter is willing to lend. When only one credit type (either bank or trade credit) is viable, we show that trade credit financing generally charges a higher wholesale price and thus becomes less attractive than bank credit financing for the retailer. When both bank and trade credits are viable, the unique equilibrium is trade credit financing if production cost is relatively low but is bank credit financing otherwise. We also study the case where both the retailer and the manufacturer are capital constrained and demonstrate that, to improve the overall supply chain efficiency, the bank should finance the manufacturer if production cost is low but finance the retailer otherwise. Our analysis further suggests that the equilibrium region of trade credit financing shrinks as demand variability or the retailer's internal capital level increases."
2347,"Gray Markets, A Product of Demand Uncertainty and Excess Inventory","Dasu, Sriram and Ahmadi, Reza and Carr, Scott M.","PRODUCTION AND OPERATIONS MANAGEMENT","21","6","1102-1113","2012","NOV-DEC","Distribution Channels;Decisions Under Uncertainty;Retailing And Wholesale;Gray Markets","","Diverting large quantities of goods from authorized distribution channels to unauthorized or gray market channels, albeit legal, significantly affects both firms and consumers due to effects on price, revenue, service and warranty availability, and product availability. In this paper we consider mechanisms by which the uncertainty surrounding inventory ordering decisions drives gray markets. We start with a minimal stochastic supply chain model composed of a producer and a retailer; then we restructure the model to add a distributor whereby the distributor and authorized retailer have the option of diverting inventory to a gray market. Our analysis sheds light on three issues: impacts of diversion on the various supply chain participants, strategies producers could use to combat or exploit gray markets, and important considerations for authorized retailers trying to set optimal order quantities in the presence of a gray market. Our analysis yields new insights into the behavior and impact of gray markets, which can inform management strategies and policies for confronting them."
2348,"Managing a Remanufacturing System with Random Yield: Properties, Observations, and Heuristics","Tao, Zhijie and Zhou, Sean X. and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","797-813","2012","SEP-OCT","Remanufacturing;Random Yield;Optimal Policy;Heuristics","","We study a remanufacturing system that involves the ordering of a serviceable product and the remanufacturing of multiple types of returned products (cores) into the serviceable product. In addition to random demand for the serviceable product and random returned quantities of different types of cores in each time period, the remanufacturing yield of each type of core is also uncertain. By analyzing a multi-period stochastic dynamic program, we derive several properties of the optimal ordering/remanufacturing policy. In addition to some insights, these properties can be used to reduce the search effort of the optimal policy. We also demonstrate that some existing results derived from related models no longer hold in remanufacturing systems with random yield. Recognizing the optimal ordering/remanufacturing policy is highly complex, we examine three simple heuristics that can be efficiently solved and implemented in practice. Among these three heuristics, our numerical analysis suggests that the heuristic that captures most of the yield uncertainty and future system evolvement as well as some of the properties of the optimal ordering/remanufacturing policy outperforms the other two heuristics."
2349,"The Role of Revenue-Focused Managerial Performance Measures in Supply Chain Coordination","Chen, Liwen and Gilbert, Stephen M. and Xu, Xiaohui","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","814-832","2012","SEP-OCT","Hold-Up Problem;Capacity Investment;Promotion;Strategic Delegation;Managerial Incentives","","Many firms employ revenue-focused managerial performance measures (RF-MPMs) that cause managers to worry more about revenues than about costs. Although this can seemingly misalign the interests of a manager, we show that the use of such measures can help supply chain partners to overcome hold-up issues with respect to capacity and promotion investments. We develop a game theoretic model in which two supply chain partners engage in repeated interactions in which the supplier invests in capacity and the buyer invests in demand promotion. Following the realization of demand in each period, the two firms negotiate over the output quantity and wholesale price. The novelty of our model is that we allow the owners of each firm to delegate decision-making power and negotiating responsibility to a free-agent manager. We characterize the conditions under which the owners of both firms employ RF-MPMs in equilibrium and benefit from doing so. For a special case of our model, we show that for the owners of the buyer, an RF-MPM is equivalent to a price only relational contract, and that it complements a price and quantity relational contract as a mechanism for mitigating hold-up issues."
2350,"On the Use of Buy Up as a Model of Customer Choice in Revenue Management","Cooper, William L. and Li, Le","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","833-850","2012","SEP-OCT","Revenue Management;Yield Management;Choice Models;Misspecification","","We consider settings in which a revenue manager controls bookings over a sequence of flights. The revenue manager uses a buy-up model to select booking limits and updates estimates of the model parameters as data are accumulated. The buy-up model we consider is based upon a simple model of customer choice, wherein each low-fare customer who is not able to purchase a low-fare ticket will, with a fixed probability, buy up to the high fare, independent of everything else. We analyze the evolution of the parameter estimates (e.g., the buy-up probability) and chosen booking limits in situations where the buy-up model is misspecified, that is, in situations where there is no setting of its parameters for which its objective function gives an accurate representation of expected revenue as a function of the booking limit. The analysis is motivated by the common situation in which a revenue manager does not know precisely how customers behave but nevertheless uses a parametric model to make decisions. Under some assumptions, we prove that the booking limits and parameter estimates converge and we compare the actual expected revenue at the limiting values with that associated with the booking limits that would be chosen if the revenue manager knew the actual behavior of customers. The analysis shows that the buy-up model often works reasonably well even when it is misspecified, and also reveals the importance of understanding how parameter estimates of misspecified models vary as functions of decisions."
2351,"A Sales Forecast Model for Short-Life-Cycle Products: New Releases at Blockbuster","Chung, Casey and Niu, Shun-Chen and Sriskandarajah, Chelliah","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","851-873","2012","SEP-OCT","Sales Forecasting;Retail Operations;New-Product Diffusion;Buyer Behavior;Dvd Movies;Stochastic Model Applications","","We develop, in this article, a sales model for movie and game products at Blockbuster. The model assumes that there are three sales components: the first is from consumers who have already committed to purchasing (or renting) a product (e.g., based on promotion of, or exposure to, the product prior to its launch); the second comes from consumers who are potential buyers of the product; and the third comes from either a networking effect on closely tied (as in a social group) potential buyers from previous buyers (in the case of movie rental and all retail products) or re-rents (in the case of game rental). In addition, we explicitly formulate into our model dynamic interactions between these sales components, both within and across sales periods. This important feature is motivated by realism, and it significantly contributes to the accuracy of our model. The model is thoroughly tested against sales data for rental and retail products from Blockbuster. Our empirical results show that the model offers excellent fit to actual sales activity. We also demonstrate that the model is capable of delivering reasonable sales forecasts based solely on environmental data (e.g., theatrical sales, studio, genre, MPAA ratings, etc.) and actual first-period sales. Accurate sales forecasts can lead to significant cost savings. In particular, it can improve the retail operations at Blockbuster by determining appropriate order quantities of products, which is critical in effective inventory management (i.e., it can reduce the extent of over-stocking and under-stocking). While our model is developed specifically for product sales at Blockbuster, we believe that with context-dependent modifications, our modeling approach could also provide a reasonable basis for the study of sales for other short-Life-Cycle products."
2352,"Appointment Overbooking in Health Care Clinics to Improve Patient Service and Clinic Performance","LaGanga, Linda R. and Lawrence, Stephen R.","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","874-888","2012","SEP-OCT","Service Operations;Appointment Scheduling;Overbooking","","The problem of no-shows (patients who do not arrive for scheduled appointments) is particularly significant for health care clinics, with reported no-show rates varying widely from 3% to 80%. No-shows reduce revenues and provider productivity, increase costs, and limit patient access by reducing effective clinic capacity. In this article, we construct a flexible appointment scheduling model to mitigate the detrimental effects of patient no-shows, and develop a fast and effective solution procedure that constructs near-optimal overbooked appointment schedules that balance the benefits of serving additional patients with the potential costs of patient waiting and clinic overtime. Computational results demonstrate the efficacy of our model and solution procedure, and connect our work to prior research in health care appointment scheduling."
2353,"End-of-Life Inventory Decisions for Consumer Electronics Service Parts","Pourakbar, M. and Frenk, J. B. G. and Dekker, R.","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","889-906","2012","SEP-OCT","Service Parts;End-Of-Life Inventory Control;Consumer Electronics","","We consider a consumer electronics manufacturer's problem of controlling the inventory of spare parts in the final phase of the service life cycle. The final phase starts when the part production is terminated and continues until the last service contract or warranty period expires. Placing final orders for service parts is considered to be a popular tactic to satisfy demand during this period and to mitigate the effect of part obsolescence at the end of the service life cycle. Previous research focuses on repairing defective products by replacing the defective parts with properly functioning spare ones. However, for consumer electronic products there typically is considerable price erosion while repair costs stay steady over time. As a consequence, there might be a point in time at which the unit price of the product drops below the repair costs. If so, it is more cost effective to adopt an alternative policy to meet service demands toward the end of the final phase, such as offering customers a new product of the similar type or a discount on a next generation product. This study examines the cost trade-offs of implementing alternative policies for the repair policy and develops an exact expression for the expected total cost function. Using this expression, the optimal final order quantity and switching time from repair to an alternative policy can be determined simultaneously. Numerical analysis of a real world case sheds light on the cost benefits of these policies and also yields insights into the quantitative importance of the various cost parameters."
2354,"Should an OEM Retain Component Procurement when the CM Produces Competing Products?","Chen, Ying-Ju and Shum, Stephen and Xiao, Wenqiang","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","907-922","2012","SEP-OCT","Buy-Sell;Price Masking;Turnkey;Information Asymmetry","","We consider a large original equipment manufacturer (OEM) who relies on a contract manufacturer (CM) to produce her product. In addition to the OEM's product, the CM also produces for a smaller OEM. Both the larger OEM and the CM can purchase the component from the supplier, but their purchase prices may differ and remain unknown to each other. The main question we address is whether the larger OEM should retain component procurement by purchasing components from the supplier and reselling to the CM (buysell), or outsource component procurement by letting the CM purchase directly from the supplier (turnkey). We show that, under buysell, the larger OEM's optimal strategy is to resell components at the highest possible component purchase price of the CM (i.e., the street price). By comparing buysell and turnkey, we find that a CM with low component price is better off under turnkey, even though under buysell he receives more profits through the products sold to the smaller OEM. Furthermore, the larger OEM's preference between buysell and turnkey depends on her component price, the volatility of the CM's component price and substitutability between the two products."
2355,"An Evaluation of the NERJIT Priority Rule in a Kanban-Controlled Flowshop","Ardalan, Alireza and Diaz, Rafael","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","923-938","2012","SEP-OCT","Just-In-Time;Flowshops;Priority Rule;Simulation","","Significant progress in production and information technologies and innovations in management of operations during the last couple of decades have made the production of small lots and deployment of Just-In-Time (JIT) concepts in flowshops possible. As a result, some researchers and practitioners have been seeking to improve the performance of non-repetitive systems using JIT concepts. In this process, the JIT concepts that were originally designed for mass production have been modified to adapt JIT to non-repetitive systems. This article uses a priority rule that is based on real-time demand and production information for sequencing jobs in a kanban-controlled flowshop. The analysis of the effect of this priority rule; the number of kanbans; the length of the withdrawal cycle; First-Come, First-Served (FCFS); and Shortest Processing Time (SPT) on four performance measurescustomer wait time, total inventory, input stock-point inventory, and output stock-point inventory, shows that the use of this priority rule results in a significant reduction of customer wait time and a slight decrease in inventory."
2356,"Workload Control and Order Release: A Lean Solution for Make-to-Order Companies","Thuerer, Matthias and Stevenson', Mark and Silva, Cristovao and Land, Martin J. and Fredendall, Lawrence D.","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","939-953","2012","SEP-OCT","Workload Control;Order Release;Lean;Make-To-Order","","Protecting throughput from variance is the key to achieving lean. Workload control (WLC) accomplishes this in complex make-to-order job shops by controlling lead times, capacity, and work-in-process (WIP). However, the concept has been dismissed by many authors who believe its order release mechanism reduces the effectiveness of shop floor dispatching and increases work center idleness, thereby also increasing job tardiness results. We show that these problems have been overcome. A WLC order release method known as LUMS OR (Lancaster University Management School order release) combines continuous with periodic release, allowing the release of work to be triggered between periodic releases if a work center is starving. This paper refines the method based on the literature (creating LUMS COR [Lancaster University Management School corrected order release]) before comparing its performance against the best-performing purely periodic and continuous release rules across a range of flow directions, from the pure job shop to the general flow shop. Results demonstrate that LUMS COR and the continuous WLC release methods consistently outperform purely periodic release and Constant WIP. LUMS COR is considered the best solution in practice due to its excellent performance and ease of implementation. Findings have significant implications for research and practice: throughput times and job tardiness results can be improved simultaneously and order release and dispatching rules can complement each other. Thus, WLC represents an effective means of implementing lean principles in a make-to-order context."
2357,"Pricing and Logistics Decisions for a Private-Sector Provider in the Cash Supply Chain","Mehrotra, Mili and Dawande, Milind and Mookerjee, Vijay and Sriskandarajah, Chelliah","PRODUCTION AND OPERATIONS MANAGEMENT","21","5","954-974","2012","SEP-OCT","Cash Supply Chain;Fit-Sorting;Logistics;Pricing;Mixed-Integer Programming","","We study a problem faced by a secure-logistics provider (SLP) of maximizing profit by jointly pricing the services of fit-sorting and transporting cash along with the design of the supporting logistics network, in a market consisting of a population of Depository Institutions (DIs). The need to jointly price the services assumes significance because they are partial substitutes of one another. Our study finds that the influence of the logistics network on prices is especially strong when there are non-linearities in the cost of provisioning the logistics services. Furthermore, the impact of logistics decisions on different types of pricing schemes (e.g., volume discount, bundled pricing) is different, both in its structure and extent. In present times, when the market for the fit-sorting service is relatively immature, our findings have major implications to the way an SLP's business is managed."
2358,"Production, Process Investment, and the Survival of Debt-Financed Startup Firms","Tanrisever, Fehmi and Erzurumlu, S. Sinan and Joglekar, Nitin","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","637-652","2012","JUL-AUG","Production And Process Investment;Operational Hedging;Startup Operations;Survival Under Debt","","Whether to invest in process development that can reduce the unit cost and thereby raise future profits or to conserve cash and reduce the likelihood of bankruptcy is a key trade-off faced by many startup firms that have taken on debt. We explore this trade-off by examining the production quantity and cost reducing R&D investment decisions in a two period model wherein a startup firm must make a minimum level of profit at the end of the first period to survive and operate in the second period. We specify a probabilistic survival measure as a function of production and investment decisions to track and manage the risk exposure of the startup depending on three key market factors: technology, demand, and competitor's cost. We develop managerial insights by characterizing how to create operational hedges against the bankruptcy risk: if a startup makes a conservative investment decision, then it also selects an optimal quantity that is less than the monopoly level and hence sacrifices some of first period expected profits to increase its survival chances. If it decides to invest aggressively, then it produces more than the monopoly level to cover the higher bankruptcy risk. We also illustrate that debt constraint shrinks the decision space, wherein such process investments are viable."
2359,"Complementary Drivers of New Product Development Performance: Cross-Functional Coordination, Information System Capability, and Intelligence Quality","Bendoly, Elliot and Bharadwaj, Anandhi and Bharadwaj, Sundar","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","653-667","2012","JUL-AUG","New Product Development;Enterprise Resource Planning;Cross-Functional Coordination;Intelligence;Market Dynamics","","Coordination efforts that access and align relevant cross-functional expertise are regarded as an essential element of innovation success. In recent years, these efforts have been further augmented through complementary investments in information systems, which provide the technological platforms for information sharing and coordination across functional and organizational boundaries. Somewhat overlooked has been the critical mediating role of the intelligence gained through these efforts and capabilities. This study draws on the theory of complementarity to elaborate on the nature of this mediating concept. Theoretical predictions of the model are tested using instrument variable regression analysis of data collected from a sample of publicly traded US manufacturing firms. The findings suggest that the effects of both internal and external coordination on market intelligence and supply-chain intelligence are moderated by the firm's information system capability. The effect of both types of intelligence quality on new product development performance was contingent with the effects being enhanced (attenuated) when the market conditions were dynamic (stable). The results are robust to common-method bias, endogeneity concerns, and alternative estimation methods."
2360,"A Production-Inventory Model for a Push-Pull Manufacturing System with Capacity and Service Level Constraints","Cheng, Feng and Ettl, Markus and Lu, Yingdong and Yao, David D.","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","668-681","2012","JUL-AUG","Push;Pull-Production;Configure-To-Order;Inventory Control;Capacitated Model;Demand Skew","","We study a hybrid pushpull production system with a two-stage manufacturing process, which builds and stocks tested components for just-in-time configuration of the final product when a specific customer order is received. The first production stage (fabrication) is a push process where parts are replenished, tested, and assembled into components according to product-level build plans. The component inventory is kept in stock ready for the final assembly of the end products. The second production stage (fulfillment) is a pull-based assemble-to-order process where the final assembly process is initiated when a customer order is received and no finished goods inventory is kept for end products. One important planning issue is to find the right trade-off between capacity utilization and inventory cost reduction that strives to meet the quarter-end peak demand. We present a nonlinear optimization model to minimize the total inventory cost subject to the service level constraints and the production capacity constraints. This results in a convex program with linear constraints. An efficient algorithm using decomposition is developed for solving the nonlinear optimization problem. Numerical results are presented to show the performance improvements achieved by the optimized solutions along with managerial insights provided."
2361,"A Universal Appointment Rule in the Presence of No-Shows and Walk-Ins","Cayirli, Tugba and Yang, Kum Khiong and Quek, Ser Aik","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","682-697","2012","JUL-AUG","Healthcare;Appointment Scheduling;Simulation;Nonlinear Regression","","This study introduces a universal Dome appointment rule that can be parameterized through a planning constant for different clinics characterized by the environmental factorsno-shows, walk-ins, number of appointments per session, variability of service times, and cost of doctor's time to patients time. Simulation and nonlinear regression are used to derive an equation to predict the planning constant as a function of the environmental factors. We also introduce an adjustment procedure for appointment systems to explicitly minimize the disruptive effects of no-shows and walk-ins. The procedure adjusts the mean and standard deviation of service times based on the expected probabilities of no-shows and walk-ins for a given target number of patients to be served, and it is thus relevant for any appointment rule that uses the mean and standard deviation of service times to construct an appointment schedule. The results show that our Dome rule with the adjustment procedure performs better than the traditional rules in the literature, with a lower total system cost calculated as a weighted sum of patients waiting time, doctor's idle time, and doctor's overtime. An open-source decision-support tool is also provided so that healthcare managers can easily develop appointment schedules for their clinical environment."
2362,"Designing Service Level Contracts for Supply Chain Coordination","Sieke, Marcel A. and Seifert, Ralf W. and Thonemann, Ulrich W.","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","698-714","2012","JUL-AUG","Service Level;Contracts;Supply Chain;Financial Penalty","","Supply contracts are used to coordinate the activities of the supply chain partners. In many industries, service level-based supply contracts are commonly used. Under such a contract, a company agrees to achieve a certain service level and to pay a financial penalty if it misses it. The service level used in our study refers to the fraction of a manufacturer's demand filled by the supplier. We analyze two types of service level-based supply contracts that are designed by a manufacturer and offered to a supplier. The first type of contract is a flat penalty contract, under which the supplier pays a fixed penalty to the manufacturer in each period in which the contract service level is not achieved. The second type of contract is a unit penalty contract, under which a penalty is due for each unit delivered fewer than specified by the parameters of the contract. We show how the supplier responds to the contracts and how the contract parameters can be chosen, such that the supply chain is coordinated. We also derive structural results about optimal values of the contract parameters, provide numerical results, and connect our service level measures to traditional service level measures. The results of our analyses can be used by decision makers to design optimal service level contracts and to provide them with a solid foundation for contract negotiations."
2363,"Managing Supply Chain Execution: Monitoring Timeliness and Correctness via Individualized Trace Data","Shu, Jun and Barton, Russell","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","715-729","2012","JUL-AUG","Supply Chain Behavior Visibility Monitoring","","Improvements in information technologies provide new opportunities to control and improve business processes based on real-time performance data. A class of data we call individualized trace data (ITD) identifies the real-time status of individual entities as they move through execution processes, such as an individual product passing through a supply chain or a uniquely identified mortgage application going through an approval process. We develop a mathematical framework which we call the State-Identity-Time (SIT) Framework to represent and manipulate ITD at multiple levels of aggregation for different managerial purposes. Using this framework, we design a pair of generic quality measurestimeliness and correctnessfor the progress of entities through a supply chain. The timeliness and correctness metrics provide behavioral visibility that can help managers to grasp the dynamics of supply chain behavior that is distinct from asset visibility such as inventory. We develop special quality control methods using this framework to address the issue of overreaction that is common among managers faced with a large volume of fast-changing data. The SIT structure and its associated methods inform managers on if, when, and where to react. We illustrate our approach using simulations based on real RFID data from a Walmart RFID pilot project."
2364,"Design of Extended Warranties in Supply Chains under Additive Demand","Li, Kunpeng and Mallik, Suman and Chhajed, Dilip","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","730-746","2012","JUL-AUG","Extended Warranty;Supply Chain Management;Warranty;Game Theory","","We study the design of extended warranties in a supply chain consisting of a manufacturer and an independent retailer. The manufacturer produces a single product and sells it exclusively through the retailer. The extended warranty can be offered either by the manufacturer or by the retailer. The party offering the extended warranty decides on the terms of the policy in its best interest and incurs the repair costs of product failures. We use game theoretic models to answer the following questions. Which scenario leads to a higher supply-chain profit, the retailer offering the extended warranty or the manufacturer? How do the optimum price and extended warranty length vary under different scenarios? We find that, depending on the parameters, either party may provide better extended warranty policies and generate more system profit. We also compare these two decentralized models with a centralized system where a single party manufactures the product, sells it to the consumer, and offers the extended warranty. We also consider an extension of our basic model where either the manufacturer or the retailer resells the extended warranty policies of a third party (e.g., an independent insurance company), instead of offering its own policy."
2365,"Service and Price Competition When Customers Are Naive","Li, Li and Jiang, Li and Liu, Liming","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","747-760","2012","JUL-AUG","Queues;Customer Behavior;Price And Service Rate Competition;Two-Stage Game","","We consider a system of two service providers each with a separate queue. Customers choose one queue to join upon arrival and can switch between queues in real time before entering service to maximize their spot utility, which is a function of price and queue length. We characterize the steady-state distribution for queue lengths, and then investigate a two-stage game in which the two service providers first simultaneously select service rates and then simultaneously charge prices. Our results indicate that neither service provider will have both a faster service and a lower price than its competitor. When price plays a less significant role in customers service selection relative to queue length or when the two service providers incur comparable costs for building capacities, they will not engage in price competition. When price plays a significant role and the capacity costs at the service providers sufficiently differ, they will adopt substitutable competition instruments: the lower cost service provider will build a faster service and the higher cost service provider will charge a lower price. Comparing our results to those in the existing literature, we find that the service providers invest in lower service rates, engage in less intense price competition, and earn higher profits, while customers wait in line longer when they are unable to infer service rates and are naive in service selection than when they can infer service rates to make sophisticated choices. The customers jockeying behavior further lowers the service providers capacity investment and lengthens the customers duration of stay."
2366,"Flexible Servers in Understaffed Tandem Lines","Kirkizlar, Eser and Andradottir, Sigrun and Ayhan, Hayriye","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","761-777","2012","JUL-AUG","Throughput Maximization;Finite Buffers;Partial And Full Server Flexibility;Tandem Production Systems;Line Balancing","","We study the dynamic assignment of cross-trained servers to stations in understaffed lines with finite buffers. Our objective is to maximize the production rate. We identify optimal server assignment policies for systems with three stations, two servers, different flexibility structures, and either deterministic service times and arbitrary buffers or exponential service times and small buffers. We use these policies to develop server assignment heuristics for Markovian systems with larger buffer sizes that appear to yield near-optimal throughput. In the deterministic setting, we prove that the best possible production rate with full server flexibility and infinite buffers can be attained with partial flexibility and zero buffers, and we identify the critical skills required to achieve this goal. We then present numerical results showing that these critical skills, employed with an effective server assignment policy, also yield near-optimal throughput in the Markovian setting, even for small buffer sizes. Thus, our results suggest that partial flexibility is sufficient for near-optimal performance, and that flexibility structures that are effective for deterministic and infinite-buffered systems are also likely to perform well for finite-buffered stochastic systems."
2367,"Early Sales of Seasonal Products with Weather-Conditional Rebates","Gao, Fei and Demirag, Ozgun Caliskan and Chen, Frank Y.","PRODUCTION AND OPERATIONS MANAGEMENT","21","4","778-794","2012","JUL-AUG","Conditional Rebates;Seasonal Products;Weather-Conditional Promotions","","Some retailers of seasonal products adopt weather-conditional rebate programs to induce early sales and increase profits. In such promotions, customers who buy the product in an advance preselling period are offered rebates if a pre-specified weather condition is realized during the later normal selling season. We investigate the potential benefits of these programs for retailers. We show that the weather-conditional rebate program can increase sales by price discriminating among a customer's post-purchase states. Taking advantage of the early sales, it can also reduce the inventory holding cost and ordering cost, and hence can increase the retailer's expected profits. In addition, we numerically investigate the sensitivity of the rebate program's effectiveness to the model parameters and illustrate its advantages over an advance-discount policy."
2368,"An Operations Perspective on Product Take-Back Legislation for E-Waste: Theory, Practice, and Research Needs","Atasu, Atalay and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","407-422","2012","MAY-JUN","Waste Electrical And Electronic Equipment;Product Take-Back;Recycling;Electronics","","Agrowing stream of environmental legislation enforces collection and recycling of used electrical and electronics products. Based on our experiences with producers coping with e-waste legislation, we find that there is a strong need for research on the implications of such legislation from an operations perspective. In particular, as a discipline at the interface of systems design and economic modeling, operations focused research can be extremely useful in identifying appropriate e-waste take-back implementations for different business environments and how producers should react to them."
2369,"Trust and Information Sharing in Supply Chains","Ebrahim-Khanjari, Neda and Hopp, Wallace and Iravani, Seyed M. R.","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","444-464","2012","MAY-JUN","Supply Chain;Trust;Information Sharing;Salesperson;Social Characteristics","","Drawing on behavioral research, we construct a multi-period model with which to examine the role of trust and other social characteristics in a supply chain. Specifically, we focus on trust building in the context of a salesperson who acts as a representative of a manufacturer and shares demand forecast information with a retailer. The actions of the salesperson affect both her immediate economic gain and her future credibility as determined by retailer's trust. Our analysis reveals that, in such environments, although salespersons of widely varying types (e.g., honest, self-serving, benevolent, loyal) lie some extent about their forecast information, they tend to be trusted in long relationships, provided their forecasting accuracy is higher than that of the retailer. Furthermore, while the presence of a salesperson can improve the profits of both the retailer and manufacturer, there are cost structures under which the manufacturer is better off without a salesperson. Finally, we make the general observation that the appropriate salesperson compensation scheme depends on her social characteristics, and the specific observation that when the salesperson cares for the retailer, the linear compensation scheme commonly suggested in the literature as the optimal compensation scheme for the salesperson is no longer optimal."
2370,"Value of and Interaction between Production Postponement and Information Sharing Strategies for Supply Chain Firms","Cavusoglu, Hasan and Cavusoglu, Huseyin and Raghunathan, Srinivasan","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","470-488","2012","MAY-JUN","Information Sharing;Production Postponement;Supply Chain Management;Demand Uncertainty;Pricing","","We analyze the value of and interaction between production postponement and information sharing, which are two distinct strategies to reduce manufacturers uncertainty about demand. In both single-level and two-level supply chains, from the manufacturer's perspective, while information sharing is always valuable, production postponement can sometimes be detrimental. Furthermore, the value of production postponement is not merely driven by savings in inventory holding cost as postponement enables the manufacturer to avoid both excess and shortfall in production. We find that production postponement and information sharing strategies may substitute, complement, or conflict with each other, depending on the extent of the increase in the unit production cost when production is postponed. In a two-level supply chain, from the retailer's perspective, information sharing and production postponement can be beneficial or detrimental. When information sharing is beneficial to the retailer, the retailer always shares her demand information with the manufacturer voluntarily. In addition, this voluntary information sharing is truthful because inflated or deflated demand information hurts the retailer through a higher wholesale price or a stock-out. However, the retailer never shares her demand information voluntarily if the manufacturer has already adopted production postponement because production postponement and information sharing strategies always conflict with each other. Even when the retailer does not benefit from information sharing, we show that the manufacturer can always design an incentive mechanism to induce the retailer to share the demand information, irrespective of whether the manufacturer has already implemented production postponement or not. The above findings underscore the need for a careful assessment of demand uncertainty-reduction strategies before the supply chain players embark upon them."
2371,"Returns Policy and Quality Risk in E-Business","Hsiao, Lu and Chen, Ying-Ju","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","489-503","2012","MAY-JUN","Consumer Returns;Quality Risk;Restocking Fees;Satisfaction Guaranteed","","In this article, we investigate the interplay between returns policy, pricing strategy, and quality risk. We define quality risk as the possibility of product misfit, defect, or unconformity with the consumers perception. These notions of quality risks differ in return policy restriction, residual values, and whether it is possible to unambiguously reduce the probability of mismatch. Using a stylized two-segment market setting, we demonstrate that consumer returns are offered only when the high-segment consumers incur a higher hassle cost, and both the quality risk and the valuation of the low segment are moderate. Moreover, it is possible to wisely design the returns policy that eliminates all inappropriate returns. Furthermore, the seller with a high-quality risk may offer a refund that exceeds the selling price, which provides a theoretical ground and specific operating regime for the satisfaction guaranteed policy used in some e-tailers. In contrast, when the quality risk is relatively low, further improvement on mitigating the quality risk may not necessarily benefit the seller. Finally, we observe that the restocking fee may be non-monotonic in product quality; thus, a more generous returns policy does not necessarily indicate a lower quality risk."
2372,"Grocery Perishables Management","Li, Yanzhi and Cheang, Brenda and Lim, Andrew","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","504-517","2012","MAY-JUN","Pricing And Inventory Control;Perishable Products;Pricing;Interface Between Operations And Marketing","","In this article, we study the joint pricing and inventory control problem for perishables when a retailer does not sell new and old inventory at the same time. At the beginning of a period, the retailer makes replenishment and pricing decisions, and at the end of a period, the retailer decides whether to dispose of ending inventory or carry it forward to the next period. The objective of the retailer is to maximize the long-run average profit. Assuming zero lead time, we propose an efficient solution approach to the problem, which is also generalized to solve three extensions to the basic model. A feature of the present study is that we consider explicitly the influence of perishability on the demand. Among the insights gathered from the numerical analysis, we find that dynamic pricing aids extending shelf life and when disposal incurs a lower cost, or even a positive salvage value, the retailer is induced to dispose earlier since the benefit of selling new inventory offsets the loss due to disposal. We also observe that the faster the perceived rate of deterioration, the lower the threshold of the ending inventory for disposal. Perhaps a bit counter-intuitive, maximizing profits does not mean eliminating disposals or expirations."
2373,"Quick Response under Competition","Lin, Yen-Ting and Parlaktuerk, Ali","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","518-533","2012","MAY-JUN","Quick Response;Competition;Pricing;Supply Chain","","We consider a manufacturer serving two competing retailers that sell their products over a single selling season. The retailers place their regular orders before the season starts. In addition to this initial order, quick response (QR) provides a retailer with an additional replenishment opportunity after demand uncertainty is resolved. The manufacturer determines the unit price for QR replenishment. We characterize the retailers ordering, and the manufacturer's pricing decisions in equilibrium when none, only one, and both of the retailers have QR ability. We study how the profitability of the manufacturer, the retailers, and the channel depend on QR and competition. We find it may be optimal for the manufacturer to offer QR to only one of the ex ante identical retailers when demand variability is sufficiently, but not overly high. The manufacturer may also find it optimal to offer QR to both or none of the retailers, depending on demand variability. Finally, while QR ability is always attractive for a retailer when competition is ignored, we find QR may prove detrimental when its impact on competition is taken into account."
2374,"Manufacturer-Retailer Negotiations in the Presence of an Oligopolistic Input Market","Arya, Anil and Pfeiffer, Thomas","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","534-546","2012","MAY-JUN","Cost-Plus Contracts;Slotting Allowances;Supply Chain Negotiations","","When a manufacturer relies solely on its own inputs in making products, the focus of negotiations between the manufacturer and retailer is exclusively on profits in the output (retail) market. In such cases, absent retail competition concerns, standard two-part tariff negotiations set the per-unit wholesale price equal to marginal cost, and require fixed transfers from the retailer to the manufacturer. In this article, we recognize that manufacturers often rely on imperfectly competitive markets for at least some inputs. Incorporating this seemingly natural feature has profound implications for manufacturerretailer negotiations since it shifts their focus from being exclusively on output markets to one that balances strategic concerns in both input and output realms. The article's main result is that the added need to discipline input prices can lead the manufacturer and retailer to write contingent contracts that are cost-plus and prescribe lump-sum slotting allowances (i.e., fixed transfer from the manufacturer to the retailer)."
2375,"Sourcing from Multiple Suppliers for Price-Dependent Demands","Feng, Qi and Shi, Ruixia","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","547-563","2012","MAY-JUN","Procurement Policies;Dynamic Pricing;Supplier Diversification","","We analyze a model that integrates demand shaping via dynamic pricing and risk mitigation via supply diversification. The firm under consideration replenishes a certain product from a set of capacitated suppliers for a price-dependent demand in each period. Under deterministic capacities, we derive a multilevel base stock list price policy and establish the optimality of cost-based supplier selection, that is, ordering from a cheaper source before more expensive ones. With general random capacities, however, neither result holds. While it is optimal to price low for a high inventory level, the optimal order quantities are not monotone with respect to the inventory level. In general, a near reorder-point policy should be followed. Specifically, there is a reorder point for each supplier such that no order is issued to him when the inventory level is above this point and a positive order is placed almost everywhere when the inventory level is below this point. Under this policy, it may be profitable to order exclusively from the most expensive source. We characterize conditions under which a strict reorder-point policy and a cost-based supplier-selection criterion become optimal. Moreover, we quantify the benefit from dynamic pricing, as opposed to static pricing, and the benefit from multiple sourcing, as opposed to single sourcing. We show that these two strategies exhibit a substitutable relationship. Dynamic pricing is less effective under multiple sourcing than under single sourcing, and supplier diversification is less valuable with price adjustments than without. Under limited supply, dynamic pricing yields a robust, long-term profit improvement. The value of supply diversification, in contrast, mainly comes from added capacities and is most significant in the short run."
2376,"Optimal Inventory Control with Dual-Sourcing, Heterogeneous Ordering Costs and Order Size Constraints","Zhang, Wei and Hua, Zhongsheng and Benjaafar, Saif","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","564-575","2012","MAY-JUN","Inventory Systems;Optimal Policy;Dual-Sourcing;Stochastic Dynamic Programming;Quasi-Convexity","","We consider a dual-sourcing inventory system, where procuring from one supplier involves a high variable cost but negligible fixed cost whereas procuring from the other supplier involves a low variable cost but high fixed cost, as well as an order size constraint. We show that the problem can be reduced to an equivalent single-sourcing problem. However, the corresponding ordering cost is neither concave nor convex. Using the notion of quasi-convexity, we partially characterize the structure of the optimal policy and show that it can be specified by multiple thresholds which determine when to order from each supplier and how much. In contrast to previous research, which does not consider order size constraints, we show that it is optimal to simultaneously source from both suppliers when the beginning inventory level is sufficiently low. We also show that the decision to source from the low-cost supplier is not monotonic in the inventory level. Our results require that the variable costs satisfy a certain condition which guarantees quasi-convexity. However, extensive numerical results suggest that our policy is almost always optimal when the condition is not satisfied. We also show how the results can be extended to systems with multiple capacitated suppliers."
2377,"Ordering, Pricing, and Lead-Time Quotation Under Lead-Time and Demand Uncertainty","Wu, Zhengping and Kazaz, Burak and Webster, Scott and Yang, Kum-Khiong","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","576-589","2012","MAY-JUN","Newsvendor Problem;Pricing;Lead-Time Quotation;Inventory;Revenue Management","","In this article, we study the newsvendor problem with endogenous setting of price and quoted lead-time. This problem can be observed in situations where a firm orders semi-finished product prior to the selling season and customizes the product in response to customer orders during the selling season. The total demand during the selling season and the lead-time required for customization are uncertain. The demand for the product depends not only on the selling price but also on the quoted lead-time. To set the quoted lead-time, the firm has to carefully balance the benefit of increasing demand as the quoted lead-time is reduced against the cost of increased tardiness. Our model enables the firm to determine the optimal selling price, quoted lead-time, and order quantity simultaneously, and provides a new set of insights to managers."
2378,"A Choice-Based Dynamic Programming Approach for Setting Opaque Prices","Anderson, Chris K. and Xie, Xiaoqing","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","590-605","2012","MAY-JUN","Revenue Management;Dynamic Programming;Marketing;Pricing;Buyer Behavior","","Opaque pricing is a form of pricing where certain characteristics of the product or service are hidden from the consumer until after purchase. In essence, opaque selling transforms a differentiated good into a commodity. Opaque pricing has become popular in service pricing as it allows firms to sell their differentiated product at higher prices to regular brand loyal customers while simultaneously selling to non-brand loyal customers at discounted prices. We use a nested logit model in combination with logistic regression and dynamic programming to illustrate how a service firm can optimally set prices on an opaque sales channel. The choice model allows the characterization of consumer trade-offs when purchasing opaque products while the dynamic programming approach allows the characterization of the optimal pricing policy as a function of inventory and time remaining. We compare optimal prices and expected revenues when dynamic pricing is restricted to daily price changes. We provide an illustrative example using data from an opaque selling mechanism () and a Washington DC-based hotel."
2379,"NERJIT: Using Net Requirement Data in Kanban-Controlled Jumbled-Flow Shops","Ardalan, Ali and Diaz, Rafael","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","606-618","2012","MAY-JUN","Priority Rules;Jit;Simulation;Jumbled-Flow Shops;Sequencing","","The bold lines that have separated the application of specific production planning and control techniques to specific production systems are being blurred by continuous advances in production technologies and innovative operational procedures. Oral communication among dispatchers and production units has given way to electronic communication between production planners and these units by continuous progress in information technologies. Current production literature alludes to the idea that, collectively, these advances have paved the way for application of Just-In-Time (JIT) production concepts, which were originally developed for mass production systems, in intermittent production systems. But this literature does not actually consider the possibility. This article presents a modification to JIT procedures to make them more suitable for jumbled-flow shops. This article suggests providing real-time information about net-requirements for each product to each work center operator for setting production priorities at each work center. Simulation experiments conducted for this study show that using Net-Requirements in JIT (NERJIT) reduces customer wait time by 4560% while reducing inventory slightly. The analysis of work centers input and output stock-point inventories shows that using the information about net-requirements results in production of items that are in current demand. NERJIT results in smaller input stock-point inventory and availability of products with higher priority in the output stock-points of work centers."
2380,"Unpacking Team Familiarity: The Effects of Geographic Location and Hierarchical Role","Staats, Bradley R.","PRODUCTION AND OPERATIONS MANAGEMENT","21","3","619-635","2012","MAY-JUN","Distributed Teams;Knowledge Work;Software;Team Familiarity;Team Productivity","","Examination of team productivity finds that team familiarity, i.e., individuals' prior shared work experience, can positively impact the efficiency and quality of team output. Despite the attention given to team familiarity and its contingencies, prior work has focused on whether team members have worked together, not on which team members have worked together, and under what conditions. In this paper, I parse overall team familiarity to consider effects of geographic location and the hierarchical roles of team members. Using data on all software-development projects completed over 3 years at a large Indian firm in the global outsourced software services industry, I find that team familiarity gained when team members work together in the same location has a significantly more positive effect on team performance compared with team familiarity gained while members were collaborating in different locations. Additionally, I find that hierarchical team familiarity (a manager's experience with front-line team members) and horizontal team familiarity (front-line team members' experience gained with one another) have differential effects on project team performance. These findings provide insight into the relationship between team experience and team performance."
2381,"An Application of Master Schedule Smoothing and Planned Lead Time Control","Teo, Chee-Chong and Bhatnagar, Rohit and Graves, Stephen C.","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","211-223","2012","MAR-APR","Make-To-Order;Production Smoothing;Master Production Schedule;Planned Lead Times;Oil-Rig Building","","Make-to-order (MTO) manufacturers must ensure concurrent availability of all parts required for production, as any unavailability may cause a delay in completion time. A major challenge for MTO manufacturers operating under high demand variability is to produce customized parts in time to meet internal production schedules. We present a case study of a producer of MTO offshore oil rigs that highlights the key aspects of the problem. The producer was faced with an increase in both demand and demand variability. Consequently, it had to rely heavily on subcontracting to handle production requirements that were in excess of its capacity. We focused on the manufacture of customized steel panels, which represent the main sub-assemblies for building an oil rig. We considered two key tactical parameters: the planning window of the master production schedule and the planned lead time of each workstation. Under the constraint of a fixed internal delivery lead time, we determined the optimal planning parameters. This improvement effort reduced the subcontracting cost by implementing several actions: the creation of a master schedule for each sub-assembly family of the steel panels, the smoothing of the master schedule over its planning window, and the controlling of production at each workstation by its planned lead time. We report our experience in applying the analytical model, the managerial insights gained, and how the application benefits the oil-rig producer."
2382,"Optimal Production and Admission Policies in Make-to-Stock/Make-to-Order Manufacturing Systems","Iravani, Seyed M. R. and Liu, Tieming and Simchi-Levi, David","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","224-235","2012","MAR-APR","Production And Inventory Control;Admission Control;Inventory Rationing;Make-To-Stock And Make-To-Order","","In this article, we study optimal production and admission control policies in manufacturing systems that produce two types of products: one type consists of identical items that are produced to stock, while the other has varying features and is produced to order. The model is motivated by applications from various industries, in particular, the automobile industry, where a part supplier receives orders from both an original equipment manufacturer and the aftermarket. The product for the original equipment manufacturer is produced to stock, it has higher priority, and its demands are fully accepted. The aftermarket product is produced to order, and its demands can be either accepted or rejected. We characterize the optimal production and admission policies with a partial-linear structure, and using computational analysis, we provide insights into the benefits of the new policies. We also investigate the impact of production capacity, cost structure, and demand structure on system performance."
2383,"Lifecycle Pricing for Installed Base Management with Constrained Capacity and Remanufacturing","Robotis, Andreas and Bhattacharya, Shantanu and Van Wassenhove, Luk N.","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","236-252","2012","MAR-APR","Installed Base Management;Operational Leasing;Remanufacturing;Lifecycle Pricing;Product;Service Bundle","","Installed base management is the policy in which the manufacturer leases the product to consumers, and bundles repair and maintenance services along with the product. In this article, we investigate for the optimal leasing price and leasing duration decisions by a monopolist when the production and servicing capacity are constrained. The effect of diffusion of consumers in the installed base is considered, with the ownership of the product resting with the monopolist during the product lifecycle. The monopolist operating the installed base jointly optimizes the profits from leasing the product/service bundle along with maintenance revenues and remanufacturing savings. We formulate the manufacturer's problem as an optimal control problem and show that the optimal pricing strategy of the firm should be a skimming strategy. We also find that the effect of remanufacturing savings on the pricing decision and the length of the leasing duration changes significantly depending on the duration of the product's lifecycle. If the product lifecycle is long and remanufacturing savings are low, the firm should offer a shorter leasing duration, whereas if the remanufacturing savings are high, the firm should optimally offer a higher leasing duration. In contrast, if the time duration of the product lifecycle is low and remanufacturing savings are low, the firm prefers to offer a shorter leasing duration, whereas if the remanufacturing savings are high, the firm should optimally have a longer leasing duration. The article also shows that if the production capacity is small, the manufacturer increases the leasing duration. If the production capacity is very small, the manufacturer sets the leasing duration to be equal to the product lifecycle and does not use remanufacturing."
2384,"Assortment Planning for Vertically Differentiated Products","Pan, Xiajun Amy and Honhon, Dorothee","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","253-275","2012","MAR-APR","Assortment Planning;Vertical Differentiation;Quality;Pricing","","We consider the problem of a retailer managing a category of vertically differentiated products. The retailer has to pay a fixed cost for each product included in the assortment and a variable cost per product sold. Quality levels, fixed, and variable costs are exogenously determined. Customers differ in their valuation of quality and choose the product (if any) that maximizes their utility. First, we consider a setting in which the selling prices are also fixed. We find that the optimal set of products to offer depends on the distribution of customer valuations and might include dominated products, that is, products which are less attractive than at least one other product, on every possible dimension. We develop an efficient algorithm to identify an optimal assortment. Second, we consider a setting in which the retailer also determines the selling prices. We show that in this case the optimal assortment does not include any dominated product and does not vary with the distribution of customer valuations when there is no fixed cost. We develop several efficient algorithms to identify an optimal assortment and optimally price the products. We also test the applicability of our methods with realistic data for two product categories."
2385,"Impact of Storage Assignment Decisions on a Bucket Brigade Order Picking Line","Webster, Scott and Ruben, Robert A. and Yang, Kum-Khiong","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","276-290","2012","MAR-APR","Warehouse Management;Storage Assignment;Order Picking;Bucket Brigade","","Bucket brigade order picking is a method for retrieving orders from a storage rack where workers follow a fixed sequence and dynamically adjust to variability in work content along the rack. The method is simple and has been shown to provide superior performance in many applications. In this article, we analyze how the location in which products are stored in the rack affects throughput. We identify conditions where storage decisions have a large impact on throughput (e.g., a 20% increase in productivity) and conditions where the impact is minimal. Conditions associated with high impact are high variation in worker skill, high variation in SKU volume, and a moderate level of walking-to-picking work content per pick list."
2386,"Inventory Policy with Parametric Demand: Operational Statistics, Linear Correction, and Regression","Ramamurthy, Vivek and Shanthikumar, J. George and Shen, Zuo-Jun Max","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","291-308","2012","MAR-APR","Newsvendor Model;Model Uncertainty;Demand Ambiguity;Operational Statistics","","In this paper, we consider data-driven approaches to the problem of inventory control. We first consider the approach of operational statistics and review related results which enable us to maximize a priori expected profit uniformly over all parameter values, when the demand distribution is known up to the location and scale parameters. For the case of the unknown shape parameter, we first suggest a heuristic approach based on operational statistics to obtain improved ordering policies and illustrate the same for the case of a Pareto demand distribution. In more general cases where the heuristic is not applicable, we suggest linear correction and support vector regression approaches to better estimate ordering policies, and illustrate these using a Gamma demand distribution. In certain cases, our proposed approaches are found to yield significant improvements."
2387,"On Optimal Expediting Policy for Supply Systems with Uncertain Lead-Times","Kouvelis, Panos and Tang, Sammi Y.","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","309-330","2012","MAR-APR","Supply Uncertainty;Random Lead-Time;Lead-Time Information;Expediting;Safety Lead-Time","","We examine the role of expediting in dealing with lead-time uncertainties associated with global supply chains of functional products (high volume, low demand uncertainty goods). In our developed stylized model, a retailer sources from a supplier with uncertain lead-time to meet his stable and known demand, and the supply lead-time is composed of two random duration stages. At the completion time of the first stage, the retailer has the option to expedite a portion of the replenishment order via an alternative faster supply mode. We characterize the optimal expediting policy in terms of if and how much of the order to expedite and explore comparative statics on the optimal policy to better understand the effects of changes in the cost parameters and lead-time properties. We also study how the expediting option affects the retailer's decisions on the replenishment order (time and size of order placement). We observe that with the expediting option the retailer places larger orders closer to the start of the selling season, thus having this option serve as a substitute for the safety lead-time and allowing him to take increased advantages of economies of scale. Finally we extend the basic model by looking at correlated lead-time stages and more than two random lead-time stages."
2388,"Price and Service Competition in an Outsourced Supply Chain","Jin, Yue and Ryan, Jennifer K.","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","331-344","2012","MAR-APR","Single-Sourcing;Multisourcing;Competition;Pricing;Coordination","","We consider a buyer who outsources the manufacturing of a product to multiple symmetric make-to-stock suppliers who compete on price and service (fill rate). The buyer allocates demand to the suppliers using a score function with an exponential form, which specifies the relative importance of price vs. service, in order to minimize his costs, while the suppliers choose their prices and fill rates to maximize their profits. For the case of dual-sourcing, we characterize the optimal parameter of the exponential score function, considering the impact of the buyer's decisions on the suppliers, and considering how the suppliers compete against each other to earn a portion of the buyer's demand. We prove the existence of a unique equilibrium and characterize the equilibrium behavior of the system. We then consider a general number of suppliers and show that the equilibrium prices and fill rates, and the buyer's cost, are increasing in the number of suppliers. We compare these results to a model of single-sourcing, in which the buyer is the Stackelberg leader and extracts all profits from the supplier. We find that the buyer always prefers single-sourcing to multisourcing. Finally, we study a centralized system and use the results to develop a coordinating contract for the decentralized system."
2389,"Contracting and Coordination under Asymmetric Production Cost Information","Cakanyildirim, Metin and Feng, Qi and Gan, Xianghua and Sethi, Suresh P.","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","345-360","2012","MAR-APR","Adverse Selection;Type-Dependent Reservation Profit;Contracting;Supply Chain Efficiency;Demand Uncertainty","","We analyze a supply chain consisting of a supplier and a retailer. The supplier's unit production cost, which characterizes his type, is only privately known to him. When trading with the retailer, the supplier demands a reservation profit that depends on his unit production cost. We model this problem as a game of adverse selection. In this model, the retailer offers a menu of contracts, each of which consists of two parameters: the ordering quantity and the supplier's share of the channel profit. We show that the optimal contract depends critically on a surrogate measurethe ratio of the types reservation profit differential to their production cost differential. An important implication from our analysis is that information asymmetry alone does not necessarily induce loss in channel efficiency. The optimal contract can coordinate the supply chain as long as the low-cost supplier's cost efficiency is neither much overvalued nor much undervalued in the outside market. We further discuss the retailer's preference of the supplier's type under different market conditions, as well as evaluate the effects of the supplier's reservation profit, the retail price, and the demand uncertainty on the optimal contract."
2390,"Combined Pricing and Portfolio Option Procurement","Fu, Qi and Zhou, Sean X. and Chao, Xiuli and Lee, Chung-Yee","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","361-377","2012","MAR-APR","Dynamic Pricing;Portfolio Procurement;Option Contracts;Optimal Policies","","In this paper, we study a single-product periodic-review inventory system that faces random and price-dependent demand. The firm can purchase the product either from option contracts or from the spot market. Different option contracts are offered by a set of suppliers with a two-part fee structure: a unit reservation cost and a unit exercising cost. The spot market price is random and its realization may affect the subsequent option contract prices. The firm decides the reservation quantity from each supplier and the product selling price at the beginning of each period and the number of options to exercise (inventory replenishment) at the end of the period to maximize the total expected profit over its planning horizon. We show that the optimal inventory replenishment policy is order-up-to type with a sequence of decreasing thresholds. We also investigate the optimal option-reservation policy and the optimal pricing strategy. The optimal reservation quantities and selling price are shown to be both decreasing in the starting inventory level when demand function is additive. Building upon the analytical results, we conduct a numerical study to unveil additional managerial insights. Among other things, we quantify the values of the option contracts and dynamic pricing to the firm and show that they are more significant when the market demand becomes more volatile."
2391,"Multiple In-Cycle Transshipments with Positive Delivery Times","Comez, Nagihan and Stecke, Kathryn E. and Cakanyildirim, Metin","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","378-395","2012","MAR-APR","Multiple In-Cycle Transshipments;Positive Transshipment And Replenishment Times;Hold-Back Levels;Centralized System","","We study a centralized inventory sharing system of two retailers that are replenished periodically. Between two replenishments, a unit can be transshipped to a stocked-out retailer from the other. It arrives a transshipment time later, during which the stocked-out retailer incurs backorder cost. Without transshipment, backorder cost is incurred until the next replenishment. Since the transshipment time is shorter than the time between two replenishments, transshipments can reduce the backorder cost at the stocked-out retailer and the holding costs at the other retailer. The system is directed by a centralized inventory manager, who minimizes the long-run average cost consisting of replenishment, holding, backorder, and transshipment costs. The transshipment policy is characterized by hold-back inventory levels, which are nonincreasing in the remaining time until the next replenishment. The transshipment policy differs from those in the literature because we allow for multiple transshipments between replenishments, positive transshipment times, and backorder costs. We also discuss the challenges associated with positive replenishment time and develop upper and lower bounds of average cost in this case. Bounds are numerically shown to have an average gap of 1.1%. A heuristic solution is based on the upper bound and differs from the optimal cost by at most this gap."
2392,"Reassessing Tradeoffs Inherent to Simultaneous Maintenance and Production Planning","Batun, Sakine and Maillart, Lisa M.","PRODUCTION AND OPERATIONS MANAGEMENT","21","2","396-403","2012","MAR-APR","Production Scheduling;Equipment Maintenance;Markov Decision Processes;First-Come-First-Serve","","Previous work has considered the simultaneous (as opposed to sequential) optimization of a maintenance policy and a production policy in a multi-product setting with random yield and product mix constraints. One of the sequential approaches to which the simultaneous approach is compared is a so-called first-come-first-served (FCFS) approach, i.e., an approach that generates randomized production policies that do not depend on the deterioration state of the machine. However, the model formulation for this approach does not generate policies consistent with this FCFS notion. Therefore, we present a revised FCFS model and analyze its performance using an existing experimental design. The results suggest that previous work overestimates the degree to which a FCFS approach is suboptimal, and underestimates the value of simultaneously optimizing the maintenance and production decisions. Lastly, we conduct additional experiments which suggest that the joint impact of using both simultaneous optimization and a deterioration dependent production policy is quite significant."
2393,"Researchers' Perspectives on Supply Chain Risk Management","Sodhi, ManMohan S. and Son, Byung-Gak and Tang, Christopher S.","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","1-13","2012","JAN-FEB","Supply Chain Risk Management;Researcher Survey;Literature Review;Research Agenda","","Supply chain risk management (SCRM) is a nascent area emerging from a growing appreciation for supply chain risk by practitioners and by researchers. However, there is diverse perception of research in supply chain risk because these researchers have approached this area from different domains. This paper presents our study of this diversity from the perspectives of operations and supply chain management scholars: First, we reviewed the researchers' output, i.e., the recent research literature. Next, we surveyed two focus groups (members of Supply Chain Thought Leaders and International SCRM groups) with open-ended questions. Finally, we surveyed operations and supply chain management researchers during the 2009 INFORMS meeting in San Diego. Our findings characterize the diversity in terms of three gaps: a definition gap in how researchers define SCRM, a process gap in terms of inadequate coverage of response to risk incidents, and a methodology gap in terms of inadequate use of empirical methods. We also list ways to close these gaps as suggested by the researchers."
2394,"Pricing Decisions During Inter-Generational Product Transition","Li, Hongmin and Graves, Stephen C.","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","14-28","2012","JAN-FEB","Dynamic Pricing;Product Transition;New Product Introduction;Multinomial Logit Model","","How should companies price products during an inter-generational transition? High uncertainty in a new product introduction often leads to extreme cases of demand and supply mismatches. Pricing is an effective tool to either prevent or alleviate these problems. We study the optimal pricing decisions in the context of a product transition in which a new-generation product replaces an old one. We formulate the dynamic pricing problem and derive the optimal prices for both the old and new products. Our analysis sheds light on the pattern of the optimal prices for the two products during the transition and on how product replacement, along with several other dynamics including substitution, external competition, scarcity, and inventory, affect the optimal prices. We also determine the optimal initial inventory for each product and discuss a heuristic method."
2395,"How Provider Selection and Management Contribute to Successful Innovation Outsourcing: An Empirical Study at Siemens","Cui, Zhijian and Loch, Christoph and Grossmann, Bernd and He, Ru","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","29-48","2012","JAN-FEB","Innovation Outsourcing;Collaborative R&D;Categorical Data;Field Research;Contingency Analysis","","It is becoming increasingly common to involve external technology providers in developing new technologies and new products. Two important phases involved in working with technology vendors are vendor selection and vendor management. Because for both steps theory development of key decision guidelines is still immature, we use detailed case studies of 31 innovation outsourcing projects at Siemens to develop grounded theory on provider selection criteria and on project management success drivers. A selection criterion often associated with successful outsourcing is the provider's track record or previous experience. Our cases suggest that there is no standard track record for success but that a match between the client firm's outsourcing motivation and the provider's strengths appears to be a necessary condition for a successful outsourcing collaboration. As to the second phasemanaging the vendorwe identify a number of operational project success drivers. There seems to be no universal checklist, but the most important drivers seem to be contingent on the type of vendor chosen and on the maturity of the technology. We compare five provider typesuniversities, competitors, customers, start-up companies, and component suppliersand find that some success drivers are common to all providers, while others are relevant only for certain types of provider. Moreover, drivers in the case of a mature technology are more focused on successful transfer to manufacturing than on development itself. Our findings offer guidelines for innovation managers on how to select innovation providers and how to manage them during the project."
2396,"Measuring Seat Value in Stadiums and Theaters","Veeraraghavan, Senthil and Vaidyanathan, Ramnath","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","49-68","2012","JAN-FEB","Seat Value;Empirical Research;Revenue Management Applications;Customer Behavior;Ordinal Logit Models","","We study how the seat value perceived by consumers attending an event in a theater/stadium depends on the location of their seat relative to the stage/field. We develop a measure of seat value, called the Seat Value Index, and relate it to seat location and consumer characteristics. We implement our analysis on a proprietary data set that a professional baseball franchise in Japan collected from its customers, and provide recommendations. For instance, we find that customers seated in symmetric seats on left and right fields might derive very different valuations from the seats. We also find that the more frequent visitors to the stadium report extreme seat value less often when compared with first-time visitors. Our findings and insights remain robust to the effects of price and game-related factors. Thus, our research quantifies the significant influence of seat location on the ex-post seat value perceived by customers. Utilizing the heterogeneity in seat values at different seat locations, we provide segment-specific pricing recommendations based on a service-level objective that would limit the fraction of customers experiencing low seat value to a desired threshold."
2397,"Revenue Management with End-of-Period Discounts in the Presence of Customer Learning","Ovchinnikov, Anton and Milner, Joseph M.","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","69-84","2012","JAN-FEB","Revenue Management;Customer Learning;Smoothing;Self-Regulating;Wait-Or-Buy;Strategic Consumers","","Consider a firm that sells identical products over a series of selling periods (e.g., weekly all-inclusive vacations at the same resort). To stimulate demand and enhance revenue, in some periods, the firm may choose to offer a part of its available inventory at a discount. As customers learn to expect such discounts, a fraction may wait rather than purchase at a regular price. A problem the firm faces is how to incorporate this waiting and learning into its revenue management decisions. To address this problem we summarize two types of learning behaviors and propose a general model that allows for both stochastic consumer demand and stochastic waiting. For the case with two customer classes, we develop a novel solution approach to the resulting dynamic program. We then examine two simplified models, where either the demand or the waiting behavior are deterministic, and present the solution in a closed form. We extend the model to incorporate three customer classes and discuss the effects of overselling the capacity and bumping customers. Through numerical simulations we study the value of offering end-of-period deals optimally and analyze how this value changes under different consumer behavior and demand scenarios."
2398,"Sharing Responsibility for Product Recovery Across the Supply Chain","Jacobs, Brian W. and Subramanian, Ravi","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","85-100","2012","JAN-FEB","Extended Producer Responsibility;Collection;Recycling;Supply Chain Coordination;Social Welfare","","Extended producer responsibility (EPR) programs typically hold the producera single actor defined by the regulatorresponsible for the environmental impacts of end-of-life products. This is despite emphasis on the need to involve all actors in the supply chain in order to best achieve the aims of EPR. In this paper, we examine the economic and environmental implications of product recovery mandates and shared responsibility within a supply chain. We use a two-echelon model consisting of a supplier and a manufacturer to determine the impacts of product collection and recycling mandates on the incentive to recycle and resulting profits in the integrated and decentralized supply chains. For the decentralized supply chain, we demonstrate how the sharing of responsibility for product recovery between the echelons can improve total supply chain profit and suggest a contract menu that can Pareto-improve profits. To examine both the economic and environmental performance associated with responsibility sharing, we propose a social welfare construct that includes supply chain profit, consumer surplus, and the externalities associated with virgin material extraction, product consumption, and disposal of nonrecycled products. Using a numerical example, we discuss how responsibility sharing may or may not improve social welfare. The results of this paper are of value to firms either anticipating or subject to product recovery legislation, and to social planners that attempt to balance economic and environmental impacts and ensure fairness of such legislation."
2399,"An Analysis of the Eco-Efficiency of Remanufactured Personal Computers and Mobile Phones","Quariguasi-Frota-Neto, Joao and Bloemhof, Jacqueline","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","101-114","2012","JAN-FEB","Sustainability;Eco-Efficiency;Remanufacturing;Closed-Loop Supply Chains;Sustainable Development","","Remanufacturing, long perceived as an environmentally friendly initiative, is supported by a number of governments. Yet, the assumption that remanufacturing is desirable to society has never been systematically investigated. In this paper, we examine the effectiveness and eco-efficiency of remanufacturing in the personal computer and mobile phone industries. We investigate whether remanufacturing substantially reduces the environmental impact, as measured by cumulative energy demand (CED), generated over the life cycles (LCs) of these products, and the size of any reduction. We also examine the relative eco-efficiency of remanufacturing compared with virgin manufacturing for these two products, where eco-efficiency includes both willingness-to-pay (WTP) for the products as well as the energy consumed in producing the products. Our main findings are the following. One, remanufacturing is an effective way to reduce the total energy consumed during the LCs of personal computers and mobile phones, with one notable exception, when the life spans of remanufactured products are substantially shorter than the life spans of their new counterparts. Two, a remanufactured personal computer or mobile phone is not always more eco-efficient than a corresponding new product. Three, the WTP for remanufactured personal computers and mobile phones, and consequently, their eco-efficiencies, are a function of the prices of the correspondent new products at launch and years elapsed between launch and remanufacturing. Four, remanufactured units are sold at a discount relative to the price of new personal computers and mobile phones. Five, on the whole, the market for remanufactured mobile phones is more eco-efficient than the market for new mobile phones. Six, the market for remanufactured computers is more eco-efficient than the market for new computers. Lastly, because the group of remanufactured products is heterogeneous, not all remanufactured units are more eco-efficient than the average new computer and mobile phone. We conclude with a discussion of the impact of our findings on European WEEE and WEEE-like legislation."
2400,"Container Scheduling: Complexity and Algorithms","Choi, Byung-Cheon and Lee, Kangbok and Leung, Joseph Y. -T. and Pinedo, Michael L. and Briskorn, Dirk","PRODUCTION AND OPERATIONS MANAGEMENT","21","1","115-128","2012","JAN-FEB","Liner Shipping;Container Allocation;On-Time Delivery;Scheduling Rules;Computational Complexity","","We consider the transport of containers through a fleet of ships. Each ship has a capacity constraint limiting the total number of containers it can carry and each ship visits a given set of ports following a predetermined route. Each container has a release date at its origination port, and a due date at its destination port. A container has a size 1 or size 2; size 1 represents a 1 TEU (20-foot equivalent unit) and size 2 represents 2 TEUs. The delivery time of a container is defined as the time when the ship that carries the container arrives at its destination port. We consider the problem of minimizing the maximum tardiness over all containers. We consider three scenarios with regard to the routes of the ships, namely, the ships having (i) identical, (ii) nested, and (iii) arbitrary routes. For each scenario, we consider different settings for origination ports, release dates, sizes of containers, and number of ports; we determine the computational complexity of various cases. We also provide a simple heuristic for some cases, with its worst case analysis. Finally, we discuss the relationship of our problems with other scheduling problems that are known to be open."
2401,"Showrooms and Information Provision in Omni-channel Retail","Bell, David and Gallino, Santiago and Moreno, Antonio","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","360-362","2015","MAR","","","1. Introduction Online and offline retail channels are increasingly intertwined. Traditional players are ramping up their Internet presence and online-first retailers are opening stores and showrooms,1 and developing offline partnerships. This intermingling reflects the fact that while online retailing is by far the fastest growing retail sector in the United States (according to Forrester Research the market will grow from $231b in 2013 to $370b in 2017 on CAGR of 10%),2 offline retailing still anchors the sector. Retailers of all types and in all locations, therefore, increasingly interact with consumers through multiple touch points (Brynjolfsson et al. 2013, P. 23). In the global consumer economy omni-channel retailers and buying experiences are now the norm. Hence, for retailers, understanding how omnichannel works is imperative and our research makes a contribution in this regard. First, we recognize that typical offline and online channels differ markedly in their ability to deliver information and product fulfillment, the two most critical channel functions (see, e.g., Coughlan et al. 2006, Pp. 910). An omni-channel retailer must respond to, and cater to, consumer heterogeneity in preferences for whether information is delivered in-store or online, or whether product is available in-store, or shipped. With regard to information in particular, some customers prefer the ease of shopping that comes from an online experience, whereas others prefer to physically sample products before buying them. Second, traditional online and offline channels also have very different cost structures depending on how orders are fulfilled. Online channels benefit from inventory pooling and lower inventory costs. On the other hand, decentralized offline channels, for example, traditional brick and mortar stores, have to forecast demand for each product and store. This is much harder to do on a per store basis than it is under the pooling that happens with an online channel. As a result, offline fulfillment usually experiences higher demand-supply mismatches and additional inventory costs. Third, and conversely, academics (e.g., Lal and Sarvary 1999) have long realized that when it comes to delivering visceral product information, that is, information about so-called non-digital attributes, offline channels have a definite edge. Practitioners and analysts have made the same observation. Leading industry commentator GigaOm.com, for example, had this to say about Warby Parker, the fashion eyewear retailer and research partner for our study: That (home try-on) has helped Warby Parker overcome one of the biggest hurdles (italics added) for online fashion brands, getting people to feel comfortable about their online purchase.3 Numerous other online-first retailers from Ayr.com to Zappos.com recognize that uncertainty about non-digital product attributes is a barrier to purchase for large segments of customers, and therefore employ free two-way shipping, pop-up stores, and related methods to combat it. The specific domain of our research is a new and increasingly common retail innovation favored by leading online-first retailers, the showroom.4 As noted above, these are offline locations where customers can physically examine products before placing an order, but orders are placed on a tablet or Internet-connected device in the store, fulfillment is done via shipping, that is, showrooms do not have products available for immediate in-store purchase. Thus, showrooms simply allow customers to obtain information prior to purchase by physically sampling products. This hybrid experience delivers information offline in a showroom yet maintains the inventory fulfillment efficiency of the online channel. Note that in markets where they are opened, the introduction of a showroom channel represents a shock in the amount and quality of product information that is available to the customers, holding fulfillment options constant. We study the market impact of this shock on several factors, including on overall demand, Web sales, and various elements of operational efficiency, for example, product returns. 2. Methodology To conduct this research on the impact of information provision on market behaviors, we partnered with Warby Parker, a leading US online-first retailer of fashion eyewear. Since opening for business in February 2010, Warby Parker progressively introduced showrooms in different locations throughout the United States. Management provided us with detailed data on customer behavior and we augmented these data with a rich set of data on ZIP-level geographic factors obtained from the US Census and www.esri. org. The institutional setting has important features that allow us to properly isolate the effect of informational differences on customer channel migration. First, eyewear is a category with significant non-digital or fit and feel attributes such that direct online purchasing is difficult for some customers.5 Second, Warby Parker began as an online-only retailer that also offered consumers a unique product sampling program nationwide called Home Try On (HTO) in which consumers could have five pairs of glasses (frames only and without lenses) delivered to them free of charge for 5 days. Thus, we are able to identify changes in customer behavior when offline showrooms are first introduced into locations where there was already online and sampling coverage. Third, and crucially for our study, the offline locations opened (and closed) by Warby Parker throughout the United States are inventory only showrooms. These showrooms are existing offline stores operated by other independent brands selling apparel and accessories. Customers entering these showrooms can physically inspect the entire Warby Parker product line and make a purchase in-store via the website, but cannot take their purchases with them. Fulfillment, conditional on a purchase, that is, shipment to the location of the customers choosing, is identical irrespective of how product information is obtained. That is, whether the purchase is made directly at the website, at the website subsequent to an HTO experience, or at the website subsequent to product inspection in a showroom, fulfillment is always via delivery. The fact that Warby Parker opened and closed showrooms in different markets throughout the United States during the period of analysis allows us to use quasi-experimental methods to assess the effect of these showrooms in the observed market outcomes. We use a combination of a difference-in-differences strategy with a propensity score method adjustment. In principle, since only customers near a showroom, that is, those within its trading area, can be influenced by the presence of the showroom, we can compare the difference in sales, returns, and other factors between ZIP codes within/beyond the area of influence of the showroom, before and after the opening of the showroom. Now, because management does not open showrooms randomly we also need to control for the endogenous nature of the treatment, that is, the opening of a showroom. We do this using a propensity score adjustment (based on fifty different ZIP code level factors) so that we compare treatment and control locations are made essentially identical in their observable characteristics, except for the presence of a showroom. 3. Results We make two new substantive contributions to the omni-channel literature. First, we show that locations contained within the trading area of a showroom: (1) see an increase in overall demand, and (2) show evidence of spillovers from one channel to another. These estimated effects are statistically and economically significant, and the overall positive demand impact alone is approximately 10%. Interestingly, the positive demand impact is not solely attributable to sales through the (new) offline channel, that is, the showroom itself. In these locations direct sales through the WarbyParker.com website increase by up to 7.0% as well. A physical offline presence seems to confer awareness, branding, and credibility benefits that deliver incremental sales through the existing online channel. Note that these benefits accrue from the provision of information alone, as fulfillment is identical in all three channels (Web, sampling, showroom). Next, we find that sales through the sampling channel decline and our second contribution is to demonstrate that the underlying mechanism is channel migration by customers. We conceptualize a shopping process in which there is a match between the information delivered by each channel (Web, sampling, showroom) and the information required by customers who vary in their tolerance for uncertainty. We predict that customers who have the least uncertainty tolerance are more likely to migrate to the offline channel when it is available. As a consequence, the pool of customers remaining in the sampling and online channels are, on average, better matched to those channels. This leads to higher conversion from sampling, lower rates of repeated sampling, and fewer returns from sales made in the online channel. Our empirical results are consistent with the conceptualization and predictions. Thus, our study, to the best of our knowledge, is the first to identify and measure the critical impact of informational differences across on customer migration and operational costs in an omni-channel setting. We also demonstrate that the positive economic impact of showrooms can be substantial. In summary, when an online-first retailer opens showrooms, these channels are much more than a mechanism for just expanding awareness and total demand. They allow customers to sort into their preferred channel on the basis of their information needs and, as a consequence firms can greatly reduce the operational cost-to-serve customers through the other channels."
2402,"Managing Risks in Federal Government Information Technology Projects: Does Process Maturity Matter?","Mishra, Anant and Das, Sidhartha and Murray, James","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","365-368","2015","MAR","","","1. Introduction As the Obama administration steps up oversight of high-risk IT projects, contracting organizations must take greater responsibility to provide a level of confidence in the services they offer. That is where one of the latest offerings from the Software Engineering Institute at Carnegie Mellon University can help. (Sacks 2010). A number of US federal government information technology (IT) initiatives (e.g., implementation of the Health Insurance Marketplace or Obamacare, development of navigation systems in missiles and unmanned vehicles) are frequently organized in the form of IT projects (Kundra 2010). The Office of Management and Budget (OMB), which tracks the progress of all federal IT projects indicates that such projects face significant schedule and cost overruns. Nearly 25% of federal IT projects with a cumulative budget exceeding $10 billion and spread over 28 government agencies are facing moderate to severe problems in meeting their schedule and budgetary targets (Source: www.itdashboard.gov). Additionally, the US Government Accountability Office (GAO) reports that nearly 72% of federal IT projects, with a total budget of $27 billion, are poorly planned and face significant schedule and cost overruns (US GAO Report 2010). Despite the evidence of schedule and budget overruns in federal IT projects, the challenges associated with the management of such projects, and more generally, of IT projects in the public sector, have received limited attention in both practice and research. Public sector projects differ from private sector projects in a number of ways (Boyne 2002). First, federal IT projects are primarily funded with taxpayers money and are aimed at maximizing public utility, instead of maximizing profits, as in private sector IT projects. Hence they face greater scrutiny from the media, the US Congress, and any number of watchdog organizations. Second, federal IT projects face challenges and risks due to increased complexity, technological uncertainty, significant resource requirements, governmental rules and regulations, and the frequent involvement of multiple stakeholders with disparate and sometimes conflicting goals. To date, much of our understanding of IT project management has been drawn from studies that have focused on the private sector (McKinsey 2012). Given the notable differences between federal and private sector IT projects and growing calls in political and media circles for the efficient utilization of tax payer contributions (Fortune 2011, P. 56), an empirical investigation of challenges in federal IT projects presents a fruitful area of research with significant implications for practitioners. 2. Objectives of the Study Our study has two major objectives. First, we identify and conceptualize a set of salient risks in federal IT projects using a lifecycle framework. As Figure 2 indicates, we focus on the planning and execution processes within an IT project and identify three distinct types of risknamely, complexity risk and contracting risk that arise in the planning process, and execution risk that arises in the execution process. We define each of the three risks below.  Complexity risk refers to the risks arising from inherent technological uncertainties, and the interdependent nature of tasks associated with a project during the planning process. Caro and Tang: POMS Applied Research Challenge 2014 Awards Production and Operations Management 24(3), pp. 359368,  2014 Production and Operations Management Society 365  Contracting risk may arise from various aspects of the contracting relationship, which are likely to be collectively reflected in the number of distinct contractors and proportion of contracted work in a project.  Execution risk refers to disruptions in the progress of a project due to unforeseen situations or uncertainties during its execution. As per industry standards and federal legislation (i.e., the Clinger-Cohen Act of 1996), the performance of federal IT projects is reported to the OMB using earned value management (EVM) metrics for schedule and cost performance. EVM is a project planning and control approach which compares actual accomplishment of scheduled work and associated cost against an integrated schedule and budget plan on a periodic basis. In this study, we examine the performance impact of each of three risks using a composite earned value metric, that is, schedule-cost performance index (SCPI). Second, prior research has emphasized the need for mature processes to manage IT projects; which leads to improvements in the control and predictability of project outcomes. In the context of federal IT projects, the vendors capability to reliably deliver missioncritical IT solutions (i.e., the vendors use of mature processes within a project) is assessed using the Capability Maturity Model Integration (CMMI) framework developed by the Software Engineering Institute (SEI). The framework consists of five levels (levels 1  5) which assess the evolution of a firms processes from immature and informal to mature and formal, and define the related infrastructure necessary to support these processes at an organizational level (CMMI for Development 2010). As a signal of process excellence, CMMI level 3 represents a significant step toward process maturity, with vendor certification at this level being frequently used as a key qualifying criterion by the federal government for awarding project contracts. Given the considerable commitment of time and organizational resources required to obtain CMMI certification and the performance challenges associated with federal IT projects, we examine whether higher levels of process maturitythat is, level 3 and higherplay a significant role in mitigating the effects of risk on performance in federal IT projects. 3. Data, Analysis, and Results The projects for this study are drawn from a proprietary database of technology projects from Lockheed Martin, a Fortune 100 global technology firm that specializes in the development of large aerospace, defense, and security systems for the federal government (i.e., the client organization). Time-series panel data are collected across 519 quarterly time periods from 82 federal IT projects that were completed during the period 2002-2012. The firm uses a rigorous two-step procedure for collecting data on federal IT projects. In the first step, tactical and project specific details are collected on a monthly basis as part of a monthly review process. The review process is typically conducted by a panel consisting of project managers, deputy project managers, and vice presidents in the IT domain within the firm. In the second step, the monthly data are aggregated to form quarterly status reports that are used for strategic review and evaluation of project performance. In addition, these reports are used to track data for internal auditing purposes and to create lessons learned. To ensure accuracy in data collection, the data are triangulated through multiple sources (e.g., interviews with project managers, project documents, etc.). Given the time-series nature of the data, we use the generalized least squares (GLS) regression method that corrects for both panel-specific autocorrelation and heteroskedasticity in the analysis. In addition, we control for a number of factors pertaining to project characteristics (e.g., project budget, project size, project priority) in our analysis. The results provide empirical support for our arguments that each of the three types of riskscomplexity, contracting, and execution risksreduce a projects ability to meet its cost and schedule targets. More importantly, our results highlight the effect of higher CMMI levels in attenuating the negative effects of project risks on performance in federal IT projects. In addition, the attenuating effect of CMMI on the risk-performance relationship is stronger at high risk levels; at low risk levels, projects with higher maturity levels (e.g., levels 4 and 5) exhibit inferior performance on schedule and cost metrics compared to projects with lower (e.g., level 3) maturity levels. To demonstrate the economic impact of increasing process maturity levels in federal IT projects, we conduct post-hoc analysis to examine the magnitude of savings (and overruns) in project costs across different levels of CMMI and project risks. This analysis is conducted in three steps. In the first step, we estimate the dependent variable (SCPI) at low (-2 SD), average, and high levels (+2 SD) of project risks across different process maturity levels, holding all control variable values at their means. Next, based on a median project budget of $35 million in the sample, we determine the estimated cost of completion (EAC) using the formula: EAC = (ProjectBudget/SCPI) 9 100. Finally, we examine the differences in EAC values across different maturity and risk levels, to determine potential savings in project budgets. The results, shown in Table 1 below, highlight the potential cost savings that may result for executing projects at higher maturity levels when project risk levels are high. Specifically, given a project budget of $35 million (based on the median project budget value in our sample), executing the project at CMMI 4 or CMMI 5 when project risks are high is associated with potential savings of $11.87 million and $8.56 million, respectively, compared to executing the project at CMMI 3. In contrast, when project risk levels are low, executing the project at CMMI 4 or CMMI 5 is associated with potential cost overruns amounting to $8.27 million and $7.26 million, respectively, compared to executing the project at CMMI 3. 4. Contributions Findings from our study make the following important contributions to the extant literature. First, our study focuses on an important and largely understudied area of research in the OM literaturethe management of public sector operations (Verma et al. 2005), and particularly, the context of federal IT projects. The second contribution of our study arises from identifying and positioning IT project risks in the context of a lifecycle framework. The importance of identifying and planning for risks has been widely discussed in the extant project management literature. Our study represents a concerted attempt to conceptualize key risks in an IT project by using the project lifecycle framework, which allows us to identify and map risks by processes associated with specific project phases. The third contribution lies in developing a nuanced understanding of the mode by which process maturity influences project performance. This is important to both theory and practice given the significant investment of resources and time that is required to acquire CMMI certification. Toward this end, our results provide the following insights to managers of federal IT projects - while the implementation of CMMI 4 relative to CMMI 3 attenuates the negative performance effects of risks in the planning process only; the implementation of CMMI 5 relative to CMMI 3 level attenuates the negative performance effects of risks in both planning and execution processes. The fourth contribution of our study is based on our results that the intrinsic benefits of CMMI implementation in federal IT projects become particularly salient at high levels of project risk; at low risk levels, the benefits of higher maturity levels (i.e., CMMI 4 and CMMI 5) on project schedule and cost metrics are inferior compared to projects with CMMI 3 maturity level. We surmise that at low levels of project risk, the improvements in project performance accruing from increased levels of process maturity, may not fully compensate the costs of implementing higher CMMI levels, thereby diminishing overall project performance. The studys final contribution arises from our use of an integrated measure of schedule-cost performance (SCPI) in the context of earned value management (EVM). While vendors working on federal IT projects are mandated to use EVM for tracking and reporting project progress as per industry standards and federal legislations, the use of EVM has also grown significantly in the private sector. Though widely used in project management, there is a dearth of studies that have used EVM for evaluating project performance. Therefore, our study provides a welcome addition to the project management literature with respect to earned value management."
2403,"How Company-Specific Production Systems Affect Plant Performance: The S-Curve Theory","Netland, Torbjorn and Ferdows, Kasra and Sanchez, Ebly","PRODUCTION AND OPERATIONS MANAGEMENT","24","3","362-364","2015","MAR","","","1. Introduction Online and offline retail channels are increasingly intertwined. Traditional players are ramping up their Internet presence and online-first retailers are opening stores and showrooms,1 and developing offline partnerships. This intermingling reflects the fact that while online retailing is by far the fastest growing retail sector in the United States (according to Forrester Research the market will grow from $231b in 2013 to $370b in 2017 on CAGR of 10%),2 offline retailing still anchors the sector. Retailers of all types and in all locations, therefore, increasingly interact with consumers through multiple touch points (Brynjolfsson et al. 2013, P. 23). In the global consumer economy omni-channel retailers and buying experiences are now the norm. Hence, for retailers, understanding how omnichannel works is imperative and our research makes a contribution in this regard. First, we recognize that typical offline and online channels differ markedly in their ability to deliver information and product fulfillment, the two most critical channel functions (see, e.g., Coughlan et al. 2006, Pp. 910). An omni-channel retailer must respond to, and cater to, consumer heterogeneity in preferences for whether information is delivered in-store or online, or whether product is available in-store, or shipped. With regard to information in particular, some customers prefer the ease of shopping that comes from an online experience, whereas others prefer to physically sample products before buying them. Second, traditional online and offline channels also have very different cost structures depending on how orders are fulfilled. Online channels benefit from inventory pooling and lower inventory costs. On the other hand, decentralized offline channels, for example, traditional brick and mortar stores, have to forecast demand for each product and store. This is much harder to do on a per store basis than it is under the pooling that happens with an online channel. As a result, offline fulfillment usually experiences higher demand-supply mismatches and additional inventory costs. Third, and conversely, academics (e.g., Lal and Sarvary 1999) have long realized that when it comes to delivering visceral product information, that is, information about so-called non-digital attributes, offline channels have a definite edge. Practitioners and analysts have made the same observation. Leading industry commentator GigaOm.com, for example, had this to say about Warby Parker, the fashion eyewear retailer and research partner for our study: That (home try-on) has helped Warby Parker overcome one of the biggest hurdles (italics added) for online fashion brands, getting people to feel comfortable about their online purchase.3 Numerous other online-first retailers from Ayr.com to Zappos.com recognize that uncertainty about non-digital product attributes is a barrier to purchase for large segments of customers, and therefore employ free two-way shipping, pop-up stores, and related methods to combat it. The specific domain of our research is a new and increasingly common retail innovation favored by leading online-first retailers, the showroom.4 As noted above, these are offline locations where customers can physically examine products before placing an order, but orders are placed on a tablet or Internet-connected device in the store, fulfillment is done via shipping, that is, showrooms do not have products available for immediate in-store purchase. Thus, showrooms simply allow customers to obtain information prior to purchase by physically sampling products. This hybrid experience delivers information offline in a showroom yet maintains the inventory fulfillment efficiency of the online channel. Note that in markets where they are opened, the introduction of a showroom channel represents a shock in the amount and quality of product information that is available to the customers, holding fulfillment options constant. We study the market impact of this shock on several factors, including on overall demand, Web sales, and various elements of operational efficiency, for example, product returns. 2. Methodology To conduct this research on the impact of information provision on market behaviors, we partnered with Warby Parker, a leading US online-first retailer of fashion eyewear. Since opening for business in February 2010, Warby Parker progressively introduced showrooms in different locations throughout the United States. Management provided us with detailed data on customer behavior and we augmented these data with a rich set of data on ZIP-level geographic factors obtained from the US Census and www.esri. org. The institutional setting has important features that allow us to properly isolate the effect of informational differences on customer channel migration. First, eyewear is a category with significant non-digital or fit and feel attributes such that direct online purchasing is difficult for some customers.5 Second, Warby Parker began as an online-only retailer that also offered consumers a unique product sampling program nationwide called Home Try On (HTO) in which consumers could have five pairs of glasses (frames only and without lenses) delivered to them free of charge for 5 days. Thus, we are able to identify changes in customer behavior when offline showrooms are first introduced into locations where there was already online and sampling coverage. Third, and crucially for our study, the offline locations opened (and closed) by Warby Parker throughout the United States are inventory only showrooms. These showrooms are existing offline stores operated by other independent brands selling apparel and accessories. Customers entering these showrooms can physically inspect the entire Warby Parker product line and make a purchase in-store via the website, but cannot take their purchases with them. Fulfillment, conditional on a purchase, that is, shipment to the location of the customers choosing, is identical irrespective of how product information is obtained. That is, whether the purchase is made directly at the website, at the website subsequent to an HTO experience, or at the website subsequent to product inspection in a showroom, fulfillment is always via delivery. The fact that Warby Parker opened and closed showrooms in different markets throughout the United States during the period of analysis allows us to use quasi-experimental methods to assess the effect of these showrooms in the observed market outcomes. We use a combination of a difference-in-differences strategy with a propensity score method adjustment. In principle, since only customers near a showroom, that is, those within its trading area, can be influenced by the presence of the showroom, we can compare the difference in sales, returns, and other factors between ZIP codes within/beyond the area of influence of the showroom, before and after the opening of the showroom. Now, because management does not open showrooms randomly we also need to control for the endogenous nature of the treatment, that is, the opening of a showroom. We do this using a propensity score adjustment (based on fifty different ZIP code level factors) so that we compare treatment and control locations are made essentially identical in their observable characteristics, except for the presence of a showroom. 3. Results We make two new substantive contributions to the omni-channel literature. First, we show that locations contained within the trading area of a showroom: (1) see an increase in overall demand, and (2) show evidence of spillovers from one channel to another. These estimated effects are statistically and economically significant, and the overall positive demand impact alone is approximately 10%. Interestingly, the positive demand impact is not solely attributable to sales through the (new) offline channel, that is, the showroom itself. In these locations direct sales through the WarbyParker.com website increase by up to 7.0% as well. A physical offline presence seems to confer awareness, branding, and credibility benefits that deliver incremental sales through the existing online channel. Note that these benefits accrue from the provision of information alone, as fulfillment is identical in all three channels (Web, sampling, showroom). Next, we find that sales through the sampling channel decline and our second contribution is to demonstrate that the underlying mechanism is channel migration by customers. We conceptualize a shopping process in which there is a match between the information delivered by each channel (Web, sampling, showroom) and the information required by customers who vary in their tolerance for uncertainty. We predict that customers who have the least uncertainty tolerance are more likely to migrate to the offline channel when it is available. As a consequence, the pool of customers remaining in the sampling and online channels are, on average, better matched to those channels. This leads to higher conversion from sampling, lower rates of repeated sampling, and fewer returns from sales made in the online channel. Our empirical results are consistent with the conceptualization and predictions. Thus, our study, to the best of our knowledge, is the first to identify and measure the critical impact of informational differences across on customer migration and operational costs in an omni-channel setting. We also demonstrate that the positive economic impact of showrooms can be substantial. In summary, when an online-first retailer opens showrooms, these channels are much more than a mechanism for just expanding awareness and total demand. They allow customers to sort into their preferred channel on the basis of their information needs and, as a consequence firms can greatly reduce the operational cost-to-serve customers through the other channels."
